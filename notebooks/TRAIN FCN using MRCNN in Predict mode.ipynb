{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train modified model on old shapes dataset\n",
    "\n",
    "### the modified model does not include any mask related heads or losses \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:56:55.572961Z",
     "start_time": "2018-07-09T14:56:52.925038Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "##-------------------------------------------------------------------------------------------\n",
    "##\n",
    "## Alternate training of FCN\n",
    "##  - start with trained MRCNN model, pass predcitions over to FCN\n",
    "##\n",
    "##-------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "import platform\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mod2  as mrcnn_modellib\n",
    "import mrcnn.model_fcn  as fcn_modellib\n",
    "\n",
    "import mrcnn.visualize  as visualize\n",
    "import mrcnn.new_shapes     as shapes\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.utils        import log, stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen      import data_generator, load_image_gt\n",
    "from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.visualize    import plot_gaussian\n",
    "# from mrcnn.prep_notebook import prep_oldshapes_train, load_model\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "syst = platform.system()\n",
    " \n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## process input arguments\n",
    "##  example:\n",
    "##           train-shapes_gpu --epochs 12 --steps-in-epoch 7 --last_epoch 1234 --logs_dir mrcnn_logs\n",
    "##------------------------------------------------------------------------------------\n",
    "# Parse command line arguments\n",
    "parser = argparse.ArgumentParser(description='Train Mask R-CNN on MS COCO.')\n",
    "# parser.add_argument(\"command\",\n",
    "                    # metavar=\"<command>\",\n",
    "                    # help=\"'train' or 'evaluate' on MS COCO\")\n",
    "# parser.add_argument('--dataset', required=True,\n",
    "                    # metavar=\"/path/to/coco/\",\n",
    "                    # help='Directory of the MS-COCO dataset')\n",
    "# parser.add_argument('--limit', required=False,\n",
    "                    # default=500,\n",
    "                    # metavar=\"<image count>\",\n",
    "                    # help='Images to use for evaluation (defaults=500)')\n",
    "                    \n",
    "parser.add_argument('--model', required=False,\n",
    "                    default='last',\n",
    "                    metavar=\"/path/to/weights.h5\",\n",
    "                    help=\"MRCNN model weights file: 'coco' , 'init' , or Path to weights .h5 file \")\n",
    "\n",
    "parser.add_argument('--fcn_model', required=False,\n",
    "                    default='last',\n",
    "                    metavar=\"/path/to/weights.h5\",\n",
    "                    help=\"FCN model weights file: 'init' , or Path to weights .h5 file \")\n",
    "\n",
    "parser.add_argument('--logs_dir', required=True,\n",
    "                    default='mrcnn_logs',\n",
    "                    metavar=\"/path/to/logs/\",\n",
    "                    help='Logs and checkpoints directory (default=logs/)')\n",
    "                    \n",
    "parser.add_argument('--last_epoch', required=False,\n",
    "                    default=0,\n",
    "                    metavar=\"<last epoch ran>\",\n",
    "                    help='Identify last completed epcoh for tensorboard continuation')\n",
    "\n",
    "parser.add_argument('--lr', required=False,\n",
    "                    default=0.001,\n",
    "                    metavar=\"<learning rate>\",\n",
    "                    help='Learning Rate (default=0.001)')\n",
    "\n",
    "parser.add_argument('--epochs', required=False,\n",
    "                    default=3,\n",
    "                    metavar=\"<epochs to run>\",\n",
    "                    help='Number of epochs to run (default=3)')\n",
    "                    \n",
    "parser.add_argument('--steps_in_epoch', required=False,\n",
    "                    default=1,\n",
    "                    metavar=\"<steps in each epoch>\",\n",
    "                    help='Number of batches to run in each epochs (default=5)')\n",
    "                    \n",
    "parser.add_argument('--batch_size', required=False,\n",
    "                    default=5,\n",
    "                    metavar=\"<batch size>\",\n",
    "                    help='Number of data samples in each batch (default=5)')                    \n",
    "                    \n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 0  --batch_size 8 --lr 0.01 --logs_dir train_fcn_alt --model /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:57:20.933603Z",
     "start_time": "2018-07-09T14:57:00.446940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size='8', epochs='100', fcn_model='init', last_epoch='0', logs_dir='train_fcn_alt', lr='0.01', model='/home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5', steps_in_epoch='128')\n",
      "\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      "Model              :    /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      "Epochs to run      :    100\n",
      "Steps in each epoch:    128\n",
      "OS Platform        :    Linux\n",
      "dataset gen complete\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(args)\n",
    "print()\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "print(\"Model              :   \", args.model)\n",
    "# print(\"Dataset: \", args.dataset)\n",
    "# print(\"Logs:    \", args.logs)\n",
    "# print(\"Limit:   \", args.limit)\n",
    "print(\"Epochs to run      :   \", args.epochs)\n",
    "print(\"Steps in each epoch:   \", args.steps_in_epoch)\n",
    "print('OS Platform        :   ', syst)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "#---------------------------------------------------------------------------------\n",
    "# # Root directory of the project \n",
    "# MODEL_DIR    :    Directory to save logs and trained model\n",
    "# COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "#---------------------------------------------------------------------------------\n",
    "if syst == 'Windows':\n",
    "    # WINDOWS MACHINE ------------------------------------------------------------------\n",
    "    ROOT_DIR          = \"E:\\\\\"\n",
    "    MODEL_PATH        = os.path.join(ROOT_DIR    , \"models\")\n",
    "    DATASET_PATH      = os.path.join(ROOT_DIR    , 'MLDatasets')\n",
    "    MODEL_DIR         = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    COCO_MODEL_PATH   = os.path.join(MODEL_PATH  , \"mask_rcnn_coco.h5\")\n",
    "    DEFAULT_LOGS_DIR  = os.path.join(MODEL_PATH  , args.logs_dir) \n",
    "    COCO_DATASET_PATH = os.path.join(DATASET_PATH, \"coco2014\")\n",
    "    RESNET_MODEL_PATH = os.path.join(MODEL_PATH  , \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "    VGG16_MODEL_PATH  = os.path.join(MODEL_PATH  , \"fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "    \n",
    "elif syst == 'Linux':\n",
    "    # LINUX MACHINE ------------------------------------------------------------------\n",
    "    ROOT_DIR          = os.getcwd()\n",
    "    MODEL_PATH        = os.path.expanduser('~/models')\n",
    "    DATASET_PATH      = os.path.expanduser('~/MLDatasets')\n",
    "    MODEL_DIR         = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    COCO_MODEL_PATH   = os.path.join(MODEL_PATH  , \"mask_rcnn_coco.h5\")\n",
    "    COCO_DATASET_PATH = os.path.join(DATASET_PATH, \"coco2014\")\n",
    "    DEFAULT_LOGS_DIR  = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    RESNET_MODEL_PATH = os.path.join(MODEL_PATH  , \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "    VGG16_MODEL_PATH  = os.path.join(MODEL_PATH  , \"fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "else :\n",
    "    raise Error('unreconized system  '      )\n",
    "\n",
    "\n",
    "    \n",
    "# class InferenceConfig(CocoConfig):\n",
    "    # # Set batch size to 1 since we'll be running inference on\n",
    "    # # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    # GPU_COUNT = 1\n",
    "    # IMAGES_PER_GPU = 1\n",
    "    # DETECTION_MIN_CONFIDENCE = 0\n",
    "# config = InferenceConfig()\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------\n",
    "mrcnn_config                    = shapes.NewShapesConfig()\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "                          \n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "mrcnn_config.VALIDATION_STEPS   = 100\n",
    "mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "mrcnn_config.MIN_LR             = 1.0e-10\n",
    "# mrcnn_config.display() \n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build shape dataset        \n",
    "##------------------------------------------------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.NewShapesDataset(mrcnn_config)\n",
    "dataset_train.load_shapes(10000)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.NewShapesDataset(mrcnn_config)\n",
    "dataset_val.load_shapes(2500)\n",
    "dataset_val.prepare()\n",
    "\n",
    "print('dataset gen complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:57:39.158999Z",
     "start_time": "2018-07-09T14:57:32.401144Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize MRCNN model, mode:  trainfcn\n",
      "    set_log_dir(): Checkpoint path/filename set to          : /home/kbardool/models/train_fcn_alt/shapes20180709T1457/mask_rcnn_shapes_{epoch:04d}.h5 \n",
      "    set_log_dir(): Last completed epoch (self.epoch) set to : 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     C1 Shape: (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "     C2 Shape:  (?, 32, 32, 256) (?, 32, 32, 256)\n",
      "     C3 Shape:  (?, 16, 16, 512) (?, 16, 16, 512)\n",
      "     C4 Shape:  (?, 8, 8, 1024) (?, 8, 8, 1024)\n",
      "     C5 Shape:  (?, 4, 4, 2048) (?, 4, 4, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  1000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (8, 4092)\n",
      "     Deltas :  (8, 4092, 4)\n",
      "     Anchors:  (8, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (8, ?, ?) (8, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (8, ?, ?) (8, ?, ?) (None, 1000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (8, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (8, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (8, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (8, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (8, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 7)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 7)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 28)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 7, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 7) (None, 32, 7)\n",
      "     mrcnn_bbox.shape     : (?, 32, 7, 4) (None, 32, 7, 4)\n",
      "     output_rois.shape    : (8, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (8, ?) (None, 32)\n",
      "     gt_bboxes.shape      : (8, ?, ?) (None, 32, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 7)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 7, 4) (?, 32, 7, 4)\n",
      "    input_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (8, None, 4)\n",
      "    pred_array        (8, 32, 6)\n",
      "scatter_ind <class 'tensorflow.python.framework.ops.Tensor'> shape (8, 32, 3)\n",
      "    pred_scatter shape is  (8, 7, 32, 6)\n",
      "(8, 7, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "\n",
      "    num_rois           :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape :  (8, ?)\n",
      "    gt_bboxes.shape    :  (8, ?, 4)\n",
      "    gt_classes_exp shape  (8, ?, 1)\n",
      "    gt_scores_exp shape  (8, ?, 1)\n",
      "    gt_array shape : (8, 32, 7) (8, 32, 7)\n",
      "     gt_tensor final shape  :  (8, 7, 32, ?)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (8, 7, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (8, 7, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (8, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (8, 7, 128, 128) Keras tensor  False\n",
      "WARNING:tensorflow:From /home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "    gauss L2 norm   :  (8, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (8, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (8, 7, 32, 6)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (8, 7, 128, 128)\n",
      "    heatmap replicated      :  (8, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (1792, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (1792, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (8, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (8, 7, 32, ?)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (8, 7, 32)\n",
      "    dense shape  (?, ?)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (8, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (8, 7, 128, 128) Keras tensor  False\n",
      "    gauss L2 norm   :  (8, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (8, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (8, 7, 32, ?)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (8, 7, 128, 128)\n",
      "    heatmap replicated      :  (8, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (1792, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (1792, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (8, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (8, 7) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (8, 7) Keras tensor  True\n",
      "     pred_heatmap_norm  :  (8, 128, 128, 7) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (8, 128, 128, 7) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (8, 128, 128, 7)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (8, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      " Keras Tensors?? \n",
      " target_class_ids  : True (None, 32)\n",
      " output_rois : True\n",
      " pr_hm       : True\n",
      " gt_heatmap  : True\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      "[]\n",
      " ================================================================\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      " COCO Model Path       :  /home/kbardool/models/mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  /home/kbardool/models/train_fcn_alt\n",
      " Model Parent Path     :  /home/kbardool/models\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build Mask RCNN Model in TRAINFCN mode\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "try :\n",
    "    del mrcnn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "mrcnn_model = mrcnn_modellib.MaskRCNN(mode=\"trainfcn\", config=mrcnn_config, model_dir=MODEL_DIR)\n",
    "\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "# print(model.find_last())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:57:55.015585Z",
     "start_time": "2018-07-09T14:57:48.211694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load model with init parm:  /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      " Exclude layers: \n",
      "None\n",
      "-----------------------------------------------\n",
      "Loading weights from  /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      "\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      "   ----------------\n",
      "    layers to load \n",
      "   ----------------\n",
      "    >layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x7f2dbe6a2be0>\n",
      "    >layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x7f2dbe653ef0>\n",
      "    >layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x7f2dbe658978>\n",
      "    >layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbe658d30>\n",
      "    >layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x7f2dbd109cc0>\n",
      "    >layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2dbd131e80>\n",
      "    >layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbd11ec50>\n",
      "    >layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbd0c39e8>\n",
      "    >layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x7f2dbd0dd278>\n",
      "    >layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbd0f0dd8>\n",
      "    >layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbd0f04a8>\n",
      "    >layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x7f2dbd094e10>\n",
      "    >layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbd045908>\n",
      "    >layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x7f2dbd068a58>\n",
      "    >layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbd045b38>\n",
      "    >layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbd002e10>\n",
      "    >layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x7f2dbd0289e8>\n",
      "    >layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x7f2dbcfd35c0>\n",
      "    >layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcfd35f8>\n",
      "    >layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcf8fef0>\n",
      "    >layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x7f2dbcf7ae48>\n",
      "    >layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcf9fe48>\n",
      "    >layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcf9f748>\n",
      "    >layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x7f2dbcf3d4a8>\n",
      "    >layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcf679e8>\n",
      "    >layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcf670b8>\n",
      "    >layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x7f2dbcf07b38>\n",
      "    >layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x7f2dbcf20978>\n",
      "    >layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcf20ef0>\n",
      "    >layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcec8c88>\n",
      "    >layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x7f2dbcedb0b8>\n",
      "    >layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbce896d8>\n",
      "    >layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbce76828>\n",
      "    >layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x7f2dbce99b00>\n",
      "    >layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbce49f98>\n",
      "    >layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbce499b0>\n",
      "    >layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x7f2dbce6fc50>\n",
      "    >layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x7f2dbce1b5f8>\n",
      "    >layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbce1b400>\n",
      "    >layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcdd6c50>\n",
      "    >layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x7f2dbcdbe4e0>\n",
      "    >layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcd7ce48>\n",
      "    >layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcdec828>\n",
      "    >layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x7f2dbcd8eda0>\n",
      "    >layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcda5fd0>\n",
      "    >layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcd629b0>\n",
      "    >layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcd3fa90>\n",
      "    >layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbccfed68>\n",
      "    >layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x7f2dbcd24630>\n",
      "    >layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x7f2dbccd0550>\n",
      "    >layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbccd0588>\n",
      "    >layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcc8cda0>\n",
      "    >layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x7f2dbcc75b38>\n",
      "    >layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcca4cf8>\n",
      "    >layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcca45f8>\n",
      "    >layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x7f2dbcc46e10>\n",
      "    >layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcbf6940>\n",
      "    >layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcbf6208>\n",
      "    >layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x7f2dbcc19b00>\n",
      "    >layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x7f2dbcc33908>\n",
      "    >layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcc33e80>\n",
      "    >layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcbd9ac8>\n",
      "    >layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x7f2dbcbee0f0>\n",
      "    >layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcb99438>\n",
      "    >layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcb877b8>\n",
      "    >layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x7f2dbcbaeac8>\n",
      "    >layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcb58f60>\n",
      "    >layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcb58978>\n",
      "    >layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x7f2dbcb00cc0>\n",
      "    >layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x7f2dbcb2e320>\n",
      "    >layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbcb2e358>\n",
      "    >layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbcae7ba8>\n",
      "    >layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x7f2dbcad1438>\n",
      "    >layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbca90c50>\n",
      "    >layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbca80208>\n",
      "    >layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x7f2dbcaa2c18>\n",
      "    >layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbca38e80>\n",
      "    >layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbca51978>\n",
      "    >layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x7f2dbc9f6908>\n",
      "    >layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x7f2dbca0fc88>\n",
      "    >layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbca0fa90>\n",
      "    >layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc9b6f60>\n",
      "    >layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x7f2dbc9ca0b8>\n",
      "    >layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc9e39e8>\n",
      "    >layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc9e3b70>\n",
      "    >layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x7f2dbc987a58>\n",
      "    >layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc935eb8>\n",
      "    >layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc959eb8>\n",
      "    >layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc9357b8>\n",
      "    >layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc9081d0>\n",
      "    >layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x7f2dbc92b0b8>\n",
      "    >layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc8c1c88>\n",
      "    >layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc8c1b70>\n",
      "    >layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc8ec7f0>\n",
      "    >layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x7f2dbc87f278>\n",
      "    >layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc89af98>\n",
      "    >layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc89ac88>\n",
      "    >layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x7f2dbc841668>\n",
      "    >layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc86cf60>\n",
      "    >layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc86c8d0>\n",
      "    >layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x7f2dbc812c50>\n",
      "    >layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc7be2e8>\n",
      "    >layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc7be320>\n",
      "    >layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc7cff60>\n",
      "    >layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x7f2dbc7e33c8>\n",
      "    >layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc7a2e10>\n",
      "    >layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc791198>\n",
      "    >layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x7f2dbc734be0>\n",
      "    >layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc74bd30>\n",
      "    >layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc760940>\n",
      "    >layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x7f2dbc772d30>\n",
      "    >layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc723ba8>\n",
      "    >layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc7239b0>\n",
      "    >layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc6c9dd8>\n",
      "    >layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x7f2dbc6db080>\n",
      "    >layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc676908>\n",
      "    >layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc676a90>\n",
      "    >layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x7f2dbc69acf8>\n",
      "    >layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc647dd8>\n",
      "    >layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc6476d8>\n",
      "    >layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x7f2dbc66b0b8>\n",
      "    >layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc61b0f0>\n",
      "    >layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc61b128>\n",
      "    >layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc629d68>\n",
      "    >layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x7f2dbc5d5fd0>\n",
      "    >layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc5ec470>\n",
      "    >layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc57bf98>\n",
      "    >layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x7f2dbc5919e8>\n",
      "    >layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc53e3c8>\n",
      "    >layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc5ab828>\n",
      "    >layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x7f2dbc54ffd0>\n",
      "    >layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc4fd9e8>\n",
      "    >layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc4fd7f0>\n",
      "    >layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc522c88>\n",
      "    >layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x7f2dbc4b4080>\n",
      "    >layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc4d0eb8>\n",
      "    >layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc4d0898>\n",
      "    >layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x7f2dbc475c88>\n",
      "    >layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc4b2f60>\n",
      "    >layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc4a1320>\n",
      "    >layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x7f2dbc446d68>\n",
      "    >layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc3f4a90>\n",
      "    >layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc3f4438>\n",
      "    >layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc407eb8>\n",
      "    >layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x7f2dbc433e48>\n",
      "    >layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc3c5048>\n",
      "    >layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc3c5b00>\n",
      "    >layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x7f2dbc3d6e10>\n",
      "    >layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc385f28>\n",
      "    >layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc3abfd0>\n",
      "    >layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc385c18>\n",
      "    >layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc359668>\n",
      "    >layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x7f2dbc2fd470>\n",
      "    >layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc32e160>\n",
      "    >layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc32e048>\n",
      "    >layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc2bdcf8>\n",
      "    >layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x7f2dbc2d04e0>\n",
      "    >layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc2e9fd0>\n",
      "    >layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc27fa90>\n",
      "    >layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x7f2dbc2a29b0>\n",
      "    >layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc2516a0>\n",
      "    >layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc23e7f0>\n",
      "    >layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x7f2dbc263ac8>\n",
      "    >layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc210978>\n",
      "    >layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc210780>\n",
      "    >layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc1b7c18>\n",
      "    >layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x7f2dbc1cb080>\n",
      "    >layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc1e4e48>\n",
      "    >layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc1e4828>\n",
      "    >layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x7f2dbc189be0>\n",
      "    >layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc146ef0>\n",
      "    >layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x7f2dbc1362b0>\n",
      "    >layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x7f2dbc158cf8>\n",
      "    >layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x7f2dbc1089e8>\n",
      "    >layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc108390>\n",
      "    >layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x7f2dbc12e400>\n",
      "    >layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc0c8710>\n",
      "    >layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x7f2dbc11acc0>\n",
      "    >layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x7f2dbc0ebac8>\n",
      "    >layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc0ebdd8>\n",
      "    >layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x7f2dbc0c8e80>\n",
      "    >layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x7f2dbc0a5898>\n",
      "    >layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc0a5160>\n",
      "    >layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x7f2dbc081d68>\n",
      "    >layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc009940>\n",
      "    >layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc0a5e10>\n",
      "    >layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc04eac8>\n",
      "    >layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x7f2dbc062c18>\n",
      "    >layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x7f2dbc02c630>\n",
      "    >layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x7f2dbbf03400>\n",
      "    >layer 190 : name : rpn_class                                 type: <keras.layers.core.Lambda object at 0x7f2dbbf6ee48>\n",
      "    >layer 191 : name : rpn_bbox                                  type: <keras.layers.core.Lambda object at 0x7f2dbbd23cf8>\n",
      "    >layer 192 : name : input_gt_boxes                            type: <keras.engine.topology.InputLayer object at 0x7f2dbe69cb70>\n",
      "    >layer 193 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x7f2dbbf6efd0>\n",
      "    >layer 194 : name : input_gt_class_ids                        type: <keras.engine.topology.InputLayer object at 0x7f2dbe6a2a58>\n",
      "    >layer 195 : name : lambda_1                                  type: <keras.layers.core.Lambda object at 0x7f2dbe69cc50>\n",
      "    >layer 196 : name : proposal_targets                          type: <mrcnn.detect_tgt_layer_mod.DetectionTargetLayer_mod object at 0x7f2dbb185780>\n",
      "    >layer 197 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x7f2db98d8dd8>\n",
      "    >layer 198 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db98adef0>\n",
      "    >layer 199 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db9832710>\n",
      "    >layer 200 : name : activation_34                             type: <keras.layers.core.Activation object at 0x7f2db97caf28>\n",
      "    >layer 201 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db97caf60>\n",
      "    >layer 202 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db97edef0>\n",
      "    >layer 203 : name : activation_35                             type: <keras.layers.core.Activation object at 0x7f2db97aeeb8>\n",
      "    >layer 204 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x7f2db97ae828>\n",
      "    >layer 205 : name : time_distributed_1                        type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db97012b0>\n",
      "    >layer 206 : name : mrcnn_class_logits                        type: <keras.layers.core.Lambda object at 0x7f2db9701160>\n",
      "    >layer 207 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db9721cf8>\n",
      "    >layer 208 : name : time_distributed_2                        type: <keras.layers.wrappers.TimeDistributed object at 0x7f2db9701c88>\n",
      "    >layer 209 : name : reshape_1                                 type: <keras.layers.core.Reshape object at 0x7f2db9721ba8>\n",
      "    >layer 210 : name : mrcnn_class                               type: <keras.layers.core.Lambda object at 0x7f2db9701e48>\n",
      "    >layer 211 : name : mrcnn_bbox_regression                     type: <keras.layers.core.Lambda object at 0x7f2db96ba0b8>\n",
      "    >layer 212 : name : rpn_class_logits                          type: <keras.layers.core.Lambda object at 0x7f2dbbf6ef28>\n",
      "    >layer 213 : name : cntxt_layer                               type: <mrcnn.chm_layer.CHMLayer object at 0x7f2db96ba7b8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    load_weights: Log directory set to : /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      "    set_log_dir(): Checkpoint path/filename set to          : /home/kbardool/models/train_fcn_alt/shapes20180621T1554/mask_rcnn_shapes_{epoch:04d}.h5 \n",
      "    set_log_dir(): Last completed epoch (self.epoch) set to : 1120 \n",
      "    Load weights complete :  /home/kbardool/models/newshape_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5\n",
      "==========================================\n",
      " MRCNN MODEL Load weight file COMPLETE    \n",
      "==========================================\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  100\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                128\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " layer:  0    output : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " layer:  1    output : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " layer:  2    output : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " layer:  3    output : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  4    output : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " layer:  5    output : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  6    output : input_gt_masks:0                           Type: bool              Shape: (?, 56, 56, ?)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output : rpn_class_logits/rpn_class_logits:0        Type: float32           Shape: (?, ?, 2)\n",
      " layer:  1    output : rpn_class/rpn_class:0                      Type: float32           Shape: (?, ?, 2)\n",
      " layer:  2    output : rpn_bbox/rpn_bbox:0                        Type: float32           Shape: (?, ?, 4)\n",
      " layer:  3    output : rpn_proposal_rois/rpn_roi_proposals:0      Type: float32           Shape: (8, ?, ?)\n",
      " layer:  4    output : proposal_targets/output_rois:0             Type: float32           Shape: (8, ?, ?)\n",
      " layer:  5    output : proposal_targets/target_class_ids:0        Type: int32             Shape: (8, ?)\n",
      " layer:  6    output : proposal_targets/target_bbox_deltas:0      Type: float32           Shape: (8, ?, ?)\n",
      " layer:  7    output : proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (8, ?, ?)\n",
      " layer:  8    output : mrcnn_class_logits/mrcnn_class_logits:0    Type: float32           Shape: (?, 32, 7)\n",
      " layer:  9    output : mrcnn_class/mrcnn_class:0                  Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output : mrcnn_bbox_regression/mrcnn_bbox:0         Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer: 11    output : cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (8, 128, 128, 7)\n",
      " layer: 12    output : cntxt_layer/gt_heatmap_norm:0              Type: float32           Shape: (8, 128, 128, 7)\n",
      " layer: 13    output : cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer: 14    output : cntxt_layer/gt_heatmap_scores:0            Type: float32           Shape: (?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "## Load Mask RCNN Model Weight file\n",
    "exclude_layers = \\\n",
    "       ['fcn_block1_conv1' \n",
    "       ,'fcn_block1_conv2' \n",
    "       ,'fcn_block1_pool' \n",
    "       ,'fcn_block2_conv1'\n",
    "       ,'fcn_block2_conv2' \n",
    "       ,'fcn_block2_pool'  \n",
    "       ,'fcn_block3_conv1' \n",
    "       ,'fcn_block3_conv2' \n",
    "       ,'fcn_block3_conv3' \n",
    "       ,'fcn_block3_pool'  \n",
    "       ,'fcn_block4_conv1' \n",
    "       ,'fcn_block4_conv2' \n",
    "       ,'fcn_block4_conv3' \n",
    "       ,'fcn_block4_pool'  \n",
    "       ,'fcn_block5_conv1' \n",
    "       ,'fcn_block5_conv2' \n",
    "       ,'fcn_block5_conv3' \n",
    "       ,'fcn_block5_pool'  \n",
    "       ,'fcn_fc1'          \n",
    "       ,'dropout_1'        \n",
    "       ,'fcn_fc2'          \n",
    "       ,'dropout_2'        \n",
    "       ,'fcn_classify'     \n",
    "       ,'fcn_bilinear'     \n",
    "       ,'fcn_heatmap_norm' \n",
    "       ,'fcn_scoring'      \n",
    "       ,'fcn_heatmap'      \n",
    "       ,'fcn_norm_loss']\n",
    "mrcnn_model.load_model_weights( init_with = args.model)   \n",
    "print('==========================================')\n",
    "print(\" MRCNN MODEL Load weight file COMPLETE    \")\n",
    "print('==========================================')\n",
    "\n",
    "mrcnn_config.display()  \n",
    "mrcnn_model.layer_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:57:57.944132Z",
     "start_time": "2018-07-09T14:57:57.886342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  100\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.005\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                128\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration for FCN model\n",
    "##------------------------------------------------------------------------------------\n",
    "fcn_config                    = shapes.NewShapesConfig()\n",
    "fcn_config.BATCH_SIZE         = mrcnn_config.BATCH_SIZE                 # Batch size is 2 (# GPUs * images/GPU).\n",
    "fcn_config.IMAGES_PER_GPU     = mrcnn_config.BATCH_SIZE               # Must match BATCH_SIZE\n",
    "fcn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "\n",
    "# fcn_config.LEARNING_RATE      = float(args.lr)\n",
    "fcn_config.LEARNING_RATE      = 0.005\n",
    "                          \n",
    "fcn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "fcn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "fcn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "fcn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "fcn_config.VALIDATION_STEPS   = 100\n",
    "fcn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN = 30\n",
    "fcn_config.REDUCE_LR_PATIENCE = 40\n",
    "fcn_config.EARLY_STOP_PATIENCE= 80\n",
    "fcn_config.MIN_LR             = 1.0e-10\n",
    "fcn_config.display() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:35:32.756370Z",
     "start_time": "2018-07-09T15:35:31.884028Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize FCN model, mode:  training\n",
      "    set_log_dir(): Checkpoint path/filename set to          : /home/kbardool/models/train_fcn_alt/shapes20180709T1535/fcn_shapes_{epoch:04d}.h5 \n",
      "    set_log_dir(): Last completed epoch (self.epoch) set to : 0 \n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    Adding  FCN layers\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> FCN Layer (without L2 Regularization) \n",
      "     feature map shape is  (?, 128, 128, 7)\n",
      "     height : 128 width : 128 classes : 7\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (?, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (?, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (?, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (?, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (?, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (?, 32, 32, 128)\n",
      "   FCN Block 31 shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 33 shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 16, 16, 256)\n",
      "   FCN Block 41 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 42 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 43 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 51 shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 52 shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 53 shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (?, 4, 4, 512)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (?, 4, 4, 2048)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (?, 4, 4, 2048)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (?, 4, 4, 7)  keras_tensor  True\n",
      "   h_factor :  32.0 w_factor :  32.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (32.0, 32.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (32.0, 32.0)\n",
      "     CHANNELS LAST: X:  (?, 4, 4, 7)  KB.int_shape() :  (None, 4, 4, 7)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (?, ?, ?, 7)\n",
      "     Dimensions of X after set_shape() :  (?, 128, 128, 7)\n",
      "     BilinearUpSampling2D. compute_output_shape()\n",
      "     Bilinear output shape is: None , 128 , 128 , 7\n",
      "   FCN Bilinear upsmapling layer  shape is :  (?, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "     size of reduce max is  (?, 1, 1, 7)\n",
      "     size of y is :  (?, 128, 128, 7)\n",
      "     size of reduce max is  (?, 1, 1, 7)\n",
      "     size of y is :  (?, 128, 128, 7)\n",
      "    fcn_heatmap       :  (?, 128, 128, 7)  Keras tensor  True\n",
      "    fcn_heatmap_norm  :  (?, 128, 128, 7)  Keras tensor  True\n",
      "    fcn_heatmap_L2norm:  (?, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      ">>> End FCN Layer (without L2 Regularization) \n",
      "   fcn_heatmap      :  (None, 128, 128, 7)  Keras tensor  True\n",
      "   fcn_heatmap_norm :  (None, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      ">>> FCN Scoring Layer \n",
      "   > FCNScoreLayer Call()  2\n",
      "     fcn_heatmap.shape    : (?, 128, 128, 7) (None, 128, 128, 7)\n",
      "      chm_scores.shape    : (?, 7, 32, 11) (None, 7, 32, 11)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  <mrcnn.new_shapes.NewShapesConfig object at 0x7f2db8cb2940>\n",
      "    orignal in_heatmap shape :  (?, 128, 128, 7)\n",
      "    num of bboxes per class is :  32\n",
      "    Rois per image  :  32\n",
      "    heatmap original shape   :  (?, 128, 128, 7)\n",
      "    heatmap transposed shape : (?, 7, 128, 128)\n",
      "    heatmap tiled            :  (?, 7, 32, 128, 128)\n",
      "    fcn_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    Output build_fcn_score \n",
      "     pred_heatmap_norm  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_scores shape : (?, 6, 32)\n",
      "    pred_scores   shape : (?, ?, ?)\n",
      "    target_scores1 shape : (?, 1) (None, 1)\n",
      "    pred_scores1  shape : (?, 1)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_scores shape : (?, 6, 32)\n",
      "    pred_scores   shape : (?, 6, 32)\n",
      "    target_scores1 shape : (?, 1) (None, 1)\n",
      "    pred_scores1  shape : (?, 1)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      "[]\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n",
      " COCO Model Path       :  /home/kbardool/models/mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  /home/kbardool/models/train_fcn_alt\n",
      " Model Parent Path     :  /home/kbardool/models\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build FCN Model in Training Mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del fcn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "fcn_model = fcn_modellib.FCN(mode=\"training\", config=fcn_config, model_dir=MODEL_DIR)\n",
    "\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:35:40.333595Z",
     "start_time": "2018-07-09T15:35:40.275867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      " Load second weight file  \n",
      "=====================================\n",
      "-----------------------------------------------\n",
      " Load model with init parm:  /home/kbardool/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      " Exclude layers: \n",
      "None\n",
      "-----------------------------------------------\n",
      "   Loading weights from provided file : /home/kbardool/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      ">>> load_weights() from : /home/kbardool/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "--------------------------------------\n",
      " layers to load (not in exclude list) \n",
      "--------------------------------------\n",
      ">layer 0 : name : input_pr_hm_norm                          type: <keras.engine.topology.InputLayer object at 0x7f2d24bb07b8>\n",
      ">layer 1 : name : fcn_block1_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bb0c18>\n",
      ">layer 2 : name : fcn_block1_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bb09b0>\n",
      ">layer 3 : name : fcn_block1_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2d24bb86d8>\n",
      ">layer 4 : name : fcn_block2_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b55278>\n",
      ">layer 5 : name : fcn_block2_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b4db00>\n",
      ">layer 6 : name : fcn_block2_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2d24b94710>\n",
      ">layer 7 : name : fcn_block3_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b633c8>\n",
      ">layer 8 : name : fcn_block3_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b6b550>\n",
      ">layer 9 : name : fcn_block3_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b46978>\n",
      ">layer 10 : name : fcn_block3_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2d24b408d0>\n",
      ">layer 11 : name : fcn_block4_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b46f60>\n",
      ">layer 12 : name : fcn_block4_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d505c8ef0>\n",
      ">layer 13 : name : fcn_block4_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24117e48>\n",
      ">layer 14 : name : fcn_block4_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2d24b44160>\n",
      ">layer 15 : name : fcn_block5_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24b438d0>\n",
      ">layer 16 : name : fcn_block5_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bb98d0>\n",
      ">layer 17 : name : fcn_block5_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bff668>\n",
      ">layer 18 : name : fcn_block5_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x7f2d24bf1400>\n",
      ">layer 19 : name : fcn_fc1                                   type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bffd68>\n",
      ">layer 20 : name : dropout_3                                 type: <keras.layers.core.Dropout object at 0x7f2d24be6e80>\n",
      ">layer 21 : name : fcn_fc2                                   type: <keras.layers.convolutional.Conv2D object at 0x7f2d24bed630>\n",
      ">layer 22 : name : dropout_4                                 type: <keras.layers.core.Dropout object at 0x7f2d24bd8a58>\n",
      ">layer 23 : name : fcn_classify                              type: <keras.layers.convolutional.Conv2D object at 0x7f2db3f12a90>\n",
      ">layer 24 : name : fcn_bilinear                              type: <mrcnn.BilinearUpSampling.BilinearUpSampling2D object at 0x7f2db3e712e8>\n",
      ">layer 25 : name : fcn_heatmap_norm                          type: <keras.layers.core.Lambda object at 0x7f2d07084d30>\n",
      ">layer 26 : name : input_pr_hm_scores                        type: <keras.engine.topology.InputLayer object at 0x7f2d24bb0438>\n",
      ">layer 27 : name : fcn_scoring                               type: <mrcnn.fcn_scoring_layer.FCNScoringLayer object at 0x7f2d070a5940>\n",
      ">layer 28 : name : input_gt_hm_scores                        type: <keras.engine.topology.InputLayer object at 0x7f2d24bb0198>\n",
      ">layer 29 : name : fcn_heatmap                               type: <keras.layers.core.Lambda object at 0x7f2d07095860>\n",
      ">layer 30 : name : fcn_norm_loss                             type: <keras.layers.core.Lambda object at 0x7f2d070a5d30>\n",
      "\n",
      "\n",
      "\n",
      "    load_weights: Log directory set to : /home/kbardool/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "    set_log_dir(): Checkpoint path/filename set to          : /home/kbardool/models/train_fcn_alt/shapes20180709T1535/fcn_shapes_{epoch:04d}.h5 \n",
      "    set_log_dir(): Last completed epoch (self.epoch) set to : 0 \n",
      "    Load weights complete :  /home/kbardool/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "=====================================\n",
      " Load second weight file COMPLETE    \n",
      "=====================================\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  100\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.005\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                128\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " layer:  0    output : input_pr_hm_norm_1:0                       Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  1    output : input_pr_hm_scores_1:0                     Type: float32           Shape: (?, 7, 32, 11)\n",
      " layer:  2    output : input_gt_hm_norm_1:0                       Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  3    output : input_gt_hm_scores_1:0                     Type: float32           Shape: (?, 7, 32, 11)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output : fcn_heatmap_norm_1/fcn_heatmap_norm:0      Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  1    output : fcn_scoring_1/fcn_heatmap_scores:0         Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer:  2    output : fcn_heatmap_1/fcn_heatmap:0                Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  3    output : fcn_norm_loss_1/fcn_norm_loss:0            Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print('=====================================')\n",
    "print(\" Load second weight file  \")\n",
    "print('=====================================')\n",
    "fcn_model.load_model_weights(init_with = VGG16_MODEL_PATH)\n",
    "\n",
    "print('=====================================')\n",
    "print(\" Load second weight file COMPLETE    \")\n",
    "print('=====================================')\n",
    "fcn_config.display()  \n",
    "fcn_model.layer_info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:51:10.865652Z",
     "start_time": "2018-07-09T15:50:00.360680Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fcn']\n",
      "['(fcn\\\\_.*)']\n",
      "layers regex : (fcn\\_.*)\n",
      "   1  fcn_block1_conv1       (Conv2D              )   TRAIN \n",
      "   2  fcn_block1_conv2       (Conv2D              )   TRAIN \n",
      "   4  fcn_block2_conv1       (Conv2D              )   TRAIN \n",
      "   5  fcn_block2_conv2       (Conv2D              )   TRAIN \n",
      "   7  fcn_block3_conv1       (Conv2D              )   TRAIN \n",
      "   8  fcn_block3_conv2       (Conv2D              )   TRAIN \n",
      "   9  fcn_block3_conv3       (Conv2D              )   TRAIN \n",
      "  11  fcn_block4_conv1       (Conv2D              )   TRAIN \n",
      "  12  fcn_block4_conv2       (Conv2D              )   TRAIN \n",
      "  13  fcn_block4_conv3       (Conv2D              )   TRAIN \n",
      "  15  fcn_block5_conv1       (Conv2D              )   TRAIN \n",
      "  16  fcn_block5_conv2       (Conv2D              )   TRAIN \n",
      "  17  fcn_block5_conv3       (Conv2D              )   TRAIN \n",
      "  19  fcn_fc1                (Conv2D              )   TRAIN \n",
      "  21  fcn_fc2                (Conv2D              )   TRAIN \n",
      "  23  fcn_classify           (Conv2D              )   TRAIN \n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['fcn_norm_loss']\n",
      "    learning rate :  0.005\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "Initial self.keras_model.losses :\n",
      "---------------------------------\n",
      "    losses:  ['fcn_norm_loss']\n",
      "    keras_model.losses :\n",
      "[]\n",
      "Added losses:  ['fcn_norm_loss']\n",
      "------------- \n",
      "    Loss: fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add add loss for  Tensor(\"fcn_norm_loss_1/fcn_norm_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      "------------------------------------------------------------------ \n",
      "[<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "[<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "{None: [<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]}\n",
      "\n",
      "Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      "---------------------------------------------------------------------------------- \n",
      "[<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "----- Compile -----------------------------------------------------------\n",
      " Length of Keras_Model.outputs: 4\n",
      "\n",
      "    ***  Tensor(\"Mean_22:0\", shape=(1, 1), dtype=float32) to total_loss  Mean_22:0\n",
      "====> training(629): Loss is a list , length is : 4\n",
      "   ====> losses.get(l) : None\n",
      "   ====> losses.get(l) : None\n",
      "   ====> losses.get(l) : None\n",
      "   ====> losses.get(l) : None\n",
      " ====> training(822) : Prepare metrics\n",
      " metrics: None\n",
      " weighted_metrics : None\n",
      "====> Model.compile (821) Compute total loss:\n",
      "   ====> i:  0  targets:  None  outputs:  Tensor(\"fcn_heatmap_norm_1/fcn_heatmap_norm:0\", shape=(?, 128, 128, 7), dtype=float32)  weighted loss:  None\n",
      "       In skip_trget_indicies ... will be skipped\n",
      "   ====> i:  1  targets:  None  outputs:  Tensor(\"fcn_scoring_1/fcn_heatmap_scores:0\", shape=(?, ?, ?, ?), dtype=float32)  weighted loss:  None\n",
      "       In skip_trget_indicies ... will be skipped\n",
      "   ====> i:  2  targets:  None  outputs:  Tensor(\"fcn_heatmap_1/fcn_heatmap:0\", shape=(?, 128, 128, 7), dtype=float32)  weighted loss:  None\n",
      "       In skip_trget_indicies ... will be skipped\n",
      "   ====> i:  3  targets:  None  outputs:  Tensor(\"fcn_norm_loss_1/fcn_norm_loss:0\", shape=(1, 1), dtype=float32)  weighted loss:  None\n",
      "       In skip_trget_indicies ... will be skipped\n",
      "    Add  Tensor(\"Mean_22:0\", shape=(1, 1), dtype=float32) to total_loss  Mean_22:0\n",
      "====> Compute metrics (line 882):\n",
      "################ self.total_loss ############\n",
      "<tf.Tensor 'loss_11/add:0' shape=(1, 1) dtype=float32>\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add metric  fcn_norm_loss  with metric tensor:  fcn_norm_loss_1/fcn_norm_loss:0  to list of metrics ...\n",
      "\n",
      "Final Keras metric_names :\n",
      "--------------------------\n",
      "['loss', 'fcn_norm_loss']\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      "------------------------------------------------------------------ \n",
      "[<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "[<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "{None: [<tf.Tensor 'Mean_22:0' shape=(1, 1) dtype=float32>]}\n",
      "Checkpoint folder already exists: /home/kbardool/models/train_fcn_alt/shapes20180709T1535\n",
      "\n",
      " out_labels from get_deduped_metrics_names() : \n",
      " --------------------------------------------- \n",
      "['loss', 'fcn_norm_loss']\n",
      "\n",
      " Callback metrics monitored by progbar :\n",
      " ---------------------------------------\n",
      "['loss', 'fcn_norm_loss', 'val_loss', 'val_fcn_norm_loss']\n",
      "Starting at epoch 0 of 100 epochs. LR=0.005\n",
      "\n",
      "Steps per epochs 128 \n",
      "    Last epoch completed : 0 \n",
      "    Starting from epoch  : 0 for 100 epochs\n",
      "    Learning Rate        : 0.005 \n",
      "    Steps per epoch      : 128 \n",
      "    Batch Size           : 8 \n",
      "    Checkpoint Folder    : /home/kbardool/models/train_fcn_alt/shapes20180709T1535/fcn_shapes_{epoch:04d}.h5 \n",
      "Epoch 1/100\n",
      " self.epoch 0   epochs 100  step 0 \n",
      "  Make training function -------------------------------\n",
      " self.total_loss : loss_11/add:0\n",
      "<tf.Tensor 'loss_11/add:0' shape=(1, 1) dtype=float32>\n",
      " self.metrics_tensors : Mean_23:0\n",
      "[<tf.Tensor 'Mean_23:0' shape=(1, 1) dtype=float32>]\n",
      " updates : \n",
      "[   <tf.Tensor 'training_7/SGD/AssignAdd:0' shape=() dtype=int64_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_1:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_2:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_3:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_4:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_5:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_6:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_7:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_8:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_9:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_10:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_11:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_12:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_13:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_14:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_15:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_16:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_17:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_18:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_19:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_20:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_21:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_22:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_23:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_24:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_25:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_26:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_27:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_28:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_29:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_30:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_31:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_32:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_33:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_34:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_35:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_36:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_37:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_38:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_39:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_40:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_41:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_42:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_43:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_44:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_45:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_46:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_47:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_48:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_49:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_50:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_51:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_52:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_53:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_54:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_55:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_56:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_57:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_58:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_59:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_60:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_61:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_62:0' shape=(7,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training_7/SGD/Assign_63:0' shape=(7,) dtype=float32_ref>]\n",
      "  ------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/128 [..............................] - ETA: 14:09 - loss: 0.0222 - fcn_norm_loss: 0.0222 self.epoch 0   epochs 100  step 1 \n",
      "  2/128 [..............................] - ETA: 10:05 - loss: 0.0217 - fcn_norm_loss: 0.0217 self.epoch 0   epochs 100  step 2 \n",
      "  3/128 [..............................] - ETA: 8:41 - loss: 0.0222 - fcn_norm_loss: 0.0222  self.epoch 0   epochs 100  step 3 \n",
      "  4/128 [..............................] - ETA: 7:56 - loss: 0.0224 - fcn_norm_loss: 0.0224 self.epoch 0   epochs 100  step 4 \n",
      "  5/128 [>.............................] - ETA: 7:27 - loss: 0.0217 - fcn_norm_loss: 0.0217 self.epoch 0   epochs 100  step 5 \n",
      "  6/128 [>.............................] - ETA: 7:07 - loss: 0.0218 - fcn_norm_loss: 0.0218 self.epoch 0   epochs 100  step 6 \n",
      "  7/128 [>.............................] - ETA: 6:53 - loss: 0.0218 - fcn_norm_loss: 0.0218 self.epoch 0   epochs 100  step 7 \n",
      "  8/128 [>.............................] - ETA: 6:42 - loss: 0.0218 - fcn_norm_loss: 0.0218 self.epoch 0   epochs 100  step 8 \n",
      "  9/128 [=>............................] - ETA: 6:32 - loss: 0.0218 - fcn_norm_loss: 0.0218 self.epoch 0   epochs 100  step 9 \n",
      " 10/128 [=>............................] - ETA: 6:23 - loss: 0.0218 - fcn_norm_loss: 0.0218 self.epoch 0   epochs 100  step 10 \n",
      " 11/128 [=>............................] - ETA: 6:16 - loss: 0.0219 - fcn_norm_loss: 0.0219 self.epoch 0   epochs 100  step 11 \n",
      " 12/128 [=>............................] - ETA: 6:10 - loss: 0.0217 - fcn_norm_loss: 0.0217 self.epoch 0   epochs 100  step 12 \n",
      " 13/128 [==>...........................] - ETA: 6:04 - loss: 0.0220 - fcn_norm_loss: 0.0220 self.epoch 0   epochs 100  step 13 \n",
      " 14/128 [==>...........................] - ETA: 5:58 - loss: 0.0221 - fcn_norm_loss: 0.0221 self.epoch 0   epochs 100  step 14 \n",
      " 15/128 [==>...........................] - ETA: 5:53 - loss: 0.0220 - fcn_norm_loss: 0.0220 self.epoch 0   epochs 100  step 15 \n",
      " 16/128 [==>...........................] - ETA: 5:48 - loss: 0.0220 - fcn_norm_loss: 0.0220 self.epoch 0   epochs 100  step 16 \n",
      " 17/128 [==>...........................] - ETA: 5:43 - loss: 0.0220 - fcn_norm_loss: 0.0220 self.epoch 0   epochs 100  step 17 \n",
      " 18/128 [===>..........................] - ETA: 5:39 - loss: 0.0221 - fcn_norm_loss: 0.0221 self.epoch 0   epochs 100  step 18 \n",
      " 19/128 [===>..........................] - ETA: 5:34 - loss: 0.0221 - fcn_norm_loss: 0.0221 self.epoch 0   epochs 100  step 19 \n",
      " 20/128 [===>..........................] - ETA: 5:30 - loss: 0.0221 - fcn_norm_loss: 0.0221 self.epoch 0   epochs 100  step 20 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-724e40aae0ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# epochs = 25,                                      # total number of epochs to run (accross multiple trainings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# batch_size = fcn_config.BATCH_SIZE,               # gets value from self.config.BATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmin_LR\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mfcn_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_LR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-b769624595c3>\u001b[0m in \u001b[0;36mtrain_in_batches_dev\u001b[0;34m(self, mrcnn_model, train_dataset, val_dataset, learning_rate, layers, losses, epochs, epochs_to_run, batch_size, steps_per_epoch, min_LR)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;31m# print('gt_hm_scores shape :', gt_hm_scores.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpr_hm_norm\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpr_hm_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_hm_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_hm_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;31m#                 print(' outs: ', outs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \u001b[0;31m# print('train_on_batch(1929) outputs: ', type(outputs) , ' len: ', len(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_layers = ['fcn']\n",
    "loss_names   = [\"fcn_norm_loss\"]\n",
    "\n",
    "fcn_model.epoch                  = fcn_config.LAST_EPOCH_RAN\n",
    "fcn_model.config.LEARNING_RATE   = fcn_config.LEARNING_RATE\n",
    "fcn_model.config.STEPS_PER_EPOCH = fcn_config.STEPS_PER_EPOCH\n",
    "batch_size                       = fcn_config.BATCH_SIZE\n",
    "epochs_to_run = fcn_config.EPOCHS_TO_RUN\n",
    "learning_rate = fcn_config.LEARNING_RATE\n",
    "steps_per_epoch = fcn_config.STEPS_PER_EPOCH\n",
    "\n",
    "\n",
    "train_in_batches_dev(fcn_model,\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            learning_rate = fcn_config.LEARNING_RATE,  \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            epochs_to_run = fcn_config.EPOCHS_TO_RUN,\n",
    "            steps_per_epoch = fcn_config.STEPS_PER_EPOCH ,    # gets value form self.config.STEPS_PER_EPOCH\n",
    "            # epochs = 25,                                      # total number of epochs to run (accross multiple trainings)\n",
    "            # batch_size = fcn_config.BATCH_SIZE,               # gets value from self.config.BATCH_SIZE\n",
    "            min_LR          = fcn_config.MIN_LR\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:49:50.082013Z",
     "start_time": "2018-07-09T15:49:49.100851Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_in_batches_dev(self,\n",
    "          mrcnn_model,\n",
    "          train_dataset, \n",
    "          val_dataset, \n",
    "          learning_rate, \n",
    "          layers            = None,\n",
    "          losses            = None,              \n",
    "          epochs            = 0,\n",
    "          epochs_to_run     = 1, \n",
    "          batch_size        = 0, \n",
    "          steps_per_epoch   = 0,\n",
    "          min_LR            = 0.00001):\n",
    "\n",
    "    '''\n",
    "    Train the model.\n",
    "    train_dataset, \n",
    "    val_dataset:    Training and validation Dataset objects.\n",
    "\n",
    "    learning_rate:  The learning rate to train with\n",
    "\n",
    "    epochs:         Number of training epochs. Note that previous training epochs\n",
    "                    are considered to be done already, so this actually determines\n",
    "                    the epochs to train in total rather than in this particaular\n",
    "                    call.\n",
    "\n",
    "    layers:         Allows selecting wich layers to train. It can be:\n",
    "                    - A regular expression to match layer names to train\n",
    "                    - One of these predefined values:\n",
    "                    heads: The RPN, classifier and mask heads of the network\n",
    "                    all: All the layers\n",
    "                    3+: Train Resnet stage 3 and up\n",
    "                    4+: Train Resnet stage 4 and up\n",
    "                    5+: Train Resnet stage 5 and up\n",
    "    '''\n",
    "    assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "\n",
    "    if batch_size == 0 :\n",
    "        batch_size = self.config.BATCH_SIZE\n",
    "\n",
    "    # if epochs_to_run > 0 :\n",
    "    epochs = self.epoch + epochs_to_run\n",
    "\n",
    "    if steps_per_epoch == 0:\n",
    "        steps_per_epoch = self.config.STEPS_PER_EPOCH\n",
    "\n",
    "    # use Pre-defined layer regular expressions\n",
    "    # if layers in self.layer_regex.keys():\n",
    "        # layers = self.layer_regex[layers]\n",
    "    print(layers)\n",
    "    # train_regex_list = []\n",
    "    # for x in layers:\n",
    "        # print( ' layers ias : ',x)\n",
    "        # train_regex_list.append(x)\n",
    "    train_regex_list = [self.layer_regex[x] for x in layers]\n",
    "    print(train_regex_list)\n",
    "    layers = '|'.join(train_regex_list)        \n",
    "    print('layers regex :', layers)\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Data generators\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    train_generator = data_generator(train_dataset, self.config, shuffle=True,\n",
    "                                     batch_size=batch_size)\n",
    "    val_generator   = data_generator(val_dataset, self.config, shuffle=True,\n",
    "                                     batch_size=batch_size,\n",
    "                                     augment=False)\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Set trainable layers and compile\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    self.set_trainable(layers)            \n",
    "    self.compile(learning_rate, self.config.LEARNING_MOMENTUM, losses)        \n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Create checkpoint folder if it doesn't exists\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    from tensorflow.python.platform import gfile\n",
    "    if not gfile.IsDirectory(self.log_dir):\n",
    "        log('Creating checkpoint folder : {}'.format(self.log_dir))\n",
    "        gfile.MakeDirs(self.log_dir)\n",
    "    else:\n",
    "        log('Checkpoint folder already exists: {}'.format(self.log_dir))                                   \n",
    "    # my_callback = MyCallback()\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Callbacks\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    # call back for model checkpoint was originally (?) loss. chanegd to val_loss (which is default) 2-5-18\n",
    "\n",
    "    # copied from \\keras\\engine\\training.py\n",
    "    # def _get_deduped_metrics_names(self):\n",
    "    ## get metrics from keras_model.metrics_names\n",
    "    out_labels = self.get_deduped_metrics_names()\n",
    "    print()\n",
    "    print(' out_labels from get_deduped_metrics_names() : ')\n",
    "    print(' --------------------------------------------- ')\n",
    "    print(out_labels)\n",
    "\n",
    "    ## setup Progress Bar callback\n",
    "    callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "    print()\n",
    "    print(' Callback metrics monitored by progbar :')\n",
    "    print(' ---------------------------------------')\n",
    "    pp.pprint(callback_metrics)\n",
    "\n",
    "    # progbar = keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "    # progbar.set_model(self.keras_model)\n",
    "    # progbar.set_params({\n",
    "        # 'epochs': epochs,\n",
    "        # 'steps': steps_per_epoch,\n",
    "        # 'verbose': 1,\n",
    "        # 'do_validation': False,\n",
    "        # 'metrics': callback_metrics,\n",
    "    # })\n",
    "\n",
    "\n",
    "    # progbar.set_model(self.keras_model) \n",
    "\n",
    "    ## setup Checkpoint callback\n",
    "    # chkpoint = keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                               # monitor='val_loss', \n",
    "                                               # verbose=1, \n",
    "                                               # save_best_only = True, \n",
    "                                               # save_weights_only=True)\n",
    "    # chkpoint.set_model(self.keras_model)\n",
    "\n",
    "    # progbar.on_train_begin()\n",
    "\n",
    "\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ProgbarLogger(count_mode='steps'),\n",
    "\n",
    "        keras.callbacks.TensorBoard(log_dir=self.log_dir,\n",
    "                                      histogram_freq=0,\n",
    "                                      batch_size=32,\n",
    "                                      write_graph=True,\n",
    "                                      write_grads=False,\n",
    "                                      write_images=True,\n",
    "                                      embeddings_freq=0,\n",
    "                                      embeddings_layer_names=None,\n",
    "                                      embeddings_metadata=None)\n",
    "\n",
    "        , keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                          mode = 'auto', \n",
    "                                          period = 1, \n",
    "                                          monitor='val_loss', \n",
    "                                          verbose=1, \n",
    "                                          save_best_only = True, \n",
    "                                          save_weights_only=True)\n",
    "\n",
    "        , keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            mode     = 'auto', \n",
    "                                            factor   = self.config.REDUCE_LR_FACTOR,   \n",
    "                                            cooldown = self.config.REDUCE_LR_COOLDOWN,\n",
    "                                            patience = self.config.REDUCE_LR_PATIENCE,\n",
    "                                            min_lr   = self.config.MIN_LR, \n",
    "                                            verbose  = 1)                                            \n",
    "\n",
    "        , keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                            mode      = 'auto', \n",
    "                                            min_delta = 0.00001, \n",
    "                                            patience  = self.config.EARLY_STOP_PATIENCE, \n",
    "                                            verbose   = 1)                                            \n",
    "        # , my_callback\n",
    "    ]\n",
    "\n",
    "\n",
    "    callbacks =  keras.callbacks.CallbackList(callbacks = callbacks_list)\n",
    "    callbacks.set_model(self.keras_model)\n",
    "    callbacks.set_params({\n",
    "        'epochs': epochs,\n",
    "        'steps': steps_per_epoch,\n",
    "        'verbose': 1,\n",
    "        'do_validation': False,\n",
    "        'metrics': callback_metrics,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    log(\"Starting at epoch {} of {} epochs. LR={}\\n\".format(self.epoch, epochs, learning_rate))\n",
    "    log(\"Steps per epochs {} \".format(steps_per_epoch))\n",
    "    log(\"    Last epoch completed : {} \".format(self.epoch))\n",
    "    log(\"    Starting from epoch  : {} for {} epochs\".format(self.epoch, epochs_to_run))\n",
    "    log(\"    Learning Rate        : {} \".format(learning_rate))\n",
    "    log(\"    Steps per epoch      : {} \".format(steps_per_epoch))\n",
    "    log(\"    Batch Size           : {} \".format(batch_size))\n",
    "    log(\"    Checkpoint Folder    : {} \".format(self.checkpoint_path))\n",
    "\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Start main training loop\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    epoch_idx = self.epoch\n",
    "    # progbar.on_train_begin()\n",
    "    callbacks.on_train_begin()\n",
    "\n",
    "    if epoch_idx >= epochs:\n",
    "        print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "    else:\n",
    "\n",
    "        while epoch_idx < epochs :\n",
    "            # progbar.on_epoch_begin(epoch_idx)\n",
    "            callbacks.on_epoch_begin(epoch_idx)\n",
    "\n",
    "            for steps_index in range(steps_per_epoch):\n",
    "\n",
    "                batch_logs = {}\n",
    "                print(' self.epoch {}   epochs {}  step {} '.format(self.epoch, epochs, steps_index))\n",
    "                batch_logs['batch'] = steps_index\n",
    "                batch_logs['size']  = batch_size\n",
    "                # progbar.on_batch_begin(steps_index, batch_logs)\n",
    "                callbacks.on_batch_begin(steps_index, batch_logs)\n",
    "\n",
    "                train_batch_x, train_batch_y = next(train_generator)\n",
    "                # print('length of train_batch_x:', len(train_batch_x))\n",
    "                # print('length of train_batch_y:', len(train_batch_y))\n",
    "\n",
    "\n",
    "                # # model_output   = get_layer_output_2(mrcnn_model.keras_model, train_batch_x, training_flag = False)\n",
    "                # # model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "                # print(len(model_output))\n",
    "                # # print(type(output_rois))\n",
    "                # for i in model_output:\n",
    "                    # print( i.shape)                    \n",
    "\n",
    "                results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "#                 print('# of items in results:', len(results))\n",
    "\n",
    "\n",
    "                pr_hm_norm, gt_hm_norm, pr_hm_scores, gt_hm_scores = results[11:]                 \n",
    "\n",
    "                # print('pr_hm_norm shape   :', pr_hm_norm.shape)\n",
    "                # print('pr_hm_scores shape :', pr_hm_scores.shape)\n",
    "                # print('gt_hm_norm shape   :', gt_hm_norm.shape)\n",
    "                # print('gt_hm_scores shape :', gt_hm_scores.shape)\n",
    "\n",
    "                outs = self.keras_model.train_on_batch([pr_hm_norm,  pr_hm_scores,gt_hm_norm, gt_hm_scores], train_batch_y)\n",
    "\n",
    "#                 print(' outs: ', outs)\n",
    "                if not isinstance(outs, list):\n",
    "                    outs = [outs]\n",
    "                for l, o in zip(out_labels, outs):\n",
    "                    batch_logs[l] = o\n",
    "\n",
    "                # progbar.on_batch_end(steps_index, batch_logs)\n",
    "                callbacks.on_batch_end(steps_index, batch_logs)\n",
    "\n",
    "                # print(outs)\n",
    "\n",
    "            ## end of epoch operations     \n",
    "            ##-------------------------------\n",
    "            val_batch_x, val_batch_y = next(val_generator)\n",
    "            val_outs = self.keras_model.test_on_batch(X_val, Y_val)\n",
    "            # write_log(callback, val_names, logs, batch_no//10)\n",
    "            print(' validation logs output: ', val_outs)\n",
    "            if not isinstance(val_outs, list):\n",
    "                val_outs = [val_outs]\n",
    "            for l, o in zip(out_labels, outs):\n",
    "                batch_logs[l] = o\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # progbar.on_epoch_end(epoch_idx, {})\n",
    "            # if (epoch_idx % 10) == 0:\n",
    "            # chkpoint.on_epoch_end(epoch_idx  , batch_logs)\n",
    "            callbacks.on_epoch_end(epoch_idx, batch_logs)\n",
    "            epoch_idx += 1\n",
    "\n",
    "        ## end of all epochs operations\n",
    "        ##--------------------------------\n",
    "        # if epoch_idx != self.epoch:\n",
    "        # chkpoint.on_epoch_end(epoch_idx -1, batch_logs)\n",
    "        callbacks.on_train_end()\n",
    "        self.epoch = max(epoch_idx - 1, epochs)\n",
    "        print('Final : self.epoch {}   epochs {}'.format(self.epoch, epochs))\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## End main training loop\n",
    "    ##--------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:38:11.488298Z",
     "start_time": "2018-07-09T15:40:38.570Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_layers)\n",
    "# train_regex_list = []\n",
    "# for x in layers:\n",
    "    # print( ' layers ias : ',x)\n",
    "    # train_regex_list.append(x)\n",
    "train_regex_list = [fcn_model.layer_regex[x] for x in train_layers]\n",
    "print(train_regex_list)\n",
    "layers = '|'.join(train_regex_list)        \n",
    "print('layers regex :', layers)\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Set trainable layers and compile\n",
    "##--------------------------------------------------------------------------------\n",
    "fcn_model.set_trainable(layers)            \n",
    "fcn_model.compile(learning_rate, fcn_model.config.LEARNING_MOMENTUM, loss_names)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:13:22.946697Z",
     "start_time": "2018-07-09T15:13:22.906821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " out_labels from get_deduped_metrics_names() : \n",
      " --------------------------------------------- \n",
      "['loss', 'fcn_norm_loss']\n"
     ]
    }
   ],
   "source": [
    "out_labels = fcn_model.get_deduped_metrics_names()\n",
    "print()\n",
    "print(' out_labels from get_deduped_metrics_names() : ')\n",
    "print(' --------------------------------------------- ')\n",
    "print(out_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:27.449382Z",
     "start_time": "2018-07-09T15:09:27.396705Z"
    }
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------------\n",
    "## Data generators\n",
    "##--------------------------------------------------------------------------------\n",
    "train_generator = data_generator(dataset_train, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "val_generator   = data_generator(dataset_val, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_config.EPOCHS_TO_RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:30.828699Z",
     "start_time": "2018-07-09T15:09:30.786146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at epoch 0 of 100 epochs. LR=0.005\n",
      "\n",
      "Steps per epochs 128 \n",
      "    Last epoch completed : 0 \n",
      "    Starting from epoch  : 0 for 100 epochs\n",
      "    Learning Rate        : 0.005 \n",
      "    Steps per epoch      : 128 \n",
      "    Batch Size           : 8 \n",
      "    Checkpoint Folder    : /home/kbardool/models/train_fcn_alt/shapes20180709T1458/fcn_shapes_{epoch:04d}.h5 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = fcn_model.epoch + epochs_to_run\n",
    "log(\"Starting at epoch {} of {} epochs. LR={}\\n\".format(fcn_model.epoch, epochs, learning_rate))\n",
    "log(\"Steps per epochs {} \".format(steps_per_epoch))\n",
    "log(\"    Last epoch completed : {} \".format(fcn_model.epoch))\n",
    "log(\"    Starting from epoch  : {} for {} epochs\".format(fcn_model.epoch, epochs_to_run))\n",
    "log(\"    Learning Rate        : {} \".format(learning_rate))\n",
    "log(\"    Steps per epoch      : {} \".format(steps_per_epoch))\n",
    "log(\"    Batch Size           : {} \".format(batch_size))\n",
    "log(\"    Checkpoint Folder    : {} \".format(fcn_model.checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:15:38.298611Z",
     "start_time": "2018-07-09T15:15:38.262121Z"
    }
   },
   "outputs": [],
   "source": [
    "steps_index = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:15:39.537649Z",
     "start_time": "2018-07-09T15:15:39.488679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " self.epoch 0   epochs 100  step 0 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d49075fba920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# progbar.on_batch_begin(steps_index, batch_logs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "batch_logs = {}\n",
    "print(' self.epoch {}   epochs {}  step {} '.format(fcn_model.epoch, epochs, steps_index))\n",
    "batch_logs['batch'] = steps_index\n",
    "batch_logs['size']  = batch_size\n",
    "# progbar.on_batch_begin(steps_index, batch_logs)\n",
    "callbacks.on_batch_begin(steps_index, batch_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:35.323441Z",
     "start_time": "2018-07-09T15:09:35.225145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 128, 3)\n",
      "(8, 15)\n",
      "(8, 4092, 1)\n",
      "(8, 256, 4)\n",
      "(8, 100)\n",
      "(8, 100, 4)\n",
      "(8, 56, 56, 100)\n"
     ]
    }
   ],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "for i in train_batch_x:\n",
    "    print( i.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MRCNN model predictions\n",
    "\n",
    "     Outputs:\n",
    "     --------\n",
    "     layer:  0    output : rpn_class_logits/rpn_class_logits:0        Type: float32           Shape: (?, ?, 2)\n",
    "     layer:  1    output : rpn_class/rpn_class:0                      Type: float32           Shape: (?, ?, 2)\n",
    "     layer:  2    output : rpn_bbox/rpn_bbox:0                        Type: float32           Shape: (?, ?, 4)\n",
    "     layer:  3    output : rpn_proposal_rois/rpn_roi_proposals:0      Type: float32           Shape: (8, ?, ?)\n",
    "     layer:  4    output : proposal_targets/output_rois:0             Type: float32           Shape: (8, ?, ?)\n",
    "     layer:  5    output : proposal_targets/target_class_ids:0        Type: int32             Shape: (8, ?)\n",
    "     layer:  6    output : proposal_targets/target_bbox_deltas:0      Type: float32           Shape: (8, ?, ?)\n",
    "     layer:  7    output : proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (8, ?, ?)\n",
    "     layer:  8    output : mrcnn_class_logits/mrcnn_class_logits:0    Type: float32           Shape: (?, 32, 7)\n",
    "     layer:  9    output : mrcnn_class/mrcnn_class:0                  Type: float32           Shape: (?, 32, 7)\n",
    "     layer: 10    output : mrcnn_bbox_regression/mrcnn_bbox:0         Type: float32           Shape: (?, 32, 7, 4)\n",
    "     layer: 11    output : cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (8, 128, 128, 7)\n",
    "     layer: 12    output : cntxt_layer/gt_heatmap_norm:0              Type: float32           Shape: (8, 128, 128, 7)\n",
    "     layer: 13    output : cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (?, ?, ?, ?)\n",
    "     layer: 14    output : cntxt_layer/gt_heatmap_scores:0            Type: float32           Shape: (?, ?, ?, ?)\n",
    "        \n",
    "\n",
    "     Inputs:\n",
    "     -------\n",
    "     layer:  0    output : input_pr_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
    "     layer:  1    output : input_pr_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 11)\n",
    "     layer:  2    output : input_gt_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
    "     layer:  3    output : input_gt_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 11)\n",
    "\n",
    "\n",
    "     Outputs:\n",
    "     --------\n",
    "     layer:  0    output : fcn_heatmap_norm/fcn_heatmap_norm:0        Type: float32           Shape: (?, 128, 128, 7)\n",
    "     layer:  1    output : fcn_scoring/fcn_heatmap_scores:0           Type: float32           Shape: (?, ?, ?, ?)\n",
    "     layer:  2    output : fcn_heatmap/fcn_heatmap:0                  Type: float32           Shape: (?, 128, 128, 7)\n",
    "     layer:  3    output : fcn_norm_loss/fcn_norm_loss:0              Type: float32           Shape: (1, 1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:44.907473Z",
     "start_time": "2018-07-09T15:09:40.245616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of items in results: 15\n",
      "(8, 4092, 2)\n",
      "(8, 4092, 2)\n",
      "(8, 4092, 4)\n",
      "(8, 1000, 4)\n",
      "(8, 32, 4)\n",
      "(8, 32)\n",
      "(8, 32, 4)\n",
      "(8, 32, 4)\n",
      "(8, 32, 7)\n",
      "(8, 32, 7)\n",
      "(8, 32, 7, 4)\n",
      "(8, 128, 128, 7)\n",
      "(8, 128, 128, 7)\n",
      "(8, 7, 32, 11)\n",
      "(8, 7, 32, 11)\n"
     ]
    }
   ],
   "source": [
    "results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "print('# of items in results:', len(results))\n",
    "\n",
    "for i in results:\n",
    "    print( i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:49.417601Z",
     "start_time": "2018-07-09T15:09:49.377184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 128, 7)\n",
      "(8, 128, 128, 7)\n",
      "(8, 7, 32, 11)\n",
      "(8, 7, 32, 11)\n"
     ]
    }
   ],
   "source": [
    "pr_hm_norm, gt_hm_norm, pr_hm_scores, gt_hm_scores = results[11:]                 \n",
    "print(pr_hm_norm.shape)\n",
    "print(gt_hm_norm.shape)\n",
    "print(pr_hm_scores.shape)\n",
    "print(gt_hm_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:10:05.116891Z",
     "start_time": "2018-07-09T15:09:55.156786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Make training function -------------------------------\n",
      " self.total_loss : loss_1/add_1:0\n",
      "<tf.Tensor 'loss_1/add_1:0' shape=(1, 1) dtype=float32>\n",
      " self.metrics_tensors : Mean_3:0\n",
      "[<tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>]\n",
      " updates : \n",
      "[   <tf.Tensor 'training/SGD/AssignAdd:0' shape=() dtype=int64_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_1:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_2:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_3:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_4:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_5:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_6:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_7:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_8:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_9:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_10:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_11:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_12:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_13:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_14:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_15:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_16:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_17:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_18:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_19:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_20:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_21:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_22:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_23:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_24:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_25:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_26:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_27:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_28:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_29:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_30:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_31:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_32:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_33:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_34:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_35:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_36:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_37:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_38:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_39:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_40:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_41:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_42:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_43:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_44:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_45:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_46:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_47:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_48:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_49:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_50:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_51:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_52:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_53:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_54:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_55:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_56:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_57:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_58:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_59:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_60:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_61:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_62:0' shape=(7,) dtype=float32_ref>,\n",
      "    <tf.Tensor 'training/SGD/Assign_63:0' shape=(7,) dtype=float32_ref>]\n",
      "  ------------------------------------------------------\n",
      "train_on_batch(1929) outputs:  <class 'list'>  len:  2\n",
      "   type: <class 'numpy.ndarray'>   shape:  (1, 1) [[0.0041]]\n",
      "   type: <class 'numpy.ndarray'>   shape:  (1, 1) [[0.0041]]\n"
     ]
    }
   ],
   "source": [
    "outs = fcn_model.keras_model.train_on_batch([pr_hm_norm,  pr_hm_scores,gt_hm_norm, gt_hm_scores], train_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:13:32.839825Z",
     "start_time": "2018-07-09T15:13:32.787299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.0041]], dtype=float32), array([[0.0041]], dtype=float32)]\n",
      " outs:  [array([[0.0041]], dtype=float32), array([[0.0041]], dtype=float32)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4f1a8c148282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_logs' is not defined"
     ]
    }
   ],
   "source": [
    "pp.pprint(outs)\n",
    "print(' outs: ', outs)\n",
    "if not isinstance(outs, list):\n",
    "    outs = [outs]\n",
    "for l, o in zip(out_labels, outs):\n",
    "    batch_logs[l] = o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_output = get_layer_output_2(fcn_model.keras_model, [pr_hm_norm,  pr_hm_scores,gt_hm_norm, gt_hm_scores], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'fcn_norm_loss']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn_model.keras_model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "### Training FPN, RPN and MRCNN heads using  Keras.model.fit_generator()\n",
    "\n",
    "print(config.BATCH_SIZE)\n",
    "print(model.config.BATCH_SIZE)\n",
    "print(model.config.LEARNING_RATE)\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:37:28.251199Z",
     "start_time": "2018-06-05T21:11:11.215070Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "## Last run prior to FCN training was 3699, last checkpoint was 3892  ...start at 3899\n",
    "\n",
    "train_layers = [ 'mrcnn', 'fpn','rpn']\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "model.epoch = 1233\n",
    "model.config.LEARNING_RATE = 1.0e-4\n",
    "model.config.STEPS_PER_EPOCH = 7\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=model.config.LEARNING_RATE, \n",
    "            epochs_to_run =3000, \n",
    "#             epochs = 25,            \n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            min_LR = 1.0e-6,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train FCN head layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T12:39:18.755289Z",
     "start_time": "2018-06-07T12:34:14.060639Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "\n",
    "## Last run prior to FCN training was 3699, last checkpoint was 3892\n",
    "\n",
    "train_layers = ['fcn']\n",
    "loss_names   = [  \"fcn_norm_loss\"]\n",
    "model.epoch = 1668\n",
    "model.config.LEARNING_RATE = 1.0e-4\n",
    "model.config.STEPS_PER_EPOCH = 8 \n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=model.config.LEARNING_RATE, \n",
    "            epochs_to_run = 500, \n",
    "#             epochs = 25,            \n",
    "#             batch_size = 6,\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            min_LR = 1.0e-9\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:17:32.353508Z",
     "start_time": "2018-05-20T18:17:32.121048Z"
    }
   },
   "outputs": [],
   "source": [
    "model.keras_model.losses\n",
    "print(model.keras_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")\n",
    "\n",
    "# train_layers = ['fcn']\n",
    "# loss_names   = [  \"fcn_norm_loss\"]\n",
    "# model.epoch = 208\n",
    "# model.config.LEARNING_RATE = 1.0e-4\n",
    "# model.config.STEPS_PER_EPOCH = 8 \n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=model.config.LEARNING_RATE, \n",
    "#             epochs_to_run = 500, \n",
    "# #             epochs = 25,            \n",
    "# #             batch_size = 6,\n",
    "# #             steps_per_epoch = 0 \n",
    "#             layers = train_layers,\n",
    "#             losses = loss_names,\n",
    "#             min_LR = 1.0e-7\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_post_training.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:25:16.962148Z",
     "start_time": "2018-05-20T18:25:16.737938Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:10:55.871863Z",
     "start_time": "2018-06-05T14:10:51.289152Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:10:58.357215Z",
     "start_time": "2018-06-05T14:10:58.128846Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:11:29.002604Z",
     "start_time": "2018-06-05T14:11:21.360692Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "print(len(model_output))\n",
    "\n",
    "# rpn_class_loss            = model_output[0]          # layer: 11   shape: (1, 1)\n",
    "# rpn_bbox_loss             = model_output[1]          # layer: 12   shape: (1, 1)\n",
    "# mrcnn_class_loss          = model_output[2]          # layer: 13   shape: (1, 1)\n",
    "# mrcnn_bbox_loss           = model_output[3]          # layer: 14   shape: (1, 1)\n",
    "# fcn_normalized_loss       = model_output[0]          # layer: 26   shape: (1, 1)\n",
    "\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)\n",
    "# print('FCN Normalized Loss is :', fcn_normalized_loss)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:40:52.258442Z",
     "start_time": "2018-05-20T18:40:52.031879Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "input_gt_masks     = train_batch_x[6]\n",
    "print(' Input image shape is :', input_image.shape)\n",
    "h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
