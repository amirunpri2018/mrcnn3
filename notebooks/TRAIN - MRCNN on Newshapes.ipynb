{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Train on NewShapes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:30:21.610850Z",
     "start_time": "2018-12-16T15:30:21.064920Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "--> Execution started at: 12-16-2018 @ 16:30:21\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.2.0 \n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.newshapes    as shapes\n",
    "import mrcnn.utils        as utils\n",
    "\n",
    "from datetime           import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.datagen      import data_generator, load_image_gt, data_gen_simulate\n",
    "# from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.prep_notebook import mrcnn_newshape_train\n",
    "from mrcnn.newshapes    import prep_newshape_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \" --epochs 2 \"\n",
    "input_parms +=\" --steps_in_epoch 32 \"\n",
    "input_parms +=\" --last_epoch 0 \" \n",
    "input_parms +=\" --batch_size 1 \" \n",
    "input_parms +=\" --lr 0.00001 \"\n",
    "input_parms +=\" --val_steps 8 \" \n",
    "input_parms +=\" --mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "input_parms +=\" --fcn_logs_dir   train_fcn8_newshapes \"\n",
    "input_parms +=\" --mrcnn_model    last \"\n",
    "input_parms +=\" --fcn_model      init \"\n",
    "input_parms +=\" --opt            adagrad \"\n",
    "input_parms +=\" --fcn_arch       fcn8 \" \n",
    "input_parms +=\" --fcn_layers     all \" \n",
    "input_parms +=\" --sysout        screen \"\n",
    "input_parms +=\" --new_log_folder    \"\n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    " \n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T15:32:04.674989Z",
     "start_time": "2018-12-16T15:31:57.387821Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments passed :\n",
      "--------------------\n",
      "batch_size                     1\n",
      "coco_classes                   None\n",
      "epochs                         2\n",
      "fcn_arch                       FCN8\n",
      "fcn_layers                     ['all']\n",
      "fcn_logs_dir                   train_fcn8_newshapes\n",
      "fcn_losses                     fcn_BCE_loss\n",
      "fcn_model                      init\n",
      "last_epoch                     0\n",
      "lr                             0.00001\n",
      "mrcnn_exclude_layers           None\n",
      "mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "mrcnn_model                    last\n",
      "new_log_folder                 True\n",
      "opt                            ADAGRAD\n",
      "scale_factor                   4\n",
      "steps_in_epoch                 32\n",
      "sysout                         SCREEN\n",
      "val_steps                      8\n",
      "\n",
      "\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_HEATMAP_PATH              F:\\MLDatasets\\coco2014_heatmaps\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_ROOT                       F:\\\n",
      "DIR_TRAINING                   F:\\models\n",
      "FCN_TRAINING_PATH              F:\\models\\train_fcn8_newshapes\n",
      "FCN_VGG16_MODEL_PATH           F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            F:\\models\\train_mrcnn_newshapes\n",
      "PRED_CLASS_INFO_PATH           F:\\PretrainedModels\\predicted_classes_info.pkl\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  F:\\models\\train_mrcnn_newshapes\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  training\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                  NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "  > CHMLayer Call()  3\n",
      "    mrcnn_class.shape    : (?, 32, 7) (None, 32, 7)\n",
      "    mrcnn_bbox.shape     : (?, 32, 7, 4) (None, 32, 7, 4)\n",
      "    output_rois.shape    : (1, ?, ?) (None, 32, 4)\n",
      "\n",
      "  > build_pr_tensor()\n",
      "    num_rois               :  32\n",
      "    norm_input_rois.shape  :  <class 'tensorflow.python.framework.ops.Tensor'> (None, 32, 4)\n",
      "    scale.shape            :  <class 'tensorflow.python.framework.ops.Tensor'> (4,) (4,)\n",
      "    dup_scale.shape        :  <class 'tensorflow.python.framework.ops.Tensor'> (1, 32, 4) (1, 32, 4)\n",
      "\n",
      "    mrcnn_class shape      :  (None, 32, 7)\n",
      "    mrcnn_bbox.shape       :  (None, 32, 7, 4) (?, 32, 7, 4)\n",
      "    config image shape     :  [128 128   3] h: 128 w: 128\n",
      "    refined rois clipped   :  (1, 32, 4)\n",
      "    input_rois.shape       :  (1, 32, 4) (1, 32, 4)\n",
      "    refined_rois.shape     :  (1, 32, 4) (1, 32, 4)\n",
      "    shape of sequence      :  (?, 32, 1)\n",
      "    pred_array             :  (1, 32, 7)\n",
      "    scatter_ind            :  (1, 32, 3)\n",
      "    pred_scatter           :  (1, 7, 32, 7)\n",
      "    - Add normalized score --\n",
      "\n",
      "    normalizer             :  (1, 7, 1)\n",
      "    norm_score             :  (1, 7, 32, 1)\n",
      "    pred_scatter           :  (1, 7, 32, 8)\n",
      "    sort_inds              :  (1, 7, 32) Keras Tensor: False\n",
      "    class_grid             :  (1, 7, 32) Keras Tensor: False\n",
      "    batch_grid             :  (1, 7, 32) Keras Tensor: False\n",
      "    roi_grid shape         :  (1, 7, 32) Keras Tensor: False\n",
      "    gather_inds            :  (1, 7, 32, 3) Keras Tensor: False\n",
      "    pred_tensor            :  (1, 7, 32, 8) Keras Tensor: False\n",
      "\n",
      " \n",
      "  > build_pr_heatmap() for  ['pred_heatmap']\n",
      "    in_tensor shape        :  (1, 7, 32, 8)\n",
      "    num bboxes per class   :  32\n",
      "    heatmap scale        :  4 Dimensions:  w: 32  h: 32\n",
      "    pt2_sum shape  :  (1, 7, 32)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "    X/Y shapes : (32, 32) (32, 32)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (32, 32) =  (?, 32, 32)\n",
      "    ones_exp * Y (?, 1, 1) * (32, 32) =  (?, 32, 32)\n",
      "    pos_grid before transpse :  (?, 32, 32, 2)\n",
      "    pos_grid after transpose :  (32, 32, ?, 2)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (32, 32, ?, 2)\n",
      "     Prob_grid shape from mvn.probe:  (32, 32, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 32, 32)\n",
      "    << output probabilities shape  :  (?, 32, 32)\n",
      "    old_style_scores        : (1, 7, 32, 3) (1, 7, 32, 3)\n",
      "    prob_grid_clipped :  (?, 32, 32)\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer     :  (?, 1, 1)\n",
      "    prob_grid_cns: clipped/normed/scaled :  (?, 32, 32)\n",
      "    alt_scores_1    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_1(by class)       :  (1, 7, 32, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 7, 32, 3)\n",
      "         reduce_min shape :  (1, 7, 1, 3)\n",
      "         reduce_max shape :  (1, 7, 1, 3)\n",
      "             output shape :  (1, 7, 32, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)  :  (1, 7, 32, 3) (1, 7, 32, 3)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape      :  (?, 3)\n",
      "    prob_grid_clippped :  (?, 32, 32)\n",
      "    gauss_heatmap      :  (1, 7, 32, 32, 32)\n",
      "\n",
      "    Reduce SUM based on class and normalize within each class -------------------------------------\n",
      "    gaussian_heatmap_sum :  (1, 7, 32, 32) Keras tensor  False\n",
      "    normalizer shape   :  (1, 7, 1, 1)\n",
      "    normalized heatmap :  (1, 7, 32, 32)  Keras tensor  False\n",
      "    hm_indices shape         : (?, 2) (None, 2)\n",
      "    pt2_heatmaps             : (?, 32, 32) (None, 32, 32)\n",
      "    alt_scores_2    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_2(scattered)       :  (1, 7, 32, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 7, 32, 3)\n",
      "         reduce_min shape :  (1, 7, 1, 3)\n",
      "         reduce_max shape :  (1, 7, 1, 3)\n",
      "             output shape :  (1, 7, 32, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)  :  (1, 7, 32, 3) (1, 7, 32, 3)\n",
      "    reshaped heatmap   :  (1, 32, 32, 7)  Keras tensor  False\n",
      "    gauss_scores    :  (1, 7, 32, 23)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    pred_refined_heatmap        :  (1, 32, 32, 7) Keras tensor  False\n",
      "    pred_refnined_heatmap_scores:  (1, 7, 32, 23) Keras tensor  False\n",
      "    complete\n",
      "--------------------------------\n",
      ">>>  CHM Layer COMPUTE OUTPUT SHAPE \n",
      "--------------------------------\n",
      "<class 'list'> 3\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "  > CHMLayerTgt Call()  2\n",
      "    tgt_class_ids.shape  : (1, ?) (None, 32)\n",
      "    tgt_bboxes.shape     : (1, ?, ?) (None, 32, 4)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    num_bboxes             :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape     :  (1, ?)    (None, 32)\n",
      "    norm_gt_bboxes.shape   :  (1, ?, ?)    (None, 32, 4)\n",
      "    gt_bboxes.shape        :  (1, 32, 4)    (1, 32, 4)\n",
      "    gt_classes_exp         :  (1, ?, 1)\n",
      "    gt_scores_exp          :  (1, ?, 1)\n",
      "    gt_array shape         :  (1, 32, 8) (1, 32, 8)\n",
      "    scatter_ind shape      :  (1, 32, 3) (1, 32, 3)\n",
      "    tf.shape(gt_array)[-1] :  8 (1, 32, 8)\n",
      "    gt_scatter shape       :  (1, 7, 32, 8) (1, 7, 32, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    gather_inds            :  (1, 7, 32, 3)\n",
      "    gt_tensor.shape        :  (1, 7, 32, 8) (1, 7, 32, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    in_tensor shape        :  (1, 7, 32, 8)\n",
      "    num bboxes per class   :  32\n",
      "    heatmap scale        :  4 Dimensions:  w: 32  h: 32\n",
      "    pt2_sum shape  :  (1, 7, 32)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "     Prob_grid shape :  (?, 32, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    prob_grid_clipped      :  (?, 32, 32)\n",
      "    old_style_scores       :  (1, 7, 32, 3)  Keras tensor  False\n",
      "    alt_scores_1    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_1(by class)       :  (1, 7, 32, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 7, 32, 3)\n",
      "         reduce_min shape :  (1, 7, 1, 3)\n",
      "         reduce_max shape :  (1, 7, 1, 3)\n",
      "             output shape :  (1, 7, 32, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)  :  (1, 7, 32, 3) (1, 7, 32, 3)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 32, 32)\n",
      "    gauss_heatmap   :  (1, 7, 32, 32, 32)\n",
      "\n",
      "    Reduce MAX based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 7, 32, 32) Keras tensor  False\n",
      "    hm_indices shape         : (?, 2) (None, 2)\n",
      "    pt2_heatmaps             : (?, 32, 32) (None, 32, 32)\n",
      "    alt_scores_2    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_2(by class)       :  (1, 7, 32, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 7, 32, 3)\n",
      "         reduce_min shape :  (1, 7, 1, 3)\n",
      "         reduce_max shape :  (1, 7, 1, 3)\n",
      "             output shape :  (1, 7, 32, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)  :  (1, 7, 32, 3) (1, 7, 32, 3)\n",
      "    gauss_heatmap :  (1, 32, 32, 7)  Keras tensor  False\n",
      "    gauss_scores    :  (1, 7, 32, 23)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    gt_heatmap                  :  (1, 32, 32, 7) Keras tensor  False\n",
      "    gt_heatmap_scores           :  (1, 7, 32, 23) Keras tensor  False\n",
      "    complete\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape_3:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape_3:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (1, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  training\n",
      ">>> MaskRCNN initialiation complete. Mode:  training\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "STEPS_PER_EPOCH                32\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  F:\\models\\train_mrcnn_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VERBOSE                        0\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 32, 7)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      " layer: 11    output name: ROI/rpn_roi_proposals:0                    Type: float32           Shape: (1, ?, ?)\n",
      " layer: 12    output name: rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer: 13    output name: rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer: 14    output name: mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer: 15    output name: mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.prep_notebook import mrcnn_newshape_train\n",
    "mrcnn_model= mrcnn_newshape_train(args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T14:39:22.093476Z",
     "start_time": "2018-11-04T14:39:22.041844Z"
    }
   },
   "outputs": [],
   "source": [
    "mrcnn_model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T18:00:27.299023Z",
     "start_time": "2018-12-16T18:00:24.341924Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      " Exclude layers: \n",
      "    -  mrcnn_class_logits\n",
      "    -  mrcnn_bbox_fc\n",
      "-----------------------------------------------\n",
      " ---> last\n",
      ">>> load_weights() from : F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0002.h5\n",
      "    Weights file loaded: F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0002.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load Mask RCNN Model Weight file\n",
    "##------------------------------------------------------------------------------------\n",
    "# exclude_list = [\"mrcnn_class_logits\"]\n",
    "exclude_list = [\"mrcnn_class_logits\", \"mrcnn_bbox_fc\"]   ## <-- must be excluded when wanting to init from mask_rcnn_shapes.h5\n",
    "mrcnn_model.load_model_weights(init_with = 'last', exclude = exclude_list, verbose = 1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build newshape datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:39:48.166871Z",
     "start_time": "2018-12-16T17:39:24.329332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepares complete\n",
      "Prepares complete\n"
     ]
    }
   ],
   "source": [
    "# del dataset_train, dataset_val, train_generator, val_generator\n",
    "# from mrcnn.prep_notebook import prep_newshape_dataset\n",
    "dataset_train, train_generator = prep_newshape_dataset( mrcnn_model.config, 10000, generator=True)\n",
    "dataset_val  , val_generator   = prep_newshape_dataset( mrcnn_model.config,  2500, generator=True)\n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:39:48.521106Z",
     "start_time": "2018-12-16T17:39:48.169855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mrcnn.newshapes.NewShapesDataset'> <class 'generator'>\n",
      "10000\n",
      "<class 'mrcnn.newshapes.NewShapesDataset'> <class 'generator'>\n",
      "2500\n",
      "10000 2500\n",
      "{'.0': 0, 'shapes.2': 2, 'shapes.3': 3, 'shapes.5': 5, 'shapes.1': 1, 'shapes.4': 4, 'shapes.6': 6}\n",
      "[{'id': 0, 'source': '', 'category': 'background', 'img_count': 0, 'internal_id': 0, 'name': 'BG'}, {'id': 1, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 1, 'name': 'person'}, {'id': 2, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 2, 'name': 'car'}, {'id': 3, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 3, 'name': 'sun'}, {'id': 4, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 4, 'name': 'building'}, {'id': 5, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 5, 'name': 'tree'}, {'id': 6, 'source': 'shapes', 'category': None, 'img_count': 0, 'internal_id': 6, 'name': 'cloud'}]\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset_train), type(train_generator))\n",
    "print(type(dataset_val), type(val_generator))\n",
    "print(len(dataset_train.image_info))\n",
    "print(len(dataset_val.image_info))\n",
    "print(len(dataset_train.image_ids), len(dataset_val.image_info))\n",
    "# dataset_train.display_active_class_info()\n",
    "print(dataset_train.class_from_source_map)\n",
    "print(dataset_train.class_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Files and Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display next image from generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:37:03.716581Z",
     "start_time": "2018-12-16T17:37:03.382292Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:39:55.325935Z",
     "start_time": "2018-12-16T17:39:54.737524Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image_id    :  914  Reference:  [('cloud', (131, 67, 251), (15, 29, 33, 8)), ('cloud', (105, 53, 65), (94, 32, 40, 13))] Coco Id: 914\n",
      " Image meta  :  [914 128 128   3   0   0 128 128]\n",
      " Class ids   :  (2,)    [6 6]\n",
      " Class Names :  ['cloud', 'cloud']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5EAAAOICAYAAABPC3XsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgEAABgmIgEAABgmIgEAABj2PzgjMW7QdSrxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize.display_training_batch(dataset_train, train_batch_x)\n",
    "\n",
    "class_names = dataset_train.class_names\n",
    "# imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "# img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "# for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "#     image_id = img_meta[img_idx,0]\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     bbox = utils.extract_bboxes(mask)\n",
    "#     print('Image id: ',image_id)\n",
    "#     print('Image meta', img_meta[img_idx])\n",
    "# #     print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "#     visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a specific image using image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:40:53.807454Z",
     "start_time": "2018-12-16T17:40:53.368124Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "## 33477 Table, bowl, cup, sandwich, knife\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "# IMAGE_LIST = [75040] \n",
    "# IMAGE_LIST = [89243]\n",
    "IMAGE_LIST = [2000,4000,5000,6000]\n",
    "# IMAGE_LIST = [29731]\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_model.config, IMAGE_LIST)\n",
    "\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:47:37.428614Z",
     "start_time": "2018-12-16T17:47:35.464220Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAACLCAYAAACpz+z5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEZlJREFUeJzt3XvQXVV9h/HnZyIhYoSQcBGwIKQd\nQMQyiBTEmlGow2W0ODJU5JIanRGMtLVWUbFCwBuo40gYLAUES0CQFkSuyiVXJQRGbYPKRSqM4iVi\ntKAQbqt/rHWSnZP9nve8kOS873qfz8yZ7L3OeddeZ619dvZ3r33eN1JKSJIkSVJNXjToBkiSJEnS\nhmbQkSRJklQdg44kSZKk6hh0JEmSJFXHoCNJkiSpOgYdSZIkSdXpGXQiYpeIuKWr7IGRbiQiboyI\nfcryYRHxu4iIsn5WRBzXRx1nRMRDzfZExD4RsTQiFkXEbRGxaynftZQtiIjbI2KnHvXuFhF3R8Tj\nEXFQo/xLEXFHeZzSKP9oRCyPiDsj4oMt9c2KiFMb6zMj4oLhe2mdOiZExMNdfXRN4/k7I+IVfdRz\nc0Ss7GrP8RGxrPTP1yNiUik/tLyvxRExPyIm9qj3yIj4cUQ82SibHBHfiYglpc8OLeWbRcSVpd5l\nEfGmkfRFP7r7uG2/7bOeeyJi67J8UkT8oPHclRHxhj7quCgiftnVnreUPlkYETdExLRS/tqu8ik9\n6j0wIv4nIp5s7s+lXd8tfTurUT6v1L08It450r7YWDymjPyYMkjdY/M8x+q8iDiyLO8ZEc91fc4+\n0UcdJ0XEfc3tR8ROZTwWlzF7bSmfGhHfLp+rpRGxd496p0TE9yLi9xFxbKP8w+UztTQizmnsW7Mi\n4q7yM18YaV8MkmNZx1g6jo5j42ccx36klIZ8ALsAt3SVPdDrZ4ao5+PAnLL8KeAWYK+yvhTYpY86\nXg7s2mwPsD0wpSwfBvxHWf48cEJZngV8rke9LwG2Bi4GDmqU/3n590XA94DdgCnA/cAEYCJwH7BF\nV32zgFMb6zOBC55Hn32n0UfXAzc12nt/n3Xs1NKeXYEJZfksYHZZvgvYuSxfDBzao95pwObNfQF4\ncWccgenAvWX5COCrjf1pWadfR9onPdqzTh+37bd91vPvwBFl+dIyBluW9QeBzfuoY8eW9vwZMKks\nnwScUZavAt5Ylk8DTuxR75bAS4EFwE4t++nmwAPl372A20v5FOCnG6qvN8BYrTc2eEzpeUwZ8Hg9\n0Gu9zzreBXy+LL+3jFXnczYfmNlHHduRjzHNY86WwLZleU9gcVmeA3yyLM8EruhR78Qy5qcBx3aP\nVVm+EnhzWf4Z8NKyvADYY9Bj5FiOr7F0HB1Hx3Fkjw1y61pJlcdHxIsizyLs3/WSJUDnyuZrgPOA\ngyLPJmyfUvrZcNtIKf0SeK6r7FcppcfK6lPAM2X5HmCrsrw18JuImBR5tmH3iNgu8tXTrVJKf0op\n/a5le/eXf58Dni2PJ4BHgMnl8QTw9HBt7zZUW7petoS1ffQU8JOI2B3YH1jWz3ZSSj9vKXswpfRs\nWV2vz0q63hJYGREzIs8WTI6IN0fE1aWOR1NKTwITI1+Jnk8+cXtbqWsz4OURcStwKjCt1HsVMD0i\nbi7vbVHkq+MLIuJlpS9ujLUzHNuU/nogIk4v5Vf08967RXZt5Nmfl5SrBq/sellzP51ODpgHlNc9\nUt5zTymlX7SUPZxSWl1Wh9pPp5L302llf9i2XKFZFBGbpZT+kFJ6vKXu+8vi0+TPRyLvo09FxIvJ\nJ9Lr7d8jERGvKv11e0TcWMoujjJbERHHRsRpZXlBRHy2XPW5tey/z2ebHlPGiIj4SOfKYURcEhFv\n73rJYtaO1euBsxvrr6OP41lK6dcppae7yv6QUvpNWW2O1Y+Bl5Xlzli1fv5TSs+klH7Vsr37G6vN\nun8CTImIzcjHud8P1/axxLGsg+NYB8dxwxjy9qSGfSNiwTCv+SfgNnJH35pS6u7cZcBF5cQrAYuA\nLwArgDsBIuIA4DMtdc9NKd3Wa+MRsQX5qu7fl6JbgJsjYjYwCXhdSml1RLybfJX1D8A/ppSG7cjI\nt8D8tHPiFBE3APeSr8qemVJ6quXHZkfEwWV5K/JsyRp9tmUJ+crxCuDuss3Xk69CLy5tORE4umX7\nb2870ep6X3uQr1gfWIq+BtwE/B/ww5TSXeV15wIXAjOAQ1uq2gV4E/AksDwiLgduBOanlE6MPOX5\nTfJO/EryeJ5ZPrBLUkofi8hTl8Bc4PKU0tci4njgo8AHyfvp1SmlT5YT6L1SSiu62nF4Yz/dHFgn\nFKSUUtkfbiDPfHwppfS/XXUsAd4T+bakn5NnBt5KDj2dPj8S+IeWfjgppfSjlvI1ImI74APAIaXo\nP4FvRcSnyP3+zymlZyLiQ8Al5APKCUPsY90+Ru671RHxFHmW4D5gC/KVnhfiLeRZufMjop+LI3ek\nlE6JiPPJ7/W6ruc9poz8mDIoO3aN1fYtrzkLuD4ivgT8MaX0X80nU0oPR8T0iJhMPn59Bzi5fM5+\nm1J6IvLFhK+21H1+SumyXg2MiAnAPPJ4QT5ezo2IFeTj70F9fv7b6p5Z2ryoFF0KfJ98vLuyhOWx\nwrGsYywdR8cRcBz71mu6hxHcZkI+mVrFELf3kK/4H00+yQD4NnAK8P5ebeijPS8mn0j9baPsMvLJ\nPsA7gXMbz80Hbmyp+2Iat5mUsoPJJziTy/pfkE+iJpGvvt4J7Nj1M7Po89a1odpSntuCfKJ6CjlI\n7ABcRA4jrxpBn63TnlK2E/lEcbfmuAKvKMtfAY4qyxOAh4CPtNT9M8qUZlm/FPg38m1e3yNPP94L\nPFyevwNYUZYnAaeXn/kMOcHfCMwoz88Abuje54ALKLd7DdXHbftJ47lPAT/q0V8PAicA7yYHrOtK\nfxw+gj5fb8zJoWUxsH+j7LvAvmX5o8C/NJ5bCpzXUvcCGreulbLjgSsotwMCfwNcXcZua/JsxKR+\n29+yzankW7fmd/YD8oHzoLJ8HHBao32d/ehUyu1ew3yGPab0OKZs7Af5doQF3fts29j0GKtDyFfm\ndhji+cvLWF1S1r9VPmdnj7Ct622ffEz4QGP908AHy/IBwPWN51o//3TdXlHK9i772PSyPoV8nNyy\nfLauIwfeTTZWjuX4GEvH0XF0HDfcOG6oW9deDswGziwd0WYJ8GHyCRzk2zWOYu2V8gMi3/bS/Rjy\ny+vl6vKlwDUppWuaTwG/Lcu/IZ/sERGHkE9ifhsRbx3mPe0PnAG8I6X0RKPex1JKq0vZavL3JkZs\nuLaklP5Inro7kvy9lkeAncknRj8qdZw4RJ9t3WO708kzCSemlH7aeOpZ8kklwEpKn5F30vOAIyNi\n55Yqd4+Il0b+5QUzySfFVwFnpZRmAl9k7dWEp8kBDvL3hD6ZUjoW2IY8a3Ava2eYDizrrW9jqPfX\nS0TsVeq9NiJOHuJldwMnA0tTSs+Qr7L/NWW/jfyLGNr6fM8e251MDh6fTuvOTAS5r2Hd/XQ2+YR3\nRpkR6/We3gYcAxyX8i1RnXpXpXyL4mPkEDmhVz3DWJ1S+lBK6V3AIRHxavLtcJ0v5O/b9frUbOLz\n2aDHlE0npTQvpTQzpfSe5/PzZfbrdOB9wJeHeFlnrL5b1jufs85YvXKIsTpmmG2fDfwypXROs5j2\nsern89+pdwb5wtLfpZQ6dT1HvtXi8fLZWkU+3o0ajmVrvWNuLB3H1nodx3aO43CGSXi7MMzVV/KJ\n4E3AX5X1r9Ny9Zt8C9CzrP1y93vJJ/J9fSmdnIyXAI+Sr4juBryDfIvSgvI4p7z2VeW1C8gnQXsB\n25JPHqeS0+My8onay0p9jwDLgdNLHSvKo1N358r7Z8gzE8uAz7a0cxbDzOgM1ZaWur4I3N1Ynw9c\n22+KJX+5/h5yUr6mlM0j35bVeV+dX0ZwVGnTIuBa8snWTOCb5fm/JN9KNBF4Q+mzJ8i37CwGfkDe\nWZeU9V+X1y8sbVhIvj3rfaW+wxpjdHPpi+3L8iLyPtX5Mlz3jM7Mrve5Th/Tvt9OJh8Idi3v4TZg\nn5Y+O5k85du8SvHfI+jzM8kHml+UPtoC+BD54NDp84+X176x7EsLSnt2AHYv/bcZa2feppAD7i3k\nA8Biyi8uIO//dzXq3pH8mby49O9y4OR+2z/Ee5pdtrmI/OXBzYA9yphfSz5onVZeu4CyL5NndGZ5\nTHlhx5RBPlrGpu2q30Xk8AbwOfJtnN2v2ZscgF9d1g8hHy+m9dmOo0qf/qn8eyDwWvLFk05/fqO8\ndgfg1lK2jHx8GPLzT74C+mAZm6+UsuvIx81O3YeX8g+UMV9K/oxNGPQYOZbjaywdR8fRcRzZI8oG\npBGLiF3IAePgYV4qSZIkbVL+wVBJkiRJ1XFGR5IkSVJ1nNGRJEmSVB2DjiRJkqTqGHQkSZIkVWfi\noBvQtOxjr/ELQwO0/6d/+Lz+5km3yfvMcRwH6Invz9sg4wiO5aBtqLF0HAfLcayD41gH/4+sRz9j\n6YyOJEmSpOoYdCRJkiRVx6AjSZIkqToGHUmSJEnVMehIkiRJqo5BR5IkSVJ1DDqSJEmSqmPQkSRJ\nklSdUfUHQwVXHPGN9cqOvu6oAbREEsCq5fPWK5u635wBtESSJI2EMzqjSFvI6ZQP9Zykjact5HTK\nh3pOkiSNDgadUaKfIGPYkTadfoKMYUeSpNHLoDMKGGCk0cUAI0nS2GfQkSRJklQdg44kSZKk6hh0\nJEmSJFXHoCNJkiSpOgYdSZIkSdUx6IwC/kFQaXTxD4JKkjT2GXRGiX7CjoFI2nT6CTsGIkmSRi+D\nzigyVJA5+rqjDDnSAAwVZKbuN8eQI0nSKDdx0A3Qugw00uhioJEkaWxyRkeSJElSdQw6kiRJkqpj\n0JEkSZJUHYOOJEmSpOoYdCRJkiRVx6AjSZIkqToGHUmSJEnVMehIkiRJqo5BR5IkSVJ1DDqSJEmS\nqmPQkSRJklQdg44kSZKk6hh0JEmSJFXHoCNJkiSpOgYdSZIkSdUx6EiSJEmqjkFHkiRJUnUMOpIk\nSZKqY9CRJEmSVB2DjiRJkqTqGHQkSZIkVcegI0mSJKk6Bh1JkiRJ1THoSJIkSaqOQUeSJElSdQw6\nkiRJkqpj0JEkSZJUHYOOJEmSpOoYdCRJkiRVx6AjSZIkqToGHUmSJEnVMehIkiRJqo5BR5IkSVJ1\nDDqSJEmSqmPQkSRJklSdiYNuwHjwiTdus876GQtXDqgleiFm/+v711m/cO65A2qJJEmShuOMjiRJ\nkqTqGHQ2su7ZHI1N3bM5kiRJGt3GXdA5ZtrOax6bgrepbRyrls9b89gUvE1NkiRpbBl3QWcQOmHn\njIUrDT5jWCfsXDj3XIOPJEnSKDeufhlB9yzOMdN25rJHH9qo22zeutZZNuy8MN2zOKuWz2PqfnM2\n6jabt651lg07kiRJo9e4mtHpDjUbO+Ro4+gONRs75EiSJGnsGVdBB9aGG0PO2NYJN4YcSZIktRm3\nt651lg08Y0/z1rXOsoFHkiRJTeNuRkeSJElS/Qw6kiRJkqpj0JEkSZJUHYOOJEmSpOoYdCRJkiRV\nx6AjSZIkqToGHUmSJEnVMehIkiRJqo5BR5IkSVJ1Jg66AePBGQtXDroJ2gAunHvuoJsgSZKkPjmj\nI0mSJKk6Bh1JkiRJ1Rl3t65d9uhDa5aPmbbzAFuiF2LqfnPWLK9aPm+ALZEkSdJo5IyOJEmSpOoY\ndCRJkiRVx6AjSZIkqToGnY3MXy1dB3+1tCRJ0thi0JEkSZJUHYOOJEmSpOoYdCRJkiRVx6AjSZIk\nqTrjKug0/1ho27rGhuYfC21blyRJksZV0JEkSZI0Phh0JEmSJFXHoCNJkiSpOgYdSZIkSdUx6EiS\nJEmqjkFHkiRJUnUMOpIkSZKqEymlQbdBkiRJkjYoZ3QkSZIkVcegI0mSJKk6Bh1JkiRJ1THoSJIk\nSaqOQUeSJElSdQw6kiRJkqpj0JEkSZJUHYOOJEmSpOoYdCRJkiRVx6AjSZIkqToGHUmSJEnVMehI\nkiRJqo5BR5IkSVJ1DDqSJEmSqmPQkSRJklQdg44kSZKk6hh0JEmSJFXHoCNJkiSpOgYdSZIkSdUx\n6EiSJEmqjkFHkiRJUnUMOpIkSZKqY9CRJEmSVJ3/B1483GPHuAVnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x288 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAACLCAYAAACpz+z5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEOgAAAAAqJz/B78l/Q4AkgPMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x288 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAACLCAYAAACpz+z5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x288 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAACLCAYAAACpz+z5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x288 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train mrcnn model : `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:45.099746Z",
     "start_time": "2018-11-04T16:41:45.052190Z"
    }
   },
   "outputs": [],
   "source": [
    "# mrcnn_model.config.EPOCHS_TO_RUN = 1\n",
    "# mrcnn_model.config.STEPS_PER_EPOCH = 2\n",
    "# mrcnn_model.config.SYSOUT = 'screen'\n",
    " \n",
    "print('    last epoch ran : ',mrcnn_model.config.LAST_EPOCH_RAN)\n",
    "print('    epochs to run  : ',mrcnn_model.config.EPOCHS_TO_RUN)\n",
    "print('    steps per epoch: ',mrcnn_model.config.STEPS_PER_EPOCH)\n",
    "print('    learning rate  : ', mrcnn_model.config.LEARNING_RATE)\n",
    "print('    momentum       : ', mrcnn_model.config.LEARNING_MOMENTUM)\n",
    "print('    weight decay   : ',mrcnn_model.config.WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training mrcnn, fpn, rpn layers\n",
    "\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "- Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-16T18:02:08.415Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrcnn', 'fpn', 'rpn']\n",
      "['(mrcnn\\\\_.*)', '(fpn\\\\_.*)', '(rpn\\\\_.*)']\n",
      "layers regex : (mrcnn\\_.*)|(fpn\\_.*)|(rpn\\_.*)\n",
      "type train_dataset: <class 'mrcnn.newshapes.NewShapesDataset'>\n",
      "type val_dataset: <class 'mrcnn.newshapes.NewShapesDataset'>\n",
      "    learning rate :  0.001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_image            (InputLayer          )   ............................no weights to train ]\n",
      "   1  zero_padding2d_1       (ZeroPadding2D       )   ............................no weights to train ]\n",
      "   2  conv1                  (Conv2D              )   ............................not a layer we want to train ]\n",
      "   3  bn_conv1               (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   4  activation_1           (Activation          )   ............................no weights to train ]\n",
      "   5  max_pooling2d_1        (MaxPooling2D        )   ............................no weights to train ]\n",
      "   6  res2a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "   7  bn2a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   8  activation_2           (Activation          )   ............................no weights to train ]\n",
      "   9  res2a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  10  bn2a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  11  activation_3           (Activation          )   ............................no weights to train ]\n",
      "  12  res2a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  13  res2a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  14  bn2a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  15  bn2a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  16  add_1                  (Add                 )   ............................no weights to train ]\n",
      "  17  res2a_out              (Activation          )   ............................no weights to train ]\n",
      "  18  res2b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  19  bn2b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  20  activation_4           (Activation          )   ............................no weights to train ]\n",
      "  21  res2b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  22  bn2b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  23  activation_5           (Activation          )   ............................no weights to train ]\n",
      "  24  res2b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  25  bn2b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  26  add_2                  (Add                 )   ............................no weights to train ]\n",
      "  27  res2b_out              (Activation          )   ............................no weights to train ]\n",
      "  28  res2c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  29  bn2c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  30  activation_6           (Activation          )   ............................no weights to train ]\n",
      "  31  res2c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  32  bn2c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  33  activation_7           (Activation          )   ............................no weights to train ]\n",
      "  34  res2c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  35  bn2c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  36  add_3                  (Add                 )   ............................no weights to train ]\n",
      "  37  res2c_out              (Activation          )   ............................no weights to train ]\n",
      "  38  res3a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  39  bn3a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  40  activation_8           (Activation          )   ............................no weights to train ]\n",
      "  41  res3a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  42  bn3a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  43  activation_9           (Activation          )   ............................no weights to train ]\n",
      "  44  res3a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  45  res3a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  46  bn3a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  47  bn3a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  48  add_4                  (Add                 )   ............................no weights to train ]\n",
      "  49  res3a_out              (Activation          )   ............................no weights to train ]\n",
      "  50  res3b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  51  bn3b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  52  activation_10          (Activation          )   ............................no weights to train ]\n",
      "  53  res3b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  54  bn3b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  55  activation_11          (Activation          )   ............................no weights to train ]\n",
      "  56  res3b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  57  bn3b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  58  add_5                  (Add                 )   ............................no weights to train ]\n",
      "  59  res3b_out              (Activation          )   ............................no weights to train ]\n",
      "  60  res3c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  61  bn3c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  62  activation_12          (Activation          )   ............................no weights to train ]\n",
      "  63  res3c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  64  bn3c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  65  activation_13          (Activation          )   ............................no weights to train ]\n",
      "  66  res3c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  67  bn3c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  68  add_6                  (Add                 )   ............................no weights to train ]\n",
      "  69  res3c_out              (Activation          )   ............................no weights to train ]\n",
      "  70  res3d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  71  bn3d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  72  activation_14          (Activation          )   ............................no weights to train ]\n",
      "  73  res3d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  74  bn3d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  75  activation_15          (Activation          )   ............................no weights to train ]\n",
      "  76  res3d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  77  bn3d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  78  add_7                  (Add                 )   ............................no weights to train ]\n",
      "  79  res3d_out              (Activation          )   ............................no weights to train ]\n",
      "  80  res4a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  81  bn4a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  82  activation_16          (Activation          )   ............................no weights to train ]\n",
      "  83  res4a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  84  bn4a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  85  activation_17          (Activation          )   ............................no weights to train ]\n",
      "  86  res4a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  87  res4a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  88  bn4a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  89  bn4a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  90  add_8                  (Add                 )   ............................no weights to train ]\n",
      "  91  res4a_out              (Activation          )   ............................no weights to train ]\n",
      "  92  res4b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  93  bn4b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  94  activation_18          (Activation          )   ............................no weights to train ]\n",
      "  95  res4b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  96  bn4b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  97  activation_19          (Activation          )   ............................no weights to train ]\n",
      "  98  res4b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  99  bn4b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 100  add_9                  (Add                 )   ............................no weights to train ]\n",
      " 101  res4b_out              (Activation          )   ............................no weights to train ]\n",
      " 102  res4c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 103  bn4c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 104  activation_20          (Activation          )   ............................no weights to train ]\n",
      " 105  res4c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 106  bn4c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 107  activation_21          (Activation          )   ............................no weights to train ]\n",
      " 108  res4c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 109  bn4c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 110  add_10                 (Add                 )   ............................no weights to train ]\n",
      " 111  res4c_out              (Activation          )   ............................no weights to train ]\n",
      " 112  res4d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 113  bn4d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 114  activation_22          (Activation          )   ............................no weights to train ]\n",
      " 115  res4d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 116  bn4d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 117  activation_23          (Activation          )   ............................no weights to train ]\n",
      " 118  res4d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 119  bn4d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 120  add_11                 (Add                 )   ............................no weights to train ]\n",
      " 121  res4d_out              (Activation          )   ............................no weights to train ]\n",
      " 122  res4e_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 123  bn4e_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 124  activation_24          (Activation          )   ............................no weights to train ]\n",
      " 125  res4e_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 126  bn4e_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 127  activation_25          (Activation          )   ............................no weights to train ]\n",
      " 128  res4e_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 129  bn4e_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 130  add_12                 (Add                 )   ............................no weights to train ]\n",
      " 131  res4e_out              (Activation          )   ............................no weights to train ]\n",
      " 132  res4f_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 133  bn4f_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 134  activation_26          (Activation          )   ............................no weights to train ]\n",
      " 135  res4f_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 136  bn4f_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 137  activation_27          (Activation          )   ............................no weights to train ]\n",
      " 138  res4f_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 139  bn4f_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 140  add_13                 (Add                 )   ............................no weights to train ]\n",
      " 141  res4f_out              (Activation          )   ............................no weights to train ]\n",
      " 142  res4g_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 143  bn4g_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 144  activation_28          (Activation          )   ............................no weights to train ]\n",
      " 145  res4g_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 146  bn4g_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 147  activation_29          (Activation          )   ............................no weights to train ]\n",
      " 148  res4g_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 149  bn4g_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 150  add_14                 (Add                 )   ............................no weights to train ]\n",
      " 151  res4g_out              (Activation          )   ............................no weights to train ]\n",
      " 152  res4h_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 153  bn4h_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 154  activation_30          (Activation          )   ............................no weights to train ]\n",
      " 155  res4h_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 156  bn4h_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 157  activation_31          (Activation          )   ............................no weights to train ]\n",
      " 158  res4h_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 159  bn4h_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 160  add_15                 (Add                 )   ............................no weights to train ]\n",
      " 161  res4h_out              (Activation          )   ............................no weights to train ]\n",
      " 162  res4i_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 163  bn4i_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 164  activation_32          (Activation          )   ............................no weights to train ]\n",
      " 165  res4i_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 166  bn4i_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 167  activation_33          (Activation          )   ............................no weights to train ]\n",
      " 168  res4i_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 169  bn4i_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 170  add_16                 (Add                 )   ............................no weights to train ]\n",
      " 171  res4i_out              (Activation          )   ............................no weights to train ]\n",
      " 172  res4j_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 173  bn4j_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 174  activation_34          (Activation          )   ............................no weights to train ]\n",
      " 175  res4j_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 176  bn4j_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 177  activation_35          (Activation          )   ............................no weights to train ]\n",
      " 178  res4j_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 179  bn4j_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 180  add_17                 (Add                 )   ............................no weights to train ]\n",
      " 181  res4j_out              (Activation          )   ............................no weights to train ]\n",
      " 182  res4k_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 183  bn4k_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 184  activation_36          (Activation          )   ............................no weights to train ]\n",
      " 185  res4k_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 186  bn4k_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 187  activation_37          (Activation          )   ............................no weights to train ]\n",
      " 188  res4k_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 189  bn4k_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 190  add_18                 (Add                 )   ............................no weights to train ]\n",
      " 191  res4k_out              (Activation          )   ............................no weights to train ]\n",
      " 192  res4l_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 193  bn4l_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 194  activation_38          (Activation          )   ............................no weights to train ]\n",
      " 195  res4l_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 196  bn4l_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 197  activation_39          (Activation          )   ............................no weights to train ]\n",
      " 198  res4l_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 199  bn4l_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 200  add_19                 (Add                 )   ............................no weights to train ]\n",
      " 201  res4l_out              (Activation          )   ............................no weights to train ]\n",
      " 202  res4m_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 203  bn4m_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 204  activation_40          (Activation          )   ............................no weights to train ]\n",
      " 205  res4m_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 206  bn4m_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 207  activation_41          (Activation          )   ............................no weights to train ]\n",
      " 208  res4m_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 209  bn4m_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 210  add_20                 (Add                 )   ............................no weights to train ]\n",
      " 211  res4m_out              (Activation          )   ............................no weights to train ]\n",
      " 212  res4n_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 213  bn4n_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 214  activation_42          (Activation          )   ............................no weights to train ]\n",
      " 215  res4n_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 216  bn4n_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 217  activation_43          (Activation          )   ............................no weights to train ]\n",
      " 218  res4n_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 219  bn4n_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 220  add_21                 (Add                 )   ............................no weights to train ]\n",
      " 221  res4n_out              (Activation          )   ............................no weights to train ]\n",
      " 222  res4o_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 223  bn4o_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 224  activation_44          (Activation          )   ............................no weights to train ]\n",
      " 225  res4o_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 226  bn4o_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 227  activation_45          (Activation          )   ............................no weights to train ]\n",
      " 228  res4o_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 229  bn4o_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 230  add_22                 (Add                 )   ............................no weights to train ]\n",
      " 231  res4o_out              (Activation          )   ............................no weights to train ]\n",
      " 232  res4p_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 233  bn4p_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 234  activation_46          (Activation          )   ............................no weights to train ]\n",
      " 235  res4p_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 236  bn4p_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 237  activation_47          (Activation          )   ............................no weights to train ]\n",
      " 238  res4p_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 239  bn4p_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 240  add_23                 (Add                 )   ............................no weights to train ]\n",
      " 241  res4p_out              (Activation          )   ............................no weights to train ]\n",
      " 242  res4q_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 243  bn4q_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 244  activation_48          (Activation          )   ............................no weights to train ]\n",
      " 245  res4q_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 246  bn4q_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 247  activation_49          (Activation          )   ............................no weights to train ]\n",
      " 248  res4q_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 249  bn4q_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 250  add_24                 (Add                 )   ............................no weights to train ]\n",
      " 251  res4q_out              (Activation          )   ............................no weights to train ]\n",
      " 252  res4r_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 253  bn4r_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 254  activation_50          (Activation          )   ............................no weights to train ]\n",
      " 255  res4r_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 256  bn4r_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 257  activation_51          (Activation          )   ............................no weights to train ]\n",
      " 258  res4r_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 259  bn4r_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 260  add_25                 (Add                 )   ............................no weights to train ]\n",
      " 261  res4r_out              (Activation          )   ............................no weights to train ]\n",
      " 262  res4s_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 263  bn4s_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 264  activation_52          (Activation          )   ............................no weights to train ]\n",
      " 265  res4s_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 266  bn4s_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 267  activation_53          (Activation          )   ............................no weights to train ]\n",
      " 268  res4s_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 269  bn4s_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 270  add_26                 (Add                 )   ............................no weights to train ]\n",
      " 271  res4s_out              (Activation          )   ............................no weights to train ]\n",
      " 272  res4t_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 273  bn4t_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 274  activation_54          (Activation          )   ............................no weights to train ]\n",
      " 275  res4t_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 276  bn4t_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 277  activation_55          (Activation          )   ............................no weights to train ]\n",
      " 278  res4t_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 279  bn4t_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 280  add_27                 (Add                 )   ............................no weights to train ]\n",
      " 281  res4t_out              (Activation          )   ............................no weights to train ]\n",
      " 282  res4u_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 283  bn4u_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 284  activation_56          (Activation          )   ............................no weights to train ]\n",
      " 285  res4u_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 286  bn4u_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 287  activation_57          (Activation          )   ............................no weights to train ]\n",
      " 288  res4u_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 289  bn4u_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 290  add_28                 (Add                 )   ............................no weights to train ]\n",
      " 291  res4u_out              (Activation          )   ............................no weights to train ]\n",
      " 292  res4v_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 293  bn4v_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 294  activation_58          (Activation          )   ............................no weights to train ]\n",
      " 295  res4v_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 296  bn4v_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 297  activation_59          (Activation          )   ............................no weights to train ]\n",
      " 298  res4v_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 299  bn4v_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 300  add_29                 (Add                 )   ............................no weights to train ]\n",
      " 301  res4v_out              (Activation          )   ............................no weights to train ]\n",
      " 302  res4w_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 303  bn4w_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 304  activation_60          (Activation          )   ............................no weights to train ]\n",
      " 305  res4w_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 306  bn4w_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 307  activation_61          (Activation          )   ............................no weights to train ]\n",
      " 308  res4w_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 309  bn4w_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 310  add_30                 (Add                 )   ............................no weights to train ]\n",
      " 311  res4w_out              (Activation          )   ............................no weights to train ]\n",
      " 312  res5a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 313  bn5a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 314  activation_62          (Activation          )   ............................no weights to train ]\n",
      " 315  res5a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 316  bn5a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 317  activation_63          (Activation          )   ............................no weights to train ]\n",
      " 318  res5a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 319  res5a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      " 320  bn5a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 321  bn5a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 322  add_31                 (Add                 )   ............................no weights to train ]\n",
      " 323  res5a_out              (Activation          )   ............................no weights to train ]\n",
      " 324  res5b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 325  bn5b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 326  activation_64          (Activation          )   ............................no weights to train ]\n",
      " 327  res5b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 328  bn5b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 329  activation_65          (Activation          )   ............................no weights to train ]\n",
      " 330  res5b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 331  bn5b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 332  add_32                 (Add                 )   ............................no weights to train ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 333  res5b_out              (Activation          )   ............................no weights to train ]\n",
      " 334  res5c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 335  bn5c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 336  activation_66          (Activation          )   ............................no weights to train ]\n",
      " 337  res5c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 338  bn5c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 339  activation_67          (Activation          )   ............................no weights to train ]\n",
      " 340  res5c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 341  bn5c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 342  add_33                 (Add                 )   ............................no weights to train ]\n",
      " 343  res5c_out              (Activation          )   ............................no weights to train ]\n",
      " 344  fpn_c5p5               (Conv2D              )   TRAIN \n",
      " 345  fpn_p5upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 346  fpn_c4p4               (Conv2D              )   TRAIN \n",
      " 347  fpn_p4add              (Add                 )   ............................no weights to train ]\n",
      " 348  fpn_p4upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 349  fpn_c3p3               (Conv2D              )   TRAIN \n",
      " 350  fpn_p3add              (Add                 )   ............................no weights to train ]\n",
      " 351  fpn_p3upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 352  fpn_c2p2               (Conv2D              )   TRAIN \n",
      " 353  fpn_p2add              (Add                 )   ............................no weights to train ]\n",
      " 354  fpn_p5                 (Conv2D              )   TRAIN \n",
      " 355  fpn_p2                 (Conv2D              )   TRAIN \n",
      " 356  fpn_p3                 (Conv2D              )   TRAIN \n",
      " 357  fpn_p4                 (Conv2D              )   TRAIN \n",
      " 358  fpn_p6                 (MaxPooling2D        )   ............................no weights to train ]\n",
      "Entering model layer:  rpn_model ------------------------------\n",
      "       0  input_rpn_feature_map   (InputLayer          )   ............................no weights to train ]\n",
      "       1  rpn_conv_shared        (Conv2D              )   TRAIN \n",
      "       2  rpn_class_raw          (Conv2D              )   TRAIN \n",
      "       3  lambda_1               (Lambda              )   ............................no weights to train ]\n",
      "       4  rpn_bbox_pred          (Conv2D              )   TRAIN \n",
      "       5  rpn_class_xxx          (Activation          )   ............................no weights to train ]\n",
      "       6  lambda_2               (Lambda              )   ............................no weights to train ]\n",
      "Exiting model layer  rpn_model --------------------------------\n",
      " 360  rpn_class              (Lambda              )   ............................no weights to train ]\n",
      " 361  rpn_bbox               (Lambda              )   ............................no weights to train ]\n",
      " 362  input_gt_boxes         (InputLayer          )   ............................no weights to train ]\n",
      " 363  ROI                    (ProposalLayer       )   ............................no weights to train ]\n",
      " 364  input_gt_class_ids     (InputLayer          )   ............................no weights to train ]\n",
      " 365  input_normalized_gt_boxes   (Lambda              )   ............................no weights to train ]\n",
      " 366  proposal_targets       (DetectionTargetLayer)   ............................no weights to train ]\n",
      " 367  roi_align_classifier   (PyramidROIAlign     )   ............................no weights to train ]\n",
      " 368  mrcnn_class_conv1      (TimeDistributed     )   TRAIN \n",
      " 369  mrcnn_class_bn1        (TimeDistributed     )   TRAIN \n",
      " 370  activation_68          (Activation          )   ............................no weights to train ]\n",
      " 371  mrcnn_class_conv2      (TimeDistributed     )   TRAIN \n",
      " 372  mrcnn_class_bn2        (TimeDistributed     )   TRAIN \n",
      " 373  activation_69          (Activation          )   ............................no weights to train ]\n",
      " 374  pool_squeeze           (Lambda              )   ............................no weights to train ]\n",
      " 375  mrcnn_class_logits     (TimeDistributed     )   TRAIN \n",
      " 376  mrcnn_logits_lambda    (Lambda              )   ............................no weights to train ]\n",
      " 377  mrcnn_bbox_fc          (TimeDistributed     )   TRAIN \n",
      " 378  mrcnn_class_act        (TimeDistributed     )   ............................no weights to train ]\n",
      " 379  mrcnn_bbox_rs          (Reshape             )   ............................no weights to train ]\n",
      " 380  input_image_meta       (InputLayer          )   ............................no weights to train ]\n",
      " 381  mrcnn_class_lambda     (Lambda              )   ............................no weights to train ]\n",
      " 382  mrcnn_bbox_lambda      (Lambda              )   ............................no weights to train ]\n",
      " 383  active_class_ids       (Lambda              )   ............................no weights to train ]\n",
      " 384  input_rpn_match        (InputLayer          )   ............................no weights to train ]\n",
      " 385  rpn_class_logits       (Lambda              )   ............................no weights to train ]\n",
      " 386  input_rpn_bbox         (InputLayer          )   ............................no weights to train ]\n",
      " 387  cntxt_layer            (CHMLayer            )   ............................no weights to train ]\n",
      " 388  cntxt_layer_gt         (CHMLayerTarget      )   ............................no weights to train ]\n",
      " 389  rpn_class_loss         (Lambda              )   ............................no weights to train ]\n",
      " 390  rpn_bbox_loss          (Lambda              )   ............................no weights to train ]\n",
      " 391  mrcnn_class_loss       (Lambda              )   ............................no weights to train ]\n",
      " 392  mrcnn_bbox_loss        (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  0.001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    optimizer     :  <keras.optimizers.Adagrad object at 0x000000722CF0CDD8>\n",
      "    learning rate :  0.001\n",
      "    momentum      :  0.9\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    keras_model.losses           : []\n",
      "\n",
      "    Loss: rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_class_loss/rpn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_bbox_loss/rpn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_class_loss/mrcnn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_bbox_loss/mrcnn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      "Keras model.losses : \n",
      "---------------------\n",
      "   Tensor(\"Mean_8:0\", shape=(1, 1), dtype=float32)    name: Mean_8:0\n",
      "   Tensor(\"Mean_10:0\", shape=(1, 1), dtype=float32)    name: Mean_10:0\n",
      "   Tensor(\"Mean_9:0\", shape=(1, 1), dtype=float32)    name: Mean_9:0\n",
      "   Tensor(\"Mean_11:0\", shape=(1, 1), dtype=float32)    name: Mean_11:0\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "   Tensor(\"Mean_8:0\", shape=(1, 1), dtype=float32)    name: Mean_8:0\n",
      "   Tensor(\"Mean_9:0\", shape=(1, 1), dtype=float32)    name: Mean_9:0\n",
      "   Tensor(\"Mean_10:0\", shape=(1, 1), dtype=float32)    name: Mean_10:0\n",
      "   Tensor(\"Mean_11:0\", shape=(1, 1), dtype=float32)    name: Mean_11:0\n",
      "\n",
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "   None    name: <class 'NoneType'>\n",
      "{   None: [   <tf.Tensor 'Mean_8:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_9:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_10:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_11:0' shape=(1, 1) dtype=float32>]}\n",
      "\n",
      "L2 Regularization losses:\n",
      "-------------------------\n",
      "   Tensor(\"truediv_30:0\", shape=(), dtype=float32)    name: truediv_30:0\n",
      "   Tensor(\"truediv_31:0\", shape=(), dtype=float32)    name: truediv_31:0\n",
      "   Tensor(\"truediv_32:0\", shape=(), dtype=float32)    name: truediv_32:0\n",
      "   Tensor(\"truediv_33:0\", shape=(), dtype=float32)    name: truediv_33:0\n",
      "   Tensor(\"truediv_34:0\", shape=(), dtype=float32)    name: truediv_34:0\n",
      "   Tensor(\"truediv_35:0\", shape=(), dtype=float32)    name: truediv_35:0\n",
      "   Tensor(\"truediv_36:0\", shape=(), dtype=float32)    name: truediv_36:0\n",
      "   Tensor(\"truediv_37:0\", shape=(), dtype=float32)    name: truediv_37:0\n",
      "   Tensor(\"truediv_38:0\", shape=(), dtype=float32)    name: truediv_38:0\n",
      "   Tensor(\"truediv_39:0\", shape=(), dtype=float32)    name: truediv_39:0\n",
      "   Tensor(\"truediv_40:0\", shape=(), dtype=float32)    name: truediv_40:0\n",
      "   Tensor(\"truediv_41:0\", shape=(), dtype=float32)    name: truediv_41:0\n",
      "   Tensor(\"truediv_42:0\", shape=(), dtype=float32)    name: truediv_42:0\n",
      "   Tensor(\"truediv_43:0\", shape=(), dtype=float32)    name: truediv_43:0\n",
      "   Tensor(\"truediv_44:0\", shape=(), dtype=float32)    name: truediv_44:0\n",
      "   Tensor(\"truediv_45:0\", shape=(), dtype=float32)    name: truediv_45:0\n",
      "   Tensor(\"truediv_46:0\", shape=(), dtype=float32)    name: truediv_46:0\n",
      "   Tensor(\"truediv_47:0\", shape=(), dtype=float32)    name: truediv_47:0\n",
      "   Tensor(\"truediv_48:0\", shape=(), dtype=float32)    name: truediv_48:0\n",
      "   Tensor(\"truediv_49:0\", shape=(), dtype=float32)    name: truediv_49:0\n",
      "   Tensor(\"truediv_50:0\", shape=(), dtype=float32)    name: truediv_50:0\n",
      "   Tensor(\"truediv_51:0\", shape=(), dtype=float32)    name: truediv_51:0\n",
      "   Tensor(\"truediv_52:0\", shape=(), dtype=float32)    name: truediv_52:0\n",
      "   Tensor(\"truediv_53:0\", shape=(), dtype=float32)    name: truediv_53:0\n",
      "   Tensor(\"truediv_54:0\", shape=(), dtype=float32)    name: truediv_54:0\n",
      "   Tensor(\"truediv_55:0\", shape=(), dtype=float32)    name: truediv_55:0\n",
      "   Tensor(\"truediv_56:0\", shape=(), dtype=float32)    name: truediv_56:0\n",
      "   Tensor(\"truediv_57:0\", shape=(), dtype=float32)    name: truediv_57:0\n",
      "   Tensor(\"truediv_58:0\", shape=(), dtype=float32)    name: truediv_58:0\n",
      "   Tensor(\"truediv_59:0\", shape=(), dtype=float32)    name: truediv_59:0\n",
      "\n",
      "    Final list of keras_model.losses \n",
      "    -------------------------------- \n",
      "[   <tf.Tensor 'Mean_8:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_10:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'AddN_1:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'Mean_9:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_11:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      " Length of Keras_Model.outputs: 16\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add metric  rpn_class_loss  with metric tensor:  rpn_class_loss/rpn_class_loss:0  to list of metrics ...\n",
      "    Loss name : rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add metric  rpn_bbox_loss  with metric tensor:  rpn_bbox_loss/rpn_bbox_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add metric  mrcnn_class_loss  with metric tensor:  mrcnn_class_loss/mrcnn_class_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add metric  mrcnn_bbox_loss  with metric tensor:  mrcnn_bbox_loss/mrcnn_bbox_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names:\n",
      " -------------------------\n",
      "['loss', 'rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "\n",
      "Starting at epoch   2 of 22 epochs. LR=0.001\n",
      "\n",
      "Steps per epoch     32 \n",
      "Batch size          1 \n",
      "Checkpoint Path:    F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_{epoch:04d}.h5 \n",
      "Learning Rate       0.001 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    8 \n",
      "REDUCE_LR_FACTOR    0.5 \n",
      "REDUCE_LR_COOLDOWN  30 \n",
      "REDUCE_LR_PATIENCE  40 \n",
      "MIN_LR              1e-10 \n",
      "EARLY_STOP_PATIENCE 80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/22\n",
      "32/32 [==============================] - 169s 5s/step - loss: 25.7922 - rpn_class_loss: 0.3293 - rpn_bbox_loss: 2.4993 - mrcnn_class_loss: 11.2732 - mrcnn_bbox_loss: 11.6904 - val_loss: 2.6448 - val_rpn_class_loss: 0.1454 - val_rpn_bbox_loss: 1.0258 - val_mrcnn_class_loss: 0.9672 - val_mrcnn_bbox_loss: 0.5064\n",
      "\n",
      "Epoch 00003: val_loss improved from inf to 2.64483, saving model to F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0003.h5\n",
      "Epoch 4/22\n",
      "32/32 [==============================] - 154s 5s/step - loss: 2.3262 - rpn_class_loss: 0.0962 - rpn_bbox_loss: 0.9055 - mrcnn_class_loss: 0.6943 - mrcnn_bbox_loss: 0.6303 - val_loss: 2.7235 - val_rpn_class_loss: 0.1066 - val_rpn_bbox_loss: 0.7313 - val_mrcnn_class_loss: 0.9525 - val_mrcnn_bbox_loss: 0.9331\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.64483\n",
      "Epoch 5/22\n",
      "32/32 [==============================] - 148s 5s/step - loss: 1.9916 - rpn_class_loss: 0.0801 - rpn_bbox_loss: 0.7675 - mrcnn_class_loss: 0.5365 - mrcnn_bbox_loss: 0.6074 - val_loss: 2.1315 - val_rpn_class_loss: 0.1090 - val_rpn_bbox_loss: 0.6634 - val_mrcnn_class_loss: 0.7816 - val_mrcnn_bbox_loss: 0.5775\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.64483 to 2.13148, saving model to F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0005.h5\n",
      "Epoch 6/22\n",
      "32/32 [==============================] - 149s 5s/step - loss: 1.8283 - rpn_class_loss: 0.0849 - rpn_bbox_loss: 0.7836 - mrcnn_class_loss: 0.4601 - mrcnn_bbox_loss: 0.4996 - val_loss: 1.7501 - val_rpn_class_loss: 0.1000 - val_rpn_bbox_loss: 0.6370 - val_mrcnn_class_loss: 0.5521 - val_mrcnn_bbox_loss: 0.4610\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.13148 to 1.75010, saving model to F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0006.h5\n",
      "Epoch 7/22\n",
      "32/32 [==============================] - 153s 5s/step - loss: 1.8045 - rpn_class_loss: 0.0832 - rpn_bbox_loss: 0.7805 - mrcnn_class_loss: 0.4367 - mrcnn_bbox_loss: 0.5041 - val_loss: 1.9968 - val_rpn_class_loss: 0.0872 - val_rpn_bbox_loss: 0.6356 - val_mrcnn_class_loss: 0.5616 - val_mrcnn_bbox_loss: 0.7124\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.75010\n",
      "Epoch 8/22\n",
      "32/32 [==============================] - 138s 4s/step - loss: 1.5748 - rpn_class_loss: 0.0694 - rpn_bbox_loss: 0.7394 - mrcnn_class_loss: 0.3021 - mrcnn_bbox_loss: 0.4640 - val_loss: 1.8579 - val_rpn_class_loss: 0.0789 - val_rpn_bbox_loss: 0.6743 - val_mrcnn_class_loss: 0.5888 - val_mrcnn_bbox_loss: 0.5159\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.75010\n",
      "Epoch 9/22\n",
      "32/32 [==============================] - 133s 4s/step - loss: 1.7151 - rpn_class_loss: 0.0707 - rpn_bbox_loss: 0.7723 - mrcnn_class_loss: 0.4050 - mrcnn_bbox_loss: 0.4670 - val_loss: 1.4498 - val_rpn_class_loss: 0.0791 - val_rpn_bbox_loss: 0.6310 - val_mrcnn_class_loss: 0.3719 - val_mrcnn_bbox_loss: 0.3678\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.75010 to 1.44979, saving model to F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0009.h5\n",
      "Epoch 10/22\n",
      "32/32 [==============================] - 136s 4s/step - loss: 1.5691 - rpn_class_loss: 0.0719 - rpn_bbox_loss: 0.7220 - mrcnn_class_loss: 0.3506 - mrcnn_bbox_loss: 0.4246 - val_loss: 1.4618 - val_rpn_class_loss: 0.0778 - val_rpn_bbox_loss: 0.6447 - val_mrcnn_class_loss: 0.3204 - val_mrcnn_bbox_loss: 0.4190\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.44979\n",
      "Epoch 11/22\n",
      "32/32 [==============================] - 14771s 462s/step - loss: 1.4193 - rpn_class_loss: 0.0556 - rpn_bbox_loss: 0.6469 - mrcnn_class_loss: 0.2984 - mrcnn_bbox_loss: 0.4184 - val_loss: 1.4348 - val_rpn_class_loss: 0.0818 - val_rpn_bbox_loss: 0.6504 - val_mrcnn_class_loss: 0.3055 - val_mrcnn_bbox_loss: 0.3971\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.44979 to 1.43481, saving model to F:\\models\\train_mrcnn_newshapes\\mrcnn20181216T1631\\mrcnn_0011.h5\n",
      "Epoch 12/22\n",
      "32/32 [==============================] - 135s 4s/step - loss: 1.4561 - rpn_class_loss: 0.0623 - rpn_bbox_loss: 0.7433 - mrcnn_class_loss: 0.2846 - mrcnn_bbox_loss: 0.3660 - val_loss: 1.6099 - val_rpn_class_loss: 0.0798 - val_rpn_bbox_loss: 0.7229 - val_mrcnn_class_loss: 0.3408 - val_mrcnn_bbox_loss: 0.4664\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.43481\n",
      "Epoch 13/22\n",
      "32/32 [==============================] - 149s 5s/step - loss: 1.3063 - rpn_class_loss: 0.0617 - rpn_bbox_loss: 0.6447 - mrcnn_class_loss: 0.2459 - mrcnn_bbox_loss: 0.3540 - val_loss: 1.5473 - val_rpn_class_loss: 0.0764 - val_rpn_bbox_loss: 0.6594 - val_mrcnn_class_loss: 0.4015 - val_mrcnn_bbox_loss: 0.4100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.43481\n",
      "Epoch 14/22\n",
      "19/32 [================>.............] - ETA: 57s - loss: 1.3429 - rpn_class_loss: 0.0568 - rpn_bbox_loss: 0.6850 - mrcnn_class_loss: 0.2574 - mrcnn_bbox_loss: 0.3437 "
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# Wed 09-05-2018\n",
    "# config.STEPS_PER_EPOCH        = 8\n",
    "# config.EARLY_STOP_PATIENCE    = 70\n",
    "train_layers = [ 'mrcnn', 'fpn','rpn']   ## equivalent to \"heads\"\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "# train_layers = [ 'mrcnn']\n",
    "# loss_names   = [ \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "mrcnn_model.config.LAST_EPOCH_RAN = 2\n",
    "mrcnn_model.config.EPOCHS_TO_RUN  = 20\n",
    "mrcnn_model.config.LEARNING_RATE   = 0.001\n",
    "# mrcnn_model.config.STEPS_PER_EPOCH = config.STEPS_PER_EPOCH\n",
    "\n",
    "mrcnn_model.epoch = mrcnn_model.config.LAST_EPOCH_RAN\n",
    "mrcnn_model.train(dataset_train, \n",
    "            dataset_val, \n",
    "            learning_rate = mrcnn_model.config.LEARNING_RATE, \n",
    "            epochs_to_run = mrcnn_model.config.EPOCHS_TO_RUN,\n",
    "            layers = train_layers,\n",
    "            losses = loss_names)                  \n",
    "#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers\n",
    "\n",
    "    - #### Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Heatmaps `pr_heatmap` and `gt_heatmap`\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:34:26.381655Z",
     "start_time": "2018-04-24T12:34:25.980564Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[0:2,2:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:49:29.945015Z",
     "start_time": "2018-04-24T13:49:29.457701Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 1 # <==== Class to display\n",
    "pred_tensor = layers_out[19]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)dd\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:39:14.676360Z",
     "start_time": "2018-04-24T12:39:14.435714Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[0][0] * [128, 128,128,128]   #output_rois*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:03:44.110249Z",
     "start_time": "2018-04-24T15:03:38.231280Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]\n",
    "target_masks        = layers_out[27][0:3]\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print(tf.shape(less_than_one).eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Mean values of GT, Pred, and FCN heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:52:02.002508Z",
     "start_time": "2018-04-24T14:51:42.964543Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "pred_masks = tf.identity(layers_out[24])\n",
    "gt_masks = tf.identity(layers_out[27])\n",
    "fcn_masks = tf.identity(layers_out[12])\n",
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        gt_mean = K.mean(gt_masks[img,:,:,cls])\n",
    "        fcn_mean= K.mean(fcn_masks[img,:,:,cls])\n",
    "        pred_mean= K.mean(pred_masks[img,:,:,cls])\n",
    "        print('Img/Cls: ', img, '/', cls,'    gtmean: ', gt_mean.eval(), '\\t fcn : ' , fcn_mean.eval(), '\\t pred :', pred_mean.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF]",
   "language": "python",
   "name": "conda-env-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
