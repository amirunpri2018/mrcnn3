{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Train on NewShapes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:40:51.096547Z",
     "start_time": "2018-11-04T16:40:43.043028Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Execution started at: 11-04-2018 @ 16:40:51\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.1.6 \n",
      "--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 --mrcnn_logs_dir train_mrcnn_newshapes --fcn_logs_dir   train_fcn8_newshapes --mrcnn_model    last --fcn_model      init --opt            adagrad --fcn_arch       fcn8 --fcn_layers     all --sysout        screen --new_log_folder    \n",
      "    MRCNN Model        :  last\n",
      "    FCN Model          :  init\n",
      "    MRCNN Log Dir      :  train_mrcnn_newshapes\n",
      "    FCN Log Dir        :  train_fcn8_newshapes\n",
      "    FCN Arch           :  FCN8\n",
      "    FCN Log Dir        :  ['all']\n",
      "    Last Epoch         :  0\n",
      "    Epochs to run      :  2\n",
      "    Steps in each epoch:  32\n",
      "    Validation steps   :  8\n",
      "    Batch Size         :  1\n",
      "    Optimizer          :  ADAGRAD\n",
      "    sysout             :  SCREEN\n",
      ">>> Initialize Paths\n",
      " Linx  Linux\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DIR_DATASET                    /home/kbardool/MLDatasets\n",
      "DIR_PRETRAINED                 /home/kbardool/PretrainedModels\n",
      "DIR_ROOT                       /home/kbardool/git_projs/mrcnn3/notebooks\n",
      "DIR_TRAINING                   /home/kbardool/models\n",
      "FCN_TRAINING_PATH              /home/kbardool/models/train_fcn8_newshapes\n",
      "FCN_VGG16_MODEL_PATH           /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            /home/kbardool/models/train_mrcnn_newshapes\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "import mrcnn.utils        as utils\n",
    "\n",
    "from datetime           import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "# from mrcnn.utils        import log, stack_tensors, stack_tensors_3d, write_stdout\n",
    "from mrcnn.datagen      import data_generator, load_image_gt, data_gen_simulate\n",
    "# from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.prep_notebook import mrcnn_newshape_train, prep_newshape_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "####  Pass input parameters to argparse\n",
    "\n",
    "# args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 1264 --batch_size 8  --lr 0.5               --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())\n",
    "# input_parms = \"--epochs 100 --steps_in_epoch 100  --last_epoch 1264 --batch_size 25 --lr 0.8 --val_steps 5 --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "# input_parms +=\" --model     /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 \"\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \"--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 \" \n",
    "input_parms +=\"--mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_newshapes \"\n",
    "input_parms +=\"--mrcnn_model    last \"\n",
    "input_parms +=\"--fcn_model      init \"\n",
    "input_parms +=\"--opt            adagrad \"\n",
    "input_parms +=\"--fcn_arch       fcn8 \" \n",
    "input_parms +=\"--fcn_layers     all \" \n",
    "input_parms +=\"--sysout        screen \"\n",
    "input_parms +=\"--new_log_folder    \"\n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## if debug is true set stdout destination to stringIO\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "# debug = False\n",
    "if args.sysout == 'FILE':\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "# print(\"    Dataset            : \", args.dataset)\n",
    "# print(\"    Logs               : \", args.logs)\n",
    "# print(\"    Limit              : \", args.limit)\n",
    "print(\"    MRCNN Model        : \", args.mrcnn_model)\n",
    "print(\"    FCN Model          : \", args.fcn_model)\n",
    "print(\"    MRCNN Log Dir      : \", args.mrcnn_logs_dir)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_logs_dir)\n",
    "print(\"    FCN Arch           : \", args.fcn_arch)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_layers)\n",
    "print(\"    Last Epoch         : \", args.last_epoch)\n",
    "print(\"    Epochs to run      : \", args.epochs)\n",
    "print(\"    Steps in each epoch: \", args.steps_in_epoch)\n",
    "print(\"    Validation steps   : \", args.val_steps)\n",
    "print(\"    Batch Size         : \", args.batch_size)\n",
    "print(\"    Optimizer          : \", args.opt)\n",
    "print(\"    sysout             : \", args.sysout)\n",
    "# print(\"    OS Platform        : \", syst)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "##   ROOT_DIR         : Root directory of the project \n",
    "##   MODEL_DIR        : Directory to save logs and trained model\n",
    "##   COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "##---------------------------------------------------------------------------------\n",
    "paths = Paths(fcn_training_folder = args.fcn_logs_dir, mrcnn_training_folder = args.mrcnn_logs_dir)\n",
    "paths.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Configuration Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:40:51.189783Z",
     "start_time": "2018-11-04T16:40:51.099330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                32\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  /home/kbardool/models/train_mrcnn_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------                          \n",
    "# mrcnn_config                    = CocoConfig()\n",
    "import mrcnn.new_shapes as new_shapes\n",
    "mrcnn_config = new_shapes.NewShapesConfig()\n",
    "\n",
    "mrcnn_config.NAME               = 'mrcnn'              \n",
    "mrcnn_config.TRAINING_PATH      = paths.MRCNN_TRAINING_PATH\n",
    "mrcnn_config.COCO_DATASET_PATH  = paths.COCO_DATASET_PATH \n",
    "mrcnn_config.COCO_MODEL_PATH    = paths.COCO_MODEL_PATH   \n",
    "mrcnn_config.RESNET_MODEL_PATH  = paths.RESNET_MODEL_PATH \n",
    "mrcnn_config.VGG16_MODEL_PATH   = paths.VGG16_MODEL_PATH  \n",
    "mrcnn_config.COCO_CLASSES       = None \n",
    "mrcnn_config.DETECTION_PER_CLASS = 200\n",
    "mrcnn_config.HEATMAP_SCALE_FACTOR = 4\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "\n",
    "mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "mrcnn_config.VALIDATION_STEPS   = int(args.val_steps)\n",
    "mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "mrcnn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "mrcnn_config.MIN_LR             = 1.0e-10\n",
    "mrcnn_config.OPTIMIZER          = args.opt.upper()\n",
    "mrcnn_config.NEW_LOG_FOLDER       = True\n",
    "mrcnn_config.SYSOUT               = args.sysout\n",
    "mrcnn_config.display() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:40:58.571908Z",
     "start_time": "2018-11-04T16:40:51.192848Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  /home/kbardool/models/train_mrcnn_newshapes\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  training\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                  NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640/mrcnn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     C1 Shape: (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "     C2 Shape:  (?, 32, 32, 256) (?, 32, 32, 256)\n",
      "     C3 Shape:  (?, 16, 16, 512) (?, 16, 16, 512)\n",
      "     C4 Shape:  (?, 8, 8, 1024) (?, 8, 8, 1024)\n",
      "     C5 Shape:  (?, 4, 4, 2048) (?, 4, 4, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "     append Tensor(\"fpn_p2/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p3/BiasAdd:0\", shape=(?, 16, 16, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p4/BiasAdd:0\", shape=(?, 8, 8, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p5/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p6/MaxPool:0\", shape=(?, 2, 2, 256), dtype=float32) to layer_outputs \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (1, 4092)\n",
      "     Deltas :  (1, 4092, 4)\n",
      "     Anchors:  (1, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (1, ?, ?) (1, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (1, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     INPUT: rois shape          : (1, ?, ?)\n",
      "     INPUT: No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     INPUT: image_shape         : [128 128   3]\n",
      "     INPUT: pool_size           : 7\n",
      "     INPUT: num_classes         : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 7)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 7)\n",
      "     mrcnn_bbox_fc        output shape is :  (?, 32, 28)\n",
      "     mrcnn_bbox_fc        reshaped output :  (?, 32, 28)\n",
      "     mrcnn_bbox           output shape is :  (?, 32, 7, 4)\n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "  > CHMLayer Call()  3\n",
      "    mrcnn_class.shape    : (?, 32, 7) (None, 32, 7)\n",
      "    mrcnn_bbox.shape     : (?, 32, 7, 4) (None, 32, 7, 4)\n",
      "    output_rois.shape    : (1, ?, ?) (None, 32, 4)\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois               :  32\n",
      "    norm_input_rois.shape  :  <class 'tensorflow.python.framework.ops.Tensor'> (None, 32, 4)\n",
      "    scale.shape            :  <class 'tensorflow.python.framework.ops.Tensor'> (4,) (4,)\n",
      "    dup_scale.shape        :  <class 'tensorflow.python.framework.ops.Tensor'> (1, 32, 4) (1, 32, 4)\n",
      "\n",
      "    mrcnn_class shape      :  (None, 32, 7)\n",
      "    mrcnn_bbox.shape       :  (None, 32, 7, 4) (?, 32, 7, 4)\n",
      "    config image shape     :  [128 128   3] h: 128 w: 128\n",
      "    refined rois clipped   :  (1, 32, 4)\n",
      "    input_rois.shape       :  (1, 32, 4) (1, 32, 4)\n",
      "    refined_rois.shape     :  (1, 32, 4) (1, 32, 4)\n",
      "    shape of sequence      :  (?, 32, 1)\n",
      "    pred_array             :  (1, 32, 7)\n",
      "    scatter_ind            :  <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 32, 3)\n",
      "    pred_scatter           :  (1, 7, 32, 7)\n",
      "    - Add normalized score --\n",
      "\n",
      "    normalizer             :  (1, 7, 1)\n",
      "    norm_score             :  (1, 7, 32, 1)\n",
      "    pred_scatter           :  (1, 7, 32, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    roi_grid shape         :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    roi_grid_exp           :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32, 1)\n",
      "    gather_inds            :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32, 3)\n",
      "    pred_tensor            :  (1, 7, 32, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['pred_heatmap']\n",
      "    in_tensor shape        :  (1, 7, 32, 8)\n",
      "    num bboxes per class   :  32\n",
      "    heatmap scale        :  4 Dimensions:  w: 32  h: 32\n",
      "    pt2_sum shape  :  (1, 7, 32)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "    X/Y shapes : (32, 32) (32, 32)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (32, 32) =  (?, 32, 32)\n",
      "    ones_exp * Y (?, 1, 1) * (32, 32) =  (?, 32, 32)\n",
      "    pos_grid before transpse :  (?, 32, 32, 2)\n",
      "    pos_grid after transpose :  (32, 32, ?, 2)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (32, 32, ?, 2)\n",
      "     Prob_grid shape from mvn.probe:  (32, 32, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 32, 32)\n",
      "    << output probabilities shape  :  (?, 32, 32)\n",
      "    scores_scattered shape :  (1, 7, 32, 3)\n",
      "    gauss_scores  (FINAL)  :  (1, 7, 32, 11)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer     :  (?, 1, 1)\n",
      "    prob_grid_norm_scaled :  (?, 32, 32)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape      :  (?, 3)\n",
      "    prob_grid_clippped :  (?, 32, 32)\n",
      "    gauss_heatmap      :  (1, 7, 32, 32, 32)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 7, 32, 32) Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer shape   :  (1, 7, 1, 1)\n",
      "    normalized heatmap :  (1, 7, 32, 32)  Keras tensor  False\n",
      "    reshaped heatmap :  (1, 32, 32, 7)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    pred_refined_heatmap        :  (1, 32, 32, 7) Keras tensor  False\n",
      "    pred_refnined_heatmap_scores:  (1, 7, 32, 11) Keras tensor  False\n",
      "    complete\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "  > CHMLayerTgt Call()  2\n",
      "    tgt_class_ids.shape  : (1, ?) (None, 32)\n",
      "    tgt_bboxes.shape     : (1, ?, ?) (None, 32, 4)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    num_bboxes             :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape     :  (1, ?)    (None, 32)\n",
      "    norm_gt_bboxes.shape   :  (1, ?, ?)    (None, 32, 4)\n",
      "    gt_bboxes.shape        :  (1, 32, 4)    (1, 32, 4)\n",
      "    gt_classes_exp         :  (1, ?, 1)\n",
      "    gt_scores_exp          :  (1, ?, 1)\n",
      "    gt_array shape         :  (1, 32, 8) (1, 32, 8)\n",
      "    scatter_ind shape      :  (1, 32, 3) (1, 32, 3)\n",
      "    tf.shape(gt_array)[-1] :  8 (1, 32, 8)\n",
      "    gt_scatter shape       :  (1, 7, 32, 8) (1, 7, 32, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 7, 32)\n",
      "    gather_inds            :  (1, 7, 32, 3)\n",
      "    gt_tensor.shape        :  (1, 7, 32, 8) (1, 7, 32, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    in_tensor shape        :  (1, 7, 32, 8)\n",
      "    num bboxes per class   :  32\n",
      "    heatmap scale        :  4 Dimensions:  w: 32  h: 32\n",
      "    pt2_sum shape  :  (1, 7, 32)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prob_grid shape :  (?, 32, 32)\n",
      "    prob_grid_clipped      :  (?, 32, 32)\n",
      "    scores_scattered shape :  (1, 7, 32, 3)\n",
      "    gauss_scores           :  (1, 7, 32, 11)  Name:    cntxt_layer_gt/gt_heatmap_scores:0\n",
      "    gauss_scores  (FINAL)  :  (1, 7, 32, 11)  Keras tensor  False\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 32, 32)\n",
      "    gauss_heatmap   :  (1, 7, 32, 32, 32)\n",
      "\n",
      "    Reduce MAX based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 7, 32, 32) Keras tensor  False\n",
      "    gauss_heatmap :  (1, 32, 32, 7)  Keras tensor  False\n",
      "\n",
      "    gt_heatmap                  :  (1, 32, 32, 7) Keras tensor  False\n",
      "    gt_heatmap_scores           :  (1, 7, 32, 11) Keras tensor  False\n",
      "    complete\n",
      "<<<  shape of pred_heatmap   :  (1, 32, 32, 7)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (1, 32, 32, 7)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape_3:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape_3:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (1, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      "[]\n",
      " ================================================================\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  training\n",
      ">>> MaskRCNN initialiation complete. Mode:  training\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer:  1    output name: rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer:  2    output name: mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.prep_notebook import mrcnn_newshape_train\n",
    "mrcnn_model, mrcnn_config = mrcnn_newshape_train(mode = 'training', mrcnn_config = mrcnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:09.787439Z",
     "start_time": "2018-11-04T16:41:03.519122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ coco ]\n",
      " Exclude layers: \n",
      "    -  mrcnn_class_logits\n",
      "    -  mrcnn_bbox_fc\n",
      "-----------------------------------------------\n",
      " ---> coco : /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      ">>> load_weights() from : /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "layers type:  <class 'list'> length:  385\n",
      "=====================================================================\n",
      " Weight Matchup between model and HDF5 weights \n",
      "=====================================================================\n",
      "\n",
      "  0 input_image               Model Layer Name/Type : [['input_image', 'InputLayer']] \n",
      "\n",
      "  1 zero_padding2d_1          Model Layer Name/Type : [['zero_padding2d_1', 'ZeroPadding2D']] \n",
      "\n",
      "  2 conv1                     Model Layer Name/Type : [['conv1', 'Conv2D']] \n",
      "    0 conv1/kernel:0                       hdf5 Weights: (7, 7, 3, 64)  \t\t Symbolic Wghts: (7, 7, 3, 64)   \n",
      "    1 conv1/bias:0                         hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      "  3 bn_conv1                  Model Layer Name/Type : [['bn_conv1', 'BatchNorm']] \n",
      "    0 bn_conv1/gamma:0                     hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn_conv1/beta:0                      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn_conv1/moving_mean:0               hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn_conv1/moving_variance:0           hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      "  4 activation_1              Model Layer Name/Type : [['activation_1', 'Activation']] \n",
      "\n",
      "  5 max_pooling2d_1           Model Layer Name/Type : [['max_pooling2d_1', 'MaxPooling2D']] \n",
      "\n",
      "  6 res2a_branch2a            Model Layer Name/Type : [['res2a_branch2a', 'Conv2D']] \n",
      "    0 res2a_branch2a/kernel:0              hdf5 Weights: (1, 1, 64, 64)  \t\t Symbolic Wghts: (1, 1, 64, 64)   \n",
      "    1 res2a_branch2a/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      "  7 bn2a_branch2a             Model Layer Name/Type : [['bn2a_branch2a', 'BatchNorm']] \n",
      "    0 bn2a_branch2a/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2a_branch2a/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2a_branch2a/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2a_branch2a/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      "  8 activation_2              Model Layer Name/Type : [['activation_2', 'Activation']] \n",
      "\n",
      "  9 res2a_branch2b            Model Layer Name/Type : [['res2a_branch2b', 'Conv2D']] \n",
      "    0 res2a_branch2b/kernel:0              hdf5 Weights: (3, 3, 64, 64)  \t\t Symbolic Wghts: (3, 3, 64, 64)   \n",
      "    1 res2a_branch2b/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 10 bn2a_branch2b             Model Layer Name/Type : [['bn2a_branch2b', 'BatchNorm']] \n",
      "    0 bn2a_branch2b/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2a_branch2b/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2a_branch2b/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2a_branch2b/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 11 activation_3              Model Layer Name/Type : [['activation_3', 'Activation']] \n",
      "\n",
      " 12 res2a_branch2c            Model Layer Name/Type : [['res2a_branch2c', 'Conv2D']] \n",
      "    0 res2a_branch2c/kernel:0              hdf5 Weights: (1, 1, 64, 256)  \t\t Symbolic Wghts: (1, 1, 64, 256)   \n",
      "    1 res2a_branch2c/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 13 res2a_branch1             Model Layer Name/Type : [['res2a_branch1', 'Conv2D']] \n",
      "    0 res2a_branch1/kernel:0               hdf5 Weights: (1, 1, 64, 256)  \t\t Symbolic Wghts: (1, 1, 64, 256)   \n",
      "    1 res2a_branch1/bias:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 14 bn2a_branch2c             Model Layer Name/Type : [['bn2a_branch2c', 'BatchNorm']] \n",
      "    0 bn2a_branch2c/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn2a_branch2c/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn2a_branch2c/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn2a_branch2c/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 15 bn2a_branch1              Model Layer Name/Type : [['bn2a_branch1', 'BatchNorm']] \n",
      "    0 bn2a_branch1/gamma:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn2a_branch1/beta:0                  hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn2a_branch1/moving_mean:0           hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn2a_branch1/moving_variance:0       hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 16 add_1                     Model Layer Name/Type : [['add_1', 'Add']] \n",
      "\n",
      " 17 res2a_out                 Model Layer Name/Type : [['res2a_out', 'Activation']] \n",
      "\n",
      " 18 res2b_branch2a            Model Layer Name/Type : [['res2b_branch2a', 'Conv2D']] \n",
      "    0 res2b_branch2a/kernel:0              hdf5 Weights: (1, 1, 256, 64)  \t\t Symbolic Wghts: (1, 1, 256, 64)   \n",
      "    1 res2b_branch2a/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 19 bn2b_branch2a             Model Layer Name/Type : [['bn2b_branch2a', 'BatchNorm']] \n",
      "    0 bn2b_branch2a/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2b_branch2a/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2b_branch2a/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2b_branch2a/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 20 activation_4              Model Layer Name/Type : [['activation_4', 'Activation']] \n",
      "\n",
      " 21 res2b_branch2b            Model Layer Name/Type : [['res2b_branch2b', 'Conv2D']] \n",
      "    0 res2b_branch2b/kernel:0              hdf5 Weights: (3, 3, 64, 64)  \t\t Symbolic Wghts: (3, 3, 64, 64)   \n",
      "    1 res2b_branch2b/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 22 bn2b_branch2b             Model Layer Name/Type : [['bn2b_branch2b', 'BatchNorm']] \n",
      "    0 bn2b_branch2b/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2b_branch2b/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2b_branch2b/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2b_branch2b/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 23 activation_5              Model Layer Name/Type : [['activation_5', 'Activation']] \n",
      "\n",
      " 24 res2b_branch2c            Model Layer Name/Type : [['res2b_branch2c', 'Conv2D']] \n",
      "    0 res2b_branch2c/kernel:0              hdf5 Weights: (1, 1, 64, 256)  \t\t Symbolic Wghts: (1, 1, 64, 256)   \n",
      "    1 res2b_branch2c/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 25 bn2b_branch2c             Model Layer Name/Type : [['bn2b_branch2c', 'BatchNorm']] \n",
      "    0 bn2b_branch2c/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn2b_branch2c/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn2b_branch2c/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn2b_branch2c/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 26 add_2                     Model Layer Name/Type : [['add_2', 'Add']] \n",
      "\n",
      " 27 res2b_out                 Model Layer Name/Type : [['res2b_out', 'Activation']] \n",
      "\n",
      " 28 res2c_branch2a            Model Layer Name/Type : [['res2c_branch2a', 'Conv2D']] \n",
      "    0 res2c_branch2a/kernel:0              hdf5 Weights: (1, 1, 256, 64)  \t\t Symbolic Wghts: (1, 1, 256, 64)   \n",
      "    1 res2c_branch2a/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 29 bn2c_branch2a             Model Layer Name/Type : [['bn2c_branch2a', 'BatchNorm']] \n",
      "    0 bn2c_branch2a/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2c_branch2a/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2c_branch2a/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2c_branch2a/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 30 activation_6              Model Layer Name/Type : [['activation_6', 'Activation']] \n",
      "\n",
      " 31 res2c_branch2b            Model Layer Name/Type : [['res2c_branch2b', 'Conv2D']] \n",
      "    0 res2c_branch2b/kernel:0              hdf5 Weights: (3, 3, 64, 64)  \t\t Symbolic Wghts: (3, 3, 64, 64)   \n",
      "    1 res2c_branch2b/bias:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 32 bn2c_branch2b             Model Layer Name/Type : [['bn2c_branch2b', 'BatchNorm']] \n",
      "    0 bn2c_branch2b/gamma:0                hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    1 bn2c_branch2b/beta:0                 hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    2 bn2c_branch2b/moving_mean:0          hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "    3 bn2c_branch2b/moving_variance:0      hdf5 Weights: (64,)  \t\t Symbolic Wghts: (64,)   \n",
      "\n",
      " 33 activation_7              Model Layer Name/Type : [['activation_7', 'Activation']] \n",
      "\n",
      " 34 res2c_branch2c            Model Layer Name/Type : [['res2c_branch2c', 'Conv2D']] \n",
      "    0 res2c_branch2c/kernel:0              hdf5 Weights: (1, 1, 64, 256)  \t\t Symbolic Wghts: (1, 1, 64, 256)   \n",
      "    1 res2c_branch2c/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 35 bn2c_branch2c             Model Layer Name/Type : [['bn2c_branch2c', 'BatchNorm']] \n",
      "    0 bn2c_branch2c/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn2c_branch2c/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn2c_branch2c/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn2c_branch2c/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 36 add_3                     Model Layer Name/Type : [['add_3', 'Add']] \n",
      "\n",
      " 37 res2c_out                 Model Layer Name/Type : [['res2c_out', 'Activation']] \n",
      "\n",
      " 38 res3a_branch2a            Model Layer Name/Type : [['res3a_branch2a', 'Conv2D']] \n",
      "    0 res3a_branch2a/kernel:0              hdf5 Weights: (1, 1, 256, 128)  \t\t Symbolic Wghts: (1, 1, 256, 128)   \n",
      "    1 res3a_branch2a/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 39 bn3a_branch2a             Model Layer Name/Type : [['bn3a_branch2a', 'BatchNorm']] \n",
      "    0 bn3a_branch2a/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3a_branch2a/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3a_branch2a/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3a_branch2a/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 40 activation_8              Model Layer Name/Type : [['activation_8', 'Activation']] \n",
      "\n",
      " 41 res3a_branch2b            Model Layer Name/Type : [['res3a_branch2b', 'Conv2D']] \n",
      "    0 res3a_branch2b/kernel:0              hdf5 Weights: (3, 3, 128, 128)  \t\t Symbolic Wghts: (3, 3, 128, 128)   \n",
      "    1 res3a_branch2b/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 42 bn3a_branch2b             Model Layer Name/Type : [['bn3a_branch2b', 'BatchNorm']] \n",
      "    0 bn3a_branch2b/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3a_branch2b/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3a_branch2b/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3a_branch2b/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 43 activation_9              Model Layer Name/Type : [['activation_9', 'Activation']] \n",
      "\n",
      " 44 res3a_branch2c            Model Layer Name/Type : [['res3a_branch2c', 'Conv2D']] \n",
      "    0 res3a_branch2c/kernel:0              hdf5 Weights: (1, 1, 128, 512)  \t\t Symbolic Wghts: (1, 1, 128, 512)   \n",
      "    1 res3a_branch2c/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 45 res3a_branch1             Model Layer Name/Type : [['res3a_branch1', 'Conv2D']] \n",
      "    0 res3a_branch1/kernel:0               hdf5 Weights: (1, 1, 256, 512)  \t\t Symbolic Wghts: (1, 1, 256, 512)   \n",
      "    1 res3a_branch1/bias:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 46 bn3a_branch2c             Model Layer Name/Type : [['bn3a_branch2c', 'BatchNorm']] \n",
      "    0 bn3a_branch2c/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn3a_branch2c/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn3a_branch2c/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn3a_branch2c/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 47 bn3a_branch1              Model Layer Name/Type : [['bn3a_branch1', 'BatchNorm']] \n",
      "    0 bn3a_branch1/gamma:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn3a_branch1/beta:0                  hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn3a_branch1/moving_mean:0           hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn3a_branch1/moving_variance:0       hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 48 add_4                     Model Layer Name/Type : [['add_4', 'Add']] \n",
      "\n",
      " 49 res3a_out                 Model Layer Name/Type : [['res3a_out', 'Activation']] \n",
      "\n",
      " 50 res3b_branch2a            Model Layer Name/Type : [['res3b_branch2a', 'Conv2D']] \n",
      "    0 res3b_branch2a/kernel:0              hdf5 Weights: (1, 1, 512, 128)  \t\t Symbolic Wghts: (1, 1, 512, 128)   \n",
      "    1 res3b_branch2a/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 51 bn3b_branch2a             Model Layer Name/Type : [['bn3b_branch2a', 'BatchNorm']] \n",
      "    0 bn3b_branch2a/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3b_branch2a/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3b_branch2a/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3b_branch2a/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 52 activation_10             Model Layer Name/Type : [['activation_10', 'Activation']] \n",
      "\n",
      " 53 res3b_branch2b            Model Layer Name/Type : [['res3b_branch2b', 'Conv2D']] \n",
      "    0 res3b_branch2b/kernel:0              hdf5 Weights: (3, 3, 128, 128)  \t\t Symbolic Wghts: (3, 3, 128, 128)   \n",
      "    1 res3b_branch2b/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 54 bn3b_branch2b             Model Layer Name/Type : [['bn3b_branch2b', 'BatchNorm']] \n",
      "    0 bn3b_branch2b/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3b_branch2b/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3b_branch2b/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3b_branch2b/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 55 activation_11             Model Layer Name/Type : [['activation_11', 'Activation']] \n",
      "\n",
      " 56 res3b_branch2c            Model Layer Name/Type : [['res3b_branch2c', 'Conv2D']] \n",
      "    0 res3b_branch2c/kernel:0              hdf5 Weights: (1, 1, 128, 512)  \t\t Symbolic Wghts: (1, 1, 128, 512)   \n",
      "    1 res3b_branch2c/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 57 bn3b_branch2c             Model Layer Name/Type : [['bn3b_branch2c', 'BatchNorm']] \n",
      "    0 bn3b_branch2c/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn3b_branch2c/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn3b_branch2c/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn3b_branch2c/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 58 add_5                     Model Layer Name/Type : [['add_5', 'Add']] \n",
      "\n",
      " 59 res3b_out                 Model Layer Name/Type : [['res3b_out', 'Activation']] \n",
      "\n",
      " 60 res3c_branch2a            Model Layer Name/Type : [['res3c_branch2a', 'Conv2D']] \n",
      "    0 res3c_branch2a/kernel:0              hdf5 Weights: (1, 1, 512, 128)  \t\t Symbolic Wghts: (1, 1, 512, 128)   \n",
      "    1 res3c_branch2a/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 61 bn3c_branch2a             Model Layer Name/Type : [['bn3c_branch2a', 'BatchNorm']] \n",
      "    0 bn3c_branch2a/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3c_branch2a/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3c_branch2a/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3c_branch2a/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 62 activation_12             Model Layer Name/Type : [['activation_12', 'Activation']] \n",
      "\n",
      " 63 res3c_branch2b            Model Layer Name/Type : [['res3c_branch2b', 'Conv2D']] \n",
      "    0 res3c_branch2b/kernel:0              hdf5 Weights: (3, 3, 128, 128)  \t\t Symbolic Wghts: (3, 3, 128, 128)   \n",
      "    1 res3c_branch2b/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 64 bn3c_branch2b             Model Layer Name/Type : [['bn3c_branch2b', 'BatchNorm']] \n",
      "    0 bn3c_branch2b/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3c_branch2b/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3c_branch2b/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3c_branch2b/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 65 activation_13             Model Layer Name/Type : [['activation_13', 'Activation']] \n",
      "\n",
      " 66 res3c_branch2c            Model Layer Name/Type : [['res3c_branch2c', 'Conv2D']] \n",
      "    0 res3c_branch2c/kernel:0              hdf5 Weights: (1, 1, 128, 512)  \t\t Symbolic Wghts: (1, 1, 128, 512)   \n",
      "    1 res3c_branch2c/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 67 bn3c_branch2c             Model Layer Name/Type : [['bn3c_branch2c', 'BatchNorm']] \n",
      "    0 bn3c_branch2c/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn3c_branch2c/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn3c_branch2c/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn3c_branch2c/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 68 add_6                     Model Layer Name/Type : [['add_6', 'Add']] \n",
      "\n",
      " 69 res3c_out                 Model Layer Name/Type : [['res3c_out', 'Activation']] \n",
      "\n",
      " 70 res3d_branch2a            Model Layer Name/Type : [['res3d_branch2a', 'Conv2D']] \n",
      "    0 res3d_branch2a/kernel:0              hdf5 Weights: (1, 1, 512, 128)  \t\t Symbolic Wghts: (1, 1, 512, 128)   \n",
      "    1 res3d_branch2a/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 71 bn3d_branch2a             Model Layer Name/Type : [['bn3d_branch2a', 'BatchNorm']] \n",
      "    0 bn3d_branch2a/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3d_branch2a/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3d_branch2a/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3d_branch2a/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 72 activation_14             Model Layer Name/Type : [['activation_14', 'Activation']] \n",
      "\n",
      " 73 res3d_branch2b            Model Layer Name/Type : [['res3d_branch2b', 'Conv2D']] \n",
      "    0 res3d_branch2b/kernel:0              hdf5 Weights: (3, 3, 128, 128)  \t\t Symbolic Wghts: (3, 3, 128, 128)   \n",
      "    1 res3d_branch2b/bias:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 74 bn3d_branch2b             Model Layer Name/Type : [['bn3d_branch2b', 'BatchNorm']] \n",
      "    0 bn3d_branch2b/gamma:0                hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    1 bn3d_branch2b/beta:0                 hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    2 bn3d_branch2b/moving_mean:0          hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "    3 bn3d_branch2b/moving_variance:0      hdf5 Weights: (128,)  \t\t Symbolic Wghts: (128,)   \n",
      "\n",
      " 75 activation_15             Model Layer Name/Type : [['activation_15', 'Activation']] \n",
      "\n",
      " 76 res3d_branch2c            Model Layer Name/Type : [['res3d_branch2c', 'Conv2D']] \n",
      "    0 res3d_branch2c/kernel:0              hdf5 Weights: (1, 1, 128, 512)  \t\t Symbolic Wghts: (1, 1, 128, 512)   \n",
      "    1 res3d_branch2c/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 77 bn3d_branch2c             Model Layer Name/Type : [['bn3d_branch2c', 'BatchNorm']] \n",
      "    0 bn3d_branch2c/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn3d_branch2c/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn3d_branch2c/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn3d_branch2c/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      " 78 add_7                     Model Layer Name/Type : [['add_7', 'Add']] \n",
      "\n",
      " 79 res3d_out                 Model Layer Name/Type : [['res3d_out', 'Activation']] \n",
      "\n",
      " 80 res4a_branch2a            Model Layer Name/Type : [['res4a_branch2a', 'Conv2D']] \n",
      "    0 res4a_branch2a/kernel:0              hdf5 Weights: (1, 1, 512, 256)  \t\t Symbolic Wghts: (1, 1, 512, 256)   \n",
      "    1 res4a_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 81 bn4a_branch2a             Model Layer Name/Type : [['bn4a_branch2a', 'BatchNorm']] \n",
      "    0 bn4a_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4a_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4a_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4a_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 82 activation_16             Model Layer Name/Type : [['activation_16', 'Activation']] \n",
      "\n",
      " 83 res4a_branch2b            Model Layer Name/Type : [['res4a_branch2b', 'Conv2D']] \n",
      "    0 res4a_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4a_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 84 bn4a_branch2b             Model Layer Name/Type : [['bn4a_branch2b', 'BatchNorm']] \n",
      "    0 bn4a_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4a_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4a_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4a_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 85 activation_17             Model Layer Name/Type : [['activation_17', 'Activation']] \n",
      "\n",
      " 86 res4a_branch2c            Model Layer Name/Type : [['res4a_branch2c', 'Conv2D']] \n",
      "    0 res4a_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4a_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      " 87 res4a_branch1             Model Layer Name/Type : [['res4a_branch1', 'Conv2D']] \n",
      "    0 res4a_branch1/kernel:0               hdf5 Weights: (1, 1, 512, 1024)  \t\t Symbolic Wghts: (1, 1, 512, 1024)   \n",
      "    1 res4a_branch1/bias:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      " 88 bn4a_branch2c             Model Layer Name/Type : [['bn4a_branch2c', 'BatchNorm']] \n",
      "    0 bn4a_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4a_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4a_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4a_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      " 89 bn4a_branch1              Model Layer Name/Type : [['bn4a_branch1', 'BatchNorm']] \n",
      "    0 bn4a_branch1/gamma:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4a_branch1/beta:0                  hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4a_branch1/moving_mean:0           hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4a_branch1/moving_variance:0       hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      " 90 add_8                     Model Layer Name/Type : [['add_8', 'Add']] \n",
      "\n",
      " 91 res4a_out                 Model Layer Name/Type : [['res4a_out', 'Activation']] \n",
      "\n",
      " 92 res4b_branch2a            Model Layer Name/Type : [['res4b_branch2a', 'Conv2D']] \n",
      "    0 res4b_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4b_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 93 bn4b_branch2a             Model Layer Name/Type : [['bn4b_branch2a', 'BatchNorm']] \n",
      "    0 bn4b_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4b_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4b_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4b_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 94 activation_18             Model Layer Name/Type : [['activation_18', 'Activation']] \n",
      "\n",
      " 95 res4b_branch2b            Model Layer Name/Type : [['res4b_branch2b', 'Conv2D']] \n",
      "    0 res4b_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4b_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 96 bn4b_branch2b             Model Layer Name/Type : [['bn4b_branch2b', 'BatchNorm']] \n",
      "    0 bn4b_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4b_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4b_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4b_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      " 97 activation_19             Model Layer Name/Type : [['activation_19', 'Activation']] \n",
      "\n",
      " 98 res4b_branch2c            Model Layer Name/Type : [['res4b_branch2c', 'Conv2D']] \n",
      "    0 res4b_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4b_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      " 99 bn4b_branch2c             Model Layer Name/Type : [['bn4b_branch2c', 'BatchNorm']] \n",
      "    0 bn4b_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4b_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4b_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4b_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "100 add_9                     Model Layer Name/Type : [['add_9', 'Add']] \n",
      "\n",
      "101 res4b_out                 Model Layer Name/Type : [['res4b_out', 'Activation']] \n",
      "\n",
      "102 res4c_branch2a            Model Layer Name/Type : [['res4c_branch2a', 'Conv2D']] \n",
      "    0 res4c_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4c_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "103 bn4c_branch2a             Model Layer Name/Type : [['bn4c_branch2a', 'BatchNorm']] \n",
      "    0 bn4c_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4c_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4c_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4c_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "104 activation_20             Model Layer Name/Type : [['activation_20', 'Activation']] \n",
      "\n",
      "105 res4c_branch2b            Model Layer Name/Type : [['res4c_branch2b', 'Conv2D']] \n",
      "    0 res4c_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4c_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "106 bn4c_branch2b             Model Layer Name/Type : [['bn4c_branch2b', 'BatchNorm']] \n",
      "    0 bn4c_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4c_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4c_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4c_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "107 activation_21             Model Layer Name/Type : [['activation_21', 'Activation']] \n",
      "\n",
      "108 res4c_branch2c            Model Layer Name/Type : [['res4c_branch2c', 'Conv2D']] \n",
      "    0 res4c_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4c_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "109 bn4c_branch2c             Model Layer Name/Type : [['bn4c_branch2c', 'BatchNorm']] \n",
      "    0 bn4c_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4c_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4c_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4c_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "110 add_10                    Model Layer Name/Type : [['add_10', 'Add']] \n",
      "\n",
      "111 res4c_out                 Model Layer Name/Type : [['res4c_out', 'Activation']] \n",
      "\n",
      "112 res4d_branch2a            Model Layer Name/Type : [['res4d_branch2a', 'Conv2D']] \n",
      "    0 res4d_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4d_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "113 bn4d_branch2a             Model Layer Name/Type : [['bn4d_branch2a', 'BatchNorm']] \n",
      "    0 bn4d_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4d_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4d_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4d_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "114 activation_22             Model Layer Name/Type : [['activation_22', 'Activation']] \n",
      "\n",
      "115 res4d_branch2b            Model Layer Name/Type : [['res4d_branch2b', 'Conv2D']] \n",
      "    0 res4d_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4d_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "116 bn4d_branch2b             Model Layer Name/Type : [['bn4d_branch2b', 'BatchNorm']] \n",
      "    0 bn4d_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4d_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4d_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4d_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "117 activation_23             Model Layer Name/Type : [['activation_23', 'Activation']] \n",
      "\n",
      "118 res4d_branch2c            Model Layer Name/Type : [['res4d_branch2c', 'Conv2D']] \n",
      "    0 res4d_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4d_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "119 bn4d_branch2c             Model Layer Name/Type : [['bn4d_branch2c', 'BatchNorm']] \n",
      "    0 bn4d_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4d_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4d_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4d_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "120 add_11                    Model Layer Name/Type : [['add_11', 'Add']] \n",
      "\n",
      "121 res4d_out                 Model Layer Name/Type : [['res4d_out', 'Activation']] \n",
      "\n",
      "122 res4e_branch2a            Model Layer Name/Type : [['res4e_branch2a', 'Conv2D']] \n",
      "    0 res4e_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4e_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "123 bn4e_branch2a             Model Layer Name/Type : [['bn4e_branch2a', 'BatchNorm']] \n",
      "    0 bn4e_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4e_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4e_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4e_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "124 activation_24             Model Layer Name/Type : [['activation_24', 'Activation']] \n",
      "\n",
      "125 res4e_branch2b            Model Layer Name/Type : [['res4e_branch2b', 'Conv2D']] \n",
      "    0 res4e_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4e_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "126 bn4e_branch2b             Model Layer Name/Type : [['bn4e_branch2b', 'BatchNorm']] \n",
      "    0 bn4e_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4e_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4e_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4e_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "127 activation_25             Model Layer Name/Type : [['activation_25', 'Activation']] \n",
      "\n",
      "128 res4e_branch2c            Model Layer Name/Type : [['res4e_branch2c', 'Conv2D']] \n",
      "    0 res4e_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4e_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "129 bn4e_branch2c             Model Layer Name/Type : [['bn4e_branch2c', 'BatchNorm']] \n",
      "    0 bn4e_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4e_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4e_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4e_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "130 add_12                    Model Layer Name/Type : [['add_12', 'Add']] \n",
      "\n",
      "131 res4e_out                 Model Layer Name/Type : [['res4e_out', 'Activation']] \n",
      "\n",
      "132 res4f_branch2a            Model Layer Name/Type : [['res4f_branch2a', 'Conv2D']] \n",
      "    0 res4f_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4f_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "133 bn4f_branch2a             Model Layer Name/Type : [['bn4f_branch2a', 'BatchNorm']] \n",
      "    0 bn4f_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4f_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4f_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4f_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "134 activation_26             Model Layer Name/Type : [['activation_26', 'Activation']] \n",
      "\n",
      "135 res4f_branch2b            Model Layer Name/Type : [['res4f_branch2b', 'Conv2D']] \n",
      "    0 res4f_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4f_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "136 bn4f_branch2b             Model Layer Name/Type : [['bn4f_branch2b', 'BatchNorm']] \n",
      "    0 bn4f_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4f_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4f_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4f_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "137 activation_27             Model Layer Name/Type : [['activation_27', 'Activation']] \n",
      "\n",
      "138 res4f_branch2c            Model Layer Name/Type : [['res4f_branch2c', 'Conv2D']] \n",
      "    0 res4f_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4f_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "139 bn4f_branch2c             Model Layer Name/Type : [['bn4f_branch2c', 'BatchNorm']] \n",
      "    0 bn4f_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4f_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4f_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4f_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "140 add_13                    Model Layer Name/Type : [['add_13', 'Add']] \n",
      "\n",
      "141 res4f_out                 Model Layer Name/Type : [['res4f_out', 'Activation']] \n",
      "\n",
      "142 res4g_branch2a            Model Layer Name/Type : [['res4g_branch2a', 'Conv2D']] \n",
      "    0 res4g_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4g_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "143 bn4g_branch2a             Model Layer Name/Type : [['bn4g_branch2a', 'BatchNorm']] \n",
      "    0 bn4g_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4g_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4g_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4g_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "144 activation_28             Model Layer Name/Type : [['activation_28', 'Activation']] \n",
      "\n",
      "145 res4g_branch2b            Model Layer Name/Type : [['res4g_branch2b', 'Conv2D']] \n",
      "    0 res4g_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4g_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "146 bn4g_branch2b             Model Layer Name/Type : [['bn4g_branch2b', 'BatchNorm']] \n",
      "    0 bn4g_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4g_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4g_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4g_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "147 activation_29             Model Layer Name/Type : [['activation_29', 'Activation']] \n",
      "\n",
      "148 res4g_branch2c            Model Layer Name/Type : [['res4g_branch2c', 'Conv2D']] \n",
      "    0 res4g_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4g_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "149 bn4g_branch2c             Model Layer Name/Type : [['bn4g_branch2c', 'BatchNorm']] \n",
      "    0 bn4g_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4g_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4g_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4g_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "150 add_14                    Model Layer Name/Type : [['add_14', 'Add']] \n",
      "\n",
      "151 res4g_out                 Model Layer Name/Type : [['res4g_out', 'Activation']] \n",
      "\n",
      "152 res4h_branch2a            Model Layer Name/Type : [['res4h_branch2a', 'Conv2D']] \n",
      "    0 res4h_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4h_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "153 bn4h_branch2a             Model Layer Name/Type : [['bn4h_branch2a', 'BatchNorm']] \n",
      "    0 bn4h_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4h_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4h_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4h_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "154 activation_30             Model Layer Name/Type : [['activation_30', 'Activation']] \n",
      "\n",
      "155 res4h_branch2b            Model Layer Name/Type : [['res4h_branch2b', 'Conv2D']] \n",
      "    0 res4h_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4h_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "156 bn4h_branch2b             Model Layer Name/Type : [['bn4h_branch2b', 'BatchNorm']] \n",
      "    0 bn4h_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4h_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4h_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4h_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "157 activation_31             Model Layer Name/Type : [['activation_31', 'Activation']] \n",
      "\n",
      "158 res4h_branch2c            Model Layer Name/Type : [['res4h_branch2c', 'Conv2D']] \n",
      "    0 res4h_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4h_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "159 bn4h_branch2c             Model Layer Name/Type : [['bn4h_branch2c', 'BatchNorm']] \n",
      "    0 bn4h_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4h_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4h_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4h_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "160 add_15                    Model Layer Name/Type : [['add_15', 'Add']] \n",
      "\n",
      "161 res4h_out                 Model Layer Name/Type : [['res4h_out', 'Activation']] \n",
      "\n",
      "162 res4i_branch2a            Model Layer Name/Type : [['res4i_branch2a', 'Conv2D']] \n",
      "    0 res4i_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4i_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "163 bn4i_branch2a             Model Layer Name/Type : [['bn4i_branch2a', 'BatchNorm']] \n",
      "    0 bn4i_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4i_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4i_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4i_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "164 activation_32             Model Layer Name/Type : [['activation_32', 'Activation']] \n",
      "\n",
      "165 res4i_branch2b            Model Layer Name/Type : [['res4i_branch2b', 'Conv2D']] \n",
      "    0 res4i_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4i_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "166 bn4i_branch2b             Model Layer Name/Type : [['bn4i_branch2b', 'BatchNorm']] \n",
      "    0 bn4i_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4i_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4i_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4i_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "167 activation_33             Model Layer Name/Type : [['activation_33', 'Activation']] \n",
      "\n",
      "168 res4i_branch2c            Model Layer Name/Type : [['res4i_branch2c', 'Conv2D']] \n",
      "    0 res4i_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4i_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "169 bn4i_branch2c             Model Layer Name/Type : [['bn4i_branch2c', 'BatchNorm']] \n",
      "    0 bn4i_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4i_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4i_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4i_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "170 add_16                    Model Layer Name/Type : [['add_16', 'Add']] \n",
      "\n",
      "171 res4i_out                 Model Layer Name/Type : [['res4i_out', 'Activation']] \n",
      "\n",
      "172 res4j_branch2a            Model Layer Name/Type : [['res4j_branch2a', 'Conv2D']] \n",
      "    0 res4j_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4j_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "173 bn4j_branch2a             Model Layer Name/Type : [['bn4j_branch2a', 'BatchNorm']] \n",
      "    0 bn4j_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4j_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4j_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4j_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "174 activation_34             Model Layer Name/Type : [['activation_34', 'Activation']] \n",
      "\n",
      "175 res4j_branch2b            Model Layer Name/Type : [['res4j_branch2b', 'Conv2D']] \n",
      "    0 res4j_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4j_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "176 bn4j_branch2b             Model Layer Name/Type : [['bn4j_branch2b', 'BatchNorm']] \n",
      "    0 bn4j_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4j_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 bn4j_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4j_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "177 activation_35             Model Layer Name/Type : [['activation_35', 'Activation']] \n",
      "\n",
      "178 res4j_branch2c            Model Layer Name/Type : [['res4j_branch2c', 'Conv2D']] \n",
      "    0 res4j_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4j_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "179 bn4j_branch2c             Model Layer Name/Type : [['bn4j_branch2c', 'BatchNorm']] \n",
      "    0 bn4j_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4j_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4j_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4j_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "180 add_17                    Model Layer Name/Type : [['add_17', 'Add']] \n",
      "\n",
      "181 res4j_out                 Model Layer Name/Type : [['res4j_out', 'Activation']] \n",
      "\n",
      "182 res4k_branch2a            Model Layer Name/Type : [['res4k_branch2a', 'Conv2D']] \n",
      "    0 res4k_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4k_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "183 bn4k_branch2a             Model Layer Name/Type : [['bn4k_branch2a', 'BatchNorm']] \n",
      "    0 bn4k_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4k_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4k_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4k_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "184 activation_36             Model Layer Name/Type : [['activation_36', 'Activation']] \n",
      "\n",
      "185 res4k_branch2b            Model Layer Name/Type : [['res4k_branch2b', 'Conv2D']] \n",
      "    0 res4k_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4k_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "186 bn4k_branch2b             Model Layer Name/Type : [['bn4k_branch2b', 'BatchNorm']] \n",
      "    0 bn4k_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4k_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4k_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4k_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "187 activation_37             Model Layer Name/Type : [['activation_37', 'Activation']] \n",
      "\n",
      "188 res4k_branch2c            Model Layer Name/Type : [['res4k_branch2c', 'Conv2D']] \n",
      "    0 res4k_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4k_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "189 bn4k_branch2c             Model Layer Name/Type : [['bn4k_branch2c', 'BatchNorm']] \n",
      "    0 bn4k_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4k_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4k_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4k_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "190 add_18                    Model Layer Name/Type : [['add_18', 'Add']] \n",
      "\n",
      "191 res4k_out                 Model Layer Name/Type : [['res4k_out', 'Activation']] \n",
      "\n",
      "192 res4l_branch2a            Model Layer Name/Type : [['res4l_branch2a', 'Conv2D']] \n",
      "    0 res4l_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4l_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "193 bn4l_branch2a             Model Layer Name/Type : [['bn4l_branch2a', 'BatchNorm']] \n",
      "    0 bn4l_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4l_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4l_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4l_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "194 activation_38             Model Layer Name/Type : [['activation_38', 'Activation']] \n",
      "\n",
      "195 res4l_branch2b            Model Layer Name/Type : [['res4l_branch2b', 'Conv2D']] \n",
      "    0 res4l_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4l_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "196 bn4l_branch2b             Model Layer Name/Type : [['bn4l_branch2b', 'BatchNorm']] \n",
      "    0 bn4l_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4l_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4l_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4l_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "197 activation_39             Model Layer Name/Type : [['activation_39', 'Activation']] \n",
      "\n",
      "198 res4l_branch2c            Model Layer Name/Type : [['res4l_branch2c', 'Conv2D']] \n",
      "    0 res4l_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4l_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "199 bn4l_branch2c             Model Layer Name/Type : [['bn4l_branch2c', 'BatchNorm']] \n",
      "    0 bn4l_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4l_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4l_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4l_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "200 add_19                    Model Layer Name/Type : [['add_19', 'Add']] \n",
      "\n",
      "201 res4l_out                 Model Layer Name/Type : [['res4l_out', 'Activation']] \n",
      "\n",
      "202 res4m_branch2a            Model Layer Name/Type : [['res4m_branch2a', 'Conv2D']] \n",
      "    0 res4m_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4m_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "203 bn4m_branch2a             Model Layer Name/Type : [['bn4m_branch2a', 'BatchNorm']] \n",
      "    0 bn4m_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4m_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4m_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4m_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "204 activation_40             Model Layer Name/Type : [['activation_40', 'Activation']] \n",
      "\n",
      "205 res4m_branch2b            Model Layer Name/Type : [['res4m_branch2b', 'Conv2D']] \n",
      "    0 res4m_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4m_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "206 bn4m_branch2b             Model Layer Name/Type : [['bn4m_branch2b', 'BatchNorm']] \n",
      "    0 bn4m_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4m_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4m_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4m_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "207 activation_41             Model Layer Name/Type : [['activation_41', 'Activation']] \n",
      "\n",
      "208 res4m_branch2c            Model Layer Name/Type : [['res4m_branch2c', 'Conv2D']] \n",
      "    0 res4m_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4m_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "209 bn4m_branch2c             Model Layer Name/Type : [['bn4m_branch2c', 'BatchNorm']] \n",
      "    0 bn4m_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4m_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4m_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4m_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "210 add_20                    Model Layer Name/Type : [['add_20', 'Add']] \n",
      "\n",
      "211 res4m_out                 Model Layer Name/Type : [['res4m_out', 'Activation']] \n",
      "\n",
      "212 res4n_branch2a            Model Layer Name/Type : [['res4n_branch2a', 'Conv2D']] \n",
      "    0 res4n_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4n_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "213 bn4n_branch2a             Model Layer Name/Type : [['bn4n_branch2a', 'BatchNorm']] \n",
      "    0 bn4n_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4n_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4n_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4n_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "214 activation_42             Model Layer Name/Type : [['activation_42', 'Activation']] \n",
      "\n",
      "215 res4n_branch2b            Model Layer Name/Type : [['res4n_branch2b', 'Conv2D']] \n",
      "    0 res4n_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4n_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "216 bn4n_branch2b             Model Layer Name/Type : [['bn4n_branch2b', 'BatchNorm']] \n",
      "    0 bn4n_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4n_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4n_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4n_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "217 activation_43             Model Layer Name/Type : [['activation_43', 'Activation']] \n",
      "\n",
      "218 res4n_branch2c            Model Layer Name/Type : [['res4n_branch2c', 'Conv2D']] \n",
      "    0 res4n_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4n_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "219 bn4n_branch2c             Model Layer Name/Type : [['bn4n_branch2c', 'BatchNorm']] \n",
      "    0 bn4n_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4n_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4n_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4n_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "220 add_21                    Model Layer Name/Type : [['add_21', 'Add']] \n",
      "\n",
      "221 res4n_out                 Model Layer Name/Type : [['res4n_out', 'Activation']] \n",
      "\n",
      "222 res4o_branch2a            Model Layer Name/Type : [['res4o_branch2a', 'Conv2D']] \n",
      "    0 res4o_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4o_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "223 bn4o_branch2a             Model Layer Name/Type : [['bn4o_branch2a', 'BatchNorm']] \n",
      "    0 bn4o_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4o_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4o_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4o_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "224 activation_44             Model Layer Name/Type : [['activation_44', 'Activation']] \n",
      "\n",
      "225 res4o_branch2b            Model Layer Name/Type : [['res4o_branch2b', 'Conv2D']] \n",
      "    0 res4o_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4o_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "226 bn4o_branch2b             Model Layer Name/Type : [['bn4o_branch2b', 'BatchNorm']] \n",
      "    0 bn4o_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4o_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4o_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4o_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "227 activation_45             Model Layer Name/Type : [['activation_45', 'Activation']] \n",
      "\n",
      "228 res4o_branch2c            Model Layer Name/Type : [['res4o_branch2c', 'Conv2D']] \n",
      "    0 res4o_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4o_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "229 bn4o_branch2c             Model Layer Name/Type : [['bn4o_branch2c', 'BatchNorm']] \n",
      "    0 bn4o_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4o_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4o_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4o_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "230 add_22                    Model Layer Name/Type : [['add_22', 'Add']] \n",
      "\n",
      "231 res4o_out                 Model Layer Name/Type : [['res4o_out', 'Activation']] \n",
      "\n",
      "232 res4p_branch2a            Model Layer Name/Type : [['res4p_branch2a', 'Conv2D']] \n",
      "    0 res4p_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4p_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "233 bn4p_branch2a             Model Layer Name/Type : [['bn4p_branch2a', 'BatchNorm']] \n",
      "    0 bn4p_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4p_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4p_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4p_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "234 activation_46             Model Layer Name/Type : [['activation_46', 'Activation']] \n",
      "\n",
      "235 res4p_branch2b            Model Layer Name/Type : [['res4p_branch2b', 'Conv2D']] \n",
      "    0 res4p_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4p_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "236 bn4p_branch2b             Model Layer Name/Type : [['bn4p_branch2b', 'BatchNorm']] \n",
      "    0 bn4p_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4p_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4p_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4p_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "237 activation_47             Model Layer Name/Type : [['activation_47', 'Activation']] \n",
      "\n",
      "238 res4p_branch2c            Model Layer Name/Type : [['res4p_branch2c', 'Conv2D']] \n",
      "    0 res4p_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4p_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "239 bn4p_branch2c             Model Layer Name/Type : [['bn4p_branch2c', 'BatchNorm']] \n",
      "    0 bn4p_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4p_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4p_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4p_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "240 add_23                    Model Layer Name/Type : [['add_23', 'Add']] \n",
      "\n",
      "241 res4p_out                 Model Layer Name/Type : [['res4p_out', 'Activation']] \n",
      "\n",
      "242 res4q_branch2a            Model Layer Name/Type : [['res4q_branch2a', 'Conv2D']] \n",
      "    0 res4q_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4q_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "243 bn4q_branch2a             Model Layer Name/Type : [['bn4q_branch2a', 'BatchNorm']] \n",
      "    0 bn4q_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4q_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4q_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4q_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "244 activation_48             Model Layer Name/Type : [['activation_48', 'Activation']] \n",
      "\n",
      "245 res4q_branch2b            Model Layer Name/Type : [['res4q_branch2b', 'Conv2D']] \n",
      "    0 res4q_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4q_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "246 bn4q_branch2b             Model Layer Name/Type : [['bn4q_branch2b', 'BatchNorm']] \n",
      "    0 bn4q_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4q_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4q_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4q_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "247 activation_49             Model Layer Name/Type : [['activation_49', 'Activation']] \n",
      "\n",
      "248 res4q_branch2c            Model Layer Name/Type : [['res4q_branch2c', 'Conv2D']] \n",
      "    0 res4q_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4q_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "249 bn4q_branch2c             Model Layer Name/Type : [['bn4q_branch2c', 'BatchNorm']] \n",
      "    0 bn4q_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4q_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4q_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4q_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "250 add_24                    Model Layer Name/Type : [['add_24', 'Add']] \n",
      "\n",
      "251 res4q_out                 Model Layer Name/Type : [['res4q_out', 'Activation']] \n",
      "\n",
      "252 res4r_branch2a            Model Layer Name/Type : [['res4r_branch2a', 'Conv2D']] \n",
      "    0 res4r_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4r_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "253 bn4r_branch2a             Model Layer Name/Type : [['bn4r_branch2a', 'BatchNorm']] \n",
      "    0 bn4r_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4r_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4r_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4r_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "254 activation_50             Model Layer Name/Type : [['activation_50', 'Activation']] \n",
      "\n",
      "255 res4r_branch2b            Model Layer Name/Type : [['res4r_branch2b', 'Conv2D']] \n",
      "    0 res4r_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4r_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "256 bn4r_branch2b             Model Layer Name/Type : [['bn4r_branch2b', 'BatchNorm']] \n",
      "    0 bn4r_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4r_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4r_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4r_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "257 activation_51             Model Layer Name/Type : [['activation_51', 'Activation']] \n",
      "\n",
      "258 res4r_branch2c            Model Layer Name/Type : [['res4r_branch2c', 'Conv2D']] \n",
      "    0 res4r_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4r_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "259 bn4r_branch2c             Model Layer Name/Type : [['bn4r_branch2c', 'BatchNorm']] \n",
      "    0 bn4r_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4r_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4r_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4r_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "260 add_25                    Model Layer Name/Type : [['add_25', 'Add']] \n",
      "\n",
      "261 res4r_out                 Model Layer Name/Type : [['res4r_out', 'Activation']] \n",
      "\n",
      "262 res4s_branch2a            Model Layer Name/Type : [['res4s_branch2a', 'Conv2D']] \n",
      "    0 res4s_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4s_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "263 bn4s_branch2a             Model Layer Name/Type : [['bn4s_branch2a', 'BatchNorm']] \n",
      "    0 bn4s_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4s_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4s_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4s_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "264 activation_52             Model Layer Name/Type : [['activation_52', 'Activation']] \n",
      "\n",
      "265 res4s_branch2b            Model Layer Name/Type : [['res4s_branch2b', 'Conv2D']] \n",
      "    0 res4s_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4s_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "266 bn4s_branch2b             Model Layer Name/Type : [['bn4s_branch2b', 'BatchNorm']] \n",
      "    0 bn4s_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4s_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4s_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4s_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "267 activation_53             Model Layer Name/Type : [['activation_53', 'Activation']] \n",
      "\n",
      "268 res4s_branch2c            Model Layer Name/Type : [['res4s_branch2c', 'Conv2D']] \n",
      "    0 res4s_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4s_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "269 bn4s_branch2c             Model Layer Name/Type : [['bn4s_branch2c', 'BatchNorm']] \n",
      "    0 bn4s_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4s_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4s_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4s_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "270 add_26                    Model Layer Name/Type : [['add_26', 'Add']] \n",
      "\n",
      "271 res4s_out                 Model Layer Name/Type : [['res4s_out', 'Activation']] \n",
      "\n",
      "272 res4t_branch2a            Model Layer Name/Type : [['res4t_branch2a', 'Conv2D']] \n",
      "    0 res4t_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4t_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "273 bn4t_branch2a             Model Layer Name/Type : [['bn4t_branch2a', 'BatchNorm']] \n",
      "    0 bn4t_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4t_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4t_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4t_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "274 activation_54             Model Layer Name/Type : [['activation_54', 'Activation']] \n",
      "\n",
      "275 res4t_branch2b            Model Layer Name/Type : [['res4t_branch2b', 'Conv2D']] \n",
      "    0 res4t_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4t_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "276 bn4t_branch2b             Model Layer Name/Type : [['bn4t_branch2b', 'BatchNorm']] \n",
      "    0 bn4t_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4t_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4t_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4t_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "277 activation_55             Model Layer Name/Type : [['activation_55', 'Activation']] \n",
      "\n",
      "278 res4t_branch2c            Model Layer Name/Type : [['res4t_branch2c', 'Conv2D']] \n",
      "    0 res4t_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4t_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "279 bn4t_branch2c             Model Layer Name/Type : [['bn4t_branch2c', 'BatchNorm']] \n",
      "    0 bn4t_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4t_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4t_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4t_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "280 add_27                    Model Layer Name/Type : [['add_27', 'Add']] \n",
      "\n",
      "281 res4t_out                 Model Layer Name/Type : [['res4t_out', 'Activation']] \n",
      "\n",
      "282 res4u_branch2a            Model Layer Name/Type : [['res4u_branch2a', 'Conv2D']] \n",
      "    0 res4u_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4u_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "283 bn4u_branch2a             Model Layer Name/Type : [['bn4u_branch2a', 'BatchNorm']] \n",
      "    0 bn4u_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4u_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4u_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4u_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "284 activation_56             Model Layer Name/Type : [['activation_56', 'Activation']] \n",
      "\n",
      "285 res4u_branch2b            Model Layer Name/Type : [['res4u_branch2b', 'Conv2D']] \n",
      "    0 res4u_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4u_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "286 bn4u_branch2b             Model Layer Name/Type : [['bn4u_branch2b', 'BatchNorm']] \n",
      "    0 bn4u_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4u_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4u_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4u_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "287 activation_57             Model Layer Name/Type : [['activation_57', 'Activation']] \n",
      "\n",
      "288 res4u_branch2c            Model Layer Name/Type : [['res4u_branch2c', 'Conv2D']] \n",
      "    0 res4u_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4u_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "289 bn4u_branch2c             Model Layer Name/Type : [['bn4u_branch2c', 'BatchNorm']] \n",
      "    0 bn4u_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4u_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4u_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4u_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "290 add_28                    Model Layer Name/Type : [['add_28', 'Add']] \n",
      "\n",
      "291 res4u_out                 Model Layer Name/Type : [['res4u_out', 'Activation']] \n",
      "\n",
      "292 res4v_branch2a            Model Layer Name/Type : [['res4v_branch2a', 'Conv2D']] \n",
      "    0 res4v_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4v_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "293 bn4v_branch2a             Model Layer Name/Type : [['bn4v_branch2a', 'BatchNorm']] \n",
      "    0 bn4v_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4v_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4v_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4v_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "294 activation_58             Model Layer Name/Type : [['activation_58', 'Activation']] \n",
      "\n",
      "295 res4v_branch2b            Model Layer Name/Type : [['res4v_branch2b', 'Conv2D']] \n",
      "    0 res4v_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4v_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "296 bn4v_branch2b             Model Layer Name/Type : [['bn4v_branch2b', 'BatchNorm']] \n",
      "    0 bn4v_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4v_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4v_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4v_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "297 activation_59             Model Layer Name/Type : [['activation_59', 'Activation']] \n",
      "\n",
      "298 res4v_branch2c            Model Layer Name/Type : [['res4v_branch2c', 'Conv2D']] \n",
      "    0 res4v_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4v_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "299 bn4v_branch2c             Model Layer Name/Type : [['bn4v_branch2c', 'BatchNorm']] \n",
      "    0 bn4v_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4v_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4v_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4v_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "300 add_29                    Model Layer Name/Type : [['add_29', 'Add']] \n",
      "\n",
      "301 res4v_out                 Model Layer Name/Type : [['res4v_out', 'Activation']] \n",
      "\n",
      "302 res4w_branch2a            Model Layer Name/Type : [['res4w_branch2a', 'Conv2D']] \n",
      "    0 res4w_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 res4w_branch2a/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "303 bn4w_branch2a             Model Layer Name/Type : [['bn4w_branch2a', 'BatchNorm']] \n",
      "    0 bn4w_branch2a/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4w_branch2a/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4w_branch2a/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4w_branch2a/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "304 activation_60             Model Layer Name/Type : [['activation_60', 'Activation']] \n",
      "\n",
      "305 res4w_branch2b            Model Layer Name/Type : [['res4w_branch2b', 'Conv2D']] \n",
      "    0 res4w_branch2b/kernel:0              hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 res4w_branch2b/bias:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "306 bn4w_branch2b             Model Layer Name/Type : [['bn4w_branch2b', 'BatchNorm']] \n",
      "    0 bn4w_branch2b/gamma:0                hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    1 bn4w_branch2b/beta:0                 hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    2 bn4w_branch2b/moving_mean:0          hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "    3 bn4w_branch2b/moving_variance:0      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "307 activation_61             Model Layer Name/Type : [['activation_61', 'Activation']] \n",
      "\n",
      "308 res4w_branch2c            Model Layer Name/Type : [['res4w_branch2c', 'Conv2D']] \n",
      "    0 res4w_branch2c/kernel:0              hdf5 Weights: (1, 1, 256, 1024)  \t\t Symbolic Wghts: (1, 1, 256, 1024)   \n",
      "    1 res4w_branch2c/bias:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "309 bn4w_branch2c             Model Layer Name/Type : [['bn4w_branch2c', 'BatchNorm']] \n",
      "    0 bn4w_branch2c/gamma:0                hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 bn4w_branch2c/beta:0                 hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 bn4w_branch2c/moving_mean:0          hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 bn4w_branch2c/moving_variance:0      hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "310 add_30                    Model Layer Name/Type : [['add_30', 'Add']] \n",
      "\n",
      "311 res4w_out                 Model Layer Name/Type : [['res4w_out', 'Activation']] \n",
      "\n",
      "312 res5a_branch2a            Model Layer Name/Type : [['res5a_branch2a', 'Conv2D']] \n",
      "    0 res5a_branch2a/kernel:0              hdf5 Weights: (1, 1, 1024, 512)  \t\t Symbolic Wghts: (1, 1, 1024, 512)   \n",
      "    1 res5a_branch2a/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "313 bn5a_branch2a             Model Layer Name/Type : [['bn5a_branch2a', 'BatchNorm']] \n",
      "    0 bn5a_branch2a/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5a_branch2a/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5a_branch2a/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5a_branch2a/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "314 activation_62             Model Layer Name/Type : [['activation_62', 'Activation']] \n",
      "\n",
      "315 res5a_branch2b            Model Layer Name/Type : [['res5a_branch2b', 'Conv2D']] \n",
      "    0 res5a_branch2b/kernel:0              hdf5 Weights: (3, 3, 512, 512)  \t\t Symbolic Wghts: (3, 3, 512, 512)   \n",
      "    1 res5a_branch2b/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "316 bn5a_branch2b             Model Layer Name/Type : [['bn5a_branch2b', 'BatchNorm']] \n",
      "    0 bn5a_branch2b/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5a_branch2b/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5a_branch2b/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5a_branch2b/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "317 activation_63             Model Layer Name/Type : [['activation_63', 'Activation']] \n",
      "\n",
      "318 res5a_branch2c            Model Layer Name/Type : [['res5a_branch2c', 'Conv2D']] \n",
      "    0 res5a_branch2c/kernel:0              hdf5 Weights: (1, 1, 512, 2048)  \t\t Symbolic Wghts: (1, 1, 512, 2048)   \n",
      "    1 res5a_branch2c/bias:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "319 res5a_branch1             Model Layer Name/Type : [['res5a_branch1', 'Conv2D']] \n",
      "    0 res5a_branch1/kernel:0               hdf5 Weights: (1, 1, 1024, 2048)  \t\t Symbolic Wghts: (1, 1, 1024, 2048)   \n",
      "    1 res5a_branch1/bias:0                 hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "320 bn5a_branch2c             Model Layer Name/Type : [['bn5a_branch2c', 'BatchNorm']] \n",
      "    0 bn5a_branch2c/gamma:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    1 bn5a_branch2c/beta:0                 hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    2 bn5a_branch2c/moving_mean:0          hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    3 bn5a_branch2c/moving_variance:0      hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "321 bn5a_branch1              Model Layer Name/Type : [['bn5a_branch1', 'BatchNorm']] \n",
      "    0 bn5a_branch1/gamma:0                 hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    1 bn5a_branch1/beta:0                  hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    2 bn5a_branch1/moving_mean:0           hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    3 bn5a_branch1/moving_variance:0       hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "322 add_31                    Model Layer Name/Type : [['add_31', 'Add']] \n",
      "\n",
      "323 res5a_out                 Model Layer Name/Type : [['res5a_out', 'Activation']] \n",
      "\n",
      "324 res5b_branch2a            Model Layer Name/Type : [['res5b_branch2a', 'Conv2D']] \n",
      "    0 res5b_branch2a/kernel:0              hdf5 Weights: (1, 1, 2048, 512)  \t\t Symbolic Wghts: (1, 1, 2048, 512)   \n",
      "    1 res5b_branch2a/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "325 bn5b_branch2a             Model Layer Name/Type : [['bn5b_branch2a', 'BatchNorm']] \n",
      "    0 bn5b_branch2a/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5b_branch2a/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5b_branch2a/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5b_branch2a/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "326 activation_64             Model Layer Name/Type : [['activation_64', 'Activation']] \n",
      "\n",
      "327 res5b_branch2b            Model Layer Name/Type : [['res5b_branch2b', 'Conv2D']] \n",
      "    0 res5b_branch2b/kernel:0              hdf5 Weights: (3, 3, 512, 512)  \t\t Symbolic Wghts: (3, 3, 512, 512)   \n",
      "    1 res5b_branch2b/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "328 bn5b_branch2b             Model Layer Name/Type : [['bn5b_branch2b', 'BatchNorm']] \n",
      "    0 bn5b_branch2b/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5b_branch2b/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5b_branch2b/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5b_branch2b/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "329 activation_65             Model Layer Name/Type : [['activation_65', 'Activation']] \n",
      "\n",
      "330 res5b_branch2c            Model Layer Name/Type : [['res5b_branch2c', 'Conv2D']] \n",
      "    0 res5b_branch2c/kernel:0              hdf5 Weights: (1, 1, 512, 2048)  \t\t Symbolic Wghts: (1, 1, 512, 2048)   \n",
      "    1 res5b_branch2c/bias:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "331 bn5b_branch2c             Model Layer Name/Type : [['bn5b_branch2c', 'BatchNorm']] \n",
      "    0 bn5b_branch2c/gamma:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    1 bn5b_branch2c/beta:0                 hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    2 bn5b_branch2c/moving_mean:0          hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    3 bn5b_branch2c/moving_variance:0      hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "332 add_32                    Model Layer Name/Type : [['add_32', 'Add']] \n",
      "\n",
      "333 res5b_out                 Model Layer Name/Type : [['res5b_out', 'Activation']] \n",
      "\n",
      "334 res5c_branch2a            Model Layer Name/Type : [['res5c_branch2a', 'Conv2D']] \n",
      "    0 res5c_branch2a/kernel:0              hdf5 Weights: (1, 1, 2048, 512)  \t\t Symbolic Wghts: (1, 1, 2048, 512)   \n",
      "    1 res5c_branch2a/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "335 bn5c_branch2a             Model Layer Name/Type : [['bn5c_branch2a', 'BatchNorm']] \n",
      "    0 bn5c_branch2a/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5c_branch2a/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5c_branch2a/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5c_branch2a/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "336 activation_66             Model Layer Name/Type : [['activation_66', 'Activation']] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "337 res5c_branch2b            Model Layer Name/Type : [['res5c_branch2b', 'Conv2D']] \n",
      "    0 res5c_branch2b/kernel:0              hdf5 Weights: (3, 3, 512, 512)  \t\t Symbolic Wghts: (3, 3, 512, 512)   \n",
      "    1 res5c_branch2b/bias:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "338 bn5c_branch2b             Model Layer Name/Type : [['bn5c_branch2b', 'BatchNorm']] \n",
      "    0 bn5c_branch2b/gamma:0                hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    1 bn5c_branch2b/beta:0                 hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 bn5c_branch2b/moving_mean:0          hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    3 bn5c_branch2b/moving_variance:0      hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "\n",
      "339 activation_67             Model Layer Name/Type : [['activation_67', 'Activation']] \n",
      "\n",
      "340 res5c_branch2c            Model Layer Name/Type : [['res5c_branch2c', 'Conv2D']] \n",
      "    0 res5c_branch2c/kernel:0              hdf5 Weights: (1, 1, 512, 2048)  \t\t Symbolic Wghts: (1, 1, 512, 2048)   \n",
      "    1 res5c_branch2c/bias:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "341 bn5c_branch2c             Model Layer Name/Type : [['bn5c_branch2c', 'BatchNorm']] \n",
      "    0 bn5c_branch2c/gamma:0                hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    1 bn5c_branch2c/beta:0                 hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    2 bn5c_branch2c/moving_mean:0          hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "    3 bn5c_branch2c/moving_variance:0      hdf5 Weights: (2048,)  \t\t Symbolic Wghts: (2048,)   \n",
      "\n",
      "342 add_33                    Model Layer Name/Type : [['add_33', 'Add']] \n",
      "\n",
      "343 res5c_out                 Model Layer Name/Type : [['res5c_out', 'Activation']] \n",
      "\n",
      "344 fpn_c5p5                  Model Layer Name/Type : [['fpn_c5p5', 'Conv2D']] \n",
      "    0 fpn_c5p5/kernel:0                    hdf5 Weights: (1, 1, 2048, 256)  \t\t Symbolic Wghts: (1, 1, 2048, 256)   \n",
      "    1 fpn_c5p5/bias:0                      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "345 fpn_p5upsampled           Model Layer Name/Type : [['fpn_p5upsampled', 'UpSampling2D']] \n",
      "\n",
      "346 fpn_c4p4                  Model Layer Name/Type : [['fpn_c4p4', 'Conv2D']] \n",
      "    0 fpn_c4p4/kernel:0                    hdf5 Weights: (1, 1, 1024, 256)  \t\t Symbolic Wghts: (1, 1, 1024, 256)   \n",
      "    1 fpn_c4p4/bias:0                      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "347 fpn_p4add                 Model Layer Name/Type : [['fpn_p4add', 'Add']] \n",
      "\n",
      "348 fpn_p4upsampled           Model Layer Name/Type : [['fpn_p4upsampled', 'UpSampling2D']] \n",
      "\n",
      "349 fpn_c3p3                  Model Layer Name/Type : [['fpn_c3p3', 'Conv2D']] \n",
      "    0 fpn_c3p3/kernel:0                    hdf5 Weights: (1, 1, 512, 256)  \t\t Symbolic Wghts: (1, 1, 512, 256)   \n",
      "    1 fpn_c3p3/bias:0                      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "350 fpn_p3add                 Model Layer Name/Type : [['fpn_p3add', 'Add']] \n",
      "\n",
      "351 fpn_p3upsampled           Model Layer Name/Type : [['fpn_p3upsampled', 'UpSampling2D']] \n",
      "\n",
      "352 fpn_c2p2                  Model Layer Name/Type : [['fpn_c2p2', 'Conv2D']] \n",
      "    0 fpn_c2p2/kernel:0                    hdf5 Weights: (1, 1, 256, 256)  \t\t Symbolic Wghts: (1, 1, 256, 256)   \n",
      "    1 fpn_c2p2/bias:0                      hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "353 fpn_p2add                 Model Layer Name/Type : [['fpn_p2add', 'Add']] \n",
      "\n",
      "354 fpn_p5                    Model Layer Name/Type : [['fpn_p5', 'Conv2D']] \n",
      "    0 fpn_p5/kernel:0                      hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 fpn_p5/bias:0                        hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "355 fpn_p2                    Model Layer Name/Type : [['fpn_p2', 'Conv2D']] \n",
      "    0 fpn_p2/kernel:0                      hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 fpn_p2/bias:0                        hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "356 fpn_p3                    Model Layer Name/Type : [['fpn_p3', 'Conv2D']] \n",
      "    0 fpn_p3/kernel:0                      hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 fpn_p3/bias:0                        hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "357 fpn_p4                    Model Layer Name/Type : [['fpn_p4', 'Conv2D']] \n",
      "    0 fpn_p4/kernel:0                      hdf5 Weights: (3, 3, 256, 256)  \t\t Symbolic Wghts: (3, 3, 256, 256)   \n",
      "    1 fpn_p4/bias:0                        hdf5 Weights: (256,)  \t\t Symbolic Wghts: (256,)   \n",
      "\n",
      "358 fpn_p6                    Model Layer Name/Type : [['fpn_p6', 'MaxPooling2D']] \n",
      "\n",
      "359 rpn_model                 Model Layer Name/Type : [['rpn_model', 'Model']] \n",
      "    0 rpn_conv_shared/kernel:0             hdf5 Weights: (3, 3, 256, 512)  \t\t Symbolic Wghts: (3, 3, 256, 512)   \n",
      "    1 rpn_conv_shared/bias:0               hdf5 Weights: (512,)  \t\t Symbolic Wghts: (512,)   \n",
      "    2 rpn_class_raw/kernel:0               hdf5 Weights: (1, 1, 512, 6)  \t\t Symbolic Wghts: (1, 1, 512, 6)   \n",
      "    3 rpn_class_raw/bias:0                 hdf5 Weights: (6,)  \t\t Symbolic Wghts: (6,)   \n",
      "    4 rpn_bbox_pred/kernel:0               hdf5 Weights: (1, 1, 512, 12)  \t\t Symbolic Wghts: (1, 1, 512, 12)   \n",
      "    5 rpn_bbox_pred/bias:0                 hdf5 Weights: (12,)  \t\t Symbolic Wghts: (12,)   \n",
      "\n",
      "360 rpn_class                 Model Layer Name/Type : [['rpn_class', 'Lambda']] \n",
      "\n",
      "361 rpn_bbox                  Model Layer Name/Type : [['rpn_bbox', 'Lambda']] \n",
      "\n",
      "362 input_gt_boxes            Model Layer Name/Type : [['input_gt_boxes', 'InputLayer']] \n",
      "\n",
      "363 ROI                       Model Layer Name/Type : [['ROI', 'ProposalLayer']] \n",
      "\n",
      "364 input_gt_class_ids        Model Layer Name/Type : [['input_gt_class_ids', 'InputLayer']] \n",
      "\n",
      "365 lambda_1                  *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "366 input_gt_masks            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "367 proposal_targets          Model Layer Name/Type : [['proposal_targets', 'DetectionTargetLayer_mod']] \n",
      "\n",
      "368 roi_align_mask            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "369 mrcnn_mask_conv1          *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_conv1/kernel:0', 'mrcnn_mask_conv1/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask_conv1/kernel:0            hdf5 Weights: (3, 3, 256, 256)\n",
      "    1 mrcnn_mask_conv1/bias:0              hdf5 Weights: (256,)\n",
      "\n",
      "370 mrcnn_mask_bn1            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_bn1/gamma:0', 'mrcnn_mask_bn1/beta:0', 'mrcnn_mask_bn1/moving_mean:0', 'mrcnn_mask_bn1/moving_variance:0'] \n",
      "\n",
      "    0 mrcnn_mask_bn1/gamma:0               hdf5 Weights: (256,)\n",
      "    1 mrcnn_mask_bn1/beta:0                hdf5 Weights: (256,)\n",
      "    2 mrcnn_mask_bn1/moving_mean:0         hdf5 Weights: (256,)\n",
      "    3 mrcnn_mask_bn1/moving_variance:0     hdf5 Weights: (256,)\n",
      "\n",
      "371 activation_71             *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "372 mrcnn_mask_conv2          *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_conv2/kernel:0', 'mrcnn_mask_conv2/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask_conv2/kernel:0            hdf5 Weights: (3, 3, 256, 256)\n",
      "    1 mrcnn_mask_conv2/bias:0              hdf5 Weights: (256,)\n",
      "\n",
      "373 roi_align_classifier      Model Layer Name/Type : [['roi_align_classifier', 'PyramidROIAlign']] \n",
      "\n",
      "374 mrcnn_mask_bn2            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_bn2/gamma:0', 'mrcnn_mask_bn2/beta:0', 'mrcnn_mask_bn2/moving_mean:0', 'mrcnn_mask_bn2/moving_variance:0'] \n",
      "\n",
      "    0 mrcnn_mask_bn2/gamma:0               hdf5 Weights: (256,)\n",
      "    1 mrcnn_mask_bn2/beta:0                hdf5 Weights: (256,)\n",
      "    2 mrcnn_mask_bn2/moving_mean:0         hdf5 Weights: (256,)\n",
      "    3 mrcnn_mask_bn2/moving_variance:0     hdf5 Weights: (256,)\n",
      "\n",
      "375 mrcnn_class_conv1         Model Layer Name/Type : [['mrcnn_class_conv1', 'TimeDistributed']] \n",
      "    0 mrcnn_class_conv1/kernel:0           hdf5 Weights: (7, 7, 256, 1024)  \t\t Symbolic Wghts: (7, 7, 256, 1024)   \n",
      "    1 mrcnn_class_conv1/bias:0             hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "376 activation_72             *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "377 mrcnn_class_bn1           Model Layer Name/Type : [['mrcnn_class_bn1', 'TimeDistributed']] \n",
      "    0 mrcnn_class_bn1/gamma:0              hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 mrcnn_class_bn1/beta:0               hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 mrcnn_class_bn1/moving_mean:0        hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 mrcnn_class_bn1/moving_variance:0    hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "378 mrcnn_mask_conv3          *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_conv3/kernel:0', 'mrcnn_mask_conv3/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask_conv3/kernel:0            hdf5 Weights: (3, 3, 256, 256)\n",
      "    1 mrcnn_mask_conv3/bias:0              hdf5 Weights: (256,)\n",
      "\n",
      "379 activation_68             Model Layer Name/Type : [['activation_68', 'Activation']] \n",
      "\n",
      "380 mrcnn_mask_bn3            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_bn3/gamma:0', 'mrcnn_mask_bn3/beta:0', 'mrcnn_mask_bn3/moving_mean:0', 'mrcnn_mask_bn3/moving_variance:0'] \n",
      "\n",
      "    0 mrcnn_mask_bn3/gamma:0               hdf5 Weights: (256,)\n",
      "    1 mrcnn_mask_bn3/beta:0                hdf5 Weights: (256,)\n",
      "    2 mrcnn_mask_bn3/moving_mean:0         hdf5 Weights: (256,)\n",
      "    3 mrcnn_mask_bn3/moving_variance:0     hdf5 Weights: (256,)\n",
      "\n",
      "381 mrcnn_class_conv2         Model Layer Name/Type : [['mrcnn_class_conv2', 'TimeDistributed']] \n",
      "    0 mrcnn_class_conv2/kernel:0           hdf5 Weights: (1, 1, 1024, 1024)  \t\t Symbolic Wghts: (1, 1, 1024, 1024)   \n",
      "    1 mrcnn_class_conv2/bias:0             hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "382 activation_73             *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "383 mrcnn_class_bn2           Model Layer Name/Type : [['mrcnn_class_bn2', 'TimeDistributed']] \n",
      "    0 mrcnn_class_bn2/gamma:0              hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    1 mrcnn_class_bn2/beta:0               hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    2 mrcnn_class_bn2/moving_mean:0        hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "    3 mrcnn_class_bn2/moving_variance:0    hdf5 Weights: (1024,)  \t\t Symbolic Wghts: (1024,)   \n",
      "\n",
      "384 mrcnn_mask_conv4          *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_conv4/kernel:0', 'mrcnn_mask_conv4/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask_conv4/kernel:0            hdf5 Weights: (3, 3, 256, 256)\n",
      "    1 mrcnn_mask_conv4/bias:0              hdf5 Weights: (256,)\n",
      "\n",
      "385 activation_69             Model Layer Name/Type : [['activation_69', 'Activation']] \n",
      "\n",
      "386 mrcnn_mask_bn4            *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_bn4/gamma:0', 'mrcnn_mask_bn4/beta:0', 'mrcnn_mask_bn4/moving_mean:0', 'mrcnn_mask_bn4/moving_variance:0'] \n",
      "\n",
      "    0 mrcnn_mask_bn4/gamma:0               hdf5 Weights: (256,)\n",
      "    1 mrcnn_mask_bn4/beta:0                hdf5 Weights: (256,)\n",
      "    2 mrcnn_mask_bn4/moving_mean:0         hdf5 Weights: (256,)\n",
      "    3 mrcnn_mask_bn4/moving_variance:0     hdf5 Weights: (256,)\n",
      "\n",
      "387 pool_squeeze              Model Layer Name/Type : [['pool_squeeze', 'Lambda']] \n",
      "\n",
      "388 activation_74             *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "389 mrcnn_bbox_fc             *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_bbox_fc/kernel:0', 'mrcnn_bbox_fc/bias:0'] \n",
      "\n",
      "    0 mrcnn_bbox_fc/kernel:0               hdf5 Weights: (1024, 324)\n",
      "    1 mrcnn_bbox_fc/bias:0                 hdf5 Weights: (324,)\n",
      "\n",
      "390 mrcnn_mask_deconv         *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask_deconv/kernel:0', 'mrcnn_mask_deconv/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask_deconv/kernel:0           hdf5 Weights: (2, 2, 256, 256)\n",
      "    1 mrcnn_mask_deconv/bias:0             hdf5 Weights: (256,)\n",
      "\n",
      "391 input_image_meta          Model Layer Name/Type : [['input_image_meta', 'InputLayer']] \n",
      "\n",
      "392 rpn_class_logits          Model Layer Name/Type : [['rpn_class_logits', 'Lambda']] \n",
      "\n",
      "393 mrcnn_class_logits        *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_class_logits/kernel:0', 'mrcnn_class_logits/bias:0'] \n",
      "\n",
      "    0 mrcnn_class_logits/kernel:0          hdf5 Weights: (1024, 81)\n",
      "    1 mrcnn_class_logits/bias:0            hdf5 Weights: (81,)\n",
      "\n",
      "394 mrcnn_bbox                Model Layer Name/Type : [['mrcnn_bbox', 'Reshape']] \n",
      "\n",
      "395 mrcnn_mask                *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : ['mrcnn_mask/kernel:0', 'mrcnn_mask/bias:0'] \n",
      "\n",
      "    0 mrcnn_mask/kernel:0                  hdf5 Weights: (1, 1, 256, 81)\n",
      "    1 mrcnn_mask/bias:0                    hdf5 Weights: (81,)\n",
      "\n",
      "396 input_rpn_match           Model Layer Name/Type : [['input_rpn_match', 'InputLayer']] \n",
      "\n",
      "397 input_rpn_bbox            Model Layer Name/Type : [['input_rpn_bbox', 'InputLayer']] \n",
      "\n",
      "398 lambda_4                  *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "399 mrcnn_class               *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "400 output_rois               *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n",
      "\n",
      "401 rpn_class_loss            Model Layer Name/Type : [['rpn_class_loss', 'Lambda']] \n",
      "\n",
      "402 rpn_bbox_loss             Model Layer Name/Type : [['rpn_bbox_loss', 'Lambda']] \n",
      "\n",
      "403 mrcnn_class_loss          Model Layer Name/Type : [['mrcnn_class_loss', 'Lambda']] \n",
      "\n",
      "404 mrcnn_bbox_loss           Model Layer Name/Type : [['mrcnn_bbox_loss', 'Lambda']] \n",
      "\n",
      "405 mrcnn_mask_loss           *** No corresponding layers found in model ***\n",
      "    HDF5 Weights  : [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Weights file loaded: /home/kbardool/PretrainedModels/mask_rcnn_coco.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load Mask RCNN Model Weight file\n",
    "##------------------------------------------------------------------------------------\n",
    "# exclude_list = [\"mrcnn_class_logits\"]\n",
    "#load_model(model, init_with = args.model)   \n",
    "exclude_list = [\"mrcnn_class_logits\", \"mrcnn_bbox_fc\"]\n",
    "mrcnn_model.load_model_weights(init_with = 'coco', exclude = exclude_list, verbose = True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build newshape datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:44.403345Z",
     "start_time": "2018-11-04T16:41:23.468334Z"
    }
   },
   "outputs": [],
   "source": [
    "# del dataset_train, dataset_val, train_generator, val_generator\n",
    "from mrcnn.prep_notebook import prep_newshape_dataset\n",
    "dataset_train, train_generator = prep_newshape_dataset( mrcnn_config, 10000, generator=True)\n",
    "dataset_val  , val_generator   = prep_newshape_dataset( mrcnn_config,  2500, generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:44.453311Z",
     "start_time": "2018-11-04T16:41:44.406453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mrcnn.new_shapes.NewShapesDataset'> <class 'generator'>\n",
      "10000\n",
      "<class 'mrcnn.new_shapes.NewShapesDataset'> <class 'generator'>\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset_train), type(train_generator))\n",
    "print(len(dataset_train.image_info))\n",
    "print(type(dataset_val), type(val_generator))\n",
    "print(len(dataset_val.image_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Files and Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display next image from generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:44.505996Z",
     "start_time": "2018-11-04T16:41:44.456308Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:45.049441Z",
     "start_time": "2018-11-04T16:41:44.508627Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  6037\n",
      "Image meta [6037  128  128    3    0    0  128  128    1    1    1    1    1    1    1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9500eafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb958d95ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class_names = dataset_train.class_names\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "#     print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a specific image using image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T14:38:18.940068Z",
     "start_time": "2018-11-04T14:38:16.880330Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "## 33477 Table, bowl, cup, sandwich, knife\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "# IMAGE_LIST = [75040] \n",
    "# IMAGE_LIST = [89243]\n",
    "IMAGE_LIST = [2000,4000,5000,6000]\n",
    "# IMAGE_LIST = [29731]\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_config, IMAGE_LIST)\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(len(IMAGE_LIST)):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "    print(' Dataset coco file:', dataset_train.image_info[image_id]['id'])\n",
    "    print(' Image meta  : ', img_meta[img_idx,:10])\n",
    "    print(' Classes     : ', class_ids)\n",
    "    print(\" Image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "    print(' Class_ids.shape[0]:', class_ids.shape[0], 'bbox.shape[0]:',bbox.shape[0])       \n",
    "    print(' Class Names : ', class_names)\n",
    "    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)   \n",
    "    # Display image and instances\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T14:38:35.069960Z",
     "start_time": "2018-11-04T14:38:33.081616Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T14:39:22.093476Z",
     "start_time": "2018-11-04T14:39:22.041844Z"
    }
   },
   "outputs": [],
   "source": [
    "mrcnn_model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train mrcnn model : `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:41:45.099746Z",
     "start_time": "2018-11-04T16:41:45.052190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last epoch ran :  0\n",
      "    epochs to run  :  2\n",
      "    steps per epoch:  32\n",
      "    learning rate  :  1e-05\n",
      "    momentum       :  0.9\n",
      "    weight decay   :  0.0002\n"
     ]
    }
   ],
   "source": [
    "# mrcnn_model.config.EPOCHS_TO_RUN = 1\n",
    "# mrcnn_model.config.STEPS_PER_EPOCH = 2\n",
    "# mrcnn_model.config.SYSOUT = 'screen'\n",
    " \n",
    "print('    last epoch ran : ',mrcnn_model.config.LAST_EPOCH_RAN)\n",
    "print('    epochs to run  : ',mrcnn_model.config.EPOCHS_TO_RUN)\n",
    "print('    steps per epoch: ',mrcnn_model.config.STEPS_PER_EPOCH)\n",
    "print('    learning rate  : ', mrcnn_model.config.LEARNING_RATE)\n",
    "print('    momentum       : ', mrcnn_model.config.LEARNING_MOMENTUM)\n",
    "print('    weight decay   : ',mrcnn_model.config.WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Training mrcnn, fpn, rpn layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:42:35.935248Z",
     "start_time": "2018-11-04T16:41:53.374165Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrcnn', 'fpn', 'rpn']\n",
      "['(mrcnn\\\\_.*)', '(fpn\\\\_.*)', '(rpn\\\\_.*)']\n",
      "layers regex : (mrcnn\\_.*)|(fpn\\_.*)|(rpn\\_.*)\n",
      "type train_dataset: <class 'mrcnn.new_shapes.NewShapesDataset'>\n",
      "type val_dataset: <class 'mrcnn.new_shapes.NewShapesDataset'>\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_image            (InputLayer          )   ............................no weights to train ]\n",
      "   1  zero_padding2d_1       (ZeroPadding2D       )   ............................no weights to train ]\n",
      "   2  conv1                  (Conv2D              )   ............................not a layer we want to train ]\n",
      "   3  bn_conv1               (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   4  activation_1           (Activation          )   ............................no weights to train ]\n",
      "   5  max_pooling2d_1        (MaxPooling2D        )   ............................no weights to train ]\n",
      "   6  res2a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "   7  bn2a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   8  activation_2           (Activation          )   ............................no weights to train ]\n",
      "   9  res2a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  10  bn2a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  11  activation_3           (Activation          )   ............................no weights to train ]\n",
      "  12  res2a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  13  res2a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  14  bn2a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  15  bn2a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  16  add_1                  (Add                 )   ............................no weights to train ]\n",
      "  17  res2a_out              (Activation          )   ............................no weights to train ]\n",
      "  18  res2b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  19  bn2b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  20  activation_4           (Activation          )   ............................no weights to train ]\n",
      "  21  res2b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  22  bn2b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  23  activation_5           (Activation          )   ............................no weights to train ]\n",
      "  24  res2b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  25  bn2b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  26  add_2                  (Add                 )   ............................no weights to train ]\n",
      "  27  res2b_out              (Activation          )   ............................no weights to train ]\n",
      "  28  res2c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  29  bn2c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  30  activation_6           (Activation          )   ............................no weights to train ]\n",
      "  31  res2c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  32  bn2c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  33  activation_7           (Activation          )   ............................no weights to train ]\n",
      "  34  res2c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  35  bn2c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  36  add_3                  (Add                 )   ............................no weights to train ]\n",
      "  37  res2c_out              (Activation          )   ............................no weights to train ]\n",
      "  38  res3a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  39  bn3a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  40  activation_8           (Activation          )   ............................no weights to train ]\n",
      "  41  res3a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  42  bn3a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  43  activation_9           (Activation          )   ............................no weights to train ]\n",
      "  44  res3a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  45  res3a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  46  bn3a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  47  bn3a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  48  add_4                  (Add                 )   ............................no weights to train ]\n",
      "  49  res3a_out              (Activation          )   ............................no weights to train ]\n",
      "  50  res3b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  51  bn3b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  52  activation_10          (Activation          )   ............................no weights to train ]\n",
      "  53  res3b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  54  bn3b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  55  activation_11          (Activation          )   ............................no weights to train ]\n",
      "  56  res3b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  57  bn3b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  58  add_5                  (Add                 )   ............................no weights to train ]\n",
      "  59  res3b_out              (Activation          )   ............................no weights to train ]\n",
      "  60  res3c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  61  bn3c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  62  activation_12          (Activation          )   ............................no weights to train ]\n",
      "  63  res3c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  64  bn3c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  65  activation_13          (Activation          )   ............................no weights to train ]\n",
      "  66  res3c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  67  bn3c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  68  add_6                  (Add                 )   ............................no weights to train ]\n",
      "  69  res3c_out              (Activation          )   ............................no weights to train ]\n",
      "  70  res3d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  71  bn3d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  72  activation_14          (Activation          )   ............................no weights to train ]\n",
      "  73  res3d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  74  bn3d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  75  activation_15          (Activation          )   ............................no weights to train ]\n",
      "  76  res3d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  77  bn3d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  78  add_7                  (Add                 )   ............................no weights to train ]\n",
      "  79  res3d_out              (Activation          )   ............................no weights to train ]\n",
      "  80  res4a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  81  bn4a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  82  activation_16          (Activation          )   ............................no weights to train ]\n",
      "  83  res4a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  84  bn4a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  85  activation_17          (Activation          )   ............................no weights to train ]\n",
      "  86  res4a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  87  res4a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  88  bn4a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  89  bn4a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  90  add_8                  (Add                 )   ............................no weights to train ]\n",
      "  91  res4a_out              (Activation          )   ............................no weights to train ]\n",
      "  92  res4b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  93  bn4b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  94  activation_18          (Activation          )   ............................no weights to train ]\n",
      "  95  res4b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  96  bn4b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  97  activation_19          (Activation          )   ............................no weights to train ]\n",
      "  98  res4b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  99  bn4b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 100  add_9                  (Add                 )   ............................no weights to train ]\n",
      " 101  res4b_out              (Activation          )   ............................no weights to train ]\n",
      " 102  res4c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 103  bn4c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 104  activation_20          (Activation          )   ............................no weights to train ]\n",
      " 105  res4c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 106  bn4c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 107  activation_21          (Activation          )   ............................no weights to train ]\n",
      " 108  res4c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 109  bn4c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 110  add_10                 (Add                 )   ............................no weights to train ]\n",
      " 111  res4c_out              (Activation          )   ............................no weights to train ]\n",
      " 112  res4d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 113  bn4d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 114  activation_22          (Activation          )   ............................no weights to train ]\n",
      " 115  res4d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 116  bn4d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 117  activation_23          (Activation          )   ............................no weights to train ]\n",
      " 118  res4d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 119  bn4d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 120  add_11                 (Add                 )   ............................no weights to train ]\n",
      " 121  res4d_out              (Activation          )   ............................no weights to train ]\n",
      " 122  res4e_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 123  bn4e_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 124  activation_24          (Activation          )   ............................no weights to train ]\n",
      " 125  res4e_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 126  bn4e_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 127  activation_25          (Activation          )   ............................no weights to train ]\n",
      " 128  res4e_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 129  bn4e_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 130  add_12                 (Add                 )   ............................no weights to train ]\n",
      " 131  res4e_out              (Activation          )   ............................no weights to train ]\n",
      " 132  res4f_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 133  bn4f_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 134  activation_26          (Activation          )   ............................no weights to train ]\n",
      " 135  res4f_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 136  bn4f_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 137  activation_27          (Activation          )   ............................no weights to train ]\n",
      " 138  res4f_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 139  bn4f_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 140  add_13                 (Add                 )   ............................no weights to train ]\n",
      " 141  res4f_out              (Activation          )   ............................no weights to train ]\n",
      " 142  res4g_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 143  bn4g_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 144  activation_28          (Activation          )   ............................no weights to train ]\n",
      " 145  res4g_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 146  bn4g_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 147  activation_29          (Activation          )   ............................no weights to train ]\n",
      " 148  res4g_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 149  bn4g_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 150  add_14                 (Add                 )   ............................no weights to train ]\n",
      " 151  res4g_out              (Activation          )   ............................no weights to train ]\n",
      " 152  res4h_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 153  bn4h_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 154  activation_30          (Activation          )   ............................no weights to train ]\n",
      " 155  res4h_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 156  bn4h_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 157  activation_31          (Activation          )   ............................no weights to train ]\n",
      " 158  res4h_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 159  bn4h_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 160  add_15                 (Add                 )   ............................no weights to train ]\n",
      " 161  res4h_out              (Activation          )   ............................no weights to train ]\n",
      " 162  res4i_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 163  bn4i_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 164  activation_32          (Activation          )   ............................no weights to train ]\n",
      " 165  res4i_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 166  bn4i_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 167  activation_33          (Activation          )   ............................no weights to train ]\n",
      " 168  res4i_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 169  bn4i_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 170  add_16                 (Add                 )   ............................no weights to train ]\n",
      " 171  res4i_out              (Activation          )   ............................no weights to train ]\n",
      " 172  res4j_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 173  bn4j_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 174  activation_34          (Activation          )   ............................no weights to train ]\n",
      " 175  res4j_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 176  bn4j_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 177  activation_35          (Activation          )   ............................no weights to train ]\n",
      " 178  res4j_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 179  bn4j_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 180  add_17                 (Add                 )   ............................no weights to train ]\n",
      " 181  res4j_out              (Activation          )   ............................no weights to train ]\n",
      " 182  res4k_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 183  bn4k_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 184  activation_36          (Activation          )   ............................no weights to train ]\n",
      " 185  res4k_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 186  bn4k_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 187  activation_37          (Activation          )   ............................no weights to train ]\n",
      " 188  res4k_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 189  bn4k_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 190  add_18                 (Add                 )   ............................no weights to train ]\n",
      " 191  res4k_out              (Activation          )   ............................no weights to train ]\n",
      " 192  res4l_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 193  bn4l_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 194  activation_38          (Activation          )   ............................no weights to train ]\n",
      " 195  res4l_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 196  bn4l_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 197  activation_39          (Activation          )   ............................no weights to train ]\n",
      " 198  res4l_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 199  bn4l_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 200  add_19                 (Add                 )   ............................no weights to train ]\n",
      " 201  res4l_out              (Activation          )   ............................no weights to train ]\n",
      " 202  res4m_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 203  bn4m_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 204  activation_40          (Activation          )   ............................no weights to train ]\n",
      " 205  res4m_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 206  bn4m_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 207  activation_41          (Activation          )   ............................no weights to train ]\n",
      " 208  res4m_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 209  bn4m_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 210  add_20                 (Add                 )   ............................no weights to train ]\n",
      " 211  res4m_out              (Activation          )   ............................no weights to train ]\n",
      " 212  res4n_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 213  bn4n_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 214  activation_42          (Activation          )   ............................no weights to train ]\n",
      " 215  res4n_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 216  bn4n_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 217  activation_43          (Activation          )   ............................no weights to train ]\n",
      " 218  res4n_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 219  bn4n_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 220  add_21                 (Add                 )   ............................no weights to train ]\n",
      " 221  res4n_out              (Activation          )   ............................no weights to train ]\n",
      " 222  res4o_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 223  bn4o_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 224  activation_44          (Activation          )   ............................no weights to train ]\n",
      " 225  res4o_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 226  bn4o_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 227  activation_45          (Activation          )   ............................no weights to train ]\n",
      " 228  res4o_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 229  bn4o_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 230  add_22                 (Add                 )   ............................no weights to train ]\n",
      " 231  res4o_out              (Activation          )   ............................no weights to train ]\n",
      " 232  res4p_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 233  bn4p_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 234  activation_46          (Activation          )   ............................no weights to train ]\n",
      " 235  res4p_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 236  bn4p_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 237  activation_47          (Activation          )   ............................no weights to train ]\n",
      " 238  res4p_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 239  bn4p_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 240  add_23                 (Add                 )   ............................no weights to train ]\n",
      " 241  res4p_out              (Activation          )   ............................no weights to train ]\n",
      " 242  res4q_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 243  bn4q_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 244  activation_48          (Activation          )   ............................no weights to train ]\n",
      " 245  res4q_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 246  bn4q_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 247  activation_49          (Activation          )   ............................no weights to train ]\n",
      " 248  res4q_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 249  bn4q_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 250  add_24                 (Add                 )   ............................no weights to train ]\n",
      " 251  res4q_out              (Activation          )   ............................no weights to train ]\n",
      " 252  res4r_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 253  bn4r_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 254  activation_50          (Activation          )   ............................no weights to train ]\n",
      " 255  res4r_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 256  bn4r_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 257  activation_51          (Activation          )   ............................no weights to train ]\n",
      " 258  res4r_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 259  bn4r_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 260  add_25                 (Add                 )   ............................no weights to train ]\n",
      " 261  res4r_out              (Activation          )   ............................no weights to train ]\n",
      " 262  res4s_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 263  bn4s_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 264  activation_52          (Activation          )   ............................no weights to train ]\n",
      " 265  res4s_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 266  bn4s_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 267  activation_53          (Activation          )   ............................no weights to train ]\n",
      " 268  res4s_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 269  bn4s_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 270  add_26                 (Add                 )   ............................no weights to train ]\n",
      " 271  res4s_out              (Activation          )   ............................no weights to train ]\n",
      " 272  res4t_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 273  bn4t_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 274  activation_54          (Activation          )   ............................no weights to train ]\n",
      " 275  res4t_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 276  bn4t_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 277  activation_55          (Activation          )   ............................no weights to train ]\n",
      " 278  res4t_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 279  bn4t_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 280  add_27                 (Add                 )   ............................no weights to train ]\n",
      " 281  res4t_out              (Activation          )   ............................no weights to train ]\n",
      " 282  res4u_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 283  bn4u_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 284  activation_56          (Activation          )   ............................no weights to train ]\n",
      " 285  res4u_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 286  bn4u_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 287  activation_57          (Activation          )   ............................no weights to train ]\n",
      " 288  res4u_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 289  bn4u_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 290  add_28                 (Add                 )   ............................no weights to train ]\n",
      " 291  res4u_out              (Activation          )   ............................no weights to train ]\n",
      " 292  res4v_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 293  bn4v_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 294  activation_58          (Activation          )   ............................no weights to train ]\n",
      " 295  res4v_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 296  bn4v_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 297  activation_59          (Activation          )   ............................no weights to train ]\n",
      " 298  res4v_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 299  bn4v_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 300  add_29                 (Add                 )   ............................no weights to train ]\n",
      " 301  res4v_out              (Activation          )   ............................no weights to train ]\n",
      " 302  res4w_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 303  bn4w_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 304  activation_60          (Activation          )   ............................no weights to train ]\n",
      " 305  res4w_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 306  bn4w_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 307  activation_61          (Activation          )   ............................no weights to train ]\n",
      " 308  res4w_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 309  bn4w_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 310  add_30                 (Add                 )   ............................no weights to train ]\n",
      " 311  res4w_out              (Activation          )   ............................no weights to train ]\n",
      " 312  res5a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 313  bn5a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 314  activation_62          (Activation          )   ............................no weights to train ]\n",
      " 315  res5a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 316  bn5a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 317  activation_63          (Activation          )   ............................no weights to train ]\n",
      " 318  res5a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 319  res5a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      " 320  bn5a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 321  bn5a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 322  add_31                 (Add                 )   ............................no weights to train ]\n",
      " 323  res5a_out              (Activation          )   ............................no weights to train ]\n",
      " 324  res5b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 325  bn5b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 326  activation_64          (Activation          )   ............................no weights to train ]\n",
      " 327  res5b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 328  bn5b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 329  activation_65          (Activation          )   ............................no weights to train ]\n",
      " 330  res5b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 331  bn5b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 332  add_32                 (Add                 )   ............................no weights to train ]\n",
      " 333  res5b_out              (Activation          )   ............................no weights to train ]\n",
      " 334  res5c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 335  bn5c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 336  activation_66          (Activation          )   ............................no weights to train ]\n",
      " 337  res5c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 338  bn5c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 339  activation_67          (Activation          )   ............................no weights to train ]\n",
      " 340  res5c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 341  bn5c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 342  add_33                 (Add                 )   ............................no weights to train ]\n",
      " 343  res5c_out              (Activation          )   ............................no weights to train ]\n",
      " 344  fpn_c5p5               (Conv2D              )   TRAIN \n",
      " 345  fpn_p5upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 346  fpn_c4p4               (Conv2D              )   TRAIN \n",
      " 347  fpn_p4add              (Add                 )   ............................no weights to train ]\n",
      " 348  fpn_p4upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 349  fpn_c3p3               (Conv2D              )   TRAIN \n",
      " 350  fpn_p3add              (Add                 )   ............................no weights to train ]\n",
      " 351  fpn_p3upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 352  fpn_c2p2               (Conv2D              )   TRAIN \n",
      " 353  fpn_p2add              (Add                 )   ............................no weights to train ]\n",
      " 354  fpn_p5                 (Conv2D              )   TRAIN \n",
      " 355  fpn_p2                 (Conv2D              )   TRAIN \n",
      " 356  fpn_p3                 (Conv2D              )   TRAIN \n",
      " 357  fpn_p4                 (Conv2D              )   TRAIN \n",
      " 358  fpn_p6                 (MaxPooling2D        )   ............................no weights to train ]\n",
      "Entering model layer:  rpn_model ------------------------------\n",
      "       0  input_rpn_feature_map   (InputLayer          )   ............................no weights to train ]\n",
      "       1  rpn_conv_shared        (Conv2D              )   TRAIN \n",
      "       2  rpn_class_raw          (Conv2D              )   TRAIN \n",
      "       3  lambda_1               (Lambda              )   ............................no weights to train ]\n",
      "       4  rpn_bbox_pred          (Conv2D              )   TRAIN \n",
      "       5  rpn_class_xxx          (Activation          )   ............................no weights to train ]\n",
      "       6  lambda_2               (Lambda              )   ............................no weights to train ]\n",
      "Exiting model layer  rpn_model --------------------------------\n",
      " 360  rpn_bbox               (Lambda              )   ............................no weights to train ]\n",
      " 361  rpn_class              (Lambda              )   ............................no weights to train ]\n",
      " 362  input_gt_boxes         (InputLayer          )   ............................no weights to train ]\n",
      " 363  ROI                    (ProposalLayer       )   ............................no weights to train ]\n",
      " 364  input_gt_class_ids     (InputLayer          )   ............................no weights to train ]\n",
      " 365  input_normalized_gt_boxes   (Lambda              )   ............................no weights to train ]\n",
      " 366  proposal_targets       (DetectionTargetLayer_mod)   ............................no weights to train ]\n",
      " 367  roi_align_classifier   (PyramidROIAlign     )   ............................no weights to train ]\n",
      " 368  mrcnn_class_conv1      (TimeDistributed     )   TRAIN \n",
      " 369  mrcnn_class_bn1        (TimeDistributed     )   TRAIN \n",
      " 370  activation_68          (Activation          )   ............................no weights to train ]\n",
      " 371  mrcnn_class_conv2      (TimeDistributed     )   TRAIN \n",
      " 372  mrcnn_class_bn2        (TimeDistributed     )   TRAIN \n",
      " 373  activation_69          (Activation          )   ............................no weights to train ]\n",
      " 374  pool_squeeze           (Lambda              )   ............................no weights to train ]\n",
      " 375  input_image_meta       (InputLayer          )   ............................no weights to train ]\n",
      " 376  mrcnn_bbox_fc          (TimeDistributed     )   TRAIN \n",
      " 377  input_rpn_match        (InputLayer          )   ............................no weights to train ]\n",
      " 378  rpn_class_logits       (Lambda              )   ............................no weights to train ]\n",
      " 379  input_rpn_bbox         (InputLayer          )   ............................no weights to train ]\n",
      " 380  mrcnn_class_logits     (TimeDistributed     )   TRAIN \n",
      " 381  lambda_3               (Lambda              )   ............................no weights to train ]\n",
      " 382  mrcnn_bbox             (Reshape             )   ............................no weights to train ]\n",
      " 383  rpn_class_loss         (Lambda              )   ............................no weights to train ]\n",
      " 384  rpn_bbox_loss          (Lambda              )   ............................no weights to train ]\n",
      " 385  mrcnn_class_loss       (Lambda              )   ............................no weights to train ]\n",
      " 386  mrcnn_bbox_loss        (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    optimizer     :  <keras.optimizers.Adagrad object at 0x7fb95652a438>\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    keras_model.losses           : []\n",
      "\n",
      "    Loss: rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_class_loss/rpn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_bbox_loss/rpn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_class_loss/mrcnn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_bbox_loss/mrcnn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      "Keras model.losses : \n",
      "---------------------\n",
      "   Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)    name: Mean:0\n",
      "   Tensor(\"Mean_3:0\", shape=(1, 1), dtype=float32)    name: Mean_3:0\n",
      "   Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)    name: Mean_2:0\n",
      "   Tensor(\"Mean_1:0\", shape=(1, 1), dtype=float32)    name: Mean_1:0\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "   Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)    name: Mean:0\n",
      "   Tensor(\"Mean_1:0\", shape=(1, 1), dtype=float32)    name: Mean_1:0\n",
      "   Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)    name: Mean_2:0\n",
      "   Tensor(\"Mean_3:0\", shape=(1, 1), dtype=float32)    name: Mean_3:0\n",
      "\n",
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "   None    name: <class 'NoneType'>\n",
      "{   None: [   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_1:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_2:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Regularization losses:\n",
      "-------------------------\n",
      "   Tensor(\"truediv:0\", shape=(), dtype=float32)    name: truediv:0\n",
      "   Tensor(\"truediv_1:0\", shape=(), dtype=float32)    name: truediv_1:0\n",
      "   Tensor(\"truediv_2:0\", shape=(), dtype=float32)    name: truediv_2:0\n",
      "   Tensor(\"truediv_3:0\", shape=(), dtype=float32)    name: truediv_3:0\n",
      "   Tensor(\"truediv_4:0\", shape=(), dtype=float32)    name: truediv_4:0\n",
      "   Tensor(\"truediv_5:0\", shape=(), dtype=float32)    name: truediv_5:0\n",
      "   Tensor(\"truediv_6:0\", shape=(), dtype=float32)    name: truediv_6:0\n",
      "   Tensor(\"truediv_7:0\", shape=(), dtype=float32)    name: truediv_7:0\n",
      "   Tensor(\"truediv_8:0\", shape=(), dtype=float32)    name: truediv_8:0\n",
      "   Tensor(\"truediv_9:0\", shape=(), dtype=float32)    name: truediv_9:0\n",
      "   Tensor(\"truediv_10:0\", shape=(), dtype=float32)    name: truediv_10:0\n",
      "   Tensor(\"truediv_11:0\", shape=(), dtype=float32)    name: truediv_11:0\n",
      "   Tensor(\"truediv_12:0\", shape=(), dtype=float32)    name: truediv_12:0\n",
      "   Tensor(\"truediv_13:0\", shape=(), dtype=float32)    name: truediv_13:0\n",
      "   Tensor(\"truediv_14:0\", shape=(), dtype=float32)    name: truediv_14:0\n",
      "   Tensor(\"truediv_15:0\", shape=(), dtype=float32)    name: truediv_15:0\n",
      "   Tensor(\"truediv_16:0\", shape=(), dtype=float32)    name: truediv_16:0\n",
      "   Tensor(\"truediv_17:0\", shape=(), dtype=float32)    name: truediv_17:0\n",
      "   Tensor(\"truediv_18:0\", shape=(), dtype=float32)    name: truediv_18:0\n",
      "   Tensor(\"truediv_19:0\", shape=(), dtype=float32)    name: truediv_19:0\n",
      "   Tensor(\"truediv_20:0\", shape=(), dtype=float32)    name: truediv_20:0\n",
      "   Tensor(\"truediv_21:0\", shape=(), dtype=float32)    name: truediv_21:0\n",
      "   Tensor(\"truediv_22:0\", shape=(), dtype=float32)    name: truediv_22:0\n",
      "   Tensor(\"truediv_23:0\", shape=(), dtype=float32)    name: truediv_23:0\n",
      "   Tensor(\"truediv_24:0\", shape=(), dtype=float32)    name: truediv_24:0\n",
      "   Tensor(\"truediv_25:0\", shape=(), dtype=float32)    name: truediv_25:0\n",
      "   Tensor(\"truediv_26:0\", shape=(), dtype=float32)    name: truediv_26:0\n",
      "   Tensor(\"truediv_27:0\", shape=(), dtype=float32)    name: truediv_27:0\n",
      "   Tensor(\"truediv_28:0\", shape=(), dtype=float32)    name: truediv_28:0\n",
      "   Tensor(\"truediv_29:0\", shape=(), dtype=float32)    name: truediv_29:0\n",
      "\n",
      "    Final list of keras_model.losses \n",
      "    -------------------------------- \n",
      "[   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'AddN:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'Mean_2:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_1:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      " Length of Keras_Model.outputs: 4\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add metric  rpn_class_loss  with metric tensor:  rpn_class_loss/rpn_class_loss:0  to list of metrics ...\n",
      "    Loss name : rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add metric  rpn_bbox_loss  with metric tensor:  rpn_bbox_loss/rpn_bbox_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add metric  mrcnn_class_loss  with metric tensor:  mrcnn_class_loss/mrcnn_class_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add metric  mrcnn_bbox_loss  with metric tensor:  mrcnn_bbox_loss/mrcnn_bbox_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names:\n",
      " -------------------------\n",
      "['loss', 'rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "\n",
      " Run information written to  /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640_sysout.out\n",
      "Starting at epoch   0 of 2 epochs. LR=1e-05\n",
      "\n",
      "Steps per epoch     32 \n",
      "Batch size          1 \n",
      "Checkpoint Path:    /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640/mrcnn_{epoch:04d}.h5 \n",
      "Learning Rate       1e-05 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    8 \n",
      "REDUCE_LR_FACTOR    0.5 \n",
      "REDUCE_LR_COOLDOWN  30 \n",
      "REDUCE_LR_PATIENCE  40 \n",
      "MIN_LR              1e-10 \n",
      "EARLY_STOP_PATIENCE 80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 3.8507 - rpn_class_loss: 0.1947 - rpn_bbox_loss: 1.4301 - mrcnn_class_loss: 1.2636 - mrcnn_bbox_loss: 0.9624 - val_loss: 3.9422 - val_rpn_class_loss: 0.1747 - val_rpn_bbox_loss: 1.4817 - val_mrcnn_class_loss: 1.1635 - val_mrcnn_bbox_loss: 1.1224\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.9422112, saving model to /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640/mrcnn_0001.h5\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 3.2722 - rpn_class_loss: 0.1739 - rpn_bbox_loss: 1.3969 - mrcnn_class_loss: 0.6857 - mrcnn_bbox_loss: 1.0157 - val_loss: 3.1498 - val_rpn_class_loss: 0.1690 - val_rpn_bbox_loss: 1.3900 - val_mrcnn_class_loss: 0.5195 - val_mrcnn_bbox_loss: 1.0712\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.9422112 to 3.1498065, saving model to /home/kbardool/models/train_mrcnn_newshapes/mrcnn20181104T1640/mrcnn_0002.h5\n",
      "Final : self.epoch 2   epochs 2\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# Wed 09-05-2018\n",
    "# config.STEPS_PER_EPOCH        = 8\n",
    "# config.EARLY_STOP_PATIENCE    = 70\n",
    "train_layers = [ 'mrcnn', 'fpn','rpn']\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "# train_layers = [ 'mrcnn']\n",
    "# loss_names   = [ \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "mrcnn_model.epoch = mrcnn_model.config.LAST_EPOCH_RAN\n",
    "\n",
    "mrcnn_model.train(dataset_train, \n",
    "            dataset_val, \n",
    "            learning_rate = mrcnn_model.config.LEARNING_RATE, \n",
    "            epochs_to_run = mrcnn_model.config.EPOCHS_TO_RUN,\n",
    "            layers = train_layers,\n",
    "            losses = loss_names\n",
    "#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Training - FCN\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "    - #### Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:35:18.936161Z",
     "start_time": "2018-04-24T08:35:09.103385Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:26:11.099812Z",
     "start_time": "2018-05-09T15:26:10.868655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_gt_class_ids = train_batch_x[4]\n",
    "\n",
    "target_class_ids = layers_out[5]\n",
    "mrcnn_class_logits = layers_out[9]\n",
    "rpn_class_loss   = layers_out[13]\n",
    "rpn_bbox_loss    = layers_out[14]\n",
    "mrcnn_class_loss = layers_out[15]\n",
    "mrcnn_bbox_loss  = layers_out[16]\n",
    "mrcnn_mask_loss  = layers_out[17]\n",
    "active_class_ids = layers_out[20]\n",
    "# pred_masks = tf.identity(layers_out[18])\n",
    "# gt_masks   = tf.identity(layers_out[19])\n",
    "\n",
    "# shape = KB.int_shape(pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:34:22.819601Z",
     "start_time": "2018-05-09T15:34:22.573917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(rpn_class_loss, rpn_bbox_loss)\n",
    "print(mrcnn_class_loss, mrcnn_bbox_loss, mrcnn_mask_loss)\n",
    "print(active_class_ids)\n",
    "print()\n",
    "print(target_class_ids[1])\n",
    "print()\n",
    "print(mrcnn_class_logits[1])\n",
    "print('gt class ids')\n",
    "print(input_gt_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:34:26.381655Z",
     "start_time": "2018-04-24T12:34:25.980564Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[0:2,2:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:49:29.945015Z",
     "start_time": "2018-04-24T13:49:29.457701Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 1 # <==== Class to display\n",
    "pred_tensor = layers_out[19]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)dd\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:39:14.676360Z",
     "start_time": "2018-04-24T12:39:14.435714Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[0][0] * [128, 128,128,128]   #output_rois*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:03:44.110249Z",
     "start_time": "2018-04-24T15:03:38.231280Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]\n",
    "target_masks        = layers_out[27][0:3]\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print(tf.shape(less_than_one).eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Mean values of GT, Pred, and FCN heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:52:02.002508Z",
     "start_time": "2018-04-24T14:51:42.964543Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "pred_masks = tf.identity(layers_out[24])\n",
    "gt_masks = tf.identity(layers_out[27])\n",
    "fcn_masks = tf.identity(layers_out[12])\n",
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        gt_mean = K.mean(gt_masks[img,:,:,cls])\n",
    "        fcn_mean= K.mean(fcn_masks[img,:,:,cls])\n",
    "        pred_mean= K.mean(pred_masks[img,:,:,cls])\n",
    "        print('Img/Cls: ', img, '/', cls,'    gtmean: ', gt_mean.eval(), '\\t fcn : ' , fcn_mean.eval(), '\\t pred :', pred_mean.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
