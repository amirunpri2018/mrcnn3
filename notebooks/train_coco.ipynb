{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:29:28.994828Z",
     "start_time": "2018-05-02T17:28:56.497400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " breakpoint 1\n",
      " breakpoint 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialize CocoConfig object - super\n",
      "E:\\Models\\mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mask R-CNN\n",
    "Configurations and data loading code for MS COCO.\n",
    "\n",
    "Copyright (c) 2017 Matterport, Inc.\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Waleed Abdulla\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "\n",
    "    # Train a new model starting from pre-trained COCO weights\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=coco\n",
    "\n",
    "    # Train a new model starting from ImageNet weights\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=imagenet\n",
    "\n",
    "    # Continue training a model that you had trained earlier\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=/path/to/weights.h5\n",
    "\n",
    "    # Continue training the last model you trained\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=last\n",
    "\n",
    "    # Run COCO evaluatoin on the last model you trained\n",
    "    python3 coco.py evaluate --dataset=/path/to/coco/ --model=last\n",
    "\"\"\"\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "sys.path.append('../')\n",
    "import pprint as pp\n",
    "pp = pp.PrettyPrinter(indent=4)\n",
    "import argparse\n",
    "from   mrcnn.coco import CocoDataset, CocoConfig, evaluate_coco, build_coco_results\n",
    "from   mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.dataset as dataset\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "ROOT_DIR = 'E:\\Models'\n",
    "# Path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "COCO_DATASET_PATH = 'E:\\MLDatasets\\coco2014'\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"mrcnn_coco_logs\")\n",
    "\n",
    "print(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:12.614718Z",
     "start_time": "2018-05-02T17:30:12.382100Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as KB \n",
    "# kears.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup tf session and debugging \n",
    "##------------------------------------------------------------------------------------\n",
    "# keras_backend.set_session(tf_debug.LocalCLIDebugWrapperSession(tf.Session()))\n",
    "\n",
    "#     if 'tensorflow' == KB.backend():\n",
    "#         from tensorflow.python import debug as tf_debug\n",
    "#         config = tf.ConfigProto(\n",
    "#                 device_count = {'GPU': 0}\n",
    "#             )\n",
    "#         tf_sess = tf.Session(config=config)    \n",
    "#         tf_sess = tf_debug.LocalCLIDebugWrapperSession(tf_sess)\n",
    "#         KB.set_session(tf_sess)\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## force no GPU usage\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "# if 'tensorflow' == KB.backend():\n",
    "#     config = tf.ConfigProto(\n",
    "#             device_count = {'GPU': 0}\n",
    "#         )\n",
    "#     tf_sess = tf.Session(config=config)    \n",
    "#     KB.set_session(tf_sess)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## limit GPU usage\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "#   tfconfig = tf.ConfigProto(\n",
    "#               gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5),\n",
    "#               device_count = {'GPU': 1}\n",
    "#              )    \n",
    "#     tfconfig = tf.ConfigProto()\n",
    "#     tfconfig.gpu_options.allow_growth=True\n",
    "#     tfconfig.gpu_options.visible_device_list = \"0\"\n",
    "#     tfconfig.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "#     tf_sess = tf.Session(config=tfconfig)\n",
    "#     set_session(tf_sess)\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "# tf_config = tf.ConfigProto()\n",
    "# tf_config.gpu_options.per_process_gpu_memory_fraction = 0.55\n",
    "# set_session(tf.Session(config=tf_config))\n",
    "\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.55)\n",
    "# set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:17.180872Z",
     "start_time": "2018-05-02T17:30:16.873060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(command='train', dataset='E:\\\\MLDatasets\\\\coco2014', limit='10', logs='E:\\\\Models\\\\mrcnn_coco_logs', model='E:\\\\Models\\\\mask_rcnn_coco.h5')\n",
      " Model     (COCO_MODEL_PATH)  :  E:\\Models\\mask_rcnn_coco.h5    E:\\Models\\mask_rcnn_coco.h5\n",
      " Dataset   (COCO_DATASET_PATH):  E:\\MLDatasets\\coco2014    E:\\MLDatasets\\coco2014\n",
      " Ckpt/Logs (DEFAULT_LOGS_DIR) :  E:\\Models\\mrcnn_coco_logs    E:\\Models\\mrcnn_coco_logs\n",
      " Limit:    10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parse command line arguments\n",
    "parser = argparse.ArgumentParser(description='Train Mask R-CNN on MS COCO.')\n",
    "parser.add_argument(\"command\",\n",
    "                    metavar=\"<command>\",\n",
    "                    help=\"'train' or 'evaluate' on MS COCO\")\n",
    "parser.add_argument('--dataset', required=False,\n",
    "                    default=COCO_DATASET_PATH,                    \n",
    "                    metavar=\"/path/to/coco/\",\n",
    "                    help='Directory of the MS-COCO dataset')\n",
    "parser.add_argument('--model', required=False,\n",
    "                    default=COCO_MODEL_PATH,                    \n",
    "                    metavar=\"/path/to/weights.h5\",\n",
    "                    help=\"Path to weights .h5 file or 'coco', 'last','imagenet' \")\n",
    "parser.add_argument('--logs', required=False,\n",
    "                    default=DEFAULT_LOGS_DIR,\n",
    "                    metavar=\"/path/to/logs/\",\n",
    "                    help='Logs and checkpoints directory (default=logs/)')\n",
    "parser.add_argument('--limit', required=False,\n",
    "                    default=500,\n",
    "                    metavar=\"<image count>\",\n",
    "                    help='Images to use for evaluation (defaults=500)')\n",
    "# args = parser.parse_args()\n",
    "# args = parser.parse_args(\"train --dataset E:\\MLDatasets\\coco2014 --model mask_rcnn_coco.h5 --limit 10\".split())\n",
    "args = parser.parse_args(\"train  --limit 10\".split())\n",
    "# pp.pprint(options)\n",
    "pp.pprint(args)\n",
    "print(\" Model     (COCO_MODEL_PATH)  : \", args.model, '  ', COCO_MODEL_PATH)\n",
    "print(\" Dataset   (COCO_DATASET_PATH): \", args.dataset, '  ',COCO_DATASET_PATH)\n",
    "print(\" Ckpt/Logs (DEFAULT_LOGS_DIR) : \", args.logs, '  ', DEFAULT_LOGS_DIR)\n",
    "print(\" Limit:   \", args.limit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:20.295173Z",
     "start_time": "2018-05-02T17:30:20.038458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialize config object - super\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [1024 1024]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "if args.command == \"train\":\n",
    "    config = CocoConfig()\n",
    "else:\n",
    "    class InferenceConfig(CocoConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "        DETECTION_MIN_CONFIDENCE = 0\n",
    "    config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:31.558123Z",
     "start_time": "2018-05-02T17:30:23.054506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup model for Training \n",
      ">>> Set_log_dir() -- model dir is  E:\\Models\\mrcnn_coco_logs\n",
      "    model_path           :    None\n",
      "    config.LAST_EPOCH_RAN:    0\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_coco_logs\\coco20180502T1930\\mask_rcnn_coco_{epoch:04d}.h5\n",
      "    self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 1024, 1024, 3)\n",
      "     After ZeroPadding2D  : (?, 1030, 1030, 3) (?, 1030, 1030, 3)\n",
      "     After Conv2D padding : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     After BatchNorm      : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     After MaxPooling2D   : (?, 256, 256, 64) (?, 256, 256, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 256, 256, 256)\n",
      "     FPN P3 shape : (None, 128, 128, 256)\n",
      "     FPN P4 shape : (None, 64, 64, 256)\n",
      "     FPN P5 shape : (None, 32, 32, 256)\n",
      "     FPN P6 shape : (None, 16, 16, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer \n",
      "    Init complete. Size of anchors:  (261888, 4)\n",
      "     Scores :  (2, 6000)\n",
      "     Deltas :  (2, 6000, 4)\n",
      "     Anchors:  (2, 6000, 4)\n",
      "     Boxes shape / type after processing:  (2, 6000, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> Detection Target Layer \n",
      "    Detection Target Layer : call()  <class 'list'> 4\n",
      "     proposals.shape    : (2, ?, ?) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     gt_class_ids.shape : (?, ?) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     gt_bboxes.shape    : (?, ?, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     gt_masks.shape     : (?, 56, 56, ?) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 5\n",
      "     output 0  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (2, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (2, ?, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 4  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (2, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 256, 256, 256)\n",
      "     feature_maps shape  : (?, 128, 128, 256)\n",
      "     feature_maps shape  : (?, 64, 64, 256)\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     input_shape         : [1024 1024    3]\n",
      "     pool_size           : 7\n",
      "\n",
      ">>> FPN Mask Graph \n",
      "     rois shape          : (2, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 256, 256, 256)\n",
      "     feature_maps shape  : (?, 128, 128, 256)\n",
      "     feature_maps shape  : (?, 64, 64, 256)\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     input_shape         : [1024 1024    3]\n",
      "     pool_size           : 14\n",
      "     FPN Mask Graph output shape : (?, 200, 28, 28, 81)\n",
      "\n",
      ">>> PCN Layer TF \n",
      "   > PCNLayerTF Call()  5\n",
      "     mrcnn_class.shape    : (?, 200, 81) (None, 200, 81)\n",
      "     mrcnn_bbox.shape     : (?, 200, 81, 4) (None, 200, 81, 4)\n",
      "     output_rois.shape    : (2, ?, ?) (None, 200, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  200\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 200, 81)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 200, 81, 4) (?, 200, 81, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (2, None, 4)\n",
      "    pred_classes     :  (?, 200)\n",
      "    pred_classes_exp :  (?, 200, 1)\n",
      "    pred_scores      :  (?, 200, 1)\n",
      "    batch_grid       :  (2, 200)\n",
      "    roi_grid         :  (2, 200)\n",
      "    bbox_idx         :  (2, 200, 1)\n",
      "\n",
      "    -- pred_tensor tf ------------------------------\n",
      "    pred_array shape: (2, 200, 6)\n",
      "    pred_scatter shape is  (2, 81, 200, 6) Tensor(\"cntxt_layer/ScatterNd:0\", shape=(2, 81, 200, 6), dtype=float32)\n",
      "    sort inds shape :  (2, 81, 200)\n",
      "    class_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (2, 81, 200)\n",
      "    batch_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (2, 81, 200)\n",
      "    roi_grid shape (2, 81, 200) roi_grid_exp shape  (2, 81, 200, 1)\n",
      "    gather_inds  <class 'tensorflow.python.framework.ops.Tensor'> shape (2, 81, 200, 3)\n",
      "    pred_tensor (gathered)  :  (2, 81, 200, 6)\n",
      "    -- pred_tensor results (bboxes sorted by score) ----\n",
      "    final pred_tensor shape  :  (2, 81, 200, 6)\n",
      "    final pred_cls_cnt shape :  (2, 81)\n",
      "    complete\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)     notm_gt_bbox.shape  :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    pred_ scores shape  (?, ?)\n",
      "    bbox_idx shape     (2, 100, 1)\n",
      "    gt_array shape     (?, ?, 6)\n",
      "    bbox_grid  shape   (2, 100)\n",
      "    batch_grid shape   (2, 100)\n",
      "    scatter_ind shape  (2, 100, 3)\n",
      "    gt_scatter shape  (2, 81, 100, 6)\n",
      "    build gathering indexes to use in sorting -------\n",
      "    sort inds shape :  (2, 81, 100)\n",
      "    class_grid  shape  (2, 81, 100)\n",
      "    batch_grid  shape  (2, 81, 100)\n",
      "    bbox_grid   shape  (2, 81, 100)  bbox_grid_exp shape  (2, 81, 100, 1)\n",
      "    gather_inds shape      :  (2, 81, 100, 3)\n",
      "    gt_tensor (gathered)   :  (2, 81, 100, 6)\n",
      "    final gt_tensor shape  :  (2, 81, 100, 6)\n",
      "    final gt_cls_cnt shape :  (2, 81)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['pred_gaussian']\n",
      "    orignal in_tensor shape :  (2, 81, 200, 6)\n",
      "    modified in_tensor shape :  (2, 81, 200, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (1024, 1024, 2, 200, 2)\n",
      "    pt2_sum shape  (2, 81, 200)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (1024, 1024, 2, 200, 2)\n",
      "    << output probabilities shape: (2, 200, 1024, 1024)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (2, 200, 1024, 1024)\n",
      "    class shape        :  (2, ?)\n",
      "    roi_grid shape     :  (2, 200)\n",
      "    batch_grid shape   :  (2, 200)\n",
      "    scatter_classes    :  (2, 200, 3)\n",
      "    gaussian scattered :  (2, 81, 200, 1024, 1024)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_gaussian_1:0 pred_gaussian\n",
      "    gaussian_sum shape     :  (2, 1024, 1024, 81) Keras tensor  False\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['gt_gaussian']\n",
      "    orignal in_tensor shape :  (2, 81, 100, 6)\n",
      "    modified in_tensor shape :  (2, 81, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (1024, 1024, 2, 100, 2)\n",
      "    pt2_sum shape  (2, 81, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (1024, 1024, 2, 100, 2)\n",
      "    << output probabilities shape: (2, 100, 1024, 1024)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (2, 100, 1024, 1024)\n",
      "    class shape        :  (2, ?)\n",
      "    roi_grid shape     :  (2, 100)\n",
      "    batch_grid shape   :  (2, 100)\n",
      "    scatter_classes    :  (2, 100, 3)\n",
      "    gaussian scattered :  (2, 81, 100, 1024, 1024)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_gaussian:0 gt_gaussian\n",
      "    gaussian_sum shape     :  (2, 1024, 1024, 81) Keras tensor  False\n",
      "\n",
      "    Output build_gaussian_tf \n",
      "     pred_gaussian :  (2, 1024, 1024, 81) Keras tensor  False\n",
      "     gt_gaussian   :  (2, 1024, 1024, 81) Keras tensor  False\n",
      "<<<  shape of pred_gaussian   :  (2, 1024, 1024, 81)  Keras tensor  True\n",
      "<<<  shape of gt_gaussian     :  (2, 1024, 1024, 81)  Keras tensor  True\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (2, 1024, 1024, 81)\n",
      "     height : 1024 width : 1024 classes : 81\n",
      "     image_data_format     channels_last\n",
      "   FCN Block 11 shape is :  (2, 1024, 1024, 64)\n",
      "   FCN Block 12 shape is :  (2, 1024, 1024, 64)\n",
      "   FCN Block 13 shape is :  (2, 512, 512, 64)\n",
      "   FCN Block 21 shape is :  (2, 512, 512, 128)\n",
      "   FCN Block 22 shape is :  (2, 512, 512, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (2, 256, 256, 128)\n",
      "   FCN Block 31 shape is :  (2, 256, 256, 256)\n",
      "   FCN Block 32 shape is :  (2, 256, 256, 256)\n",
      "   FCN Block 33 shape is :  (2, 256, 256, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (2, 128, 128, 256)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (2, 128, 128, 2048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FCN fully connected 2 (fcn_fc2) shape is :  (2, 128, 128, 2048)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (None, 128, 128, 81)\n",
      "   h_factor :  8.0 w_factor :  8.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (8.0, 8.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (8.0, 8.0)\n",
      "     CHANNELS LAST: X:  (2, 128, 128, 81)  KB.int_shape() :  (None, 128, 128, 81)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (2, ?, ?, 81)\n",
      "     Dimensions of X after set_shape() :  (2, 1024, 1024, 81)\n",
      "    BilinearUpSampling2D. compute_output_shape()\n",
      "   FCN output (fcn_bilinear) shape is :  (2, 1024, 1024, 81) Keras tensor  True\n",
      "   fcn_output  shape is :  (None, 1024, 1024, 81)  Keras tensor  True\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_class_logits size : (?, 200, 81)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_class_logits size : (?, 200, 81)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_bbox size         : (?, 200, 81, 4)\n",
      "    target_bbox size       : (2, ?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_bbox size         : (?, 200, 81, 4)\n",
      "    target_bbox size       : (?, 200, 4)\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    mrcnn_mask_loss    \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (2, ?)\n",
      "    target_masks     shape : (2, ?, ?, ?)\n",
      "    pred_masks       shape : (?, 200, 28, 28, 81)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (?, 1)\n",
      "    target_masks     shape : (?, 200, 28, 28)\n",
      "    pred_masks       shape : (?, 200, 28, 28, 81)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_loss\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> fcn_loss_graph \n",
      "    target_masks     shape : (2, 1024, 1024, 81) Tensor(\"fcn_loss/Shape:0\", shape=(4,), dtype=int32)\n",
      "    target_masks is keras tensor: True\n",
      "    pred_masks       shape : (2, 1024, 1024, 81) Tensor(\"fcn_loss/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "    pred_masks is keras tensor: True\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (4,)\n",
      "    pred_masks       shape : (?, ?, ?)\n",
      "    loss is keras tensor: False\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_loss_graph \n",
      "    target_masks     shape : (?, 1024, 1024, 81) Tensor(\"fcn_loss/Shape_4:0\", shape=(4,), dtype=int32)\n",
      "    target_masks is keras tensor: False\n",
      "    pred_masks       shape : (?, 1024, 1024, 81) Tensor(\"fcn_loss/Shape_5:0\", shape=(4,), dtype=int32)\n",
      "    pred_masks is keras tensor: False\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (4,)\n",
      "    pred_masks       shape : (?, ?, ?)\n",
      "    loss is keras tensor: False\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_norm_loss\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_masks     shape : (2, 1024, 1024, 81)\n",
      "    pred_masks       shape : (2, 1024, 1024, 81)\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"fcn_norm_loss/Shape:0\", shape=(4,), dtype=int32)  tf.get_shape():  (2, 1024, 1024, 81)  pred_maks.shape: (2, 1024, 1024, 81) tf.shape : Tensor(\"fcn_norm_loss/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "   output_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm final :  (2, 1024, 1024, 81) (2, 1024, 1024, 81)  Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " target shape is : Tensor(\"fcn_norm_loss/Shape_2:0\", shape=(4,), dtype=int32)     (2, 1024, 1024, 81) (2, 1024, 1024, 81) Tensor(\"fcn_norm_loss/Shape_3:0\", shape=(4,), dtype=int32)\n",
      "    guass_flatten         :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm shape      :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm final shape:  (2, 1024, 1024, 81) (2, 1024, 1024, 81) Keras tensor  False\n",
      "    target_masks1 shape : (?, ?, ?) (None, None, None)\n",
      "    pred_masks1  shape : (?, ?, ?)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_masks     shape : (?, 1024, 1024, 81)\n",
      "    pred_masks       shape : (?, 1024, 1024, 81)\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"fcn_norm_loss/Shape_4:0\", shape=(4,), dtype=int32)  tf.get_shape():  (?, 1024, 1024, 81)  pred_maks.shape: (?, 1024, 1024, 81) tf.shape : Tensor(\"fcn_norm_loss/Shape_5:0\", shape=(4,), dtype=int32)\n",
      "   output_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm final :  (None, 1024, 1024, 81) (?, 1024, 1024, 81)  Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " target shape is : Tensor(\"fcn_norm_loss/Shape_6:0\", shape=(4,), dtype=int32)     (?, 1024, 1024, 81) (?, 1024, 1024, 81) Tensor(\"fcn_norm_loss/Shape_7:0\", shape=(4,), dtype=int32)\n",
      "    guass_flatten         :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm shape      :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm final shape:  (?, 1024, 1024, 81) (?, 1024, 1024, 81) Keras tensor  False\n",
      "    target_masks1 shape : (?, ?, ?) (None, None, None)\n",
      "    pred_masks1  shape : (?, ?, ?)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      " Keras Tensors?? \n",
      " pred_gaussian : True\n",
      " gt_gaussian   : True\n",
      " mask_loss     : True\n",
      " rpn_rois      : True\n",
      " fcn_loss      : True\n",
      " fcn_norm_loss : True\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "if args.command == \"train\":\n",
    "    print('setup model for Training ')\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=args.logs)\n",
    "else:\n",
    "    print('setup model for Inference ')\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                              model_dir=args.logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:31.768644Z",
     "start_time": "2018-05-02T17:30:31.559087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " args.model:  E:\\Models\\mask_rcnn_coco.h5\n",
      " model path  E:\\Models\\mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "# Select weights file to load\n",
    "#-----------------------------------------------------\n",
    "print(' args.model: ', args.model)\n",
    "# print(' model.find_last() :',model.find_last())\n",
    "if args.model.lower() == \"coco\":\n",
    "    model_path = COCO_MODEL_PATH\n",
    "elif args.model.lower() == \"last\":\n",
    "    # Find last trained weights\n",
    "    model_path = model.find_last()[1]\n",
    "elif args.model.lower() == \"imagenet\":\n",
    "    # Start from ImageNet trained weights\n",
    "    model_path = model.get_imagenet_weights()\n",
    "else:\n",
    "    model_path = args.model\n",
    "\n",
    "    print(' model path ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:30:42.519361Z",
     "start_time": "2018-05-02T17:30:31.770651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  E:\\Models\\mask_rcnn_coco.h5\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mask_rcnn_coco.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mask_rcnn_coco.h5\n",
      ">>> Set_log_dir() -- model dir is  E:\\Models\\mrcnn_coco_logs\n",
      "    model_path           :    E:\\Models\\mask_rcnn_coco.h5\n",
      "    config.LAST_EPOCH_RAN:    0\n",
      "    set_log_dir: model_path (input) is : E:/Models/mask_rcnn_coco.h5  \n",
      "    set_log_dir: self.epoch set to 0  (Next epoch to run)\n",
      "    set_log_dir: tensorboard path: E:\\Models\\mrcnn_coco_logs\\tensorboard\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_coco_logs\\coco20180502T1930\\mask_rcnn_coco_{epoch:04d}.h5\n",
      "    self.epoch set to 0 \n",
      "    Load weights complete :  E:\\Models\\mask_rcnn_coco.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Models\\\\mask_rcnn_coco.h5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights\n",
    "#-----------------------------------------------------\n",
    "print(\"Loading weights \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training and Validation datasets. \n",
    "#### Use the training set and 35K from the  validation set, as as in the Mask RCNN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:31:14.549016Z",
     "start_time": "2018-05-02T17:30:43.746073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.19s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=8.35s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Training dataset. Use the training set and 35K from the\n",
    "# validation set, as as in the Mask RCNN paper.\n",
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco(args.dataset, \"train\")\n",
    "dataset_train.load_coco(args.dataset, \"val35k\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CocoDataset()\n",
    "dataset_val.load_coco(args.dataset, \"minival\")\n",
    "dataset_val.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T17:23:54.365011Z",
     "start_time": "2018-05-02T17:23:48.545274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outputs: \n",
      "[   <tf.Tensor 'output_rois/mul:0' shape=(2, ?, ?) dtype=float32>,\n",
      "    <tf.Tensor 'proposal_targets/target_class_ids:0' shape=(2, ?) dtype=int32>,\n",
      "    <tf.Tensor 'proposal_targets/target_bbox:0' shape=(2, ?, ?) dtype=float32>,\n",
      "    <tf.Tensor 'proposal_targets/target_mask:0' shape=(2, ?, ?, ?) dtype=float32>,\n",
      "    <tf.Tensor 'rpn_class_logits/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "    <tf.Tensor 'proposal_rois/packed_2:0' shape=(2, ?, ?) dtype=float32>,\n",
      "    <tf.Tensor 'rpn_class/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "    <tf.Tensor 'rpn_bbox/concat:0' shape=(?, ?, 4) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_class_logits/Reshape_1:0' shape=(?, 200, 81) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_class/Reshape_1:0' shape=(?, 200, 81) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_bbox/Reshape:0' shape=(?, 200, 81, 4) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_mask/Reshape_1:0' shape=(?, 200, 28, 28, 81) dtype=float32>,\n",
      "    <tf.Tensor 'fcn_bilinear/ResizeBilinear:0' shape=(2, 1024, 1024, 81) dtype=float32>,\n",
      "    <tf.Tensor 'rpn_class_loss/cond/Merge:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'rpn_bbox_loss/Mean:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_class_loss/Reshape:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_bbox_loss/Reshape_3:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'mrcnn_mask_loss/Reshape_3:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'cntxt_layer/pred_gaussian_1:0' shape=(2, 1024, 1024, 81) dtype=float32>,\n",
      "    <tf.Tensor 'cntxt_layer/gt_gaussian:0' shape=(2, 1024, 1024, 81) dtype=float32>,\n",
      "    <tf.Tensor 'fcn_loss/Reshape_2:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'fcn_norm_loss/Reshape_6:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'cntxt_layer/pred_tensor:0' shape=(2, 81, 200, 6) dtype=float32>,\n",
      "    <tf.Tensor 'cntxt_layer/gt_tensor:0' shape=(2, 81, 100, 6) dtype=float32>]\n",
      "   Layer:  input_image  doesnt have any weights !!!\n",
      "   Layer:  zero_padding2d_1  doesnt have any weights !!!\n",
      "   Layer:  activation_1  doesnt have any weights !!!\n",
      "   Layer:  max_pooling2d_1  doesnt have any weights !!!\n",
      "   Layer:  activation_2  doesnt have any weights !!!\n",
      "   Layer:  activation_3  doesnt have any weights !!!\n",
      "   Layer:  add_1  doesnt have any weights !!!\n",
      "   Layer:  res2a_out  doesnt have any weights !!!\n",
      "   Layer:  activation_4  doesnt have any weights !!!\n",
      "   Layer:  activation_5  doesnt have any weights !!!\n",
      "   Layer:  add_2  doesnt have any weights !!!\n",
      "   Layer:  res2b_out  doesnt have any weights !!!\n",
      "   Layer:  activation_6  doesnt have any weights !!!\n",
      "   Layer:  activation_7  doesnt have any weights !!!\n",
      "   Layer:  add_3  doesnt have any weights !!!\n",
      "   Layer:  res2c_out  doesnt have any weights !!!\n",
      "   Layer:  activation_8  doesnt have any weights !!!\n",
      "   Layer:  activation_9  doesnt have any weights !!!\n",
      "   Layer:  add_4  doesnt have any weights !!!\n",
      "   Layer:  res3a_out  doesnt have any weights !!!\n",
      "   Layer:  activation_10  doesnt have any weights !!!\n",
      "   Layer:  activation_11  doesnt have any weights !!!\n",
      "   Layer:  add_5  doesnt have any weights !!!\n",
      "   Layer:  res3b_out  doesnt have any weights !!!\n",
      "   Layer:  activation_12  doesnt have any weights !!!\n",
      "   Layer:  activation_13  doesnt have any weights !!!\n",
      "   Layer:  add_6  doesnt have any weights !!!\n",
      "   Layer:  res3c_out  doesnt have any weights !!!\n",
      "   Layer:  activation_14  doesnt have any weights !!!\n",
      "   Layer:  activation_15  doesnt have any weights !!!\n",
      "   Layer:  add_7  doesnt have any weights !!!\n",
      "   Layer:  res3d_out  doesnt have any weights !!!\n",
      "   Layer:  activation_16  doesnt have any weights !!!\n",
      "   Layer:  activation_17  doesnt have any weights !!!\n",
      "   Layer:  add_8  doesnt have any weights !!!\n",
      "   Layer:  res4a_out  doesnt have any weights !!!\n",
      "   Layer:  activation_18  doesnt have any weights !!!\n",
      "   Layer:  activation_19  doesnt have any weights !!!\n",
      "   Layer:  add_9  doesnt have any weights !!!\n",
      "   Layer:  res4b_out  doesnt have any weights !!!\n",
      "   Layer:  activation_20  doesnt have any weights !!!\n",
      "   Layer:  activation_21  doesnt have any weights !!!\n",
      "   Layer:  add_10  doesnt have any weights !!!\n",
      "   Layer:  res4c_out  doesnt have any weights !!!\n",
      "   Layer:  activation_22  doesnt have any weights !!!\n",
      "   Layer:  activation_23  doesnt have any weights !!!\n",
      "   Layer:  add_11  doesnt have any weights !!!\n",
      "   Layer:  res4d_out  doesnt have any weights !!!\n",
      "   Layer:  activation_24  doesnt have any weights !!!\n",
      "   Layer:  activation_25  doesnt have any weights !!!\n",
      "   Layer:  add_12  doesnt have any weights !!!\n",
      "   Layer:  res4e_out  doesnt have any weights !!!\n",
      "   Layer:  activation_26  doesnt have any weights !!!\n",
      "   Layer:  activation_27  doesnt have any weights !!!\n",
      "   Layer:  add_13  doesnt have any weights !!!\n",
      "   Layer:  res4f_out  doesnt have any weights !!!\n",
      "   Layer:  activation_28  doesnt have any weights !!!\n",
      "   Layer:  activation_29  doesnt have any weights !!!\n",
      "   Layer:  add_14  doesnt have any weights !!!\n",
      "   Layer:  res5a_out  doesnt have any weights !!!\n",
      "   Layer:  activation_30  doesnt have any weights !!!\n",
      "   Layer:  activation_31  doesnt have any weights !!!\n",
      "   Layer:  add_15  doesnt have any weights !!!\n",
      "   Layer:  res5b_out  doesnt have any weights !!!\n",
      "   Layer:  activation_32  doesnt have any weights !!!\n",
      "   Layer:  activation_33  doesnt have any weights !!!\n",
      "   Layer:  add_16  doesnt have any weights !!!\n",
      "   Layer:  res5c_out  doesnt have any weights !!!\n",
      "   Layer:  fpn_p5upsampled  doesnt have any weights !!!\n",
      "   Layer:  fpn_p4add  doesnt have any weights !!!\n",
      "   Layer:  fpn_p4upsampled  doesnt have any weights !!!\n",
      "   Layer:  fpn_p3add  doesnt have any weights !!!\n",
      "   Layer:  fpn_p3upsampled  doesnt have any weights !!!\n",
      "   Layer:  fpn_p2add  doesnt have any weights !!!\n",
      "   Layer:  fpn_p6  doesnt have any weights !!!\n",
      "   Layer:  rpn_class  doesnt have any weights !!!\n",
      "   Layer:  rpn_bbox  doesnt have any weights !!!\n",
      "   Layer:  input_gt_boxes  doesnt have any weights !!!\n",
      "   Layer:  proposal_rois  doesnt have any weights !!!\n",
      "   Layer:  input_gt_class_ids  doesnt have any weights !!!\n",
      "   Layer:  lambda_1  doesnt have any weights !!!\n",
      "   Layer:  input_gt_masks  doesnt have any weights !!!\n",
      "   Layer:  proposal_targets  doesnt have any weights !!!\n",
      "   Layer:  roi_align_classifier  doesnt have any weights !!!\n",
      "   Layer:  activation_34  doesnt have any weights !!!\n",
      "   Layer:  activation_35  doesnt have any weights !!!\n",
      "   Layer:  pool_squeeze  doesnt have any weights !!!\n",
      "   Layer:  output_rois  doesnt have any weights !!!\n",
      "   Layer:  activation_36  doesnt have any weights !!!\n",
      "   Layer:  mrcnn_bbox  doesnt have any weights !!!\n",
      "   Layer:  cntxt_layer  doesnt have any weights !!!\n",
      "   Layer:  roi_align_mask  doesnt have any weights !!!\n",
      "   Layer:  fcn_block1_pool  doesnt have any weights !!!\n",
      "   Layer:  activation_37  doesnt have any weights !!!\n",
      "   Layer:  fcn_block2_pool  doesnt have any weights !!!\n",
      "   Layer:  activation_38  doesnt have any weights !!!\n",
      "   Layer:  fcn_block3_pool  doesnt have any weights !!!\n",
      "   Layer:  activation_39  doesnt have any weights !!!\n",
      "   Layer:  dropout_1  doesnt have any weights !!!\n",
      "   Layer:  activation_40  doesnt have any weights !!!\n",
      "   Layer:  dropout_2  doesnt have any weights !!!\n",
      "   Layer:  input_image_meta  doesnt have any weights !!!\n",
      "   Layer:  rpn_class_logits  doesnt have any weights !!!\n",
      "   Layer:  fcn_bilinear  doesnt have any weights !!!\n",
      "   Layer:  input_rpn_match  doesnt have any weights !!!\n",
      "   Layer:  input_rpn_bbox  doesnt have any weights !!!\n",
      "   Layer:  lambda_4  doesnt have any weights !!!\n",
      "   Layer:  rpn_class_loss  doesnt have any weights !!!\n",
      "   Layer:  rpn_bbox_loss  doesnt have any weights !!!\n",
      "   Layer:  mrcnn_class_loss  doesnt have any weights !!!\n",
      "   Layer:  mrcnn_bbox_loss  doesnt have any weights !!!\n",
      "   Layer:  mrcnn_mask_loss  doesnt have any weights !!!\n",
      "   Layer:  fcn_loss  doesnt have any weights !!!\n",
      "   Layer:  fcn_norm_loss  doesnt have any weights !!!\n",
      " Layer: conv1\n",
      " Layer: bn_conv1\n",
      " Layer: res2a_branch2a\n",
      " Layer: bn2a_branch2a\n",
      " Layer: res2a_branch2b\n",
      " Layer: bn2a_branch2b\n",
      " Layer: res2a_branch2c\n",
      " Layer: res2a_branch1\n",
      " Layer: bn2a_branch2c\n",
      " Layer: bn2a_branch1\n",
      " Layer: res2b_branch2a\n",
      " Layer: bn2b_branch2a\n",
      " Layer: res2b_branch2b\n",
      " Layer: bn2b_branch2b\n",
      " Layer: res2b_branch2c\n",
      " Layer: bn2b_branch2c\n",
      " Layer: res2c_branch2a\n",
      " Layer: bn2c_branch2a\n",
      " Layer: res2c_branch2b\n",
      " Layer: bn2c_branch2b\n",
      " Layer: res2c_branch2c\n",
      " Layer: bn2c_branch2c\n",
      " Layer: res3a_branch2a\n",
      " Layer: bn3a_branch2a\n",
      " Layer: res3a_branch2b\n",
      " Layer: bn3a_branch2b\n",
      " Layer: res3a_branch2c\n",
      " Layer: res3a_branch1\n",
      " Layer: bn3a_branch2c\n",
      " Layer: bn3a_branch1\n",
      " Layer: res3b_branch2a\n",
      " Layer: bn3b_branch2a\n",
      " Layer: res3b_branch2b\n",
      " Layer: bn3b_branch2b\n",
      " Layer: res3b_branch2c\n",
      " Layer: bn3b_branch2c\n",
      " Layer: res3c_branch2a\n",
      " Layer: bn3c_branch2a\n",
      " Layer: res3c_branch2b\n",
      " Layer: bn3c_branch2b\n",
      " Layer: res3c_branch2c\n",
      " Layer: bn3c_branch2c\n",
      " Layer: res3d_branch2a\n",
      " Layer: bn3d_branch2a\n",
      " Layer: res3d_branch2b\n",
      " Layer: bn3d_branch2b\n",
      " Layer: res3d_branch2c\n",
      " Layer: bn3d_branch2c\n",
      " Layer: res4a_branch2a\n",
      " Layer: bn4a_branch2a\n",
      " Layer: res4a_branch2b\n",
      " Layer: bn4a_branch2b\n",
      " Layer: res4a_branch2c\n",
      " Layer: res4a_branch1\n",
      " Layer: bn4a_branch2c\n",
      " Layer: bn4a_branch1\n",
      " Layer: res4b_branch2a\n",
      " Layer: bn4b_branch2a\n",
      " Layer: res4b_branch2b\n",
      " Layer: bn4b_branch2b\n",
      " Layer: res4b_branch2c\n",
      " Layer: bn4b_branch2c\n",
      " Layer: res4c_branch2a\n",
      " Layer: bn4c_branch2a\n",
      " Layer: res4c_branch2b\n",
      " Layer: bn4c_branch2b\n",
      " Layer: res4c_branch2c\n",
      " Layer: bn4c_branch2c\n",
      " Layer: res4d_branch2a\n",
      " Layer: bn4d_branch2a\n",
      " Layer: res4d_branch2b\n",
      " Layer: bn4d_branch2b\n",
      " Layer: res4d_branch2c\n",
      " Layer: bn4d_branch2c\n",
      " Layer: res4e_branch2a\n",
      " Layer: bn4e_branch2a\n",
      " Layer: res4e_branch2b\n",
      " Layer: bn4e_branch2b\n",
      " Layer: res4e_branch2c\n",
      " Layer: bn4e_branch2c\n",
      " Layer: res4f_branch2a\n",
      " Layer: bn4f_branch2a\n",
      " Layer: res4f_branch2b\n",
      " Layer: bn4f_branch2b\n",
      " Layer: res4f_branch2c\n",
      " Layer: bn4f_branch2c\n",
      " Layer: res5a_branch2a\n",
      " Layer: bn5a_branch2a\n",
      " Layer: res5a_branch2b\n",
      " Layer: bn5a_branch2b\n",
      " Layer: res5a_branch2c\n",
      " Layer: res5a_branch1\n",
      " Layer: bn5a_branch2c\n",
      " Layer: bn5a_branch1\n",
      " Layer: res5b_branch2a\n",
      " Layer: bn5b_branch2a\n",
      " Layer: res5b_branch2b\n",
      " Layer: bn5b_branch2b\n",
      " Layer: res5b_branch2c\n",
      " Layer: bn5b_branch2c\n",
      " Layer: res5c_branch2a\n",
      " Layer: bn5c_branch2a\n",
      " Layer: res5c_branch2b\n",
      " Layer: bn5c_branch2b\n",
      " Layer: res5c_branch2c\n",
      " Layer: bn5c_branch2c\n",
      " Layer: fpn_c5p5\n",
      " Layer: fpn_c4p4\n",
      " Layer: fpn_c3p3\n",
      " Layer: fpn_c2p2\n",
      " Layer: fpn_p5\n",
      " Layer: fpn_p2\n",
      " Layer: fpn_p3\n",
      " Layer: fpn_p4\n",
      " Layer: rpn_model\n",
      " Layer: conv2d_1\n",
      " Layer: batch_norm_1\n",
      " Layer: conv2d_2\n",
      " Layer: batch_norm_2\n",
      " Layer: dense_1\n",
      " Layer: dense_2\n",
      " Layer: fcn_block1_conv1\n",
      " Layer: fcn_block1_conv2\n",
      " Layer: conv2d_3\n",
      " Layer: batch_norm_3\n",
      " Layer: fcn_block2_conv1\n",
      " Layer: fcn_block2_conv2\n",
      " Layer: conv2d_4\n",
      " Layer: batch_norm_4\n",
      " Layer: fcn_block3_conv1\n",
      " Layer: fcn_block3_conv2\n",
      " Layer: conv2d_5\n",
      " Layer: fcn_block3_conv3\n",
      " Layer: batch_norm_5\n",
      " Layer: fcn_fc1\n",
      " Layer: conv2d_6\n",
      " Layer: batch_norm_6\n",
      " Layer: fcn_fc2\n",
      " Layer: conv2d_transpose_1\n",
      " Layer: fcn_classify\n",
      " Layer: conv2d_7\n"
     ]
    }
   ],
   "source": [
    "print('\\n Outputs: ') \n",
    "pp.pprint(model.keras_model.outputs)\n",
    "\n",
    "trainable = model.get_trainable_layers()\n",
    "for i in trainable:\n",
    "    print(' Layer:', i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training - Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-02T17:31:17.092Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "In model:  rpn_model\n",
      "212  fcn_block1_conv1       (Conv2D)\n",
      "214  fcn_block1_conv2       (Conv2D)\n",
      "218  fcn_block2_conv1       (Conv2D)\n",
      "220  fcn_block2_conv2       (Conv2D)\n",
      "224  fcn_block3_conv1       (Conv2D)\n",
      "226  fcn_block3_conv2       (Conv2D)\n",
      "228  fcn_block3_conv3       (Conv2D)\n",
      "232  fcn_fc1                (Conv2D)\n",
      "236  fcn_fc2                (Conv2D)\n",
      "240  fcn_classify           (Conv2D)\n",
      "   keras model add loss for  Tensor(\"fcn_loss/Reshape_2:0\", shape=(1, 1), dtype=float32)\n",
      "   keras model add loss for  Tensor(\"fcn_norm_loss/Reshape_6:0\", shape=(1, 1), dtype=float32)\n",
      "Starting at epoch 0 of 2 epochs. LR=0.001\n",
      "\n",
      "Steps per epochs 2 \n",
      "Checkpoint Path: E:\\Models\\mrcnn_coco_logs\\coco20180502T1930\\mask_rcnn_coco_{epoch:04d}.h5\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:616: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training - Stage 1\n",
    "model.config.STEPS_PER_EPOCH = 2\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=2,\n",
    "            layers='fcn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training - Stage 2 - Finetune layers from ResNet stage 4 and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.331480Z",
     "start_time": "2018-05-02T16:55:17.538Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=120,\n",
    "            layers='4+')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Stage 3 - Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.333484Z",
     "start_time": "2018-05-02T16:55:17.541Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=160,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.334488Z",
     "start_time": "2018-05-02T16:55:17.544Z"
    }
   },
   "outputs": [],
   "source": [
    "# for layer in model.keras_model.layers\n",
    "#     print layer.name \n",
    "mdl = model.keras_model\n",
    "layers    = [layer for layer in mdl.layers]          # all layer outputs\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.335522Z",
     "start_time": "2018-05-02T16:55:17.548Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(layers)):\n",
    "    lay = layers[i]\n",
    "    print('** Layer {} , ({})'.format(i, lay.name))\n",
    "    print('===========================================')\n",
    "    for innode in lay._inbound_nodes:\n",
    "        print('\\t Inbound Node:  ', innode)\n",
    "        print('\\t               From Layers: ', [inlayer.name for inlayer in innode.inbound_layers])\n",
    "        print('\\t                    Shapes: ', [inshape for inshape in innode.input_shapes])\n",
    "        print('\\t               To   Layers: ', innode.outbound_layer.name)\n",
    "#         pp.pprint(innode.__dict__)\n",
    "#         print('\\t                    Shapes: ', [outshape for outshape in innode.output_shapes])        \n",
    "    print('\\t-------------------------------------------')\n",
    "    print('\\t Layer:', lay.name, '\\t\\t type  ' , lay)\n",
    "#     print('-------------------------------------------')\n",
    "#     pp.pprint(lay.__dict__)\n",
    "#     print('-------------------------------------------')\n",
    "    print('\\t     Layer Output Shapes: ', [outshape for outshape in innode.output_shapes])        \n",
    "    print('\\t-------------------------------------------')\n",
    "    for outnode in lay._outbound_nodes:\n",
    "        print('\\t Outbound Node: ', outnode)\n",
    "#         print('\\t               From Layers: ', [inlayer.name for inlayer in outnode.inbound_layers])\n",
    "#         print('\\t                    Shapes: ', [inshape for inshape in outnode.input_shapes])\n",
    "        print('\\t               To   Layer: ', outnode.outbound_layer.name)\n",
    "#         print('                    Shapes: ', [outshape for outshape in outnode.output_shapes])    \n",
    "    \n",
    "#         pp.pprint(outnode.__dict__)\n",
    "    print('===========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.336520Z",
     "start_time": "2018-05-02T16:55:17.552Z"
    }
   },
   "outputs": [],
   "source": [
    "model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.338003Z",
     "start_time": "2018-05-02T16:55:17.556Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_anchors(scales, ratios, shape, feature_stride, anchor_stride):\n",
    "    \"\"\"\n",
    "    scales: 1D array of anchor sizes in pixels. Example: [32, 64, 128]\n",
    "    ratios: 1D array of anchor ratios of width/height. Example: [0.5, 1, 2]\n",
    "    shape: [height, width] spatial shape of the feature map over which\n",
    "            to generate anchors.\n",
    "    feature_stride: Stride of the feature map relative to the image in pixels.\n",
    "    anchor_stride: Stride of anchors on the feature map. For example, if the\n",
    "        value is 2 then generate anchors for every other feature map pixel.\n",
    "    \"\"\"\n",
    "    print('Generate Anchors: \\n ================== \\n scales: ',scales, 'Anchor Ratios:', ratios, 'Anchor stride', anchor_stride,'Feat. Shape:', shape, ' Feat stride', feature_stride)\n",
    "    # Get all combinations of scales and ratios\n",
    "    scales, ratios = np.meshgrid(np.array(scales), np.array(ratios))\n",
    "    scales = scales.flatten()\n",
    "    ratios = ratios.flatten()\n",
    "    print('Scales: ',scales,'\\n Ratios:', ratios)\n",
    "    # Enumerate heights and widths from scales and ratios\n",
    "    heights = scales / np.sqrt(ratios)\n",
    "    widths = scales * np.sqrt(ratios)\n",
    "\n",
    "    print(' heights: ',heights,'\\n widths: ', widths)\n",
    "    \n",
    "    # Enumerate shifts in feature space\n",
    "    shifts_y = np.arange(0, shape[0], anchor_stride) * feature_stride\n",
    "    shifts_x = np.arange(0, shape[1], anchor_stride) * feature_stride\n",
    "#     print(' shifts_x : ',shifts_x.shape, '\\n shifts_y : ',  shifts_y.shape )    \n",
    "    shifts_x, shifts_y = np.meshgrid(shifts_x, shifts_y)\n",
    "#     print(' shifts_x : ',shifts_x.shape,shifts_x,'\\n shifts_y : ',  shifts_y.shape,shifts_y)\n",
    "    \n",
    "    # Enumerate combinations of shifts, widths, and heights\n",
    "    box_widths, box_centers_x = np.meshgrid(widths, shifts_x)\n",
    "    box_heights, box_centers_y = np.meshgrid(heights, shifts_y)\n",
    "#     print('box_widths : ',box_widths.shape,'\\n',box_widths,'\\n box_centers_x: ',  box_centers_x.shape,'\\n',box_centers_x)\n",
    "#     print('box_heights : ',box_heights.shape,'\\n',box_heights,'\\n box_centers_y: ',  box_centers_y.shape,'\\n',box_centers_y)\n",
    "\n",
    "    # Reshape to get a list of (y, x) and a list of (h, w)\n",
    "    # This will create a array of (y,x) which has \n",
    "    box_centers = np.stack([box_centers_y, box_centers_x], axis=2)\n",
    "#     print('box_centers : ', box_centers.shape,'\\n',box_centers)\n",
    "    box_centers = box_centers.reshape([-1, 2])\n",
    "    box_sizes   = np.stack([box_heights, box_widths], axis=2).reshape([-1, 2])\n",
    "#     print('box_centers : ', box_centers.shape,'\\n',box_centers)\n",
    "#     print('box_sizes   : ', box_sizes.shape,'\\n',box_sizes)\n",
    "\n",
    "    # Convert to corner coordinates (y1, x1, y2, x2)\n",
    "    boxes = np.concatenate([box_centers - 0.5 * box_sizes, box_centers + 0.5 * box_sizes], axis=1)\n",
    "#     print('boxes   : ', boxes.shape,'\\n',boxes)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.339500Z",
     "start_time": "2018-05-02T16:55:17.558Z"
    }
   },
   "outputs": [],
   "source": [
    "# self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,\n",
    "#                                               config.RPN_ANCHOR_RATIOS,\n",
    "#                                               config.BACKBONE_SHAPES,\n",
    "#                                               config.BACKBONE_STRIDES,\n",
    "#                                               config.RPN_ANCHOR_STRIDE)\n",
    "# Anchors\n",
    "# [anchor_count, (y1, x1, y2, x2)]\n",
    "scales = config.RPN_ANCHOR_SCALES\n",
    "ratios = config.RPN_ANCHOR_RATIOS\n",
    "anchor_stride   = config.RPN_ANCHOR_STRIDE\n",
    "feature_shapes  = config.BACKBONE_SHAPES\n",
    "feature_strides = config.BACKBONE_STRIDES\n",
    "\n",
    "print ('Anchoo scales: ',scales, 'Anchor Ratios:', ratios, 'Anchor stride', anchor_stride)\n",
    "print(feature_shapes, '\\n Feature strides', feature_strides)\n",
    "anchors = []\n",
    "for i in range(len(scales)):    \n",
    "    anchors.append(generate_anchors(scales[i], ratios, feature_shapes[i],\n",
    "                                    feature_strides[i], anchor_stride))\n",
    "    \n",
    "# return np.concatenate(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:55:39.341004Z",
     "start_time": "2018-05-02T16:55:17.562Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in anchors :\n",
    "    print(i.shape)\n",
    "np.concatenate(anchors, axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
