{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:18:50.220820Z",
     "start_time": "2018-11-08T19:18:37.520500Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "--> Execution started at: 11-08-2018 @ 20:18:39\n",
      ">>> Initialize Paths\n",
      " Linx  Linux\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              /users/students/r0653928/MLDatasets/coco2014\n",
      "COCO_HEATMAP_PATH              /users/students/r0653928/MLDatasets/coco2014_heatmaps\n",
      "COCO_MODEL_PATH                /users/students/r0653928/PretrainedModels/mask_rcnn_coco.h5\n",
      "DIR_DATASET                    /users/students/r0653928/MLDatasets\n",
      "DIR_PRETRAINED                 /users/students/r0653928/PretrainedModels\n",
      "DIR_ROOT                       /esat/tiger/joramas/mscStudentsData/kbardool/projs/mrcnn3/notebooks\n",
      "DIR_TRAINING                   /users/students/r0653928/models\n",
      "FCN_TRAINING_PATH              /users/students/r0653928/models/train_fcn_coco\n",
      "FCN_VGG16_MODEL_PATH           /users/students/r0653928/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            /users/students/r0653928/models/train_mrcnn_coco\n",
      "RESNET_MODEL_PATH              /users/students/r0653928/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "VGG16_MODEL_PATH               /users/students/r0653928/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n",
      "image_dir :  /users/students/r0653928/MLDatasets/coco2014/train2014 \n",
      " heatmap_dir:  /users/students/r0653928/MLDatasets/coco2014_heatmaps/train2014\n",
      "heat ap dir : /users/students/r0653928/MLDatasets/coco2014_heatmaps/train2014\n",
      " heatmap_files : 5000\n",
      "-1     hm_000000567278.npz img meta:  30016\n",
      "-1     hm_000000567245.npz img meta:  30000\n",
      "-1     hm_000000174066.npz img meta:  30017\n",
      "-1     hm_000000312252.npz img meta:  34998\n",
      "-1     hm_000000436182.npz img meta:  30001\n",
      "-1     hm_000000050101.npz img meta:  34999\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "# import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "# import mrcnn.model_fcn    as fcn_modellib\n",
    "# import mrcnn.visualize    as visualize\n",
    "# import mrcnn.utils        as utils\n",
    "\n",
    "from datetime           import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "\n",
    "# from mrcnn.utils        import log, stack_tensors, stack_tensors_3d, write_stdout\n",
    "# from mrcnn.datagen      import data_generator, load_image_gt, data_gen_simulate\n",
    "\n",
    "from mrcnn.datagen_fcn  import fcn_data_gen_simulate\n",
    "# from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.coco         import CocoDataset, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.coco         import CocoConfig\n",
    "# from mrcnn.heatmap      import HeatmapDataset\n",
    "from mrcnn.prep_notebook import prep_heatmap_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "# print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "\n",
    "\n",
    "paths = Paths()\n",
    "paths.display()\n",
    "\n",
    "subset = 'train'\n",
    "dataset_dir = paths.COCO_DATASET_PATH\n",
    "heatmap_dir = paths.COCO_HEATMAP_PATH\n",
    "image_dir = os.path.join(dataset_dir, \"train2014\" if subset == \"train\" else \"val2014\")\n",
    "heatmap_dir = os.path.join(heatmap_dir, \"train2014\" if subset == \"train\" else \"val2014\")\n",
    "print('image_dir : ', image_dir,'\\n heatmap_dir: ', heatmap_dir)\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Get image ids - using walk on HEATMAP_PATH\n",
    "#--------------------------------------------------------------\n",
    "# print(' image dir        : ', image_dir) \n",
    "# print(' json_path_dir    : ', os.path.join(dataset_dir, json_path_dict[subset]))\n",
    "# regex = re.compile(\".*/\\w+(\\d{12})\\.jpg\")\n",
    "\n",
    "\n",
    "# image_ids = [] \n",
    "heatmap_files = next(os.walk(heatmap_dir))[2]\n",
    "print('heat ap dir :' , heatmap_dir)\n",
    "print(' heatmap_files :', len(heatmap_files))\n",
    "for hm_file in heatmap_files :\n",
    "#     hm_file =  heatmap_files[it]\n",
    "#     print(' Processing file: ', hm_file)\n",
    "    heatmap_path=os.path.join(heatmap_dir, hm_file) \n",
    "    # i = int(os.path.splitext(hm_file.lstrip('hm_'))[0])\n",
    "    loaddata = np.load(heatmap_path)\n",
    "#     print(loaddata.keys())\n",
    "    img_meta = loaddata['input_image_meta'][0]\n",
    "#     img_id   = img_meta[0]\n",
    "#     input_image_meta = loaddata['input_image_meta']\n",
    "#     input_filename   = str(loaddata['dataset_name']) \n",
    "    loaddata.close()\n",
    "    if img_meta in [30000, 30001, 30016, 30017, 34998, 34999]:\n",
    "        print(it,'   ', hm_file, 'img meta: ', img_meta)\n",
    "    # coco_filename = input_filename.replace('\\\\' , \"/\")\n",
    "    # print(coco_filename)\n",
    "    # regex_match  = regex.match(input_filename)            \n",
    "    # # Add images to dataset.image_info structure\n",
    "    # if regex_match:\n",
    "        # coco_id = int(regex_match.group(1))\n",
    "    # print(i, input_image_meta[:8],' ', input_filename, ' coco_id : ',coco_id)\n",
    " \n",
    "# print(' number of images : ', len(image_ids))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
