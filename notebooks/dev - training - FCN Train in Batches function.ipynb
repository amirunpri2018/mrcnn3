{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Development notebook  FCN model \n",
    "\n",
    "Evaluate returned heatmap values from FCN, by passing data through MRCNN and then through FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:48.077377Z",
     "start_time": "2018-11-08T11:47:33.890832Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Execution started at: 11-08-2018 @ 11:47:41\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.1.6 \n",
      "--epochs 2 --steps_in_epoch 2 --val_steps 8 --last_epoch 0 --batch_size 1 --lr 0.00001 --mrcnn_logs_dir train_mrcnn_coco --fcn_logs_dir   train_fcn8_coco --mrcnn_model    last --fcn_model      init --opt            adagrad --fcn_arch       fcn8 --fcn_layers     all --sysout        screen --new_log_folder    \n",
      "    MRCNN Model        :  last\n",
      "    FCN Model          :  init\n",
      "    MRCNN Log Dir      :  train_mrcnn_coco\n",
      "    FCN Log Dir        :  train_fcn8_coco\n",
      "    FCN Arch           :  FCN8\n",
      "    FCN Log Dir        :  ['all']\n",
      "    Last Epoch         :  0\n",
      "    Epochs to run      :  2\n",
      "    Steps in each epoch:  2\n",
      "    Validation steps   :  8\n",
      "    Batch Size         :  1\n",
      "    Optimizer          :  ADAGRAD\n",
      "    sysout             :  SCREEN\n",
      ">>> Initialize Paths\n",
      " Linx  Linux\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DIR_DATASET                    /home/kbardool/MLDatasets\n",
      "DIR_PRETRAINED                 /home/kbardool/PretrainedModels\n",
      "DIR_ROOT                       /home/kbardool/git_projs/mrcnn3/notebooks\n",
      "DIR_TRAINING                   /home/kbardool/models\n",
      "FCN_TRAINING_PATH              /home/kbardool/models/train_fcn8_coco\n",
      "FCN_VGG16_MODEL_PATH           /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            /home/kbardool/models/train_mrcnn_coco\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [1024 1024]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    81\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  /home/kbardool/models/train_mrcnn_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  trainfcn\n",
      "   Model dir :  /home/kbardool/models/train_mrcnn_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  trainfcn\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 1024, 1024, 3)\n",
      "     After ZeroPadding2D  : (?, 1030, 1030, 3) (?, 1030, 1030, 3)\n",
      "     After Conv2D padding : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     After BatchNorm      : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     C1 Shape: (?, 256, 256, 64) (?, 256, 256, 64)\n",
      "     C2 Shape:  (?, 256, 256, 256) (?, 256, 256, 256)\n",
      "     C3 Shape:  (?, 128, 128, 512) (?, 128, 128, 512)\n",
      "     C4 Shape:  (?, 64, 64, 1024) (?, 64, 64, 1024)\n",
      "     C5 Shape:  (?, 32, 32, 2048) (?, 32, 32, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 256, 256, 256)\n",
      "     FPN P3 shape : (None, 128, 128, 256)\n",
      "     FPN P4 shape : (None, 64, 64, 256)\n",
      "     FPN P5 shape : (None, 32, 32, 256)\n",
      "     FPN P6 shape : (None, 16, 16, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "     append Tensor(\"fpn_p2/BiasAdd:0\", shape=(?, 256, 256, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p3/BiasAdd:0\", shape=(?, 128, 128, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p4/BiasAdd:0\", shape=(?, 64, 64, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p5/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p6/MaxPool:0\", shape=(?, 16, 16, 256), dtype=float32) to layer_outputs \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (261888, 4)\n",
      "     Scores :  (1, 6000)\n",
      "     Deltas :  (1, 6000, 4)\n",
      "     Anchors:  (1, 6000, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      " Parse Image Meta Graph \n",
      "     meta :  <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n",
      " Parse Image Meta Graph \n",
      "     meta :  <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (1, ?, ?) (1, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (1, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     INPUT: rois shape          : (1, ?, ?)\n",
      "     INPUT: No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 256, 256, 256)\n",
      "        feature_maps shape  : (?, 128, 128, 256)\n",
      "        feature_maps shape  : (?, 64, 64, 256)\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "     INPUT: image_shape         : [1024 1024    3]\n",
      "     INPUT: pool_size           : 7\n",
      "     INPUT: num_classes         : 81\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 200, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 200, 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mrcnn_class_logits   output shape is :  (?, 200, 81)\n",
      "     mrcnn_class_probs    output shape is :  (?, 200, 81)\n",
      "     mrcnn_bbox_fc        output shape is :  (?, 200, 324)\n",
      "     mrcnn_bbox_fc        reshaped output :  (?, 200, 324)\n",
      "     mrcnn_bbox           output shape is :  (?, 200, 81, 4)\n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "  > CHMLayer Call()  3\n",
      "    mrcnn_class.shape    : (?, 200, 81) (None, 200, 81)\n",
      "    mrcnn_bbox.shape     : (?, 200, 81, 4) (None, 200, 81, 4)\n",
      "    output_rois.shape    : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois               :  200\n",
      "    norm_input_rois.shape  :  <class 'tensorflow.python.framework.ops.Tensor'> (None, 200, 4)\n",
      "    scale.shape            :  <class 'tensorflow.python.framework.ops.Tensor'> (4,) (4,)\n",
      "    dup_scale.shape        :  <class 'tensorflow.python.framework.ops.Tensor'> (1, 200, 4) (1, 200, 4)\n",
      "\n",
      "    mrcnn_class shape      :  (None, 200, 81)\n",
      "    mrcnn_bbox.shape       :  (None, 200, 81, 4) (?, 200, 81, 4)\n",
      "    config image shape     :  [1024 1024    3] h: 1024 w: 1024\n",
      "    refined rois clipped   :  (1, 200, 4)\n",
      "    input_rois.shape       :  (1, 200, 4) (1, 200, 4)\n",
      "    refined_rois.shape     :  (1, 200, 4) (1, 200, 4)\n",
      "    shape of sequence      :  (?, 200, 1)\n",
      "    pred_array             :  (1, 200, 7)\n",
      "    scatter_ind            :  <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 200, 3)\n",
      "    pred_scatter           :  (1, 81, 200, 7)\n",
      "    - Add normalized score --\n",
      "\n",
      "    normalizer             :  (1, 81, 1)\n",
      "    norm_score             :  (1, 81, 200, 1)\n",
      "    pred_scatter           :  (1, 81, 200, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    roi_grid shape         :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    roi_grid_exp           :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200, 1)\n",
      "    gather_inds            :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200, 3)\n",
      "    pred_tensor            :  (1, 81, 200, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['pred_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "    X/Y shapes : (256, 256) (256, 256)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    ones_exp * Y (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    pos_grid before transpse :  (?, 256, 256, 2)\n",
      "    pos_grid after transpose :  (256, 256, ?, 2)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (256, 256, ?, 2)\n",
      "     Prob_grid shape from mvn.probe:  (256, 256, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 256, 256)\n",
      "    << output probabilities shape  :  (?, 256, 256)\n",
      "    scores_scattered shape :  (1, 81, 200, 3)\n",
      "    gauss_scores  (FINAL)  :  (1, 81, 200, 11)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer     :  (?, 1, 1)\n",
      "    prob_grid_norm_scaled :  (?, 256, 256)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape      :  (?, 3)\n",
      "    prob_grid_clippped :  (?, 256, 256)\n",
      "    gauss_heatmap      :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 81, 256, 256) Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer shape   :  (1, 81, 1, 1)\n",
      "    normalized heatmap :  (1, 81, 256, 256)  Keras tensor  False\n",
      "    reshaped heatmap :  (1, 256, 256, 81)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    pred_refined_heatmap        :  (1, 256, 256, 81) Keras tensor  False\n",
      "    pred_refnined_heatmap_scores:  (1, 81, 200, 11) Keras tensor  False\n",
      "    complete\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "  > CHMLayerTgt Call()  2\n",
      "    tgt_class_ids.shape  : (1, ?) (None, 200)\n",
      "    tgt_bboxes.shape     : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    num_bboxes             :  200 (building  gt_tensor )\n",
      "    gt_class_ids shape     :  (1, ?)    (None, 200)\n",
      "    norm_gt_bboxes.shape   :  (1, ?, ?)    (None, 200, 4)\n",
      "    gt_bboxes.shape        :  (1, 200, 4)    (1, 200, 4)\n",
      "    gt_classes_exp         :  (1, ?, 1)\n",
      "    gt_scores_exp          :  (1, ?, 1)\n",
      "    gt_array shape         :  (1, 200, 8) (1, 200, 8)\n",
      "    scatter_ind shape      :  (1, 200, 3) (1, 200, 3)\n",
      "    tf.shape(gt_array)[-1] :  8 (1, 200, 8)\n",
      "    gt_scatter shape       :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    gather_inds            :  (1, 81, 200, 3)\n",
      "    gt_tensor.shape        :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "     Prob_grid shape :  (?, 256, 256)\n",
      "    prob_grid_clipped      :  (?, 256, 256)\n",
      "    scores_scattered shape :  (1, 81, 200, 3)\n",
      "    gauss_scores           :  (1, 81, 200, 11)  Name:    cntxt_layer_gt/gt_heatmap_scores:0\n",
      "    gauss_scores  (FINAL)  :  (1, 81, 200, 11)  Keras tensor  False\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 256, 256)\n",
      "    gauss_heatmap   :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce MAX based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 81, 256, 256) Keras tensor  False\n",
      "    gauss_heatmap :  (1, 256, 256, 81)  Keras tensor  False\n",
      "\n",
      "    gt_heatmap                  :  (1, 256, 256, 81) Keras tensor  False\n",
      "    gt_heatmap_scores           :  (1, 81, 200, 11) Keras tensor  False\n",
      "    complete\n",
      "<<<  shape of pred_heatmap   :  (1, 256, 256, 81)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (1, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 1024, 1024, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 81, 200, 11)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 81, 200, 11)\n",
      " layer:  4    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  5    output name: mrcnn_class_logits/Reshape_1:0             Type: float32           Shape: (?, 200, 81)\n",
      " layer:  6    output name: lambda_3/strided_slice_3:0                 Type: float32           Shape: (?, ?)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "import mrcnn.utils        as utils\n",
    "\n",
    "from datetime           import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.utils        import log   ##, stack_tensors, stack_tensors_3d, write_stdout\n",
    "from mrcnn.datagen      import data_generator, load_image_gt, data_gen_simulate\n",
    "from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.prep_notebook import mrcnn_newshape_train, prep_newshape_dataset,prep_coco_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "####  Pass input parameters to argparse\n",
    "\n",
    "# args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 1264 --batch_size 8  --lr 0.5               --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())\n",
    "# input_parms = \"--epochs 100 --steps_in_epoch 100  --last_epoch 1264 --batch_size 25 --lr 0.8 --val_steps 5 --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "# input_parms +=\" --model     /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 \"\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \"--epochs 2 \"\n",
    "input_parms += \"--steps_in_epoch 2 \" \n",
    "input_parms += \"--val_steps 8 \" \n",
    "input_parms += \"--last_epoch 0 --batch_size 1 --lr 0.00001 \"\n",
    "# input_parms +=\"--mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "# input_parms +=\"--fcn_logs_dir   train_fcn8_newshapes \"\n",
    "input_parms +=\"--mrcnn_logs_dir train_mrcnn_coco \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_coco \"\n",
    "input_parms +=\"--mrcnn_model    last \"\n",
    "input_parms +=\"--fcn_model      init \"\n",
    "input_parms +=\"--opt            adagrad \"\n",
    "input_parms +=\"--fcn_arch       fcn8 \" \n",
    "input_parms +=\"--fcn_layers     all \" \n",
    "input_parms +=\"--sysout        screen \"\n",
    "input_parms +=\"--new_log_folder    \"\n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## if debug is true set stdout destination to stringIO\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "# debug = False\n",
    "if args.sysout == 'FILE':\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "# print(\"    Dataset            : \", args.dataset)\n",
    "# print(\"    Logs               : \", args.logs)\n",
    "# print(\"    Limit              : \", args.limit)\n",
    "print(\"    MRCNN Model        : \", args.mrcnn_model)\n",
    "print(\"    FCN Model          : \", args.fcn_model)\n",
    "print(\"    MRCNN Log Dir      : \", args.mrcnn_logs_dir)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_logs_dir)\n",
    "print(\"    FCN Arch           : \", args.fcn_arch)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_layers)\n",
    "print(\"    Last Epoch         : \", args.last_epoch)\n",
    "print(\"    Epochs to run      : \", args.epochs)\n",
    "print(\"    Steps in each epoch: \", args.steps_in_epoch)\n",
    "print(\"    Validation steps   : \", args.val_steps)\n",
    "print(\"    Batch Size         : \", args.batch_size)\n",
    "print(\"    Optimizer          : \", args.opt)\n",
    "print(\"    sysout             : \", args.sysout)\n",
    "# print(\"    OS Platform        : \", syst)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "##   ROOT_DIR         : Root directory of the project \n",
    "##   MODEL_DIR        : Directory to save logs and trained model\n",
    "##   COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "##---------------------------------------------------------------------------------\n",
    "paths = Paths(fcn_training_folder = args.fcn_logs_dir, mrcnn_training_folder = args.mrcnn_logs_dir)\n",
    "paths.display()\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------                          \n",
    "mrcnn_config                    = CocoConfig()\n",
    "# import mrcnn.new_shapes as new_shapes\n",
    "# mrcnn_config = new_shapes.NewShapesConfig()\n",
    "\n",
    "mrcnn_config.NAME               = 'mrcnn'              \n",
    "mrcnn_config.TRAINING_PATH      = paths.MRCNN_TRAINING_PATH\n",
    "mrcnn_config.COCO_DATASET_PATH  = paths.COCO_DATASET_PATH \n",
    "mrcnn_config.COCO_MODEL_PATH    = paths.COCO_MODEL_PATH   \n",
    "mrcnn_config.RESNET_MODEL_PATH  = paths.RESNET_MODEL_PATH \n",
    "mrcnn_config.VGG16_MODEL_PATH   = paths.VGG16_MODEL_PATH  \n",
    "mrcnn_config.COCO_CLASSES       = None \n",
    "mrcnn_config.DETECTION_PER_CLASS = 200\n",
    "mrcnn_config.HEATMAP_SCALE_FACTOR = 4\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "\n",
    "mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "mrcnn_config.VALIDATION_STEPS   = int(args.val_steps)\n",
    "mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "mrcnn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "mrcnn_config.MIN_LR             = 1.0e-10\n",
    "mrcnn_config.OPTIMIZER          = args.opt.upper()\n",
    "mrcnn_config.NEW_LOG_FOLDER       = True\n",
    "mrcnn_config.SYSOUT               = args.sysout\n",
    "mrcnn_config.display() \n",
    "\n",
    "\n",
    "###  Build Model\n",
    "\n",
    "from mrcnn.prep_notebook import mrcnn_coco_train\n",
    "mrcnn_model, mrcnn_config = mrcnn_coco_train(mode = 'trainfcn', mrcnn_config = mrcnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:48.129929Z",
     "start_time": "2018-11-08T11:47:48.080169Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            80\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [1024 1024]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    81\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             40\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  /home/kbardool/models/train_mrcnn_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 1024, 1024, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 81, 200, 11)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 81, 200, 11)\n",
      " layer:  4    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  5    output name: mrcnn_class_logits/Reshape_1:0             Type: float32           Shape: (?, 200, 81)\n",
      " layer:  6    output name: lambda_3/strided_slice_3:0                 Type: float32           Shape: (?, ?)\n"
     ]
    }
   ],
   "source": [
    "# mrcnn_model.config.EPOCHS_TO_RUN = 1\n",
    "mrcnn_model.config.display()  \n",
    "mrcnn_model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build FCN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:48.237352Z",
     "start_time": "2018-11-08T11:47:48.134367Z"
    }
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration for FCN model\n",
    "##------------------------------------------------------------------------------------\n",
    "fcn_config = CocoConfig()\n",
    "fcn_config.NAME                 = 'fcn'              \n",
    "fcn_config.TRAINING_PATH        = paths.FCN_TRAINING_PATH\n",
    "fcn_config.VGG16_MODEL_PATH     = paths.FCN_VGG16_MODEL_PATH\n",
    "fcn_config.FCN_INPUT_SHAPE      = mrcnn_config.IMAGE_SHAPE[0:2] // mrcnn_config.HEATMAP_SCALE_FACTOR \n",
    "\n",
    "fcn_config.BATCH_SIZE           = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "fcn_config.IMAGES_PER_GPU       = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "fcn_config.EPOCHS_TO_RUN        = int(args.epochs)\n",
    "fcn_config.STEPS_PER_EPOCH      = int(args.steps_in_epoch)\n",
    "fcn_config.LEARNING_RATE        = float(args.lr)\n",
    "fcn_config.LAST_EPOCH_RAN       = int(args.last_epoch)\n",
    "fcn_config.VALIDATION_STEPS     = int(args.val_steps)\n",
    "\n",
    "fcn_config.WEIGHT_DECAY         = 2.0e-4     ## FCN Weight decays are 5.0e-4 or 2.0e-4\n",
    "fcn_config.BATCH_MOMENTUM       = 0.9\n",
    "\n",
    "fcn_config.REDUCE_LR_FACTOR     = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN   = 15\n",
    "fcn_config.REDUCE_LR_PATIENCE   = 50\n",
    "fcn_config.REDUCE_LR_MIN_DELTA  = 1e-6\n",
    "\n",
    "fcn_config.EARLY_STOP_PATIENCE  = 75\n",
    "fcn_config.EARLY_STOP_MIN_DELTA = 1.0e-7\n",
    "\n",
    "fcn_config.MIN_LR               = 1.0e-10\n",
    "fcn_config.CHECKPOINT_PERIOD    = 1\n",
    "\n",
    "fcn_config.NEW_LOG_FOLDER       = args.new_log_folder\n",
    "fcn_config.OPTIMIZER            = args.opt.upper()\n",
    "fcn_config.SYSOUT               = args.sysout\n",
    "# fcn_config.display()\n",
    "\n",
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:48.914726Z",
     "start_time": "2018-11-08T11:47:48.239792Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  /home/kbardool/models/train_fcn8_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN8\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                  NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): /home/kbardool/models/train_fcn8_coco/fcn20181108T1147/fcn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : /home/kbardool/models/train_fcn8_coco/fcn20181108T1147 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      "    arch set to FCN8 - with No L2 Regularization\n",
      "<function fcn8_graph at 0x7f221f2e18c8>\n",
      " Parse Image Meta Graph \n",
      "     meta :  <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n",
      " Parse Image Meta Graph \n",
      "     meta :  <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n",
      "   active_class_ids  shape is :  (None, None)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "   Arch:  FCN8  Adding  FCN layers\n",
      "---------------------------------------------------\n",
      "\n",
      "---------------\n",
      ">>> FCN8 Layer \n",
      "---------------\n",
      "     feature map      : (?, 256, 256, 81)\n",
      "     height : 256 width : 256 classes : 81\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   Input feature map                   :  (?, 256, 256, 81)\n",
      "   FCN Block 11 shape is               :  (None, 256, 256, 64)\n",
      "   FCN Block 12 shape is               :  (None, 256, 256, 64)\n",
      "   FCN Block 13 (Max pooling) shape is :  (None, 128, 128, 64)\n",
      "   FCN Block 21 shape is               :  (?, 128, 128, 128)\n",
      "   FCN Block 22 shape is               :  (None, 128, 128, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (None, 64, 64, 128)\n",
      "   FCN Block 31 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 32 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 33 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 41 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 42 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 43 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 51 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 52 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 53 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (None, 8, 8, 512)\n",
      "\n",
      "   --- FCN32 ----------------------------\n",
      "   FCN fully connected 1 (fc1) shape   :  (None, 8, 8, 4096)\n",
      "   FCN fully connected 2 (fc2) shape   :  (None, 8, 8, 4096)\n",
      "   FCN conv2d (fcn32_deconv2D) shape   :  (?, 8, 8, 81)  keras_tensor  True\n",
      "\n",
      "   --- FCN16 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape is                   :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling (Deconvolution2D(fcn32_classify)) shape :  (None, 18, 18, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 Add(score2_c, scorePool4) shape :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN upscore_pool4 (Deconv(fuse_Pool4)) shape              :  (None, 32, 32, 81)    keras_tensor  True\n",
      "\n",
      "   --- FCN8 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape                      :  (None, 32, 32, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 32, 32, 81)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 shape is                        :  (None, 32, 32, 81)    keras_tensor  True\n",
      "\n",
      "   FCN fcn8_classify/heatmap  (Deconv(fuse_Pool4)) shape:  (None, 256, 256, 81)    keras_tensor  True\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  True\n",
      "    pred_heatmap : (?, ?, ?, 81) (None, 256, 256, 81) KerasTensor:  True\n",
      "    loss         : (?, 256, 256) (None, 256, 256) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  False\n",
      "    pred_heatmap : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  False\n",
      "    loss         : (?, 256, 256) (None, 256, 256) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 256, 256, 81)\n",
      "    pred_class_logits : (None, 256, 256, 81)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, None, None) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 256, 256) <dtype: 'int64'>\n",
      "    pred_active       : (None, None, None) <dtype: 'float32'>\n",
      "    loss              : (None, None, None) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, None, None) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 256, 256, 81)\n",
      "    pred_class_logits : (None, 256, 256, 81)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 256, 256) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 256, 256) <dtype: 'int64'>\n",
      "    pred_active       : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss              : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 256, 256) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build FCN Model in Training Mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del fcn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass    \n",
    "fcn_model = fcn_modellib.FCN(mode=\"training\", arch = 'FCN8', config=fcn_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:48.975972Z",
     "start_time": "2018-11-08T11:47:48.917434Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_pr_hm_norm (InputLayer)   (None, 256, 256, 81) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 46720       input_pr_hm_norm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fcn32_fc1 (Conv2D)              (None, 8, 8, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 4096)   0           fcn32_fc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fcn32_fc2 (Conv2D)              (None, 8, 8, 4096)   16781312    dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 4096)   0           fcn32_fc2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fcn32_deconv2D (Conv2D)         (None, 8, 8, 81)     331857      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fcn16_score2 (Conv2DTranspose)  (None, 18, 18, 81)   105057      fcn32_deconv2D[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fcn16_crop_score2 (Cropping2D)  (None, 16, 16, 81)   0           fcn16_score2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fcn16_score_pool4 (Conv2D)      (None, 16, 16, 81)   41553       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fcn16_fuse_pool4 (Add)          (None, 16, 16, 81)   0           fcn16_crop_score2[0][0]          \n",
      "                                                                 fcn16_score_pool4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fcn16_upscore_pool4 (Conv2DTran (None, 32, 32, 81)   105057      fcn16_fuse_pool4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fcn8_crop_pool4 (Cropping2D)    (None, 32, 32, 81)   0           fcn16_upscore_pool4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fcn8_score_pool3 (Conv2D)       (None, 32, 32, 81)   20817       block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fcn8_fuse_pool3 (Add)           (None, 32, 32, 81)   0           fcn8_crop_pool4[0][0]            \n",
      "                                                                 fcn8_score_pool3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fcn8_heatmap (Conv2DTranspose)  (None, 256, 256, 81) 1679697     fcn8_fuse_pool3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_hm_norm (InputLayer)   (None, 256, 256, 81) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "active_class_ids (Lambda)       (None, None)         0           input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fcn_MSE_loss (Lambda)           (1, 1)               0           input_gt_hm_norm[0][0]           \n",
      "                                                                 fcn8_heatmap[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fcn_CE_loss (Lambda)            (1, 1)               0           input_gt_hm_norm[0][0]           \n",
      "                                                                 fcn8_heatmap[0][0]               \n",
      "                                                                 active_class_ids[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 136,589,510\n",
      "Trainable params: 136,589,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 11)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 11)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn8_heatmap/BiasAdd:0                     Type: float32           Shape: (?, ?, ?, 81)\n",
      " layer:  1    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  2    output name: fcn_CE_loss/fcn_CE_loss:0                  Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "fcn_model.keras_model.summary()\n",
    "fcn_model.layer_info()\n",
    "# fcn_model.config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T12:08:54.460186Z",
     "start_time": "2018-11-08T12:08:54.391978Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_image_meta_1:0\", shape=(?, ?), dtype=float32) (None, None)\n",
      "Tensor(\"active_class_ids/strided_slice:0\", shape=(?, ?), dtype=float32) (None, None)\n",
      "ff.outputNames ['fcn8_heatmap', 'fcn_MSE_loss', 'fcn_CE_loss']\n",
      "ff.outputShapes [(None, 256, 256, 81), (1, 1), (1, 1)]\n",
      "ff.targets : 3\n",
      "   None\n",
      "   None\n",
      "   None\n",
      "ff.inputs  : 5\n",
      "    Tensor(\"input_image_meta_1:0\", shape=(?, ?), dtype=float32)\n",
      "    Tensor(\"input_pr_hm_norm:0\", shape=(?, 256, 256, 81), dtype=float32)\n",
      "    Tensor(\"input_pr_hm_scores:0\", shape=(?, 81, 200, 11), dtype=float32)\n",
      "    Tensor(\"input_gt_hm_norm:0\", shape=(?, 256, 256, 81), dtype=float32)\n",
      "    Tensor(\"input_gt_hm_scores:0\", shape=(?, 81, 200, 11), dtype=float32)\n",
      "fd.sample_weights : [None, None, None]\n",
      "ff.input          : 5\n",
      "_feed_input_nmes:  ['input_image_meta', 'input_pr_hm_norm', 'input_pr_hm_scores', 'input_gt_hm_norm', 'input_gt_hm_scores']\n",
      "_feed_output_nmes:  []\n"
     ]
    }
   ],
   "source": [
    "# del fcn_m\n",
    "ff = fcn_model.keras_model\n",
    "# pp.pprint(dir(ff))\n",
    "# for i in ff.layers:\n",
    "#     print(i.name)\n",
    "ly = ff.layers[35]\n",
    "dir(ly)\n",
    "print(ly.input, ly.input_shape)\n",
    "print(ly.output, ly.output_shape)\n",
    "# test = [None] *len(fcn_m.targets)\n",
    "\n",
    "print('ff.outputNames', ff.output_names)\n",
    "print('ff.outputShapes', ff.output_shape)\n",
    "\n",
    "print('ff.targets :', len(ff.targets))\n",
    "for tensor in ff.targets:\n",
    "      print('  ', tensor)\n",
    "print('ff.inputs  :', len(ff.inputs))\n",
    "for tensor in ff.inputs:\n",
    "      print('   ', tensor)\n",
    "print('fd.sample_weights :', ff.sample_weights)\n",
    "print('ff.input          :', len(ff.input))\n",
    "print('_feed_input_nmes: ', ff._feed_input_names)\n",
    "print('_feed_output_nmes: ', ff._feed_output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T14:16:11.504032Z",
     "start_time": "2018-11-07T14:16:11.385020Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train, train_generator= prep_coco_dataset(['train','val35k'], mrcnn_config, generator = True)\n",
    "dataset_val, val_generator   = prep_coco_dataset(['minival'], mrcnn_config, generator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Display image with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T15:15:24.892368Z",
     "start_time": "2018-11-07T15:15:23.628553Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "from mrcnn.datagen  import data_gen_simulate\n",
    "# [75040, 89243]\n",
    "IMAGE_IDS = [11998]\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_config, IMAGE_IDS)\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    print('Image meta  : ', img_meta[img_idx,:10])\n",
    "    print('Classes     : ', class_ids)\n",
    "    print(\"image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "    print(' class_ids.shape[0]:', class_ids.shape[0], 'bbox.shape[0]:',bbox.shape[0])    \n",
    "    \n",
    "    class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "    print('Class Names : ', class_names)\n",
    "    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)   \n",
    "    # Display image and instances\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### other image displays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Display Training / Validation Training set information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:41:58.073076Z",
     "start_time": "2018-09-20T13:41:58.017365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Train Dataset Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Training Dataset Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    \n",
    "    \n",
    "print(\"Validation Dataset Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Validation Dataset Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display top masks for a random group of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:01.523874Z",
     "start_time": "2018-09-20T13:41:58.075930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 7)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display a random image with instances and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:02.368569Z",
     "start_time": "2018-09-20T13:42:01.527170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "# image_id = np.random.choice(dataset_train.image_ids)\n",
    "\n",
    "\n",
    "image    = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, dataset_train.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "print(class_ids.shape[0], bbox.shape[0])\n",
    "# Display image and instances\n",
    "visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:54.739947Z",
     "start_time": "2018-11-08T11:47:48.980254Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      "-----------------------------------------------\n",
      " ---> last\n",
      ">>> find_last checkpoint in :  /home/kbardool/models/train_mrcnn_coco\n",
      "    Dir starting with  mrcnn  : ['mrcnn20181105T1801', 'mrcnn20181107T1443', 'mrcnn20181107T1450', 'mrcnn20181105T1811', 'mrcnn20181105T1813', 'mrcnn20181011T1100']\n",
      "    find_last():   dir_name: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100\n",
      "    find_last(): checkpoint: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      ">>> load_weights() from : /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      "layers type:  <class 'list'> length:  383\n",
      "    Weights file loaded: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# exclude=[\"mrcnn_class_logits\"] # ,\"mrcnn_bbox_fc\"]   #, \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "mrcnn_model.load_model_weights(init_with = 'last', exclude = None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:47:55.886312Z",
     "start_time": "2018-11-08T11:47:54.743053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ /home/kbardool/models/train_fcn8_coco/fcn20181031T0000/fcn_0106.h5 ]\n",
      "-----------------------------------------------\n",
      " ---> Explicit weight file\n",
      ">>> load_weights() from : /home/kbardool/models/train_fcn8_coco/fcn20181031T0000/fcn_0106.h5\n",
      "layers type:  <class 'list'> length:  38\n",
      "    Weights file loaded: /home/kbardool/models/train_fcn8_coco/fcn20181031T0000/fcn_0106.h5 \n",
      "==========================================\n",
      "FCN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load FCN Model weights  \n",
    "##------------------------------------------------------------------------------------\n",
    "WEIGHTS_PATH = '/home/kbardool/models/train_fcn8_coco/fcn20181031T0000/fcn_0106.h5'\n",
    "fcn_model.load_model_weights(init_with = WEIGHTS_PATH) # 'fcn_config.VGG16_MODEL_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN `train_in_batches()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### setup datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:48:03.362792Z",
     "start_time": "2018-11-08T11:47:55.890725Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.72s)\n",
      "creating index...\n",
      "index created!\n",
      " image dir            :  /home/kbardool/MLDatasets/coco2014/val2014\n",
      " json_path_dir        :  /home/kbardool/MLDatasets/coco2014/annotations/instances_valminusminival2014.json\n",
      " number of images     :  35185\n",
      " image_ids[:10]       :  [262148, 393225, 131089, 262161, 262162, 393243, 262175, 131108, 393254, 42]\n",
      " image_ids[1000:1010] :  [134290, 527506, 527504, 134288, 527510, 265372, 265374, 265378, 527529, 3244]\n",
      "loading annotations into memory...\n",
      "Done (t=1.51s)\n",
      "creating index...\n",
      "index created!\n",
      " image dir            :  /home/kbardool/MLDatasets/coco2014/val2014\n",
      " json_path_dir        :  /home/kbardool/MLDatasets/coco2014/annotations/instances_minival2014.json\n",
      " number of images     :  4952\n",
      " image_ids[:10]       :  [532481, 458755, 245764, 385029, 311303, 393226, 532493, 475150, 458768, 8211]\n",
      " image_ids[1000:1010] :  [99053, 329219, 91654, 148999, 509451, 214539, 132622, 222735, 468501, 534041]\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.prep_notebook import prep_coco_dataset\n",
    "dataset_train = prep_coco_dataset(['val35k'], mrcnn_config)\n",
    "dataset_val   = prep_coco_dataset(['minival'], mrcnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " #### Display parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:48:03.449695Z",
     "start_time": "2018-11-08T11:48:03.365586Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MRCNN-------------------------------------------------------\n",
      "Epochs to run       2 \n",
      "Steps per epochs    2 \n",
      "Batch size          1 \n",
      "Learning Rate       1e-05 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    8 \n",
      "--- FCN --------------------------------------------------------\n",
      "Epochs to run       2 \n",
      "Steps per epochs    2 \n",
      "Batch size          1 \n",
      "Learning Rate       1e-05 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    4 \n",
      "Checkpoint Path:    /home/kbardool/models/train_fcn8_coco/fcn20181108T1147/fcn_{epoch:04d}.h5 \n",
      "REDUCE_LR_FACTOR    0.5 \n",
      "REDUCE_LR_COOLDOWN  15 \n",
      "REDUCE_LR_PATIENCE  50 \n",
      "MIN_LR              1e-10 \n",
      "EARLY_STOP_PATIENCE 75 \n"
     ]
    }
   ],
   "source": [
    "from mrcnn.utils        import log\n",
    "# fcn_config.EPOCHS_TO_RUN  = 4\n",
    "# fcn_config.LEARNING_RATE  = 0.1\n",
    "fcn_config.VALIDATION_STEPS = 4\n",
    "print('--- MRCNN-------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(mrcnn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(mrcnn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(mrcnn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(mrcnn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(mrcnn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(mrcnn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(mrcnn_model.config.VALIDATION_STEPS   ))\n",
    "# log(\"Checkpoint Path:    {} \".format(mrcnn_model.checkpoint_path))\n",
    "# log(\"REDUCE_LR_FACTOR    {} \".format(mrcnn_model.config.REDUCE_LR_FACTOR   ))\n",
    "# log(\"REDUCE_LR_COOLDOWN  {} \".format(mrcnn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "# log(\"REDUCE_LR_PATIENCE  {} \".format(mrcnn_model.config.REDUCE_LR_PATIENCE ))\n",
    "# log(\"MIN_LR              {} \".format(mrcnn_model.config.MIN_LR             ))\n",
    "# log(\"EARLY_STOP_PATIENCE {} \".format(mrcnn_model.config.EARLY_STOP_PATIENCE))     \n",
    "\n",
    "print('--- FCN --------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(fcn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(fcn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(fcn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(fcn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(fcn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(fcn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(fcn_model.config.VALIDATION_STEPS   ))\n",
    "log(\"Checkpoint Path:    {} \".format(fcn_model.checkpoint_path))\n",
    "log(\"REDUCE_LR_FACTOR    {} \".format(fcn_model.config.REDUCE_LR_FACTOR   ))\n",
    "log(\"REDUCE_LR_COOLDOWN  {} \".format(fcn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "log(\"REDUCE_LR_PATIENCE  {} \".format(fcn_model.config.REDUCE_LR_PATIENCE ))\n",
    "log(\"MIN_LR              {} \".format(fcn_model.config.MIN_LR             ))\n",
    "log(\"EARLY_STOP_PATIENCE {} \".format(fcn_model.config.EARLY_STOP_PATIENCE))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Original Train_in_batches() call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T10:37:29.852126Z",
     "start_time": "2018-11-08T10:37:29.810246Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "# train_layers = ['all']\n",
    "# loss_names   = [\"fcn_MSE_loss\"]\n",
    "# fcn_config.LAST_EPOCH_RAN = 56\n",
    "# fcn_model.epoch = fcn_config.LAST_EPOCH_RAN\n",
    "\n",
    "# fcn_model.train_in_batches(\n",
    "#             mrcnn_model,    \n",
    "#             dataset_train,\n",
    "#             dataset_val, \n",
    "#             layers = train_layers,\n",
    "#             losses = loss_names\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### modified train_in_btches call - invokes compile2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:33:25.886940Z",
     "start_time": "2018-11-08T11:32:34.650694Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = ['all']\n",
    "loss_names   = [\"fcn_MSE_loss\"]\n",
    "fcn_config.LAST_EPOCH_RAN = 56\n",
    "fcn_model.epoch = fcn_config.LAST_EPOCH_RAN\n",
    "\n",
    "train_in_batches(fcn_model,\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T14:24:00.803567Z",
     "start_time": "2018-11-07T14:24:00.756959Z"
    }
   },
   "source": [
    "## Simulate Train in Batches - step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T12:48:57.185213Z",
     "start_time": "2018-11-08T12:48:35.063979Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all']\n",
      "['.*']\n",
      "layers regex : .*\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_pr_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "   1  block1_conv1           (Conv2D              )   TRAIN \n",
      "   2  block1_conv2           (Conv2D              )   TRAIN \n",
      "   3  block1_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   4  block2_conv1           (Conv2D              )   TRAIN \n",
      "   5  block2_conv2           (Conv2D              )   TRAIN \n",
      "   6  block2_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   7  block3_conv1           (Conv2D              )   TRAIN \n",
      "   8  block3_conv2           (Conv2D              )   TRAIN \n",
      "   9  block3_conv3           (Conv2D              )   TRAIN \n",
      "  10  block3_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  11  block4_conv1           (Conv2D              )   TRAIN \n",
      "  12  block4_conv2           (Conv2D              )   TRAIN \n",
      "  13  block4_conv3           (Conv2D              )   TRAIN \n",
      "  14  block4_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  15  block5_conv1           (Conv2D              )   TRAIN \n",
      "  16  block5_conv2           (Conv2D              )   TRAIN \n",
      "  17  block5_conv3           (Conv2D              )   TRAIN \n",
      "  18  block5_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  19  fcn32_fc1              (Conv2D              )   TRAIN \n",
      "  20  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      "  21  fcn32_fc2              (Conv2D              )   TRAIN \n",
      "  22  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      "  23  fcn32_deconv2D         (Conv2D              )   TRAIN \n",
      "  24  fcn16_score2           (Conv2DTranspose     )   TRAIN \n",
      "  25  fcn16_crop_score2      (Cropping2D          )   ............................no weights to train ]\n",
      "  26  fcn16_score_pool4      (Conv2D              )   TRAIN \n",
      "  27  fcn16_fuse_pool4       (Add                 )   ............................no weights to train ]\n",
      "  28  fcn16_upscore_pool4    (Conv2DTranspose     )   TRAIN \n",
      "  29  fcn8_crop_pool4        (Cropping2D          )   ............................no weights to train ]\n",
      "  30  fcn8_score_pool3       (Conv2D              )   TRAIN \n",
      "  31  fcn8_fuse_pool3        (Add                 )   ............................no weights to train ]\n",
      "  32  input_image_meta       (InputLayer          )   ............................no weights to train ]\n",
      "  33  fcn8_heatmap           (Conv2DTranspose     )   TRAIN \n",
      "  34  input_gt_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "  35  active_class_ids       (Lambda              )   ............................no weights to train ]\n",
      "  36  fcn_MSE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  37  fcn_CE_loss            (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      "  Compile Model :\n",
      " ----------------\n",
      "    losses        :  ['fcn_MSE_loss']\n",
      "    optimizer     :  <keras.optimizers.Adagrad object at 0x7f21b4247e80>\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      " Initial self.keras_model.losses :\n",
      " ---------------------------------\n",
      " losses passed to compile :  ['fcn_MSE_loss']\n",
      " self.keras_model.losses  : \n",
      "\n",
      " Add loss_functions to self.keras_model.losses\n",
      " -------------------------------------\n",
      " --  Loss: fcn_MSE_loss  Related Layer is : fcn_MSE_loss\n",
      "    >> Add add loss for  Tensor(\"fcn_MSE_loss/fcn_MSE_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding loss_functions passed to compile() : \n",
      " ------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " --------------------\n",
      "      0    Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      " Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      " ---------------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Compile \n",
      " --------\n",
      " Length of Keras_Model.outputs: 3\n",
      "\n",
      " Add Metrics for losses :\n",
      " -------------------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_MSE_loss  Related Layer is : fcn_MSE_loss\n",
      "    >> Add metric  fcn_MSE_loss  with metric tensor:  fcn_MSE_loss/fcn_MSE_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names :\n",
      " --------------------------\n",
      "      0    loss\n",
      "      1    fcn_MSE_loss\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      " ----------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " ---------------------\n",
      "      0    Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      "\n",
      " Post-compile out_labels from get_deduped_metrics_names() : \n",
      " ---------------------------------------------------------- \n",
      "     - loss\n",
      "     - fcn_MSE_loss\n",
      "\n",
      " Post-compile Callback metrics monitored by progbar :\n",
      " ----------------------------------------------------\n",
      "     - loss\n",
      "     - fcn_MSE_loss\n",
      "     - val_loss\n",
      "     - val_fcn_MSE_loss\n",
      "\n",
      " Post-compile Keras metric_names :\n",
      " ---------------------------------\n",
      "      0    loss\n",
      "      1    fcn_MSE_loss\n",
      "\n",
      " Post-compile Keras stateful_metric_names :\n",
      " ------------------------------------------\n",
      "layer:  input_pr_hm_norm\n",
      "   write output layer  input_pr_hm_norm  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block1_conv1\n",
      "   mapped_weight_name :  block1_conv1/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block1_conv1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block1_conv1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block1_conv2\n",
      "   mapped_weight_name :  block1_conv2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block1_conv2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block1_conv2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block1_pool\n",
      "   write output layer  block1_pool  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block2_conv1\n",
      "   mapped_weight_name :  block2_conv1/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block2_conv1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block2_conv1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block2_conv2\n",
      "   mapped_weight_name :  block2_conv2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block2_conv2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block2_conv2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block2_pool\n",
      "   write output layer  block2_pool  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block3_conv1\n",
      "   mapped_weight_name :  block3_conv1/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block3_conv1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block3_conv1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block3_conv2\n",
      "   mapped_weight_name :  block3_conv2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block3_conv2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block3_conv2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block3_conv3\n",
      "   mapped_weight_name :  block3_conv3/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block3_conv3/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block3_conv3  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block3_pool\n",
      "   write output layer  block3_pool  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block4_conv1\n",
      "   mapped_weight_name :  block4_conv1/kernel_0\n",
      "   write grads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block4_conv1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block4_conv1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block4_conv2\n",
      "   mapped_weight_name :  block4_conv2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block4_conv2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block4_conv2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block4_conv3\n",
      "   mapped_weight_name :  block4_conv3/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block4_conv3/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block4_conv3  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block4_pool\n",
      "   write output layer  block4_pool  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block5_conv1\n",
      "   mapped_weight_name :  block5_conv1/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block5_conv1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block5_conv1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block5_conv2\n",
      "   mapped_weight_name :  block5_conv2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block5_conv2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block5_conv2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block5_conv3\n",
      "   mapped_weight_name :  block5_conv3/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  block5_conv3/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  block5_conv3  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  block5_pool\n",
      "   write output layer  block5_pool  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn32_fc1\n",
      "   mapped_weight_name :  fcn32_fc1/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn32_fc1/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn32_fc1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  dropout_1\n",
      "   write output layer  dropout_1  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn32_fc2\n",
      "   mapped_weight_name :  fcn32_fc2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn32_fc2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn32_fc2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  dropout_2\n",
      "   write output layer  dropout_2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn32_deconv2D\n",
      "   mapped_weight_name :  fcn32_deconv2D/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn32_deconv2D/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn32_deconv2D  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn16_score2\n",
      "   mapped_weight_name :  fcn16_score2/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn16_score2/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn16_score2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn16_crop_score2\n",
      "   write output layer  fcn16_crop_score2  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn16_score_pool4\n",
      "   mapped_weight_name :  fcn16_score_pool4/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn16_score_pool4/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn16_score_pool4  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn16_fuse_pool4\n",
      "   write output layer  fcn16_fuse_pool4  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn16_upscore_pool4\n",
      "   mapped_weight_name :  fcn16_upscore_pool4/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn16_upscore_pool4/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn16_upscore_pool4  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn8_crop_pool4\n",
      "   write output layer  fcn8_crop_pool4  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn8_score_pool3\n",
      "   mapped_weight_name :  fcn8_score_pool3/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn8_score_pool3/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn8_score_pool3  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn8_fuse_pool3\n",
      "   write output layer  fcn8_fuse_pool3  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  input_image_meta\n",
      "   write output layer  input_image_meta  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn8_heatmap\n",
      "   mapped_weight_name :  fcn8_heatmap/kernel_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   mapped_weight_name :  fcn8_heatmap/bias_0\n",
      "   write grads\n",
      " grads:  <class 'list'>\n",
      "   write output layer  fcn8_heatmap  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  input_gt_hm_norm\n",
      "   write output layer  input_gt_hm_norm  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  active_class_ids\n",
      "   write output layer  active_class_ids  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn_MSE_loss\n",
      "   write output layer  fcn_MSE_loss  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer:  fcn_CE_loss\n",
      "   write output layer  fcn_CE_loss  type(output):  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      " summary merge all\n",
      " \n",
      "Training Start Parameters:\n",
      "--------------------------\n",
      "Starting at epoch     56 of 58 epochs.\n",
      "Steps per epochs      2 \n",
      "Last epoch completed  56 \n",
      "Batch size            1 \n",
      "Learning Rate         1e-05 \n",
      "Momentum              0.9 \n",
      "Weight Decay:         0.0002 \n",
      "VALIDATION_STEPS      4 \n",
      "REDUCE_LR_FACTOR      0.5 \n",
      "REDUCE_LR_COOLDOWN    15 \n",
      "REDUCE_LR_PATIENCE    50 \n",
      "MIN_LR                1e-10 \n",
      "EARLY_STOP_PATIENCE   75 \n",
      "Checkpoint Path:      /home/kbardool/models/train_fcn8_coco/fcn20181108T1147/fcn_{epoch:04d}.h5 \n"
     ]
    }
   ],
   "source": [
    "from mrcnn.standardize import *\n",
    "# def train_in_batches(self,\n",
    "#                 mrcnn_model,\n",
    "#               train_dataset, \n",
    "#               val_dataset,  \n",
    "#               layers            = None,\n",
    "#               losses            = None,\n",
    "train_layers      = ['all']\n",
    "loss_names        = [\"fcn_MSE_loss\"]\n",
    "fcn_config.LAST_EPOCH_RAN = 56\n",
    "fcn_model.epoch   = fcn_config.LAST_EPOCH_RAN\n",
    "self              = fcn_model\n",
    "mrcnn_model       = mrcnn_model\n",
    "train_dataset     = dataset_train\n",
    "val_dataset       = dataset_val\n",
    "layers            = train_layers\n",
    "losses            = loss_names\n",
    "learning_rate     = 0           \n",
    "epochs            = 0\n",
    "epochs_to_run     = 0 \n",
    "batch_size        = 0 \n",
    "steps_per_epoch   = 0\n",
    "min_LR            = 0\n",
    "debug             = False\n",
    "\n",
    "'''\n",
    "Train the model.\n",
    "train_dataset, \n",
    "val_dataset:    Training and validation Dataset objects.\n",
    "\n",
    "learning_rate:  The learning rate to train with\n",
    "\n",
    "epochs:         Number of training epochs. Note that previous training epochs\n",
    "                are considered to be done already, so this actually determines\n",
    "                the epochs to train in total rather than in this particaular\n",
    "                call.\n",
    "\n",
    "layers:         Allows selecting wich layers to train. It can be:\n",
    "                - A regular expression to match layer names to train\n",
    "                - One of these predefined values:\n",
    "                heads: The RPN, classifier and mask heads of the network\n",
    "                all: All the layers\n",
    "                3+: Train Resnet stage 3 and up\n",
    "                4+: Train Resnet stage 4 and up\n",
    "                5+: Train Resnet stage 5 and up\n",
    "'''\n",
    "assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "\n",
    "if batch_size == 0 :\n",
    "    batch_size = self.config.BATCH_SIZE\n",
    "\n",
    "if epochs_to_run ==  0 :\n",
    "    epochs_to_run = self.config.EPOCHS_TO_RUN\n",
    "\n",
    "if steps_per_epoch == 0:\n",
    "    steps_per_epoch = self.config.STEPS_PER_EPOCH\n",
    "\n",
    "if min_LR == 0 :\n",
    "    min_LR = self.config.MIN_LR\n",
    "\n",
    "if learning_rate == 0:\n",
    "    learning_rate = self.config.LEARNING_RATE\n",
    "\n",
    "epochs = self.epoch + epochs_to_run\n",
    "\n",
    "# use Pre-defined layer regular expressions\n",
    "# if layers in self.layer_regex.keys():\n",
    "    # layers = self.layer_regex[layers]\n",
    "print(layers)\n",
    "# train_regex_list = []\n",
    "# for x in layers:\n",
    "    # print( ' layers ias : ',x)\n",
    "    # train_regex_list.append(x)\n",
    "train_regex_list = [self.layer_regex[x] for x in layers]\n",
    "print(train_regex_list)\n",
    "layers = '|'.join(train_regex_list)        \n",
    "print('layers regex :', layers)\n",
    "\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Data generators\n",
    "##--------------------------------------------------------------------------------\n",
    "train_generator = data_generator(train_dataset, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "val_generator   = data_generator(val_dataset, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 augment=False)\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Set trainable layers and compile\n",
    "##--------------------------------------------------------------------------------\n",
    "self.set_trainable(layers)            \n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## Setup optimizaion method \n",
    "##----------------------------------------------------------------------------------------------            \n",
    "optimizer = self.set_optimizer()\n",
    "\n",
    "# self.compile(learning_rate, self.config.LEARNING_MOMENTUM, losses)        \n",
    "self.compile(losses, optimizer)\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## get metrics from keras_model.metrics_names and setup callback metrics \n",
    "##--------------------------------------------------------------------------------\n",
    "out_labels = self.get_deduped_metrics_names()\n",
    "callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "\n",
    "print()\n",
    "print(' Post-compile out_labels from get_deduped_metrics_names() : ')\n",
    "print(' ---------------------------------------------------------- ')\n",
    "for i in out_labels:\n",
    "    print('     -',i)\n",
    "print()\n",
    "print(' Post-compile Callback metrics monitored by progbar :')\n",
    "print(' ----------------------------------------------------')\n",
    "for i in callback_metrics:\n",
    "    print('     -',i)\n",
    "\n",
    "print()\n",
    "print(' Post-compile Keras metric_names :') \n",
    "print(' ---------------------------------') \n",
    "for idx, i in enumerate(self.keras_model.metrics_names):\n",
    "    print('     ',idx, '  ', i)\n",
    "\n",
    "print()\n",
    "print(' Post-compile Keras stateful_metric_names :') \n",
    "print(' ------------------------------------------') \n",
    "for idx, i in enumerate(self.keras_model.stateful_metric_names):\n",
    "    print('     ',idx, '  ', i)\n",
    "\n",
    "## Setup for stateful_metric_indices Validation process \n",
    "##--------------------------------------------------------------------------------\n",
    "stateful_metric_indices = []\n",
    "if hasattr(self, 'metrics'):\n",
    "    for m in self.stateful_metric_functions:\n",
    "        m.reset_states()\n",
    "    stateful_metric_indices = [\n",
    "        i for i, name in enumerate(self.metrics_names)\n",
    "        if str(name) in self.stateful_metric_names]\n",
    "else:\n",
    "    stateful_metric_indices = []\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Callbacks\n",
    "##--------------------------------------------------------------------------------\n",
    "# call back for model checkpoint was originally (?) loss. chanegd to val_loss (which is default) 2-5-18\n",
    "# copied from \\keras\\engine\\training.py\n",
    "# def _get_deduped_metrics_names(self):\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "      keras.callbacks.ProgbarLogger(count_mode='steps',\n",
    "                                    stateful_metrics=self.keras_model.stateful_metric_names)\n",
    "\n",
    "    , keras.callbacks.BaseLogger(stateful_metrics=self.keras_model.stateful_metric_names)\n",
    "\n",
    "    , keras.callbacks.TensorBoard(log_dir=self.log_dir,\n",
    "                                  histogram_freq=1,\n",
    "                                  write_graph=True,\n",
    "                                  write_images=False, \n",
    "                                  write_grads=True,\n",
    "                                  batch_size=self.config.BATCH_SIZE)\n",
    "                                  # write_graph=True,\n",
    "\n",
    "                                  # write_images=True,\n",
    "                                  # embeddings_freq=0,\n",
    "                                  # embeddings_layer_names=None,\n",
    "                                  # embeddings_metadata=None)\n",
    "\n",
    "    , keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                      mode    = 'auto', \n",
    "                                      period  = self.config.CHECKPOINT_PERIOD, \n",
    "                                      monitor = 'val_loss', \n",
    "                                      verbose = 1, \n",
    "                                      save_best_only = True, \n",
    "                                      save_weights_only=True)\n",
    "\n",
    "    , keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                        mode     = 'auto', \n",
    "                                        factor   = self.config.REDUCE_LR_FACTOR,   \n",
    "                                        cooldown = self.config.REDUCE_LR_COOLDOWN,\n",
    "                                        patience = self.config.REDUCE_LR_PATIENCE,\n",
    "                                        min_delta= self.config.REDUCE_LR_MIN_DELTA,\n",
    "                                        min_lr   = self.config.MIN_LR, \n",
    "                                        verbose  = 1)                                            \n",
    "\n",
    "    , keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                        mode      = 'auto', \n",
    "                                        min_delta = self.config.EARLY_STOP_MIN_DELTA, \n",
    "\n",
    "                                        patience  = self.config.EARLY_STOP_PATIENCE, \n",
    "                                        verbose   = 1)                                            \n",
    "    , keras.callbacks.History() \n",
    "]\n",
    "\n",
    "\n",
    "callbacks =  keras.callbacks.CallbackList(callbacks = callbacks_list)\n",
    "callbacks.set_model(self.keras_model)\n",
    "callbacks.set_params({\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'steps': steps_per_epoch,\n",
    "    'verbose': 1 ,\n",
    "    'do_validation': True,\n",
    "    'metrics': callback_metrics\n",
    "})\n",
    "\n",
    "    # 'samples': num_train_samples,\n",
    "    # 'verbose': verbose,\n",
    "    # 'do_validation': do_validation,\n",
    "    # 'metrics': callback_metrics or [],\n",
    "\n",
    "log(\" \")\n",
    "log(\"Training Start Parameters:\")\n",
    "log(\"--------------------------\")\n",
    "log(\"Starting at epoch     {} of {} epochs.\".format(self.epoch, epochs))\n",
    "log(\"Steps per epochs      {} \".format(steps_per_epoch))\n",
    "log(\"Last epoch completed  {} \".format(self.epoch))\n",
    "log(\"Batch size            {} \".format(batch_size))\n",
    "log(\"Learning Rate         {} \".format(self.config.LEARNING_RATE))\n",
    "log(\"Momentum              {} \".format(self.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:         {} \".format(self.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS      {} \".format(self.config.VALIDATION_STEPS   ))\n",
    "log(\"REDUCE_LR_FACTOR      {} \".format(self.config.REDUCE_LR_FACTOR   ))\n",
    "log(\"REDUCE_LR_COOLDOWN    {} \".format(self.config.REDUCE_LR_COOLDOWN ))\n",
    "log(\"REDUCE_LR_PATIENCE    {} \".format(self.config.REDUCE_LR_PATIENCE ))\n",
    "log(\"MIN_LR                {} \".format(self.config.MIN_LR             ))\n",
    "log(\"EARLY_STOP_PATIENCE   {} \".format(self.config.EARLY_STOP_PATIENCE))        \n",
    "log(\"Checkpoint Path:      {} \".format(self.checkpoint_path))\n",
    "\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## If in debug mode write stdout intercepted IO to output file  \n",
    "##----------------------------------------------------------------------------------------------            \n",
    "if self.config.SYSOUT == 'FILE':\n",
    "    utils.write_sysout(self.log_dir)\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Start main training loop\n",
    "##--------------------------------------------------------------------------------\n",
    "early_stopping  = False\n",
    "val_steps = self.config.VALIDATION_STEPS\n",
    "epoch_idx = self.epoch\n",
    "callbacks.on_train_begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T12:49:12.587362Z",
     "start_time": "2018-11-08T12:49:03.287037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/58\n",
      "1/2 [==============>...............] - ETA: 7s - loss: 0.0132 - fcn_MSE_loss: 0.0132"
     ]
    }
   ],
   "source": [
    "if epoch_idx >= epochs:\n",
    "    print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "else:\n",
    "\n",
    "    while epoch_idx < epochs :\n",
    "        callbacks.on_epoch_begin(epoch_idx)\n",
    "        epoch_logs = {}\n",
    "\n",
    "        ##------------------------------------------------------------------------\n",
    "        ## TRAINING Phase - emulating fit_generator()\n",
    "        ##------------------------------------------------------------------------\n",
    "        for steps_index in range(steps_per_epoch):\n",
    "\n",
    "            # print(' self.epoch {}   epochs {}  step {} '.format(self.epoch, epochs, steps_index))\n",
    "            batch_logs = {}\n",
    "            batch_logs['batch'] = steps_index\n",
    "            batch_logs['size']  = batch_size    \n",
    "\n",
    "            callbacks.on_batch_begin(steps_index, batch_logs)\n",
    "\n",
    "            train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "\n",
    "            # print('len of train batch x' ,len(train_batch_x))\n",
    "            # for idx, i in  enumerate(train_batch_x):\n",
    "                # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "            # print('len of train batch y' ,len(train_batch_y))\n",
    "            # for idx, i in  enumerate(train_batch_y):\n",
    "                # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "            # print(type(output_rois))\n",
    "            # for i in model_output:\n",
    "                # print( i.shape)       \n",
    "\n",
    "            ## Run prediction on MRCNN  \n",
    "            try:\n",
    "                results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "                fcn_x = [train_batch_x[1]]\n",
    "                fcn_x.extend(results[:4])\n",
    "\n",
    "            except Exception as e :\n",
    "                print('failure on mrcnn predict - epoch {} , image ids: {} '.format(epoch_idx, train_batch_x[1][:,0]))\n",
    "                print('Exception information:')\n",
    "                print(str(e))\n",
    "\n",
    "            # print('size of results : ', len(results))\n",
    "            # for idx, i in  enumerate(x):\n",
    "                # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "\n",
    "            ## Train on FCN\n",
    "            try:\n",
    "                outs = self.keras_model.train_on_batch(fcn_x , train_batch_y)                                            \n",
    "            except Exception as e :\n",
    "                print('failure on fcn train - epoch {} , image ids: {} '.format(epoch_idx, train_batch_x[1][:,0]))\n",
    "                print('Exception information:')\n",
    "                print(str(e))                \n",
    "\n",
    "            # print('size of outputs from train_on_batch : ', len(outs), outs)\n",
    "            # for idx, i in  enumerate(outs):\n",
    "                # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "\n",
    "            if not isinstance(outs, list):\n",
    "                outs = [outs]\n",
    "\n",
    "            for l, o in zip(out_labels, outs):\n",
    "                # print(' out label: ', l, ' out value: ', o,' shape: ', o.shape)\n",
    "                batch_logs[l] = o\n",
    "\n",
    "            callbacks.on_batch_end(steps_index, batch_logs)\n",
    "            epoch_idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T12:49:26.132233Z",
     "start_time": "2018-11-08T12:49:17.874795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn_model.test_on_batch() size of results :  2\n",
      "0 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0039]]\n",
      "1 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0039]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/scipy/ndimage/interpolation.py:616: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn_model.test_on_batch() size of results :  2\n",
      "0 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0038]]\n",
      "1 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0038]]\n",
      "fcn_model.test_on_batch() size of results :  2\n",
      "0 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0036]]\n",
      "1 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0036]]\n",
      "fcn_model.test_on_batch() size of results :  2\n",
      "0 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0038]]\n",
      "1 type:  <class 'numpy.ndarray'> shape:  (1, 1) val:  [[0.0038]]\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------\n",
    "## VALIDATION Phase - emulating evaluate_generator()\n",
    "##------------------------------------------------------------------------\n",
    "# print(' Start validation ')\n",
    "# print(' ---------------- ')\n",
    "# print(' Stateful metric indices:' )\n",
    "# pp.pprint(stateful_metric_indices)\n",
    "\n",
    "\n",
    "val_steps_done      = 0\n",
    "val_outs_per_batch  = []\n",
    "val_batch_sizes     = []\n",
    "\n",
    "# setup validation progress bar if we wish\n",
    "# progbar = Progbar(target=val_steps)\n",
    "\n",
    "while val_steps_done < val_steps:\n",
    "    # print(' ** Validation step: ', val_steps_done)\n",
    "\n",
    "    mrcnn_val_x, mrcnn_val_y = next(val_generator)\n",
    "\n",
    "    # print('len of train batch x' ,len(val_x))\n",
    "    # for idx, i in  enumerate(val_x):\n",
    "        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "\n",
    "    ## Run prediction on MRCNN  \n",
    "    try:\n",
    "        val_results = mrcnn_model.keras_model.predict(mrcnn_val_x)\n",
    "        fcn_val_x = [mrcnn_val_x[1]]\n",
    "        fcn_val_x.extend(val_results[:4])   ## image_meta, pr_hm, pr_hm_scores, gt_hm, gt_hm_scores\n",
    "    except Exception as e :\n",
    "        print('failure on mrcnn predict (validation)- epoch {} , image ids: {} '.format(epoch_idx, mrcnn_val_x[1][:,0]))\n",
    "        print('Exception information:')\n",
    "        print(str(e))                \n",
    "\n",
    "    # print('    mrcnn_model.predict() size of results : ', len(val_results))\n",
    "    # for idx, i in  enumerate(xval_results):\n",
    "        # print('    ',idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "\n",
    "    ## Train on FCN\n",
    "    try:\n",
    "        outs2 = self.keras_model.test_on_batch( fcn_val_x , mrcnn_val_y)\n",
    "        # print('\\n valstep {} outs2 len:{} '.format(val_steps_done, len(outs2)))\n",
    "        val_outs_per_batch.append(outs2)\n",
    "        print('fcn_model.test_on_batch() size of results : ', len(outs2))\n",
    "        for idx, i in  enumerate(outs2):\n",
    "            print(idx, 'type: ', type(i), 'shape: ', i.shape, 'val: ', i)\n",
    "    except Exception as e :\n",
    "        print('failure on fcn train (validation)- epoch {} , image ids: {} '.format(epoch_idx, mrcnn_val_x[1][:,0]))                    \n",
    "        print('Exception information:')\n",
    "        print(str(e))                \n",
    "\n",
    "\n",
    "\n",
    "    if isinstance(fcn_val_x, list):\n",
    "        batch_size = fcn_val_x[0].shape[0]\n",
    "    elif isinstance(fcn_val_x, dict):\n",
    "        batch_size = list(fcn_val_x.values())[0].shape[0]\n",
    "    else:\n",
    "        batch_size = fcn_val_x.shape[0]\n",
    "\n",
    "    if batch_size == 0:\n",
    "        raise ValueError('Received an empty batch. '\n",
    "                         'Batches should at least contain one item.')\n",
    "    # else:\n",
    "        # print('batch size:', batch_size)\n",
    "\n",
    "    val_steps_done += 1\n",
    "    val_batch_sizes.append(batch_size)\n",
    "    # print validation progress bar if we wish\n",
    "    # progbar.update(val_steps_done)\n",
    "\n",
    "## calculate val_averages after all validations steps complete, which is passed \n",
    "## back to fit_generator() as val_outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T12:49:28.307086Z",
     "start_time": "2018-11-08T12:49:28.230910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    val_batch_sizes            : <class 'list'>  len : 4 [1, 1, 1, 1]\n",
      "    val_batch_sizes-shape      : (4,)\n",
      "    val_outs_per_batch:        : <class 'list'>  len : 4\n",
      "    val_outs_per_batch - shape : (4, 2, 1, 1)\n",
      "        batch:  0    [array([[0.0039]], dtype=float32), array([[0.0039]], dtype=float32)]\n",
      "        batch:  1    [array([[0.0038]], dtype=float32), array([[0.0038]], dtype=float32)]\n",
      "        batch:  2    [array([[0.0036]], dtype=float32), array([[0.0036]], dtype=float32)]\n",
      "        batch:  3    [array([[0.0038]], dtype=float32), array([[0.0038]], dtype=float32)]\n",
      "\n",
      "val_averages : [array([[0.0038]]), array([[0.0038]])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('    val_batch_sizes            :', type(val_batch_sizes),' len :', len(val_batch_sizes), val_batch_sizes)\n",
    "print('    val_batch_sizes-shape      :', np.asarray(val_batch_sizes).shape)\n",
    "\n",
    "print('    val_outs_per_batch:        :', type(val_outs_per_batch),' len :', len(val_outs_per_batch))\n",
    "print('    val_outs_per_batch - shape :', np.asarray(val_outs_per_batch).shape)\n",
    "for i,j in enumerate(val_outs_per_batch):\n",
    "    print('        batch: ', i, '  ', j)\n",
    "\n",
    "val_averages = []\n",
    "for i in range(len(outs2)):\n",
    "    if i not in stateful_metric_indices:\n",
    "        tt = [out[i] for out in val_outs_per_batch]\n",
    "        # print(' tt type: ',type(tt), tt)\n",
    "        # print('val_batch_sizes.shape' , type(val_batch_sizes), len(val_batch_sizes))\n",
    "        val_averages.append(\n",
    "                np.average([out[i] for out in val_outs_per_batch], axis = 0, weights=val_batch_sizes)\n",
    "                           )\n",
    "    else:\n",
    "        val_averages.append(float(val_outs_per_batch[-1][i]))\n",
    "if len(val_averages) == 1:\n",
    "    val_averages = val_averages[0]\n",
    "print()\n",
    "print('val_averages :', val_averages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:00:51.933609Z",
     "start_time": "2018-11-08T13:00:51.866194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensordlow histogram attempt\n",
      "-----------------------------\n",
      "model targets: [None, None, None]\n",
      " Total loss  : Tensor(\"loss_1/add:0\", shape=(1, 1), dtype=float32)\n",
      " Metric Tensors: [<tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>]\n",
      " len(fcn_val_x)  :  5\n",
      " len(fcn_val_y)  :  3\n",
      " len(mrcnn_val_y):  0\n",
      " len(fcn_val_x)             :  5\n",
      " len(fcn_val_y)             :  3\n",
      " len(fcn_val_sample_weights):  3\n",
      " len(fcn_val_data)          :  11\n",
      " add \n"
     ]
    }
   ],
   "source": [
    "#-- (unsuccessful) attempt to add histogram info to tensoflow summary  ------------------------\n",
    "print(' Tensordlow histogram attempt')\n",
    "print('-----------------------------')\n",
    "print('model targets:', self.keras_model.targets)\n",
    "print(' Total loss  :', self.keras_model.total_loss)\n",
    "print(' Metric Tensors:', self.keras_model.metrics_tensors)\n",
    "fcn_val_y = self.keras_model.targets\n",
    "fcn_val_sample_weights = self.keras_model.sample_weights\n",
    "\n",
    "\n",
    "print(' len(fcn_val_x)  : ',len(fcn_val_x))\n",
    "print(' len(fcn_val_y)  : ',len(fcn_val_y))\n",
    "print(' len(mrcnn_val_y): ',len(mrcnn_val_y))\n",
    "\n",
    "# fcn_val_x, fcn_val_y, fcn_val_sample_weights = my_standardize_user_data(self.keras_model, fcn_val_x, fcn_val_y, val_sample_weight)\n",
    "fcn_val_data = fcn_val_x + fcn_val_y  + fcn_val_sample_weights\n",
    "\n",
    "print(' len(fcn_val_x)             : ',len(fcn_val_x))\n",
    "print(' len(fcn_val_y)             : ',len(fcn_val_y))\n",
    "print(' len(fcn_val_sample_weights): ',len(fcn_val_sample_weights))\n",
    "print(' len(fcn_val_data)          : ',len(fcn_val_data))\n",
    "if self.keras_model.uses_learning_phase and not isinstance(KB.learning_phase(), int):\n",
    "    print(' add ')\n",
    "    fcn_val_data += [0.]\n",
    "for cbk in callbacks:\n",
    "    cbk.validation_data = fcn_val_data\n",
    "\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:00:57.167839Z",
     "start_time": "2018-11-08T13:00:57.121446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_image_meta_1:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'input_pr_hm_norm:0' shape=(?, 256, 256, 81) dtype=float32>, <tf.Tensor 'input_pr_hm_scores:0' shape=(?, 81, 200, 11) dtype=float32>, <tf.Tensor 'input_gt_hm_norm:0' shape=(?, 256, 256, 81) dtype=float32>, <tf.Tensor 'input_gt_hm_scores:0' shape=(?, 81, 200, 11) dtype=float32>]\n",
      "[None, None, None]\n",
      "[None, None, None]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# pp.pprint(val_averages)\n",
    "# print(out_labels)\n",
    "# epoch_logs = {}\n",
    "# print(epoch_logs)\n",
    "print(self.keras_model.inputs)\n",
    "print(self.keras_model.targets)\n",
    "print(self.keras_model.sample_weights)\n",
    "print(self.keras_model.uses_learning_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:01:00.454390Z",
     "start_time": "2018-11-08T13:01:00.373443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 717s 359s/step - loss: 0.0157 - fcn_MSE_loss: 0.0157 - val_loss: 0.0038 - val_fcn_MSE_loss: 0.0038\n",
      "\n",
      "len(self.model.inputs)  : 5 len(self.model.targets) : 3 len(self.model.sample_weights) : 3\n",
      " len(val_data):  12  len(tensors):  12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d2ae3beac771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                         \u001b[0;31m# do not slice the learning phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                         \u001b[0mbatch_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                         \u001b[0;31m# do not slice the learning phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                         \u001b[0mbatch_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------\n",
    "## END OF EPOCH Phase \n",
    "##------------------------------------------------------------------------\n",
    "## end of evaluate_generator() emulation\n",
    "## val_averages returned back to fit_generator() as val_outs\n",
    "## calculate val_outs after all validations steps complete\n",
    "##------------------------------------------------------------------------\n",
    "if not isinstance(val_averages, list):\n",
    "    val_averages = [val_averages]\n",
    "# Same labels assumed.\n",
    "for l, o in zip(out_labels, val_averages):\n",
    "    epoch_logs['val_' + l] = o\n",
    "\n",
    "#----commented 31-10-18 replaced with above lines -------------------------------------------\n",
    "# if not isinstance(outs2, list):\n",
    "    # val_outs =  np.average(np.asarray(val_all_outs), weights=val_batch_sizes)\n",
    "# else:\n",
    "    # averages = []\n",
    "    # for i in range(len(outs2)):\n",
    "        # averages.append(np.average([out[i] for out in val_all_outs], axis = 0, weights=val_batch_sizes))\n",
    "    # val_outs = averages\n",
    "# if not isinstance(val_outs, list):\n",
    "    # val_outs = [val_outs]\n",
    "\n",
    "# # Same labels assumed.\n",
    "# for l, o in zip(out_labels, val_outs):\n",
    "    # # print(' Validations : out label: val_', l, ' out value: ', o)\n",
    "    # epoch_logs['val_' + l] = o\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "# write_log(callback, val_names, logs, batch_no//10)\n",
    "# print('\\n    validation logs output: ', val_outs)\n",
    "\n",
    "\n",
    "epoch_logs.update({'lr': KB.eval(self.keras_model.optimizer.lr)})    \n",
    "callbacks.on_epoch_end(epoch_idx, epoch_logs)\n",
    "epoch_idx += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:31:50.425647Z",
     "start_time": "2018-11-08T11:31:46.561376Z"
    }
   },
   "outputs": [],
   "source": [
    "                for callback in callbacks:\n",
    "                    # print(callback)\n",
    "                    # pp.pprint(dir(callback.model))\n",
    "                    if hasattr(callback.model, 'stop_training') and (callback.model.stop_training ==True):\n",
    "                        print(' +++++++++++ ON EPOCH END CALLBACKS TRIGGERED STOP_TRAINING +++++++++++++')\n",
    "                        print(callback.model, ' triggered stop_training +++++++++++++')\n",
    "                        early_stopping = True\n",
    "                        \n",
    "                if early_stopping:\n",
    "                    print('{}  Early Stopping triggered on epoch {} of {} epochs'.format(callback, epoch_idx, epochs))\n",
    "                    break    \n",
    "                \n",
    "            ##-------------------------------\n",
    "            ## end of training operations\n",
    "            ##--------------------------------\n",
    "            # if epoch_idx != self.epoch:\n",
    "            # chkpoint.on_epoch_end(epoch_idx -1, batch_logs)\n",
    "            callbacks.on_train_end()\n",
    "            self.epoch = max(epoch_idx - 1, epochs)\n",
    "            print('Final : self.epoch {}   epochs {}'.format(self.epoch, epochs))\n",
    "            \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## End main training loop\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        return \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T14:24:00.803567Z",
     "start_time": "2018-11-07T14:24:00.756959Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Simulate Train in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:31:28.241914Z",
     "start_time": "2018-11-08T11:31:28.192270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_in_batches(self,\n",
    "                mrcnn_model,\n",
    "              train_dataset, \n",
    "              val_dataset,  \n",
    "              layers            = None,\n",
    "              losses            = None,\n",
    "              learning_rate     = 0,              \n",
    "              epochs            = 0,\n",
    "              epochs_to_run     = 0, \n",
    "              batch_size        = 0, \n",
    "              steps_per_epoch   = 0,\n",
    "              min_LR            = 0,\n",
    "              debug             = False):\n",
    "              \n",
    "        '''\n",
    "        Train the model.\n",
    "        train_dataset, \n",
    "        val_dataset:    Training and validation Dataset objects.\n",
    "        \n",
    "        learning_rate:  The learning rate to train with\n",
    "        \n",
    "        epochs:         Number of training epochs. Note that previous training epochs\n",
    "                        are considered to be done already, so this actually determines\n",
    "                        the epochs to train in total rather than in this particaular\n",
    "                        call.\n",
    "                        \n",
    "        layers:         Allows selecting wich layers to train. It can be:\n",
    "                        - A regular expression to match layer names to train\n",
    "                        - One of these predefined values:\n",
    "                        heads: The RPN, classifier and mask heads of the network\n",
    "                        all: All the layers\n",
    "                        3+: Train Resnet stage 3 and up\n",
    "                        4+: Train Resnet stage 4 and up\n",
    "                        5+: Train Resnet stage 5 and up\n",
    "        '''\n",
    "        assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "        \n",
    "        if batch_size == 0 :\n",
    "            batch_size = self.config.BATCH_SIZE\n",
    "        \n",
    "        if epochs_to_run ==  0 :\n",
    "            epochs_to_run = self.config.EPOCHS_TO_RUN\n",
    "        \n",
    "        if steps_per_epoch == 0:\n",
    "            steps_per_epoch = self.config.STEPS_PER_EPOCH\n",
    "\n",
    "        if min_LR == 0 :\n",
    "            min_LR = self.config.MIN_LR\n",
    "        \n",
    "        if learning_rate == 0:\n",
    "            learning_rate = self.config.LEARNING_RATE\n",
    "            \n",
    "        epochs = self.epoch + epochs_to_run\n",
    "            \n",
    "        # use Pre-defined layer regular expressions\n",
    "        # if layers in self.layer_regex.keys():\n",
    "            # layers = self.layer_regex[layers]\n",
    "        print(layers)\n",
    "        # train_regex_list = []\n",
    "        # for x in layers:\n",
    "            # print( ' layers ias : ',x)\n",
    "            # train_regex_list.append(x)\n",
    "        train_regex_list = [self.layer_regex[x] for x in layers]\n",
    "        print(train_regex_list)\n",
    "        layers = '|'.join(train_regex_list)        \n",
    "        print('layers regex :', layers)\n",
    "        \n",
    "        \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## Data generators\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        train_generator = data_generator(train_dataset, mrcnn_model.config, shuffle=True,\n",
    "                                         batch_size=batch_size)\n",
    "        val_generator   = data_generator(val_dataset, mrcnn_model.config, shuffle=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         augment=False)\n",
    "\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## Set trainable layers and compile\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        self.set_trainable(layers)            \n",
    "\n",
    "        ##----------------------------------------------------------------------------------------------\n",
    "        ## Setup optimizaion method \n",
    "        ##----------------------------------------------------------------------------------------------            \n",
    "        optimizer = self.set_optimizer()\n",
    "\n",
    "        # self.compile(learning_rate, self.config.LEARNING_MOMENTUM, losses)        \n",
    "        self.compile(losses, optimizer)\n",
    "\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## get metrics from keras_model.metrics_names and setup callback metrics \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        out_labels = self.get_deduped_metrics_names()\n",
    "        callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "        \n",
    "        print()\n",
    "        print(' Post-compile out_labels from get_deduped_metrics_names() : ')\n",
    "        print(' ---------------------------------------------------------- ')\n",
    "        for i in out_labels:\n",
    "            print('     -',i)\n",
    "        print()\n",
    "        print(' Post-compile Callback metrics monitored by progbar :')\n",
    "        print(' ----------------------------------------------------')\n",
    "        for i in callback_metrics:\n",
    "            print('     -',i)\n",
    "\n",
    "        print()\n",
    "        print(' Post-compile Keras metric_names :') \n",
    "        print(' ---------------------------------') \n",
    "        for idx, i in enumerate(self.keras_model.metrics_names):\n",
    "            print('     ',idx, '  ', i)\n",
    "            \n",
    "        print()\n",
    "        print(' Post-compile Keras stateful_metric_names :') \n",
    "        print(' ------------------------------------------') \n",
    "        for idx, i in enumerate(self.keras_model.stateful_metric_names):\n",
    "            print('     ',idx, '  ', i)\n",
    "\n",
    "        ## Setup for stateful_metric_indices Validation process \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        stateful_metric_indices = []\n",
    "        if hasattr(self, 'metrics'):\n",
    "            for m in self.stateful_metric_functions:\n",
    "                m.reset_states()\n",
    "            stateful_metric_indices = [\n",
    "                i for i, name in enumerate(self.metrics_names)\n",
    "                if str(name) in self.stateful_metric_names]\n",
    "        else:\n",
    "            stateful_metric_indices = []\n",
    "            \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## Callbacks\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        # call back for model checkpoint was originally (?) loss. chanegd to val_loss (which is default) 2-5-18\n",
    "        # copied from \\keras\\engine\\training.py\n",
    "        # def _get_deduped_metrics_names(self):\n",
    "\n",
    "            \n",
    "        callbacks_list = [\n",
    "              keras.callbacks.ProgbarLogger(count_mode='steps',\n",
    "                                            stateful_metrics=self.keras_model.stateful_metric_names)\n",
    "            \n",
    "            , keras.callbacks.BaseLogger(stateful_metrics=self.keras_model.stateful_metric_names)\n",
    "            \n",
    "            , keras.callbacks.TensorBoard(log_dir=self.log_dir,\n",
    "                                          histogram_freq=1,\n",
    "                                          write_graph=True,\n",
    "                                          write_images=False, \n",
    "                                          write_grads=True,\n",
    "                                          batch_size=self.config.BATCH_SIZE)\n",
    "                                          # write_graph=True,\n",
    "\n",
    "                                          # write_images=True,\n",
    "                                          # embeddings_freq=0,\n",
    "                                          # embeddings_layer_names=None,\n",
    "                                          # embeddings_metadata=None)\n",
    "\n",
    "            , keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                              mode    = 'auto', \n",
    "                                              period  = self.config.CHECKPOINT_PERIOD, \n",
    "                                              monitor = 'val_loss', \n",
    "                                              verbose = 1, \n",
    "                                              save_best_only = True, \n",
    "                                              save_weights_only=True)\n",
    "                                            \n",
    "            , keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                mode     = 'auto', \n",
    "                                                factor   = self.config.REDUCE_LR_FACTOR,   \n",
    "                                                cooldown = self.config.REDUCE_LR_COOLDOWN,\n",
    "                                                patience = self.config.REDUCE_LR_PATIENCE,\n",
    "                                                min_delta= self.config.REDUCE_LR_MIN_DELTA,\n",
    "                                                min_lr   = self.config.MIN_LR, \n",
    "                                                verbose  = 1)                                            \n",
    "                                                \n",
    "            , keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                mode      = 'auto', \n",
    "                                                min_delta = self.config.EARLY_STOP_MIN_DELTA, \n",
    "\n",
    "                                                patience  = self.config.EARLY_STOP_PATIENCE, \n",
    "                                                verbose   = 1)                                            \n",
    "            , keras.callbacks.History() \n",
    "        ]\n",
    "         \n",
    "        \n",
    "        callbacks =  keras.callbacks.CallbackList(callbacks = callbacks_list)\n",
    "        callbacks.set_model(self.keras_model)\n",
    "        callbacks.set_params({\n",
    "            'batch_size': batch_size,\n",
    "            'epochs': epochs,\n",
    "            'steps': steps_per_epoch,\n",
    "            'verbose': 1 ,\n",
    "            'do_validation': True,\n",
    "            'metrics': callback_metrics\n",
    "        })\n",
    "        \n",
    "            # 'samples': num_train_samples,\n",
    "            # 'verbose': verbose,\n",
    "            # 'do_validation': do_validation,\n",
    "            # 'metrics': callback_metrics or [],\n",
    "        \n",
    "        log(\" \")\n",
    "        log(\"Training Start Parameters:\")\n",
    "        log(\"--------------------------\")\n",
    "        log(\"Starting at epoch     {} of {} epochs.\".format(self.epoch, epochs))\n",
    "        log(\"Steps per epochs      {} \".format(steps_per_epoch))\n",
    "        log(\"Last epoch completed  {} \".format(self.epoch))\n",
    "        log(\"Batch size            {} \".format(batch_size))\n",
    "        log(\"Learning Rate         {} \".format(self.config.LEARNING_RATE))\n",
    "        log(\"Momentum              {} \".format(self.config.LEARNING_MOMENTUM))\n",
    "        log(\"Weight Decay:         {} \".format(self.config.WEIGHT_DECAY       ))\n",
    "        log(\"VALIDATION_STEPS      {} \".format(self.config.VALIDATION_STEPS   ))\n",
    "        log(\"REDUCE_LR_FACTOR      {} \".format(self.config.REDUCE_LR_FACTOR   ))\n",
    "        log(\"REDUCE_LR_COOLDOWN    {} \".format(self.config.REDUCE_LR_COOLDOWN ))\n",
    "        log(\"REDUCE_LR_PATIENCE    {} \".format(self.config.REDUCE_LR_PATIENCE ))\n",
    "        log(\"MIN_LR                {} \".format(self.config.MIN_LR             ))\n",
    "        log(\"EARLY_STOP_PATIENCE   {} \".format(self.config.EARLY_STOP_PATIENCE))        \n",
    "        log(\"Checkpoint Path:      {} \".format(self.checkpoint_path))\n",
    "\n",
    "\n",
    "        ##----------------------------------------------------------------------------------------------\n",
    "        ## If in debug mode write stdout intercepted IO to output file  \n",
    "        ##----------------------------------------------------------------------------------------------            \n",
    "        if self.config.SYSOUT == 'FILE':\n",
    "            utils.write_sysout(self.log_dir)\n",
    "\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## Start main training loop\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        early_stopping  = False\n",
    "        val_steps = self.config.VALIDATION_STEPS\n",
    "        epoch_idx = self.epoch\n",
    "        callbacks.on_train_begin()\n",
    "\n",
    "\n",
    "        if epoch_idx >= epochs:\n",
    "            print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "        else:\n",
    "        \n",
    "            while epoch_idx < epochs :\n",
    "                callbacks.on_epoch_begin(epoch_idx)\n",
    "                epoch_logs = {}\n",
    "                \n",
    "                ##------------------------------------------------------------------------\n",
    "                ## TRAINING Phase - emulating fit_generator()\n",
    "                ##------------------------------------------------------------------------\n",
    "                for steps_index in range(steps_per_epoch):\n",
    "                    \n",
    "                    # print(' self.epoch {}   epochs {}  step {} '.format(self.epoch, epochs, steps_index))\n",
    "                    batch_logs = {}\n",
    "                    batch_logs['batch'] = steps_index\n",
    "                    batch_logs['size']  = batch_size    \n",
    "\n",
    "                    callbacks.on_batch_begin(steps_index, batch_logs)\n",
    "\n",
    "                    train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "                    \n",
    "                    # print('len of train batch x' ,len(train_batch_x))\n",
    "                    # for idx, i in  enumerate(train_batch_x):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                    # print('len of train batch y' ,len(train_batch_y))\n",
    "                    # for idx, i in  enumerate(train_batch_y):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                    # print(type(output_rois))\n",
    "                    # for i in model_output:\n",
    "                        # print( i.shape)       \n",
    "                        \n",
    "                    ## Run prediction on MRCNN  \n",
    "                    try:\n",
    "                        results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "                        fcn_x = [train_batch_x[1]]\n",
    "                        fcn_x.extend(results[:4])\n",
    "                    \n",
    "                    except Exception as e :\n",
    "                        print('failure on mrcnn predict - epoch {} , image ids: {} '.format(epoch_idx, train_batch_x[1][:,0]))\n",
    "                        print('Exception information:')\n",
    "                        print(str(e))\n",
    "                    \n",
    "                    # print('size of results : ', len(results))\n",
    "                    # for idx, i in  enumerate(x):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                    \n",
    "                    ## Train on FCN\n",
    "                    try:\n",
    "                        outs = self.keras_model.train_on_batch(fcn_x , train_batch_y)                                            \n",
    "                    except Exception as e :\n",
    "                        print('failure on fcn train - epoch {} , image ids: {} '.format(epoch_idx, train_batch_x[1][:,0]))\n",
    "                        print('Exception information:')\n",
    "                        print(str(e))                \n",
    "                        \n",
    "                    # print('size of outputs from train_on_batch : ', len(outs), outs)\n",
    "                    # for idx, i in  enumerate(outs):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                        \n",
    "                    if not isinstance(outs, list):\n",
    "                        outs = [outs]\n",
    "\n",
    "                    for l, o in zip(out_labels, outs):\n",
    "                        # print(' out label: ', l, ' out value: ', o,' shape: ', o.shape)\n",
    "                        batch_logs[l] = o\n",
    "    \n",
    "                    callbacks.on_batch_end(steps_index, batch_logs)\n",
    "\n",
    "                ##------------------------------------------------------------------------\n",
    "                ## VALIDATION Phase - emulating evaluate_generator()\n",
    "                ##------------------------------------------------------------------------\n",
    "                # print(' Start validation ')\n",
    "                # print(' ---------------- ')\n",
    "                # print(' Stateful metric indices:' )\n",
    "                # pp.pprint(stateful_metric_indices)\n",
    "                \n",
    "                \n",
    "                val_steps_done      = 0\n",
    "                val_outs_per_batch  = []\n",
    "                val_batch_sizes     = []\n",
    "                \n",
    "                # setup validation progress bar if we wish\n",
    "                # progbar = Progbar(target=val_steps)\n",
    "\n",
    "                while val_steps_done < val_steps:\n",
    "                    # print(' ** Validation step: ', val_steps_done)\n",
    "                    \n",
    "                    mrcnn_val_x, mrcnn_val_y = next(val_generator)\n",
    "                    \n",
    "                    # print('len of train batch x' ,len(val_x))\n",
    "                    # for idx, i in  enumerate(val_x):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                        \n",
    "                    ## Run prediction on MRCNN  \n",
    "                    try:\n",
    "                        val_results = mrcnn_model.keras_model.predict(mrcnn_val_x)\n",
    "                        fcn_val_x = [mrcnn_val_x[1]]\n",
    "                        fcn_val_x.extend(val_results[:4])   ## image_meta, pr_hm, pr_hm_scores, gt_hm, gt_hm_scores\n",
    "                    except Exception as e :\n",
    "                        print('failure on mrcnn predict (validation)- epoch {} , image ids: {} '.format(epoch_idx, mrcnn_val_x[1][:,0]))\n",
    "                        print('Exception information:')\n",
    "                        print(str(e))                \n",
    "\n",
    "                    # print('    mrcnn_model.predict() size of results : ', len(val_results))\n",
    "                    # for idx, i in  enumerate(xval_results):\n",
    "                        # print('    ',idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                                       \n",
    "                    ## Train on FCN\n",
    "                    try:\n",
    "                        outs2 = self.keras_model.test_on_batch( fcn_val_x , mrcnn_val_y)\n",
    "                        # print('\\n valstep {} outs2 len:{} '.format(val_steps_done, len(outs2)))\n",
    "                        val_outs_per_batch.append(outs2)\n",
    "                    except Exception as e :\n",
    "                        print('failure on fcn train (validation)- epoch {} , image ids: {} '.format(epoch_idx, mrcnn_val_x[1][:,0]))                    \n",
    "                        print('Exception information:')\n",
    "                        print(str(e))                \n",
    "\n",
    "                    # print('fcn_model.test_on_batch() size of results : ', len(outs2))\n",
    "                    # for idx, i in  enumerate(outs2):\n",
    "                        # print(idx, 'type: ', type(i), 'shape: ', i.shape)\n",
    "                    \n",
    "                    if isinstance(fcn_val_x, list):\n",
    "                        batch_size = fcn_val_x[0].shape[0]\n",
    "                    elif isinstance(fcn_val_x, dict):\n",
    "                        batch_size = list(fcn_val_x.values())[0].shape[0]\n",
    "                    else:\n",
    "                        batch_size = fcn_val_x.shape[0]\n",
    "                        \n",
    "                    if batch_size == 0:\n",
    "                        raise ValueError('Received an empty batch. '\n",
    "                                         'Batches should at least contain one item.')\n",
    "                    # else:\n",
    "                        # print('batch size:', batch_size)\n",
    "                        \n",
    "                    val_steps_done += 1\n",
    "                    val_batch_sizes.append(batch_size)\n",
    "                    # print validation progress bar if we wish\n",
    "                    # progbar.update(val_steps_done)\n",
    "\n",
    "                ## calculate val_averages after all validations steps complete, which is passed \n",
    "                ## back to fit_generator() as val_outs \n",
    "                \n",
    "                print('    val_batch_sizes            :', type(val_batch_sizes),' len :', len(val_batch_sizes), val_batch_sizes)\n",
    "                print('    val_batch_sizes-shape      :', np.asarray(val_batch_sizes).shape)\n",
    "                \n",
    "                print('    val_outs_per_batch:        :', type(val_batch_sizes),' len :', len(val_outs_per_batch))\n",
    "                print('    val_outs_per_batch - shape :', np.asarray(val_outs_per_batch).shape)\n",
    "                for i,j in enumerate(val_outs_per_batch):\n",
    "                    print('        batch: ', i, '  ', j)\n",
    "                \n",
    "                val_averages = []\n",
    "                for i in range(len(outs2)):\n",
    "                    if i not in stateful_metric_indices:\n",
    "                        tt = [out[i] for out in val_outs_per_batch]\n",
    "                        # print(' tt type: ',type(tt), tt)\n",
    "                        # print('val_batch_sizes.shape' , type(val_batch_sizes), len(val_batch_sizes))\n",
    "                        val_averages.append(\n",
    "                                np.average([out[i] for out in val_outs_per_batch], axis = 0, weights=val_batch_sizes)\n",
    "                                           )\n",
    "                    else:\n",
    "                        val_averages.append(float(val_outs_per_batch[-1][i]))\n",
    "                if len(val_averages) == 1:\n",
    "                    val_averages = val_averages[0]\n",
    "                print()\n",
    "                print('val_averages :', val_averages)\n",
    "                print()\n",
    "                #-- (unsuccessful) attempt to add histogram info to tensoflow summary  ------------------------\n",
    "                print(' Tensordlow histogram attempt')\n",
    "                print('-----------------------------')\n",
    "                fcn_val_y = self.keras_model.targets\n",
    "                val_sample_weight = self.keras_model.sample_weights\n",
    "                print(' len(fcn_val_x)  : ',len(fcn_val_x))\n",
    "                print(' len(fcn_val_y)  : ',len(fcn_val_y))\n",
    "                print(' len(mrcnn_val_y): ',len(mrcnn_val_y))\n",
    "\n",
    "                fcn_val_x, fcn_val_y, fcn_val_sample_weights = my_standardize_user_data(self.keras_model, fcn_val_x, fcn_val_y, val_sample_weight)\n",
    "                fcn_val_data = fcn_val_x + fcn_val_y  + fcn_val_sample_weights\n",
    "\n",
    "                print(' len(fcn_val_x)             : ',len(fcn_val_x))\n",
    "                print(' len(fcn_val_y)             : ',len(fcn_val_y))\n",
    "                print(' len(fcn_val_sample_weights): ',len(fcn_val_sample_weights))\n",
    "                print(' len(fcn_val_data)          : ',len(fcn_val_data))\n",
    "                if self.keras_model.uses_learning_phase and not isinstance(KB.learning_phase(), int):\n",
    "                    fcn_val_data += [0.]\n",
    "                for cbk in callbacks:\n",
    "                    cbk.validation_data = fcn_val_data\n",
    "\n",
    "                #-------------------------------------------------------------------------------\n",
    "                \n",
    "                ##------------------------------------------------------------------------\n",
    "                ## END OF EPOCH Phase \n",
    "                ##------------------------------------------------------------------------\n",
    "                ## end of evaluate_generator() emulation\n",
    "                ## val_averages returned back to fit_generator() as val_outs\n",
    "                ## calculate val_outs after all validations steps complete\n",
    "                ##------------------------------------------------------------------------\n",
    "                if not isinstance(val_averages, list):\n",
    "                    val_averages = [val_averages]\n",
    "                # Same labels assumed.\n",
    "                for l, o in zip(out_labels, val_averages):\n",
    "                    epoch_logs['val_' + l] = o\n",
    "                    \n",
    "                #----commented 31-10-18 replaced with above lines -------------------------------------------\n",
    "                # if not isinstance(outs2, list):\n",
    "                    # val_outs =  np.average(np.asarray(val_all_outs), weights=val_batch_sizes)\n",
    "                # else:\n",
    "                    # averages = []\n",
    "                    # for i in range(len(outs2)):\n",
    "                        # averages.append(np.average([out[i] for out in val_all_outs], axis = 0, weights=val_batch_sizes))\n",
    "                    # val_outs = averages\n",
    "                # if not isinstance(val_outs, list):\n",
    "                    # val_outs = [val_outs]\n",
    "                \n",
    "                # # Same labels assumed.\n",
    "                # for l, o in zip(out_labels, val_outs):\n",
    "                    # # print(' Validations : out label: val_', l, ' out value: ', o)\n",
    "                    # epoch_logs['val_' + l] = o\n",
    "                #-------------------------------------------------------------------------------------\n",
    "                \n",
    "                # write_log(callback, val_names, logs, batch_no//10)\n",
    "                # print('\\n    validation logs output: ', val_outs)\n",
    "                \n",
    "                    \n",
    "                epoch_logs.update({'lr': KB.eval(self.keras_model.optimizer.lr)})    \n",
    "                callbacks.on_epoch_end(epoch_idx, epoch_logs)\n",
    "                epoch_idx += 1\n",
    "                \n",
    "\n",
    "                for callback in callbacks:\n",
    "                    # print(callback)\n",
    "                    # pp.pprint(dir(callback.model))\n",
    "                    if hasattr(callback.model, 'stop_training') and (callback.model.stop_training ==True):\n",
    "                        print(' +++++++++++ ON EPOCH END CALLBACKS TRIGGERED STOP_TRAINING +++++++++++++')\n",
    "                        print(callback.model, ' triggered stop_training +++++++++++++')\n",
    "                        early_stopping = True\n",
    "                        \n",
    "                if early_stopping:\n",
    "                    print('{}  Early Stopping triggered on epoch {} of {} epochs'.format(callback, epoch_idx, epochs))\n",
    "                    break    \n",
    "                \n",
    "            ##-------------------------------\n",
    "            ## end of training operations\n",
    "            ##--------------------------------\n",
    "            # if epoch_idx != self.epoch:\n",
    "            # chkpoint.on_epoch_end(epoch_idx -1, batch_logs)\n",
    "            callbacks.on_train_end()\n",
    "            self.epoch = max(epoch_idx - 1, epochs)\n",
    "            print('Final : self.epoch {}   epochs {}'.format(self.epoch, epochs))\n",
    "            \n",
    "        ##--------------------------------------------------------------------------------\n",
    "        ## End main training loop\n",
    "        ##--------------------------------------------------------------------------------\n",
    "        return \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run data through MRCNN and FCN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display model input / output information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:35.696820Z",
     "start_time": "2018-10-17T14:34:33.592738Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mrcnn_model.layer_info()\n",
    "print('\\n FCN')\n",
    "fcn_model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:33.590986Z",
     "start_time": "2018-10-17T14:33:20.870486Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [4,5,6,7,9,10,11,12,13,14], 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5,6,7,9,10,11], 1)\n",
    "model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:35:47.365657Z",
     "start_time": "2018-10-17T14:35:46.115830Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "\n",
    "# output_rois               = model_output[0]          # layer:  4   shape: (1, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  5   shape: (1, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  6   shape: (1, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  7   shape: (1, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  8   shape: (1, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  9   shape: (1, 200, 81, 4)\n",
    "# pred_refined_tensor       = model_output[6]          # layer: 16   shape: (1, 81, 25, 7)\n",
    "# output_rois               = model_output[0]          # layer:  0   shape: (2, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  1   shape: (2, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  2   shape: (2, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  3   shape: (2, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  4   shape: (2, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  5   shape: (2, 200, 81, 4)\n",
    "# model_pred_heatmap_norm         = model_output[6]          # layer:  6   shape: (2, 256, 256, 81)\n",
    "# model_pred_heatmap_scores       = model_output[7]          # layer:  7   shape: (2, 81, 25, 11)\n",
    "# model_gt_heatmap_scores         = model_output[8]          # layer:  9   shape: (2, 81, 25, 11)\n",
    "# model_pred_tensor               = model_output[9]          # layer: 10   shape: (2, 81, 25, 8)\n",
    "# model_gt_tensor                 = model_output[10]          # layer: 11   shape: (2, 81, 25, 8)\n",
    "\n",
    "pred_heatmap_norm         = model_output[0]          # layer:  0   shape: (2, 256, 256, 81)\n",
    "pred_heatmap_scores       = model_output[1]          # layer:  1   shape: (2, 81, 200, 11)\n",
    "gt_heatmap_norm           = model_output[2]          # layer:  2   shape: (2, 256, 256, 81)\n",
    "gt_heatmap_scores         = model_output[3]          # layer:  3   shape: (2, 81, 200, 11)\n",
    "pred_tensor               = model_output[4]          # layer:  4   shape: (2, 81, 200, 8)\n",
    "gt_tensor                 = model_output[5]          # layer:  5   shape: (2, 81, 200, 8)\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:37:20.794299Z",
     "start_time": "2018-10-17T14:37:17.275078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fcn_input = [pred_heatmap_norm, pred_heatmap_scores, gt_heatmap_norm, gt_heatmap_scores] \n",
    "model_output2 = get_layer_output_1(fcn_model.keras_model, fcn_input, [0,1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:33:34.842266Z",
     "start_time": "2018-10-15T17:33:34.808415Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image          =  train_batch_x[0]\n",
    "input_image_meta     =  train_batch_x[1]\n",
    "# input_rpn_match      =  train_batch_x[2]\n",
    "# input_rpn_bbox       =  train_batch_x[3]\n",
    "input_gt_class_ids   =  train_batch_x[4]\n",
    "input_gt_bboxes      =  train_batch_x[5]\n",
    "print(' Input image shape is    :', input_image.shape)\n",
    "print(' input_image_meta        :', input_image_meta[0,:10])\n",
    "# print(' input_rpn_match         :', input_rpn_match.shape)\n",
    "# print(' input_rpn_bbox          :', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids      :', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes         :', input_gt_bboxes.shape)\n",
    "# h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "# input_gt_bboxes_norm = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "# print(' input_gt_bboxes_norm    :', input_gt_bboxes_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display output from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  `input_gt_class_ids`, `input_gt_bboxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:34:03.805818Z",
     "start_time": "2018-10-15T17:34:02.696855Z"
    },
    "hidden": true,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(roi_gt_boxes[0,:50] * [1024,1024,1024,1024])\n",
    "print(input_gt_class_ids[0])\n",
    "print(input_gt_bboxes[0,:10])\n",
    "# for i in range(input_gt_class_ids.shape[1]):\n",
    "#     if input_gt_class_ids[0,i] == 1:\n",
    "#         print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display `output_rois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:59:35.184714Z",
     "start_time": "2018-09-26T08:59:35.139366Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  `max_mrcnn_class` , `argmax_mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:46:21.282072Z",
     "start_time": "2018-09-22T16:46:21.216616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print(' mrcnn_class', mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,0,:])\n",
    "# \n",
    "max_mrcnn_class    = np.max(mrcnn_class, axis = (0,2))\n",
    "argmax_mrcnn_class = np.argmax(mrcnn_class, axis = 2)\n",
    "\n",
    "# print()\n",
    "print('\\n mrcnn_class Max Values   : ', max_mrcnn_class.shape)\n",
    "print(max_mrcnn_class)\n",
    "\n",
    "# print()\n",
    "print(' mrcnn_class Argmax Values: ', argmax_mrcnn_class.shape)\n",
    "print(argmax_mrcnn_class[0])\n",
    "\n",
    "print(' target_class_ds    Values: ', target_class_ids.shape)\n",
    "print(target_class_ids[0])\n",
    "\n",
    "# for i in range(100):\n",
    "#     print('Predicted: ', argmax_mrcnn_class[0,i],  '  Actual ', target_class_ids[0,i])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Display  `target_class_ids()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T09:00:14.575438Z",
     "start_time": "2018-09-26T09:00:14.534931Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  apply `deltas` from predicted delta `mrcnn_bbox`  to  `output_rois` to obtain refined rois "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:52:01.206727Z",
     "start_time": "2018-09-21T12:52:01.068748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img_idx = 0 \n",
    "\n",
    "print('output_rois',output_rois.shape, 'deltas ', deltas.shape)\n",
    "cls = 1\n",
    "for i in range(input_gt_class_ids.shape[1]):\n",
    "    if input_gt_class_ids[0,i] == cls:\n",
    "        print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])\n",
    "\n",
    "        \n",
    "print()        \n",
    "for i in range(output_rois.shape[1]):\n",
    "    if classes[0,i] ==cls:\n",
    "        print(' i ', i, 'class: ',classes[0,i])\n",
    "#         print('   orig           : ', output_rois[0,i])\n",
    "        d1 = deltas[0,i] * mrcnn_config.BBOX_STD_DEV\n",
    "#         print('   delta          : ', deltas[0,i],'   delta * std dev: ', d1)\n",
    "        d2 = utils.apply_box_delta(output_rois[0,i],d1)\n",
    "#         print('   refined        : ', d2)\n",
    "#         print()\n",
    "        print('   orig           : ',output_rois[0,i] * [1024,1024,1024,1024])\n",
    "        print('   refined        : ', d2 * [1024,1024,1024,1024]) \n",
    "        print('   roi_gt_bboxes  : ', roi_gt_boxes[0,i]* [1024,1024,1024,1024]) \n",
    "        print()\n",
    "        print('   pred delta     : ', deltas[0,i] )\n",
    "        print('   tgt delta      : ', target_bbox_deltas[0,i] )\n",
    "        \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display roi_gt_boxes , and class_ids vs. output_bbox and prediceted class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:34:41.699530Z",
     "start_time": "2018-09-22T16:34:41.650195Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ref_out_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:35:45.777944Z",
     "start_time": "2018-09-22T16:35:45.598528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ref_out_roi1 = ref_out_roi * [1024,1024,1024,1024]\n",
    "print(ref_out_roi1)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "print(window.shape)\n",
    "ref_out_roi2  = utils.clip_to_window_np( window, ref_out_roi1)\n",
    "print(ref_out_roi2.shape)\n",
    "for i in range(200):\n",
    "    print(ref_out_roi1[i],' --- ', ref_out_roi2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Display pred_refined_tensor and gt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:00:33.070168Z",
     "start_time": "2018-10-16T10:00:33.031739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for cls in [1]:\n",
    "    for box in range(20):\n",
    "        print(pred_tensor[0,cls,box])\n",
    "        print(gt_tensor[0,cls,box])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Display roi_gt_boxes along with corresponding refined/clipped output_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:41:23.457232Z",
     "start_time": "2018-10-08T13:41:22.950711Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "print(roi_gt_boxes[0].shape, target_class_ids[0].shape , np.expand_dims(target_class_ids[0],axis=-1).shape)\n",
    "classes, deltas = utils.get_predicted_mrcnn_deltas(mrcnn_class, mrcnn_bbox, verbose=True)\n",
    "deltas *= mrcnn_config.BBOX_STD_DEV\n",
    "print('classes.shape: ',classes.shape, ' deltas.shape: ',deltas.shape)\n",
    "\n",
    "ref_out_roi = utils.apply_box_deltas_np(output_rois[img_id],deltas[img_id])\n",
    "#     ##   Clip boxes to image window    \n",
    "# print(ref_out_roi.shape)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "clipped_out_roi  = utils.clip_to_window_np( window, ref_out_roi*[1024,1024,1024,1024])\n",
    "\n",
    "for i in range(200):\n",
    "#     ref_out_roi = utils.apply_box_delta_np(output_rois[0],d1[0])\n",
    "#     if classes[img_id,i] == 1 or target_class_ids[img_id,i] == 1 :\n",
    "\n",
    "    print('idx: ',200-i,' GT Cls: ', target_class_ids[img_id,i]  , ' -', roi_gt_boxes[img_id,i]*[1024,1024,1024,1024], \n",
    "                    ' PR Cls: ', classes[img_id,i],' - ', ref_out_roi[i]*[1024.0,1024.0,1024.0,1024.0] ,\n",
    "                     'ClpdCls: ', clipped_out_roi[i]   ) #) *[1024,1024,1024,1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### display gt_heatmap_scores and pred_heatmap_scores outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:22:55.077601Z",
     "start_time": "2018-10-16T10:22:54.959295Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=200, suppress=True)\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "img_id = 1\n",
    "print(' GT Heatmap Scores')\n",
    "\n",
    "print('gt_heatmap_scores: ', gt_heatmap_scores.dtype,  gt_heatmap_scores.shape)\n",
    "print('pred_heatmap_scores: ', pred_heatmap_scores.dtype,  pred_heatmap_scores.shape)\n",
    "\n",
    "# print(gt_heatmap_scores[img,1])\n",
    "# for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "\n",
    "for img_id in [0]:    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    pr_class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    gt_class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist() \n",
    "    union_class_ids = np.union1d(pr_class_ids, gt_class_ids)\n",
    "    print('-'*56)\n",
    "    print('Image : {}  GT ClassIds: {}   PR ClassIds: {} '.format(img_id, gt_class_ids, pr_class_ids))\n",
    "    print('Image : {}  Union ClassIds: {}'.format(img_id, union_class_ids))\n",
    "    print('-'*56)\n",
    "    for cls in union_class_ids:  \n",
    "        print()\n",
    "        for i in range(25):\n",
    "#             print(' GT: img_id:',img_id, ' cls: ',cls, ' -',gt_tensor[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "#             print(' PR: img_id:',img_id, ' cls: ',cls, ' -',pred_tensor[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "\n",
    "            print(' GT: img/cls:',img_id, '/',cls, ' -',gt_heatmap_scores[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "            print(' PR: img/cls:',img_id, '/',cls, ' -',pred_heatmap_scores[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display `Pred_Tensor`, `Pred_heatmap`, `mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T13:55:40.491731Z",
     "start_time": "2018-09-19T13:55:40.409332Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, threshold=None, linewidth=150, suppress=True)\n",
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    "\n",
    "print('input_gt_class_ids')\n",
    "print(input_gt_class_ids[0])\n",
    "\n",
    "# print(' rpn_bbox')\n",
    "# print(rpn_bbox.shape)\n",
    "# print(rpn_bbox[0,:100,:])\n",
    "\n",
    "# print(' rpn_roi_proposals')\n",
    "# print(rpn_roi_proposals.shape)\n",
    "# print(rpn_roi_proposals[0,:100,:])\n",
    "\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:40])\n",
    "# print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "# print(' Pred_tensor')\n",
    "# print(pred_tensor.shape)\n",
    "# print(pred_tensor[img,:,:10])\n",
    "\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "\n",
    "# print(' mrcnn_class')\n",
    "# print( mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,:,:])\n",
    "\n",
    "# print(' mrcnn_bbox')\n",
    "# print( mrcnn_bbox.shape)\n",
    "# print( mrcnn_bbox)\n",
    "\n",
    "# print(' roi_gt_boxes')\n",
    "# print(roi_gt_boxes.shape)\n",
    "# print(roi_gt_boxes[img,:,:])\n",
    "\n",
    "# print(' Pred Heatmap Scores')\n",
    "# print(pred_heatmap_scores.dtype, pred_heatmap_scores.shape)\n",
    "# print(pred_heatmap_scores[img,1])\n",
    "\n",
    "# print(' FCN Scores')\n",
    "# print(fcn_scores.dtype)\n",
    "# for cls in range(4):\n",
    "#     print(pred_heatmap_scores[img,cls,:10])\n",
    "#     print(fcn_scores[img,cls,:10,2:])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:48:00.011050Z",
     "start_time": "2018-10-08T13:47:59.957418Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in [0]:\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display  - `pred_refined_tensor` which is passed on to  `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:34:53.538773Z",
     "start_time": "2018-10-08T15:34:53.480026Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "img_id = 0\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('model_pred_tensor shape is ', model_pred_tensor.shape)\n",
    "print(input_image_meta[0,:10])\n",
    "pr_class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  PR ClassIds: {} '.format(img_id, pr_class_ids))\n",
    "for k in pr_class_ids:\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(model_pred_tensor[img,k,:30])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Compare  `pred_heatmap_scores` vs. `pred_refined_heatmap_scores`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Setup tensors to be passed to `build_predictions ()`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:52:33.994332Z",
     "start_time": "2018-09-26T13:52:33.946512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mrcnn_bbox  = tf.identity(mrcnn_bbox)\n",
    "mrcnn_class = tf.identity(mrcnn_class)\n",
    "norm_input_rois = tf.identity(output_rois)\n",
    "config      = mrcnn_config\n",
    "sess = KB.get_session()\n",
    "print(' Keras session :', sess)\n",
    "import mrcnn.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Run TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "# FeedList = [ rois, roi_gt_class_ids,  roi_gt_deltas, roi_gt_boxes]\n",
    "Fetches  = [ pred_heatmap, pred_heatmap_norm, pred_heatmap_scores]\n",
    "tt = sess.run(Fetches)\n",
    "print(type(tt), len(tt))\n",
    "for i in tt:\n",
    "    print(type(i), i.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
