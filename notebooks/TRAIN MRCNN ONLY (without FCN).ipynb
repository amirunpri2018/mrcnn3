{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Train MRCNN Model from pipeline\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------------------------------------------------------------\n",
    "##\n",
    "## Combined MRCNN-FCN Pipeline (import model_mrcnn)\n",
    "## Train MRCNN heads only\n",
    "##\n",
    "##  \n",
    "##-------------------------------------------------------------------------------------------\n",
    "\n",
    "import os, sys, math, io, time\n",
    "import gc\n",
    "import numpy as np\n",
    "import argparse\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "import platform\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "# import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "from datetime import datetime   \n",
    "\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.utils        import log, stack_tensors, stack_tensors_3d, write_stdout\n",
    "from mrcnn.datagen      import data_generator, load_image_gt\n",
    "from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.visualize    import plot_gaussian\n",
    "# from mrcnn.prep_notebook import prep_oldshapes_train, load_model\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "syst = platform.system()\n",
    "\n",
    "\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "##-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##  \n",
    "## Example:\n",
    "##           train-shapes_gpu --epochs 12 --steps-in-epoch 7 --last_epoch 1234 --logs_dir mrcnn_logs\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = argparse.ArgumentParser(description='Train Mask R-CNN on MS COCO.')\n",
    "# parser.add_argument(\"command\",\n",
    "                    # metavar=\"<command>\",\n",
    "                    # help=\"'train' or 'evaluate' on MS COCO\")\n",
    "# parser.add_argument('--dataset', required=True,\n",
    "                    # metavar=\"/path/to/coco/\",\n",
    "                    # help='Directory of the MS-COCO dataset')\n",
    "# parser.add_argument('--limit', required=False,\n",
    "                    # default=500,\n",
    "                    # metavar=\"<image count>\",\n",
    "                    # help='Images to use for evaluation (defaults=500)')\n",
    "                    \n",
    "parser.add_argument('--model', required=False,\n",
    "                    default='last',\n",
    "                    metavar=\"/path/to/weights.h5\",\n",
    "                    help=\"MRCNN model weights file: 'coco' , 'init' , or Path to weights .h5 file \")\n",
    "\n",
    "parser.add_argument('--fcn_model', required=False,\n",
    "                    default='last',\n",
    "                    metavar=\"/path/to/weights.h5\",\n",
    "                    help=\"FCN model weights file: 'init' , or Path to weights .h5 file \")\n",
    "\n",
    "parser.add_argument('--logs_dir', required=True,\n",
    "                    default='mrcnn_logs',\n",
    "                    metavar=\"/path/to/logs/\",\n",
    "                    help='Logs and checkpoints directory (default=logs/)')\n",
    "\n",
    "parser.add_argument('--last_epoch', required=False,\n",
    "                    default=0,\n",
    "                    metavar=\"<last epoch ran>\",\n",
    "                    help='Identify last completed epcoh for tensorboard continuation')\n",
    "                    \n",
    "parser.add_argument('--epochs', required=False,\n",
    "                    default=3,\n",
    "                    metavar=\"<epochs to run>\",\n",
    "                    help='Number of epochs to run (default=3)')\n",
    "                    \n",
    "parser.add_argument('--steps_in_epoch', required=False,\n",
    "                    default=1,\n",
    "                    metavar=\"<steps in each epoch>\",\n",
    "                    help='Number of batches to run in each epochs (default=5)')\n",
    "\n",
    "parser.add_argument('--val_steps', required=False,\n",
    "                    default=1,\n",
    "                    metavar=\"<val steps in each epoch>\",\n",
    "                    help='Number of validation batches to run at end of each epoch (default=1)')\n",
    "                    \n",
    "parser.add_argument('--batch_size', required=False,\n",
    "                    default=5,\n",
    "                    metavar=\"<batch size>\",\n",
    "                    help='Number of data samples in each batch (default=5)')                    \n",
    "\n",
    "parser.add_argument('--lr', required=False,\n",
    "                    default=0.001,\n",
    "                    metavar=\"<learning rate>\",\n",
    "                    help='Learning Rate (default=0.001)')\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:56:55.572961Z",
     "start_time": "2018-07-09T14:56:52.925038Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 1264 --batch_size 8  --lr 0.5               --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())\n",
    "args = parser.parse_args(\"--epochs 100 --steps_in_epoch 100  --last_epoch 1264 --batch_size 25 --lr 0.8 --val_steps 5 --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## if debug is true set stdout destination to stringIO\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "debug = False\n",
    "if debug:\n",
    "    sys.stdout = io.StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "# print(\"Dataset: \", args.dataset)\n",
    "# print(\"Logs:    \", args.logs)\n",
    "# print(\"Limit:   \", args.limit)\n",
    "\n",
    "print(\"    MRCNN Model        : \", args.model)\n",
    "print(\"    FCN Model          : \", args.fcn_model)\n",
    "print(\"    Log Dir            : \", args.logs_dir)\n",
    "print(\"    Last Epoch         : \", args.last_epoch)\n",
    "print(\"    Epochs to run      : \", args.epochs)\n",
    "print(\"    Steps in each epoch: \", args.steps_in_epoch)\n",
    "print(\"    Validation steps   : \", args.val_steps)\n",
    "print(\"    Batch Size         : \", args.batch_size)\n",
    "print(\"    OS Platform        : \", syst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "#---------------------------------------------------------------------------------\n",
    "# # Root directory of the project \n",
    "# MODEL_DIR    :    Directory to save logs and trained model\n",
    "# COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "#---------------------------------------------------------------------------------\n",
    "import platform\n",
    "syst = platform.system()\n",
    "if syst == 'Windows':\n",
    "    # WINDOWS MACHINE ------------------------------------------------------------------\n",
    "    ROOT_DIR          = \"E:\\\\\"\n",
    "    MODEL_PATH        = os.path.join(ROOT_DIR    , \"models\")\n",
    "    DATASET_PATH      = os.path.join(ROOT_DIR    , 'MLDatasets')\n",
    "    MODEL_DIR         = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    COCO_MODEL_PATH   = os.path.join(MODEL_PATH  , \"mask_rcnn_coco.h5\")\n",
    "    DEFAULT_LOGS_DIR  = os.path.join(MODEL_PATH  , args.logs_dir) \n",
    "    COCO_DATASET_PATH = os.path.join(DATASET_PATH, \"coco2014\")\n",
    "    RESNET_MODEL_PATH = os.path.join(MODEL_PATH  , \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "    VGG16_MODEL_PATH  = os.path.join(MODEL_PATH  , \"fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "    \n",
    "elif syst == 'Linux':\n",
    "    # LINUX MACHINE ------------------------------------------------------------------\n",
    "    ROOT_DIR          = os.getcwd()\n",
    "    MODEL_PATH        = os.path.expanduser('~/models')\n",
    "    DATASET_PATH      = os.path.expanduser('~/MLDatasets')\n",
    "    MODEL_DIR         = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    COCO_MODEL_PATH   = os.path.join(MODEL_PATH  , \"mask_rcnn_coco.h5\")\n",
    "    COCO_DATASET_PATH = os.path.join(DATASET_PATH, \"coco2014\")\n",
    "    DEFAULT_LOGS_DIR  = os.path.join(MODEL_PATH  , args.logs_dir)\n",
    "    RESNET_MODEL_PATH = os.path.join(MODEL_PATH  , \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "    VGG16_MODEL_PATH  = os.path.join(MODEL_PATH  , \"fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "else :\n",
    "    raise Error('unreconized system  '      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------\n",
    "mrcnn_config                    = shapes.NewShapesConfig()\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "mrcnn_config.VALIDATION_STEPS   = int(args.val_steps)\n",
    "mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "mrcnn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "mrcnn_config.MIN_LR             = 1.0e-10\n",
    "mrcnn_config.NEW_LOG_FOLDER     = True  \n",
    "mrcnn_config.display() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build shape dataset for Training and Validation       \n",
    "##------------------------------------------------------------------------------------\n",
    "dataset_train = shapes.NewShapesDataset(mrcnn_config)\n",
    "dataset_train.load_shapes(10000)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = shapes.NewShapesDataset(mrcnn_config)\n",
    "dataset_val.load_shapes(2500)\n",
    "dataset_val.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build Mask RCNN Model in TRAINING mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del mrcnn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "mrcnn_model = mrcnn_modellib.MaskRCNN(mode=\"training\", config=mrcnn_config, model_dir=MODEL_DIR, FCN_layers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load Mask RCNN Model Weight file\n",
    "##------------------------------------------------------------------------------------\n",
    "# exclude_list = [\"mrcnn_class_logits\"]\n",
    "#load_model(model, init_with = args.model)   \n",
    "exclude_list = []\n",
    "mrcnn_model.load_model_weights(init_with = args.model, exclude = exclude_list)   \n",
    "\n",
    "print('==========================================')\n",
    "print(\" MRCNN MODEL Load weight file COMPLETE    \")\n",
    "print('==========================================')\n",
    "\n",
    "mrcnn_config.display()  \n",
    "mrcnn_model.layer_info()\n",
    "\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print('config.BATCH_SIZE      : ', config.BATCH_SIZE)\n",
    "print('model.config.BATCH_SIZE: ', model.config.BATCH_SIZE)\n",
    "# exit(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
