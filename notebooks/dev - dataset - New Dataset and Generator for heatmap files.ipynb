{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Build MRCNN Model\n",
    "Pass data through MRCNN and then FCN and investigte output values from FCN\n",
    "- First we generate the heatmaps, and also visually cehck them. \n",
    "- the we pass the heatmaps to the routine that prodcues the scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:27:03.712587Z",
     "start_time": "2018-11-08T13:26:10.458400Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "from datetime import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.utils        import log, stack_tensors, stack_tensors_3d, write_stdout\n",
    "from mrcnn.datagen      import data_generator, load_image_gt\n",
    "from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.prep_notebook import mrcnn_coco_train, prep_coco_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "####  Pass input parameters to argparse\n",
    "\n",
    "# args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 1264 --batch_size 8  --lr 0.5               --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())\n",
    "# input_parms = \"--epochs 100 --steps_in_epoch 100  --last_epoch 1264 --batch_size 25 --lr 0.8 --val_steps 5 --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "# input_parms +=\" --model     /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 \"\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \"--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 \" \n",
    "input_parms +=\"--mrcnn_logs_dir train_mrcnn_coco \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_coco \"\n",
    "input_parms +=\"--mrcnn_model    last \"\n",
    "input_parms +=\"--fcn_model      init \"\n",
    "input_parms +=\"--opt            adagrad \"\n",
    "input_parms +=\"--fcn_arch       fcn8 \" \n",
    "input_parms +=\"--fcn_layers     all \" \n",
    "input_parms +=\"--sysout        screen \"\n",
    "input_parms +=\"--new_log_folder    \"\n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## if debug is true set stdout destination to stringIO\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "# debug = False\n",
    "if args.sysout == 'FILE':\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "# print(\"    Dataset            : \", args.dataset)\n",
    "# print(\"    Logs               : \", args.logs)\n",
    "# print(\"    Limit              : \", args.limit)\n",
    "print(\"    MRCNN Model        : \", args.mrcnn_model)\n",
    "print(\"    FCN Model          : \", args.fcn_model)\n",
    "print(\"    MRCNN Log Dir      : \", args.mrcnn_logs_dir)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_logs_dir)\n",
    "print(\"    FCN Arch           : \", args.fcn_arch)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_layers)\n",
    "print(\"    Last Epoch         : \", args.last_epoch)\n",
    "print(\"    Epochs to run      : \", args.epochs)\n",
    "print(\"    Steps in each epoch: \", args.steps_in_epoch)\n",
    "print(\"    Validation steps   : \", args.val_steps)\n",
    "print(\"    Batch Size         : \", args.batch_size)\n",
    "print(\"    Optimizer          : \", args.opt)\n",
    "print(\"    sysout             : \", args.sysout)\n",
    "# print(\"    OS Platform        : \", syst)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "##   ROOT_DIR         : Root directory of the project \n",
    "##   MODEL_DIR        : Directory to save logs and trained model\n",
    "##   COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "##---------------------------------------------------------------------------------\n",
    "paths = Paths(fcn_training_folder = args.fcn_logs_dir, mrcnn_training_folder = args.mrcnn_logs_dir)\n",
    "paths.display()\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------                          \n",
    "mrcnn_config                    = CocoConfig()\n",
    "mrcnn_config.NAME               = 'mrcnn'              \n",
    "mrcnn_config.TRAINING_PATH      = paths.MRCNN_TRAINING_PATH\n",
    "mrcnn_config.COCO_DATASET_PATH  = paths.COCO_DATASET_PATH \n",
    "mrcnn_config.COCO_MODEL_PATH    = paths.COCO_MODEL_PATH   \n",
    "mrcnn_config.RESNET_MODEL_PATH  = paths.RESNET_MODEL_PATH \n",
    "mrcnn_config.VGG16_MODEL_PATH   = paths.VGG16_MODEL_PATH  \n",
    "mrcnn_config.COCO_CLASSES       = None \n",
    "mrcnn_config.DETECTION_PER_CLASS = 200\n",
    "mrcnn_config.HEATMAP_SCALE_FACTOR = 4\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "\n",
    "# mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "# mrcnn_config.VALIDATION_STEPS   = int(args.val_steps)\n",
    "# mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "# mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "# mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "# mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "# mrcnn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "# mrcnn_config.MIN_LR             = 1.0e-10\n",
    "# mrcnn_config.OPTIMIZER          = args.opt.upper()\n",
    "# mrcnn_model.config.OPTIMIZER    = 'ADAGRAD'\n",
    "mrcnn_config.NEW_LOG_FOLDER       = False\n",
    "mrcnn_config.SYSOUT               = args.sysout\n",
    "mrcnn_config.display() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T15:13:15.157453Z",
     "start_time": "2018-11-02T15:13:14.885678Z"
    }
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build & Load Training and Validation datasets\n",
    "##------------------------------------------------------------------------------------\n",
    "# dataset_train = prep_coco_dataset([\"train\",  \"val35k\"], mrcnn_config, generator = False)\n",
    "# dataset_val   = prep_coco_dataset([\"minival\"]         , mrcnn_config, generator = False)\n",
    "# from mrcnn.prep_notebook import coco_dataset\n",
    "# dataset_train = coco_dataset([\"val35k\"], mrcnn_config)\n",
    "# dataset_val   = coco_dataset([\"minival\"], mrcnn_config)\n",
    "from mrcnn.dataset      import Dataset \n",
    "from pycocotools.coco import COCO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:27:04.118145Z",
     "start_time": "2018-11-08T13:27:03.716576Z"
    }
   },
   "outputs": [],
   "source": [
    "HEATMAP_PATH = os.path.join(paths.DIR_DATASET,'coco2014_heatmaps')\n",
    "print(HEATMAP_PATH)\n",
    "from mrcnn.heatmap import HeatmapDataset\n",
    "dataset = HeatmapDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:27:22.132441Z",
     "start_time": "2018-11-08T13:27:18.179279Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.load_heatmap(mrcnn_config.COCO_DATASET_PATH, HEATMAP_PATH, 'minival')\n",
    "# def load_heatmap(self, dataset_dir, heatmap_dataset_dir, subset, class_ids=None,class_map=None, return_coco=False):\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### simulate `load_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T14:16:25.752604Z",
     "start_time": "2018-11-01T14:16:25.438393Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_dir =mrcnn_config.COCO_DATASET_PATH\n",
    "heatmap_dataset_dir = HEATMAP_PATH\n",
    "subset = 'minival'\n",
    "class_ids=None\n",
    "class_map=None\n",
    "return_coco=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:40:12.871117Z",
     "start_time": "2018-11-01T13:40:11.468123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_dir = os.path.join(dataset_dir, \"train2014\" if subset == \"train\" else \"val2014\")\n",
    "heatmap_dir = os.path.join(heatmap_dataset_dir, \"train2014\" if subset == \"train\" else \"val2014\")\n",
    "#       image_dir = os.path.join(dataset_dir, \"train2017\" if subset == \"train\" lse \"val2017\")\n",
    "print(image_dir,'\\n', heatmap_dir)\n",
    " \n",
    "# Create COCO object\n",
    "json_path_dict = {\n",
    "    \"train\"  :  \"annotations/instances_train2014.json\",\n",
    "    \"val\"    :  \"annotations/instances_val2014.json\",\n",
    "    \"minival\":  \"annotations/instances_minival2014.json\",\n",
    "    \"val35k\" :  \"annotations/instances_valminusminival2014.json\",\n",
    "    \"test\"   :  \"annotations/image_info_test2014.json\"\n",
    "}\n",
    "print('subset: ', subset, 'json_path_dir: ', json_path_dict[subset])\n",
    "coco = COCO(os.path.join(dataset_dir, json_path_dict[subset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:33:00.045125Z",
     "start_time": "2018-11-01T13:32:59.728900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load all classes or a subset?\n",
    "if not class_ids:\n",
    "    # All classes\n",
    "    class_ids = sorted(coco.getCatIds())\n",
    "print(' ClassIds     :', class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:57:57.660840Z",
     "start_time": "2018-11-01T13:57:57.355623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------\n",
    "## Get image ids - using COCO\n",
    "##--------------------------------------------------------------\n",
    "#All images or a subset?\n",
    "if class_ids:\n",
    "    print(' Subset of classes')\n",
    "    image_ids = []\n",
    "    for id in class_ids:\n",
    "        image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
    "    # Remove duplicates\n",
    "    image_ids = list(set(image_ids))\n",
    "else:\n",
    "    # All images\n",
    "    class_ids = sorted(coco.getCatIds())\n",
    "    print(' All classes')    \n",
    "    image_ids = list(coco.imgs.keys())\n",
    "    \n",
    "print(' ClassIds     : ', len(class_ids))\n",
    "print(' Image ids    : ', len(image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:41:54.702907Z",
     "start_time": "2018-11-01T13:41:54.423711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Add classes to dataset.class_info structure\n",
    "for i in class_ids:\n",
    "    dataset.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:58:29.670558Z",
     "start_time": "2018-11-01T13:58:29.390360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(dataset.class_info)\n",
    "# image_ids[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T14:06:05.057996Z",
     "start_time": "2018-11-01T14:06:01.594521Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # print(' ClassIds     :', class_ids)\n",
    "# # Add images to dataset.image_info structure\n",
    "dataset.image_info = []\n",
    "heatmap_notfound=  heatmap_found = 0\n",
    "print(heatmap_notfound, heatmap_found)\n",
    "for i in image_ids:\n",
    "    print('image id: ',i)\n",
    "    heatmap_filename = 'hm_{:012d}.npz'.format(i)\n",
    "    heatmap_path = os.path.join(heatmap_dir, heatmap_filename) \n",
    "    \n",
    "    ## Only load image_info data structure for images where the corrsponding \n",
    "    ## heatmap .npz file exist\n",
    "    if not os.path.isfile(heatmap_path):\n",
    "        print('file not found:::',heatmap_filename)\n",
    "        heatmap_notfound += 1\n",
    "    else:\n",
    "        dataset.add_image(\n",
    "            \"coco\", image_id=i,\n",
    "            path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
    "            width=coco.imgs[i][\"width\"],\n",
    "            height=coco.imgs[i][\"height\"],\n",
    "            heatmap_path=heatmap_path\n",
    "          )\n",
    "        heatmap_found += 1\n",
    "        # annotations=coco.loadAnns(coco.getAnnIds(imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "        \n",
    "        \n",
    "print(' Images ids :', len(image_ids))\n",
    "print('    Corresponding heatmap found     :' , heatmap_found)\n",
    "print('    Corresponding heatmap not found :' , heatmap_notfound)\n",
    "print(' Total      :', heatmap_found + heatmap_notfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T14:07:39.509639Z",
     "start_time": "2018-11-01T14:07:39.230439Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(dataset.image_ids))\n",
    "print(len(dataset.image_info))\n",
    "print(dataset.image_info[0])\n",
    "# print(dataset.image_info[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:48:51.478819Z",
     "start_time": "2018-11-01T13:48:51.192614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------\n",
    "## Get image ids - using walk on HEATMAP_PATH\n",
    "##--------------------------------------------------------------\n",
    "print(' image dir        : ', image_dir) \n",
    "print(' json_path_dir    : ', os.path.join(dataset_dir, json_path_dict[subset]))\n",
    "regex = re.compile(\".*/\\w+(\\d{12})\\.jpg\")\n",
    "\n",
    "\n",
    "image_ids = [] \n",
    "heatmap_files = next(os.walk(heatmap_dir))[2]\n",
    "print('heat ap dir :' , heatmap_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:51:52.168174Z",
     "start_time": "2018-11-01T13:51:50.059678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for hm_file in heatmap_files:\n",
    "    print(' Processing file: ', hm_file)\n",
    "    heatmap_path=os.path.join(heatmap_dir, hm_file) \n",
    "    i = int(os.path.splitext(hm_file.lstrip('hm_'))[0])\n",
    "    loaddata = np.load(heatmap_path)\n",
    "    print(loaddata['coco_info'])\n",
    "    coco_id = loaddata['coco_info'][0]\n",
    "    coco_filename = loaddata['coco_info'][1]\n",
    "    input_image_meta = loaddata['input_image_meta']\n",
    "    loaddata.close()\n",
    "    dataset.add_image(\n",
    "        \"coco\", \n",
    "        image_id=i,\n",
    "        path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
    "        width=coco.imgs[i][\"width\"],\n",
    "        height=coco.imgs[i][\"height\"],\n",
    "        heatmap_path=os.path.join(heatmap_dir, 'hm_{:012d}'.format(i)) \n",
    "      )    \n",
    "#     print(input_filename, type(input_filename), len(input_filename))\n",
    "#     coco_filename = input_filename.replace('\\\\' , \"/\")\n",
    "#     print(coco_filename)\n",
    "#     regex_match  = regex.match(input_filename)            \n",
    "#     # Add images to dataset.image_info structure\n",
    "#     if regex_match:\n",
    "#         coco_id = int(regex_match.group(1))\n",
    "#     print(i, input_image_meta[:8],' ', input_filename, ' coco_id : ',coco_id)\n",
    "\n",
    "#     self.add_image(\n",
    "#         \"coco\", \n",
    "#         image_id=i,\n",
    "#         path = input_filename,\n",
    "#         height=input_image_meta[1],\n",
    "#         width= input_image_meta[2],\n",
    "#         heatmap_path=heatmap_path\n",
    "#       )\n",
    "#     image_ids.append(i)\n",
    "#         # annotations=coco.loadAnns(coco.getAnnIds(imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "# print(' number of images : ', len(image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:27:33.072654Z",
     "start_time": "2018-11-08T13:27:31.637215Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.datagen_fcn import fcn_data_generator, fcn_data_gen_simulate\n",
    "##--------------------------------------------------------------------------------\n",
    "## Data generators\n",
    "##--------------------------------------------------------------------------------\n",
    "generator = fcn_data_generator(dataset, mrcnn_config, shuffle=True,\n",
    "                                 batch_size=mrcnn_config.BATCH_SIZE)\n",
    "# val_generator   = data_generator(dataset_val, mrcnn_model.config, shuffle=True,\n",
    "#                                  batch_size=mrcnn_config.BATCH_SIZE,\n",
    "#                                  augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T13:51:17.542567Z",
     "start_time": "2018-11-08T13:51:16.132590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(generator)\n",
    "\n",
    "for i in train_batch_x:\n",
    "    print(type(i), i.shape, i.dtype)\n",
    "for i in train_batch_y:\n",
    "    print(type(i), i.shape)\n",
    "print(train_batch_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:13:06.040423Z",
     "start_time": "2018-11-08T14:13:01.959581Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "from mrcnn.visualize import plot_2d_heatmap_compare\n",
    "import mrcnn.utils as utils\n",
    "# def plot_2d_heatmap_compare( Z1, Z2, boxes, image_idx, class_ids,  size = None, \n",
    "#                                  num_bboxes = 0, class_names=None, scale = 1,\n",
    "#                                  title = '2D Comparison between 2d heatmaps w/ bboxes'):\n",
    "train_batch_x, train_batch_y = fcn_data_gen_simulate(dataset, mrcnn_config, [210])\n",
    "img_meta    = train_batch_x[1]\n",
    "class_names = dataset.class_names\n",
    "print(img_meta.shape)\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    print(img_meta[img_idx])\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset.load_image(image_id)\n",
    "    timg  = train_batch_x[0][img_idx]\n",
    "    print(' image from train_batch_x :', timg.shape, timg.dtype, np.min(timg), np.max(timg))\n",
    "    print(' image from dataset load  :', image.shape, image.dtype, np.min(image), np.max(image))\n",
    "    ## Display image, and mean-subtracted image\n",
    "    visualize.display_image_bw(image)\n",
    "#     visualize.display_images([image, train_batch_x[0][img_idx]], cols = 2, width = 18)\n",
    "    \n",
    "    ## display masks and bounding boxes\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    print('class_ids:', class_ids)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset.class_names, figsize =(8,8)) \n",
    "    \n",
    "\n",
    "    ## display ground truth heatmaps\n",
    "    gt_class_ids = np.unique(train_batch_x[5][img_idx,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  GT ClassIds: {}'.format(img_idx, gt_class_ids))\n",
    "#     visualize.plot_2d_heatmap_no_bboxes(train_batch_x[4],img_idx, columns = 4, class_names=class_names)    \n",
    "    visualize.plot_2d_heatmap_no_bboxes(train_batch_x[4], img_idx,class_ids = gt_class_ids, columns = 4, class_names=class_names)\n",
    "    \n",
    "    \n",
    "    ## display predicted heatmaps\n",
    "    pr_class_ids = np.unique(train_batch_x[3][img_idx,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  PR ClassIds: {}'.format(img_idx, pr_class_ids))\n",
    "#     visualize.plot_2d_heatmap_no_bboxes(train_batch_x[2],img_idx, columns = 4, class_names=class_names)\n",
    "    visualize.plot_2d_heatmap_no_bboxes(train_batch_x[2], img_idx,class_ids = gt_class_ids, columns = 4, class_names=class_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:14:19.481981Z",
     "start_time": "2018-11-08T14:14:18.296162Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import unresize_image\n",
    "from   matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage.util\n",
    "import skimage.io\n",
    "paths.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:15:00.976729Z",
     "start_time": "2018-11-08T14:15:00.877733Z"
    }
   },
   "outputs": [],
   "source": [
    "# ds = os.path.join(paths.COCO_DATASET_PATH,'val2014/COCO_val2014_000000017031.jpg')\n",
    "ds = dataset.image_info[210]['path']\n",
    "print(ds)\n",
    "im = skimage.io.imread(ds)\n",
    "print(im.shape, im.dtype, np.min(im), np.max(im))\n",
    "# im = skimage.io.imread(ds)\n",
    "# im = Image.open(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:18:46.351132Z",
     "start_time": "2018-11-08T14:18:44.820753Z"
    }
   },
   "outputs": [],
   "source": [
    "print('image    : ', image.shape, image.dtype)\n",
    "image_bw = Image.fromarray(image).convert(mode='L')\n",
    "# print('image_bw : ', image_bw.shape, image_bw.dtype)\n",
    "\n",
    "molded_image, window, scale, padding = utils.resize_image(\n",
    "    image,\n",
    "    min_dim=mrcnn_config.IMAGE_MIN_DIM,\n",
    "    max_dim=mrcnn_config.IMAGE_MAX_DIM,\n",
    "    padding=mrcnn_config.IMAGE_PADDING)\n",
    "print('molded_image   : ', molded_image.shape, molded_image.dtype)\n",
    "print(' image meta    :', train_batch_x[1][0])\n",
    "\n",
    "unresized_image = unresize_image(molded_image,train_batch_x[1][0])\n",
    "print('unresized_image : ', unresized_image.shape, unmolded_image.dtype)\n",
    "\n",
    "unresized_image_bw = np.asarray(Image.fromarray(unresized_image).convert(mode='L'))\n",
    "print('unresized_image_bw: ',unresized_image_bw.shape, unresized_image_bw.dtype)\n",
    "\n",
    "\n",
    "unmolded_image = utils.unmold_image(molded_image, mrcnn_config)\n",
    "print('unmolded_image : ', unmolded_image.shape, unmolded_image.dtype)\n",
    "\n",
    "unmolded_image_bw = np.asarray(Image.fromarray(unmolded_image).convert(mode='L'))\n",
    "print('unmolded_image_bw : ', unmolded_image_bw.shape, unmolded_image_bw.dtype)\n",
    "\n",
    "\n",
    "unmolded_heatmap = unresize_image(train_batch_x[2][0,:,:,24],train_batch_x[1][0], upscale = mrcnn_config.HEATMAP_SCALE_FACTOR)\n",
    "print('unmolded_heatmap : ', unmolded_heatmap.shape, unmolded_heatmap.dtype)\n",
    "\n",
    "\n",
    "print(train_batch_x[2][0,:,:,24].dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:21:43.891377Z",
     "start_time": "2018-11-08T14:21:39.922338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print('Orig image shape: ', image.shape)\n",
    "print('Image window is : ', window)\n",
    "print('Scale is        : ', scale)\n",
    "print(train_batch_x[1][0,:8])\n",
    "print('Padding is :', padding)\n",
    "fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "im1 = plt.imshow(molded_image)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "im1 = plt.imshow(unresized_image)\n",
    "fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "im1 = plt.imshow(unresized_image_bw, cmap=plt.cm.gray)\n",
    "\n",
    "fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "im1 = plt.imshow(unmolded_image)\n",
    "fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "im1 = plt.imshow(unmolded_image_bw, cmap=plt.cm.gray)\n",
    "# fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "# im1 = plt.imshow(unmolded_image_bw)\n",
    "\n",
    "# fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "# im1 = plt.imshow(unmolded_heatmap,cmap = cm.YlOrRd)\n",
    "\n",
    "\n",
    "# fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "# im1 = plt.imshow(unmolded_image , cmap=plt.cm.gray)\n",
    "# im1 = plt.imshow(unmolded_heatmap, alpha = 0.6,cmap=cm.YlOrRd)  \n",
    "\n",
    "\n",
    "# fig = plt.figure(frameon=False, figsize=(10,10))\n",
    "# im1 = plt.imshow(image_bw , cmap=plt.cm.gray)\n",
    "# im1 = plt.imshow(unmolded_heatmap, alpha = 0.6,cmap=cm.YlOrRd)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:01:20.518351Z",
     "start_time": "2018-11-08T14:01:13.969457Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import display_heatmaps, display_heatmaps_fcn, display_heatmaps_mrcnn\n",
    "# visualize.display_image_bw(image)\n",
    "display_heatmaps(train_batch_x, 0, hm = 'pr', config = mrcnn_config, class_ids = [0,1,2,3,4,5,24], class_names = dataset.class_names)\n",
    "# display_heatmaps(train_batch_x, 0, hm = 'gt', config = mrcnn_config, class_ids = [0,1,2,3,4,5,24], class_names = dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:16:39.765092Z",
     "start_time": "2018-11-02T14:16:39.025699Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build FCN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T18:59:25.131336Z",
     "start_time": "2018-10-29T18:59:25.012530Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import Paths\n",
    "paths = Paths(fcn_training_folder='train_fcn8_coco')\n",
    "paths.display()\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration for FCN model\n",
    "##------------------------------------------------------------------------------------\n",
    "fcn_config = CocoConfig()\n",
    "# fcn_config.IMAGE_MAX_DIM        = 600\n",
    "# fcn_config.IMAGE_MIN_DIM        = 480      \n",
    "# mrcnn_config.COCO_DATASET_PATH  = COCO_DATASET_PATH \n",
    "# mrcnn_config.COCO_MODEL_PATH    = COCO_MODEL_PATH   \n",
    "# mrcnn_config.RESNET_MODEL_PATH  = RESNET_MODEL_PATH \n",
    "fcn_config.NAME                 = 'fcn'              \n",
    "fcn_config.TRAINING_PATH        = paths.FCN_TRAINING_PATH\n",
    "fcn_config.VGG16_MODEL_PATH     = paths.FCN_VGG16_MODEL_PATH\n",
    "fcn_config.FCN_INPUT_SHAPE      = mrcnn_config.IMAGE_SHAPE[0:2] // mrcnn_config.HEATMAP_SCALE_FACTOR \n",
    "\n",
    "fcn_config.BATCH_SIZE           = mrcnn_config.BATCH_SIZE                # Batch size is 2 (# GPUs * images/GPU).\n",
    "fcn_config.IMAGES_PER_GPU       = mrcnn_config.BATCH_SIZE                  # Must match BATCH_SIZE\n",
    "fcn_config.EPOCHS_TO_RUN        = 1\n",
    "fcn_config.STEPS_PER_EPOCH      = 4\n",
    "fcn_config.LAST_EPOCH_RAN       = 0\n",
    "\n",
    "fcn_config.LEARNING_RATE        = 0.0001 \n",
    "\n",
    "fcn_config.BATCH_MOMENTUM       = 0.9\n",
    "fcn_config.WEIGHT_DECAY         = 2.0e-4\n",
    "fcn_config.REDUCE_LR_FACTOR     = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN   = 5\n",
    "fcn_config.REDUCE_LR_PATIENCE   = 5\n",
    "fcn_config.EARLY_STOP_PATIENCE  = 15\n",
    "fcn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "fcn_config.MIN_LR               = 1.0e-10\n",
    " \n",
    "fcn_config.VALIDATION_STEPS     = 5\n",
    "fcn_config.REDUCE_LR_FACTOR     = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN   = 50\n",
    "fcn_config.REDUCE_LR_PATIENCE   = 33\n",
    "fcn_config.EARLY_STOP_PATIENCE  = 50\n",
    "fcn_config.EARLY_STOP_MIN_DELTA = 1.0e-6\n",
    "fcn_config.MIN_LR               = 1.0e-10\n",
    "fcn_config.NEW_LOG_FOLDER       = True  \n",
    "fcn_config.OPTIMIZER            = 'ADAGRAD'\n",
    "fcn_config.SYSOUT               = 'screen'\n",
    "\n",
    "fcn_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T18:59:29.474844Z",
     "start_time": "2018-10-29T18:59:28.758946Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build FCN Model in Training Mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del fcn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass    \n",
    "fcn_model = fcn_modellib.FCN(mode=\"training\", arch = 'FCN8', config=fcn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Display FCN model info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Files and Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T18:28:17.679171Z",
     "start_time": "2018-10-29T18:27:50.347756Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train, train_generator  = prep_coco_dataset(['train','val35k'], mrcnn_config, generator = True)\n",
    "# dataset_val, val_generator      = prep_coco_dataset(['minival'], mrcnn_config, generator = True) \n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T18:28:42.406439Z",
     "start_time": "2018-10-29T18:28:42.014895Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T18:42:32.214127Z",
     "start_time": "2018-10-29T18:42:31.319119Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "#     print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a specific image using image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T14:46:12.160211Z",
     "start_time": "2018-10-28T14:46:11.037546Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "## 33477 Table, bowl, cup, sandwich, knife\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "# IMAGE_LIST = [75040] \n",
    "IMAGE_LIST = [89243]\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_config, IMAGE_LIST)\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "    \n",
    "    print(' Image meta  : ', img_meta[img_idx,:10])\n",
    "    print(' Classes     : ', class_ids)\n",
    "    print(\" Image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "    print(' Class_ids.shape[0]:', class_ids.shape[0], 'bbox.shape[0]:',bbox.shape[0])       \n",
    "    print(' Class Names : ', class_names)\n",
    "    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)   \n",
    "    # Display image and instances\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
