{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:52:43.494511Z",
     "start_time": "2018-05-16T13:52:43.056219Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def apply_box_deltas_graph(boxes, deltas):\n",
    "    \"\"\"\n",
    "    Applies the given deltas to the given boxes.\n",
    "\n",
    "    x,y,w,h : Bounding Box coordinates, width, and height\n",
    "\n",
    "    Boxes:  is the (y1, x1, y2, x2) of the anchor boxes\n",
    "    deltas: [dy, dx, log(dh), log(dw)] \n",
    "            is the predicted bounding box returned from the RPN layer (in test phase)\n",
    "            These are considered the targets or ground truth \n",
    "    Refer to Bounding Box Regression - R-CNN paper \n",
    "    Regression targets are calculated as follows:   \n",
    "      tx = (GTx - PRx)/PRw       ty = (Gy - Py)/Ph\n",
    "      th = log(Gw/Pw)         tw = log(Gh/Ph)\n",
    "    ---------------------------------------------------------------------------------            \n",
    "    \n",
    "    boxes:  [N, 4] where each row is [y1, x1, y2, x2]\n",
    "    deltas: [N, 4] where each row is [dy, dx, log(dh), log(dw)]\n",
    "    \"\"\"\n",
    "    # Convert to y, x, h, w\n",
    "    height   = boxes[:, 2] - boxes[:, 0]\n",
    "    width    = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + 0.5 * height\n",
    "    center_x = boxes[:, 1] + 0.5 * width\n",
    "    \n",
    "    # Apply deltas\n",
    "    center_y += deltas[:, 0] * height\n",
    "    center_x += deltas[:, 1] * width\n",
    "    height   *= tf.exp(deltas[:, 2])\n",
    "    width    *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    # Convert back to y1, x1, y2, x2\n",
    "    y1 = center_y - 0.5 * height\n",
    "    x1 = center_x - 0.5 * width\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "    result = tf.stack([y1, x1, y2, x2], axis=1, name=\"apply_box_deltas_out\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def clip_boxes_graph(boxes, window):\n",
    "    \"\"\"\n",
    "    clip refined anchor boxes such that they remain within the dimensions of the image \n",
    "    boxes:  [N, 4] each row is y1, x1, y2, x2\n",
    "    window: [4] in the form y1, x1, y2, x2 \n",
    "    \"\"\"\n",
    "    # Split corners\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)   #  0, 0 , 128,128\n",
    "    y1 , x1 , y2 , x2  = tf.split(boxes, 4, axis=1)\n",
    "    \n",
    "    # Clip\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)   # ensure  wy1 <= y1 <= wy2\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    clipped = tf.concat([y1, x1, y2, x2], axis=1, name=\"clipped_boxes\")\n",
    "    return clipped\n",
    "\n",
    "def suppress_small_boxes_graph(boxes, scores, area_threshold ):\n",
    "    \"\"\"\n",
    "    supress boxes with area less than area_threshold\n",
    "    boxes:  [N, 4] each row is y1, x1, y2, x2\n",
    "    \n",
    "    \"\"\"\n",
    "    bx_area = (boxes[...,2]-boxes[...,0])*(boxes[...,3]-boxes[...,1])\n",
    "    selected_idxs   = tf.where(tf.greater_equal(bx_area, area_threshold))\n",
    "    selected_boxes  = tf.gather_nd(boxes, selected_idxs)\n",
    "    selected_scores = tf.gather_nd(scores, selected_idxs)\n",
    "    padding   = tf.maximum(tf.shape(boxes)[0] - tf.shape(selected_boxes)[0], 0)\n",
    "\n",
    "#     print(' box area       : ', bx_area.shape)    \n",
    "#     print(' selected_idxs  : ', tf.shape(selected_idxs).eval())\n",
    "#     print(' selected scores: ', tf.shape(selected_scores).eval())\n",
    "#     print(' Req padding    : ', padding.eval())\n",
    "    \n",
    "    selected_boxes  = tf.pad(selected_boxes, [(0, padding), (0, 0)])    \n",
    "    selected_scores = tf.pad(selected_scores, [(0, padding)])    \n",
    "    return selected_boxes, selected_scores\n",
    "\n",
    "def nms(normalized_boxes, scores):\n",
    "    proposal_count = model.config.POST_NMS_ROIS_TRAINING\n",
    "    rms_threshold  = model.config.RPN_NMS_THRESHOLD\n",
    "    indices = tf.image.non_max_suppression(normalized_boxes, \n",
    "                                           scores, \n",
    "                                           proposal_count,\n",
    "                                           nms_threshold, \n",
    "                                           name=\"rpn_non_max_suppression\")\n",
    "\n",
    "    proposals = tf.gather(normalized_boxes, indices)\n",
    "    # Pad if needed\n",
    "    padding   = tf.maximum(proposal_count - tf.shape(proposals)[0], 0)\n",
    "    proposals = tf.pad(proposals, [(0, padding), (0, 0)])\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:52:51.950082Z",
     "start_time": "2018-05-16T13:52:47.181975Z"
    },
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    scores = rpn_class[:, :, 1]\n",
    "    print(scores.shape)\n",
    "    deltas = rpn_bbox\n",
    "    print('deltas shape', deltas.shape)\n",
    "    deltas = deltas * np.reshape(model.config.RPN_BBOX_STD_DEV, [1, 1, 4])\n",
    "    print('deltas shape', deltas.shape)\n",
    "    anchors = model.anchors\n",
    "    print('model.anchors.shape', model.anchors.shape)\n",
    "    pre_nms_limit = min(6000, model.anchors.shape[0])\n",
    "    print('pre nms limit', pre_nms_limit)\n",
    "\n",
    "    ix = tf.nn.top_k(scores, pre_nms_limit, sorted=True,name=\"top_anchors\").indices\n",
    "\n",
    "    ## gather top scores (pre_nms_limit = min(6000, # anchors) number of scores from scores)        \n",
    "    scores  = utils.batch_slice([scores, ix], lambda x, y: tf.gather(x, y), model.config.IMAGES_PER_GPU) \n",
    "    print(' selected scores: ',scores.shape)\n",
    "\n",
    "    ## get corrsponding deltas generated by RPN\n",
    "    deltas  = utils.batch_slice([deltas, ix], lambda x, y: tf.gather(x, y), model.config.IMAGES_PER_GPU)\n",
    "    print(' selected deltas: ',deltas.shape)\n",
    "    anchors = utils.batch_slice(         ix , lambda x   : tf.gather(anchors, x), model.config.IMAGES_PER_GPU, names=[\"pre_nms_anchors\"])\n",
    "    print(' selected anchors: ',anchors.shape)\n",
    "    boxes = utils.batch_slice([anchors, deltas],\n",
    "                              lambda x, y: apply_box_deltas_graph(x, y),model.config.IMAGES_PER_GPU,\n",
    "                              names=[\"refined_anchors\"])\n",
    "    print(' delta applied boxes :', boxes.shape)\n",
    "\n",
    "    # Clip to image boundaries. [batch, N, (y1, x1, y2, x2)]\n",
    "    height, width = model.config.IMAGE_SHAPE[:2]\n",
    "    window = np.array([0, 0, height, width]).astype(np.float64)\n",
    "    print(' window is ', window)\n",
    "    clipped_boxes  = utils.batch_slice(boxes, \n",
    "                                   lambda x: clip_boxes_graph(x, window), model.config.IMAGES_PER_GPU,\n",
    "                                   names=[\"refined_anchors_clipped\"])\n",
    "\n",
    "    print(' clipped boxes :', clipped_boxes.shape)\n",
    "    \n",
    "    ## Suppress proposal boxes (and  corresponding score) if the area is less than ROI_AREA_THRESHOLD\n",
    "    roi_area_threshold = 2\n",
    "    mod_boxes, mod_scores = utils.batch_slice([clipped_boxes,scores], \n",
    "                            lambda x, y: suppress_small_boxes_graph(x, y, roi_area_threshold), model.config.IMAGES_PER_GPU,\n",
    "                            names=[\"mod_boxes\", \"mod_scores\"])  \n",
    "    print(' mod boxes :', tf.shape(mod_boxes).eval())\n",
    "    print(' mod_scores:', tf.shape(mod_scores).eval())   \n",
    "    \n",
    "    normalized_boxes = tf.cast(mod_boxes / np.array([[height, width, height, width]]), tf.float32)\n",
    "    print(' normalized boxes:', normalized_boxes.shape)\n",
    "\n",
    "    proposals = utils.batch_slice([normalized_boxes, mod_scores], nms, model.config.IMAGES_PER_GPU)\n",
    "    print('     Output: Prposals shape : ', proposals.shape, tf.shape(proposals).eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "####  Analyze proposals results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:16:27.148573Z",
     "start_time": "2018-05-16T14:16:25.527179Z"
    },
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    proposals = tf.identity(rpn_proposal_rois)  # <--- this uses the results from the model \n",
    "\n",
    "    bx_area = (proposals[...,2]-proposals[...,0])*(proposals[...,3]-proposals[...,1])\n",
    "    print(' proposals :', tf.shape(proposals).eval())\n",
    "    print(' box area : ', tf.shape(bx_area).eval())\n",
    "    \n",
    "    selected_idxs = tf.where(tf.less_equal(bx_area, (2/(128*128))) )\n",
    "    print('selected bx:', tf.shape(selected_idxs).eval())\n",
    "    \n",
    "    print(selected_idxs.eval())\n",
    "    selected_area      = tf.gather_nd(bx_area  , selected_idxs)\n",
    "    selected_proposals = tf.gather_nd(proposals, selected_idxs)\n",
    "    print('selected proposals shape', tf.shape(selected_proposals).eval())\n",
    "    print(selected_proposals[0:30].eval())\n",
    "    print('selected area shape', tf.shape(selected_area).eval())\n",
    "    print(selected_area[0:30].eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyze bounding box areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T10:44:24.008139Z",
     "start_time": "2018-05-16T10:44:09.624904Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(' boxes :', boxes.shape)\n",
    "    for i in [0,10,17,25,26,34,39]:\n",
    "        print(i, ' non-clipped ', boxes[0, i].eval())\n",
    "    bx_area = (boxes[...,2]-boxes[...,0])*(boxes[...,3]-boxes[...,1])\n",
    "    print(' box area : ', bx_area.shape)\n",
    "    np.set_printoptions(linewidth=130,precision=4,threshold=4096)\n",
    "    print(bx_area[:, :20].eval(session=sess))\n",
    "    small_idxs = tf.where(bx_area < 1)\n",
    "    print('small bx:', tf.shape(small_idxs).eval())\n",
    "    print(small_idxs[0:10].eval())\n",
    "    small_area  = tf.gather_nd(bx_area, small_idxs)\n",
    "    small_boxes = tf.gather_nd(boxes, small_idxs)\n",
    "    print('small boxes shape', tf.shape(small_boxes).eval())\n",
    "    print(small_boxes[0:30].eval())\n",
    "    print('small area shape', tf.shape(small_area).eval())\n",
    "    print(small_area[0:30].eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "####  Setup tensors to be passed to `detections_target_graph()`    - Detection Target Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T21:12:07.570951Z",
     "start_time": "2018-05-16T21:12:03.473575Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mrcnn.utils  as utils\n",
    "from mrcnn.detect_tgt_layer import overlaps_graph\n",
    "# sess = KB.get_session()\n",
    "# with  sess.as_default():\n",
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "image_id = 1\n",
    "\n",
    "proposals    = KB.identity(rpn_proposal_rois)[image_id]\n",
    "gt_class_ids = KB.identity(input_gt_class_ids)[image_id]\n",
    "gt_boxes     = KB.cast(KB.identity(input_gt_bboxes_norm), dtype='float32')[image_id]\n",
    "# gt_masks     = KB.identity(input_gt_masks)\n",
    "print('rpn_roi_proposals')\n",
    "print(proposals.dtype, gt_class_ids.dtype, gt_boxes.dtype)\n",
    "print(proposals.shape)\n",
    "print(proposals.eval())\n",
    "print('gt_class_ids')\n",
    "print(gt_class_ids.shape)\n",
    "print(gt_class_ids.eval())\n",
    "print('gt_boxes')\n",
    "print(gt_boxes.shape)\n",
    "print(gt_boxes.eval())\n",
    "# proposals    = rpn_proposal_rois[1]\n",
    "# gt_class_ids = input_gt_class_ids[1]\n",
    "# gt_boxes     = input_normlzd_gt_boxes[1]\n",
    "# gt_masks     = input_gt_masks[1]\n",
    "# config       = model.config"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
