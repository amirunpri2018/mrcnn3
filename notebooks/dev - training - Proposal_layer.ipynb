{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Development of a score based on the gaussian heatmaps \n",
    "This can be used to generate the 'ground truth' score of the heatmaps produced from the Contextual layer , which will be compared with the score produced from the FCN heatmaps layer. \n",
    "\n",
    "- First we generate the heatmaps, and also visually cehck them. \n",
    "- the we pass the heatmaps to the routine that prodcues the scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:11:22.120260Z",
     "start_time": "2018-05-16T14:11:13.583867Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180516T1611\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> Generate pyramid anchors \n",
      "      Anchor  scales:   (8, 16, 32, 64, 128)\n",
      "      Anchor  ratios:   [0.5, 1, 2]\n",
      "      Anchor  stride:   1\n",
      "      Feature shapes:   [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "      Feature strides:  [4, 8, 16, 32, 64]\n",
      ">>> generate_anchors()\n",
      "    scales:  8 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [11.3137  8.      5.6569]  widths   [ 5.6569  8.     11.3137]\n",
      ">>> generate_anchors()\n",
      "    scales:  16 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [22.6274 16.     11.3137]  widths   [11.3137 16.     22.6274]\n",
      ">>> generate_anchors()\n",
      "    scales:  32 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [45.2548 32.     22.6274]  widths   [22.6274 32.     45.2548]\n",
      ">>> generate_anchors()\n",
      "    scales:  64 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [90.5097 64.     45.2548]  widths   [45.2548 64.     90.5097]\n",
      ">>> generate_anchors()\n",
      "    scales:  128 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [181.0193 128.      90.5097]  widths   [ 90.5097 128.     181.0193]\n",
      "    Size of anchor array is : (4092, 4)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (3, 4092)\n",
      "     Deltas :  (3, 4092, 4)\n",
      "     Anchors:  (3, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (3, ?, ?) (3, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (3, ?, ?) (3, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (3, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (3, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  6\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (3, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (3, ?) (None, 32)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(3,), dtype=int32) (3, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (3, 32)\n",
      "    roi_grid         :  (3, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)\n",
      "    gt_bboxes.shape    :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    gt_scores_exp shape  (?, ?, 1)\n",
      "    gt_array shape : (3, 100, 7) (3, 100, 7)\n",
      "     gt_tensor final shape  :  (3, 4, 100, 6)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (3, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (3, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (3, 4, 128, 128) Keras tensor  False\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_heatmap:0 pred_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss-sum.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_4:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "    gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "    scatter_flattened is  (384, 6)\n",
      "    boxes shape           (384, 4)\n",
      "    gaussian scatter shape :  (3, 4, 32, 128, 128)\n",
      "    gaussian scatter reshaped :  (384, 128, 128)\n",
      "    Scatter Flattened shape :  (384, 6)\n",
      "    Scores shape :             (384, 2)\n",
      "    gaussian_boxes_scores initial shape:  (384, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gaussian_bbox_scores final shape   :  (?, ?, ?, ?)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 100, 6)\n",
      "    num of bboxes per class is :  100\n",
      "    pt2_sum shape  (3, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (3, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (3, 4, 128, 128) Keras tensor  False\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_heatmap:0 gt_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss-sum.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_9:0\", shape=(4,), dtype=int32)\n",
      "    gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "    scatter_flattened is  (1200, 6)\n",
      "    boxes shape           (1200, 4)\n",
      "    gaussian scatter shape :  (3, 4, 100, 128, 128)\n",
      "    gaussian scatter reshaped :  (1200, 128, 128)\n",
      "    Scatter Flattened shape :  (1200, 6)\n",
      "    Scores shape :             (1200, 2)\n",
      "    gaussian_boxes_scores initial shape:  (1200, 8)\n",
      "    gaussian_bbox_scores final shape   :  (?, ?, ?, ?)\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (3, 4) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (3, 4) Keras tensor  True\n",
      "\n",
      "    Output build_heatmap \n",
      "     pred_heatmap_norm  :  (3, 128, 128, 4) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (3, 128, 128, 4) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (3, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (3, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (3, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      " output_rois       : True\n",
      " pred_heatmap      : True\n",
      " gt_heatmap        : True\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      " Model Parent Path     :  E:\\Models\n",
      " Resent Model Path     :  E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_logs\n",
      "('E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928', 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2500.h5')\n",
      "-----------------------------------------------\n",
      "Load model with init parm:  init\n",
      "-----------------------------------------------\n",
      "Load weights complete\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     3\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    2\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_dev_notebook\n",
    "\n",
    "model, dataset_train, train_generator, config = prep_dev_notebook(init_with = 'last', FCN_layers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:15:43.617276Z",
     "start_time": "2018-05-16T14:15:42.157379Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  40\n",
      "Image meta [ 40 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d5c60cd0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  122\n",
      "Image meta [122 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 2 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d568eef438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  54\n",
      "Image meta [ 54 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d5c60e7358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:15:48.970893Z",
     "start_time": "2018-05-16T14:15:48.733694Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Inputs: \n",
      "0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
      "1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
      "2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
      "3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
      "4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
      "5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
      "6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
      "\n",
      " Outputs: \n",
      "0      Tensor(\"rpn_class_logits/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "1      Tensor(\"rpn_class/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "2      Tensor(\"rpn_bbox/concat:0\", shape=(?, ?, 4), dtype=float32)\n",
      "3      Tensor(\"rpn_proposal_rois/packed_2:0\", shape=(3, ?, ?), dtype=float32)\n",
      "4      Tensor(\"proposal_targets/output_rois:0\", shape=(3, ?, ?), dtype=float32)\n",
      "5      Tensor(\"proposal_targets/target_class_ids:0\", shape=(3, ?), dtype=int32)\n",
      "6      Tensor(\"proposal_targets/target_bbox_deltas:0\", shape=(3, ?, ?), dtype=float32)\n",
      "7      Tensor(\"proposal_targets/roi_gt_boxes:0\", shape=(3, ?, ?), dtype=float32)\n",
      "8      Tensor(\"mrcnn_class_logits/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "9      Tensor(\"mrcnn_class/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "10      Tensor(\"mrcnn_bbox/Reshape:0\", shape=(?, 32, 4, 4), dtype=float32)\n",
      "11      Tensor(\"rpn_class_loss/rpn_class_loss:0\", shape=(1, 1), dtype=float32)\n",
      "12      Tensor(\"rpn_bbox_loss/rpn_bbox_loss:0\", shape=(1, 1), dtype=float32)\n",
      "13      Tensor(\"mrcnn_class_loss/mrcnn_class_loss:0\", shape=(1, 1), dtype=float32)\n",
      "14      Tensor(\"mrcnn_bbox_loss/mrcnn_bbox_loss:0\", shape=(1, 1), dtype=float32)\n",
      "15      Tensor(\"cntxt_layer/pred_heatmap_norm:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "16      Tensor(\"cntxt_layer/gt_heatmap_norm:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "17      Tensor(\"cntxt_layer/pred_heatmap_scores:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "18      Tensor(\"cntxt_layer/gt_heatmap_scores:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "19      Tensor(\"cntxt_layer/pred_tensor:0\", shape=(3, 4, 32, 6), dtype=float32)\n",
      "20      Tensor(\"cntxt_layer/gt_tensor:0\", shape=(3, 4, 100, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:15:54.268038Z",
     "start_time": "2018-05-16T14:15:52.270402Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input  0:  (input_image:0                           ) \t  Input shape: (3, 128, 128, 3)\n",
      "Input  1:  (input_image_meta:0                      ) \t  Input shape: (3, 12)\n",
      "Input  2:  (input_rpn_match:0                       ) \t  Input shape: (3, 4092, 1)\n",
      "Input  3:  (input_rpn_bbox:0                        ) \t  Input shape: (3, 256, 4)\n",
      "Input  4:  (input_gt_class_ids:0                    ) \t  Input shape: (3, 100)\n",
      "Input  5:  (input_gt_boxes:0                        ) \t  Input shape: (3, 100, 4)\n",
      "Input  6:  (input_gt_masks:0                        ) \t  Input shape: (3, 56, 56, 100)\n",
      "\n",
      "/* Outputs */\n",
      "Output  1: (rpn_class/concat:0                      ) \t  Output shape: (3, 4092, 2)\n",
      "Output  2: (rpn_bbox/concat:0                       ) \t  Output shape: (3, 4092, 4)\n",
      "Output  3: (rpn_proposal_rois/packed_2:0            ) \t  Output shape: (3, 2000, 4)\n",
      "Output  4: (proposal_targets/output_rois:0          ) \t  Output shape: (3, 32, 4)\n",
      "Output 15: (cntxt_layer/pred_heatmap_norm:0         ) \t  Output shape: (3, 128, 128, 4)\n",
      "Output 17: (cntxt_layer/pred_heatmap_scores:0       ) \t  Output shape: (3, 4, 32, 8)\n",
      "Output 19: (cntxt_layer/pred_tensor:0               ) \t  Output shape: (3, 4, 32, 6)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "model_output = get_layer_output_1(model.keras_model, train_batch_x, [1,2,3,4, 15,17,19], 1)\n",
    "print(len(model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:12:54.769439Z",
     "start_time": "2018-05-16T14:12:54.530260Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_rpn_match     (3, 4092, 1)\n",
      " input_rpn_bbox      (3, 256, 4)\n",
      " input_gt_class_ids  (3, 100)\n",
      " input_gt_bboxes     (3, 100, 4)\n",
      " input_normlzd_gt_bboxes     (3, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "input_gt_masks     = train_batch_x[6]\n",
    "h, w = input_image.shape[0], input_image.shape[1]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:15:59.972831Z",
     "start_time": "2018-05-16T14:15:59.717672Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(3, 4092, 2)\n",
      "(3, 4092, 4)\n",
      "(3, 2000, 4)\n",
      "(3, 32, 4)\n",
      "(3, 128, 128, 4)\n",
      "(3, 4, 32, 8)\n",
      "(3, 4, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "rpn_class          = model_output[0]\n",
    "rpn_bbox           = model_output[1]\n",
    "rpn_proposal_rois  = model_output[2]\n",
    "output_rois        = model_output[3]\n",
    "# target_class_ids   = model_output[5]\n",
    "# target_bbox_deltas = model_output[6]\n",
    "# roi_gt_boxes       = model_output[7]\n",
    "# mrcnn_class_logits = model_output[8]\n",
    "# mrcnn_class        = model_output[0]\n",
    "# mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "# fcn_bbox_loss      = model_output[15]\n",
    "# pred_hm            = model_output[1]\n",
    "# gt_hm              = model_output[17]\n",
    "# pred_hm_norm       = model_output[1]\n",
    "# gt_hm_norm         = model_output[2]\n",
    "# pred_hm_scores     = model_output[3]\n",
    "# gt_hm_scores       = model_output[4]\n",
    "# pred_tensor        = model_output[5]\n",
    "# fcn_heatmap        = model_output[23]\n",
    "# fcn_class_logits   = model_output[24]\n",
    "# fcn_scores         = model_output[25]\n",
    "# fcn_bbox_deltas    = model_output[26]\n",
    "# pred_hm2            = model_output[2]\n",
    "# pred_hm2_norm       = model_output[3]\n",
    "# rpn_proposal_rois  = model_output[0]\n",
    "# output_rois        = model_output[1]\n",
    "pred_hm_norm       = model_output[4]\n",
    "# gt_hm_norm         = model_output[3]\n",
    "pred_hm_scores     = model_output[5]\n",
    "# gt_hm_scores       = model_output[5]\n",
    "pred_tensor        = model_output[6]\n",
    "\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T10:29:41.105871Z",
     "start_time": "2018-05-16T10:29:40.880272Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:16:18.148825Z",
     "start_time": "2018-05-16T14:16:17.917166Z"
    }
   },
   "outputs": [],
   "source": [
    "import mrcnn.utils as utils\n",
    "sess = KB.get_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:52:43.494511Z",
     "start_time": "2018-05-16T13:52:43.056219Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_box_deltas_graph(boxes, deltas):\n",
    "    \"\"\"\n",
    "    Applies the given deltas to the given boxes.\n",
    "\n",
    "    x,y,w,h : Bounding Box coordinates, width, and height\n",
    "\n",
    "    Boxes:  is the (y1, x1, y2, x2) of the anchor boxes\n",
    "    deltas: [dy, dx, log(dh), log(dw)] \n",
    "            is the predicted bounding box returned from the RPN layer (in test phase)\n",
    "            These are considered the targets or ground truth \n",
    "    Refer to Bounding Box Regression - R-CNN paper \n",
    "    Regression targets are calculated as follows:   \n",
    "      tx = (GTx - PRx)/PRw       ty = (Gy - Py)/Ph\n",
    "      th = log(Gw/Pw)         tw = log(Gh/Ph)\n",
    "    ---------------------------------------------------------------------------------            \n",
    "    \n",
    "    boxes:  [N, 4] where each row is [y1, x1, y2, x2]\n",
    "    deltas: [N, 4] where each row is [dy, dx, log(dh), log(dw)]\n",
    "    \"\"\"\n",
    "    # Convert to y, x, h, w\n",
    "    height   = boxes[:, 2] - boxes[:, 0]\n",
    "    width    = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + 0.5 * height\n",
    "    center_x = boxes[:, 1] + 0.5 * width\n",
    "    \n",
    "    # Apply deltas\n",
    "    center_y += deltas[:, 0] * height\n",
    "    center_x += deltas[:, 1] * width\n",
    "    height   *= tf.exp(deltas[:, 2])\n",
    "    width    *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    # Convert back to y1, x1, y2, x2\n",
    "    y1 = center_y - 0.5 * height\n",
    "    x1 = center_x - 0.5 * width\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "    result = tf.stack([y1, x1, y2, x2], axis=1, name=\"apply_box_deltas_out\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def clip_boxes_graph(boxes, window):\n",
    "    \"\"\"\n",
    "    clip refined anchor boxes such that they remain within the dimensions of the image \n",
    "    boxes:  [N, 4] each row is y1, x1, y2, x2\n",
    "    window: [4] in the form y1, x1, y2, x2 \n",
    "    \"\"\"\n",
    "    # Split corners\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)   #  0, 0 , 128,128\n",
    "    y1 , x1 , y2 , x2  = tf.split(boxes, 4, axis=1)\n",
    "    \n",
    "    # Clip\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)   # ensure  wy1 <= y1 <= wy2\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    clipped = tf.concat([y1, x1, y2, x2], axis=1, name=\"clipped_boxes\")\n",
    "    return clipped\n",
    "\n",
    "def suppress_small_boxes_graph(boxes, scores, area_threshold ):\n",
    "    \"\"\"\n",
    "    supress boxes with area less than area_threshold\n",
    "    boxes:  [N, 4] each row is y1, x1, y2, x2\n",
    "    \n",
    "    \"\"\"\n",
    "    bx_area = (boxes[...,2]-boxes[...,0])*(boxes[...,3]-boxes[...,1])\n",
    "    selected_idxs   = tf.where(tf.greater_equal(bx_area, area_threshold))\n",
    "    selected_boxes  = tf.gather_nd(boxes, selected_idxs)\n",
    "    selected_scores = tf.gather_nd(scores, selected_idxs)\n",
    "    padding   = tf.maximum(tf.shape(boxes)[0] - tf.shape(selected_boxes)[0], 0)\n",
    "\n",
    "#     print(' box area       : ', bx_area.shape)    \n",
    "#     print(' selected_idxs  : ', tf.shape(selected_idxs).eval())\n",
    "#     print(' selected scores: ', tf.shape(selected_scores).eval())\n",
    "#     print(' Req padding    : ', padding.eval())\n",
    "    \n",
    "    selected_boxes  = tf.pad(selected_boxes, [(0, padding), (0, 0)])    \n",
    "    selected_scores = tf.pad(selected_scores, [(0, padding)])    \n",
    "    return selected_boxes, selected_scores\n",
    "\n",
    "def nms(normalized_boxes, scores):\n",
    "    proposal_count = model.config.POST_NMS_ROIS_TRAINING\n",
    "    rms_threshold  = model.config.RPN_NMS_THRESHOLD\n",
    "    indices = tf.image.non_max_suppression(normalized_boxes, \n",
    "                                           scores, \n",
    "                                           proposal_count,\n",
    "                                           nms_threshold, \n",
    "                                           name=\"rpn_non_max_suppression\")\n",
    "\n",
    "    proposals = tf.gather(normalized_boxes, indices)\n",
    "    # Pad if needed\n",
    "    padding   = tf.maximum(proposal_count - tf.shape(proposals)[0], 0)\n",
    "    proposals = tf.pad(proposals, [(0, padding), (0, 0)])\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:52:51.950082Z",
     "start_time": "2018-05-16T13:52:47.181975Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    \n",
    "    \n",
    "    scores = rpn_class[:, :, 1]\n",
    "    print(scores.shape)\n",
    "    deltas = rpn_bbox\n",
    "    print('deltas shape', deltas.shape)\n",
    "    deltas = deltas * np.reshape(model.config.RPN_BBOX_STD_DEV, [1, 1, 4])\n",
    "    print('deltas shape', deltas.shape)\n",
    "    anchors = model.anchors\n",
    "    print('model.anchors.shape', model.anchors.shape)\n",
    "    pre_nms_limit = min(6000, model.anchors.shape[0])\n",
    "    print('pre nms limit', pre_nms_limit)\n",
    "\n",
    "    ix = tf.nn.top_k(scores, pre_nms_limit, sorted=True,name=\"top_anchors\").indices\n",
    "\n",
    "    ## gather top scores (pre_nms_limit = min(6000, # anchors) number of scores from scores)        \n",
    "    scores  = utils.batch_slice([scores, ix], lambda x, y: tf.gather(x, y), model.config.IMAGES_PER_GPU) \n",
    "    print(' selected scores: ',scores.shape)\n",
    "\n",
    "    ## get corrsponding deltas generated by RPN\n",
    "    deltas  = utils.batch_slice([deltas, ix], lambda x, y: tf.gather(x, y), model.config.IMAGES_PER_GPU)\n",
    "    print(' selected deltas: ',deltas.shape)\n",
    "    anchors = utils.batch_slice(         ix , lambda x   : tf.gather(anchors, x), model.config.IMAGES_PER_GPU, names=[\"pre_nms_anchors\"])\n",
    "    print(' selected anchors: ',anchors.shape)\n",
    "    boxes = utils.batch_slice([anchors, deltas],\n",
    "                              lambda x, y: apply_box_deltas_graph(x, y),model.config.IMAGES_PER_GPU,\n",
    "                              names=[\"refined_anchors\"])\n",
    "    print(' delta applied boxes :', boxes.shape)\n",
    "\n",
    "    # Clip to image boundaries. [batch, N, (y1, x1, y2, x2)]\n",
    "    height, width = model.config.IMAGE_SHAPE[:2]\n",
    "    window = np.array([0, 0, height, width]).astype(np.float64)\n",
    "    print(' window is ', window)\n",
    "    clipped_boxes  = utils.batch_slice(boxes, \n",
    "                                   lambda x: clip_boxes_graph(x, window), model.config.IMAGES_PER_GPU,\n",
    "                                   names=[\"refined_anchors_clipped\"])\n",
    "\n",
    "    print(' clipped boxes :', clipped_boxes.shape)\n",
    "    \n",
    "    ## Suppress proposal boxes (and  corresponding score) if the area is less than ROI_AREA_THRESHOLD\n",
    "    roi_area_threshold = 2\n",
    "    mod_boxes, mod_scores = utils.batch_slice([clipped_boxes,scores], \n",
    "                            lambda x, y: suppress_small_boxes_graph(x, y, roi_area_threshold), model.config.IMAGES_PER_GPU,\n",
    "                            names=[\"mod_boxes\", \"mod_scores\"])  \n",
    "    print(' mod boxes :', tf.shape(mod_boxes).eval())\n",
    "    print(' mod_scores:', tf.shape(mod_scores).eval())   \n",
    "    \n",
    "    normalized_boxes = tf.cast(mod_boxes / np.array([[height, width, height, width]]), tf.float32)\n",
    "    print(' normalized boxes:', normalized_boxes.shape)\n",
    "\n",
    "    proposals = utils.batch_slice([normalized_boxes, mod_scores], nms, model.config.IMAGES_PER_GPU)\n",
    "    print('     Output: Prposals shape : ', proposals.shape, tf.shape(proposals).eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyze proposals results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T14:16:27.148573Z",
     "start_time": "2018-05-16T14:16:25.527179Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " proposals : [   3 2000    4]\n",
      " box area :  [   3 2000]\n",
      "selected bx: [1383    2]\n",
      "[[   0 1242]\n",
      " [   0 1243]\n",
      " [   0 1244]\n",
      " ...\n",
      " [   2 1997]\n",
      " [   2 1998]\n",
      " [   2 1999]]\n",
      "selected proposals shape [1383    4]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "selected area shape [1383]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    proposals = tf.identity(rpn_proposal_rois)  # <--- this uses the results from the model \n",
    "\n",
    "    bx_area = (proposals[...,2]-proposals[...,0])*(proposals[...,3]-proposals[...,1])\n",
    "    print(' proposals :', tf.shape(proposals).eval())\n",
    "    print(' box area : ', tf.shape(bx_area).eval())\n",
    "    \n",
    "    selected_idxs = tf.where(tf.less_equal(bx_area, (2/(128*128))) )\n",
    "    print('selected bx:', tf.shape(selected_idxs).eval())\n",
    "    \n",
    "    print(selected_idxs.eval())\n",
    "    selected_area      = tf.gather_nd(bx_area  , selected_idxs)\n",
    "    selected_proposals = tf.gather_nd(proposals, selected_idxs)\n",
    "    print('selected proposals shape', tf.shape(selected_proposals).eval())\n",
    "    print(selected_proposals[0:30].eval())\n",
    "    print('selected area shape', tf.shape(selected_area).eval())\n",
    "    print(selected_area[0:30].eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyze bounding box areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T10:44:24.008139Z",
     "start_time": "2018-05-16T10:44:09.624904Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(' boxes :', boxes.shape)\n",
    "    for i in [0,10,17,25,26,34,39]:\n",
    "        print(i, ' non-clipped ', boxes[0, i].eval())\n",
    "    bx_area = (boxes[...,2]-boxes[...,0])*(boxes[...,3]-boxes[...,1])\n",
    "    print(' box area : ', bx_area.shape)\n",
    "    np.set_printoptions(linewidth=130,precision=4,threshold=4096)\n",
    "    print(bx_area[:, :20].eval(session=sess))\n",
    "    small_idxs = tf.where(bx_area < 1)\n",
    "    print('small bx:', tf.shape(small_idxs).eval())\n",
    "    print(small_idxs[0:10].eval())\n",
    "    small_area  = tf.gather_nd(bx_area, small_idxs)\n",
    "    small_boxes = tf.gather_nd(boxes, small_idxs)\n",
    "    print('small boxes shape', tf.shape(small_boxes).eval())\n",
    "    print(small_boxes[0:30].eval())\n",
    "    print('small area shape', tf.shape(small_area).eval())\n",
    "    print(small_area[0:30].eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply non-maximal Supression for 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T10:57:34.284473Z",
     "start_time": "2018-05-16T10:57:24.229806Z"
    }
   },
   "outputs": [],
   "source": [
    "proposal_count = model.config.POST_NMS_ROIS_TRAINING\n",
    "nms_threshold  = model.config.RPN_NMS_THRESHOLD\n",
    "img = 1\n",
    "with sess.as_default():\n",
    "\n",
    "    print('image', img)\n",
    "    indices = tf.image.non_max_suppression(normalized_boxes[img], \n",
    "                                       scores[img], \n",
    "                                       proposal_count,\n",
    "                                       nms_threshold, \n",
    "                                       name=\"rpn_non_max_suppression\")\n",
    "    print(' nms indices shape: ', tf.shape(indices).eval())\n",
    "#     print( indices[751].eval())\n",
    "    proposals = tf.gather(normalized_boxes[0], indices)\n",
    "    print(' Prposals shape:', tf.shape(proposals).eval())\n",
    "    # Pad if needed\n",
    "    padding   = tf.maximum(proposal_count - tf.shape(proposals)[0], 0)\n",
    "    print(' Required padding ', padding.eval())\n",
    "    proposals = tf.pad(proposals, [(0, padding), (0, 0)])\n",
    "    print(' Prposals shape after padding :', tf.shape(proposals).eval())\n",
    "    \n",
    "    bx_area = (proposals[...,2]-proposals[...,0])*(proposals[...,3]-proposals[...,1])\n",
    "    print(' box area : ', tf.shape(bx_area).eval())\n",
    "    \n",
    "    np.set_printoptions(linewidth=130,precision=4,threshold=4096)\n",
    "    print(bx_area[:20].eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T10:17:16.339910Z",
     "start_time": "2018-05-16T10:17:15.183049Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print('     Scores : ' , scores.shape)\n",
    "    print('     Deltas : ' , deltas.shape)\n",
    "    print('     Anchors: ' , anchors.shape)\n",
    "    print('     Boxes shape / type after processing: ', boxes.shape)\n",
    "#     print('Anchors: \\n',anchors[0,-20:].eval())\n",
    "#     print('Deltas: \\n',deltas[0,-20:].eval())\n",
    "    print('Boxes: \\n',boxes[1,-20:].eval())\n",
    "    print('Clipped Boxes: \\n',clipped_boxes[1,-20:].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Clipped Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T12:14:49.732604Z",
     "start_time": "2018-05-16T12:14:37.751836Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=130,precision=4,threshold=4096)\n",
    "\n",
    "with sess.as_default():\n",
    "    print(' clipped boxes :', clipped_boxes.shape)\n",
    "#     for i in [0,10,17,25,26,34,39]:\n",
    "#         print(i, ' non-clipped ', boxes[0, i].eval())\n",
    "#         print(i, ' clipped     ', clipped_boxes[0, i].eval())\n",
    "\n",
    "    clp_bx_area = (clipped_boxes[...,2]-clipped_boxes[...,0])*(clipped_boxes[...,3]-clipped_boxes[...,1])\n",
    "    print(' clipped box area shape: ', clp_bx_area.shape)\n",
    "    clp_bx_shp = tf.shape(clp_bx_area).eval()\n",
    "    ttl_proposals = clp_bx_shp[0]*clp_bx_shp[1]\n",
    "    \n",
    "    ## --- print ratios of proposals that are dropped due to suppressing small roi boxes\n",
    "#     for min_area in range(20):\n",
    "#         clp_selected_idxs = tf.where(clp_bx_area >= min_area)\n",
    "#         selected_proposals = tf.shape(clp_selected_idxs).eval()[0]\n",
    "#         print(' min area lmt : ', min_area, ' clp_selected_idxs:', selected_proposals, ' Ratio:', 1 - (selected_proposals/ttl_proposals))\n",
    "\n",
    "    clp_selected_idxs = tf.where(clp_bx_area >= min_area)\n",
    "    print(clp_selected_idxs[0:10].eval())\n",
    "    \n",
    "#     non_clp_area  = tf.gather_nd(bx_area, clp_selected_idxs)\n",
    "#     non_clp_boxes = tf.gather_nd(boxes, clp_selected_idxs) \n",
    "\n",
    "    clp_selected_area  = tf.gather_nd(clp_bx_area, clp_selected_idxs)\n",
    "    clp_selected_boxes = tf.gather_nd(clipped_boxes, clp_selected_idxs)\n",
    "\n",
    "    print('clipped selected boxes shape', tf.shape(clp_selected_boxes).eval())\n",
    "#     print(clp_selected_boxes[0:30].eval())\n",
    "    print('clipped selected area shape ', tf.shape(clp_selected_area).eval())\n",
    "#     print(clp_selected_area[0:30].eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run detection target layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:19:16.210787Z",
     "start_time": "2018-05-15T20:19:15.954596Z"
    }
   },
   "outputs": [],
   "source": [
    "import mrcnn.utils  as utils\n",
    "from mrcnn.detect_tgt_layer import overlaps_graph\n",
    "# proposals    = KB.identity(rpn_proposal_rois)[0]\n",
    "# gt_class_ids = KB.identity(input_gt_class_ids)[0]\n",
    "# gt_boxes     = KB.identity(input_normlzd_gt_boxes)[0]\n",
    "# gt_masks     = KB.identity(input_gt_masks)[0]\n",
    "\n",
    "# proposals    = rpn_proposal_rois[1]\n",
    "# gt_class_ids = input_gt_class_ids[1]\n",
    "# gt_boxes     = input_normlzd_gt_boxes[1]\n",
    "# gt_masks     = input_gt_masks[1]\n",
    "# config       = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def `dev_detection_targets_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "def dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):\n",
    "\n",
    "\n",
    "    print('>>> detection_targets_graph ')\n",
    "    print('     propsals.shape        :',  proposals.shape, proposals.get_shape(), KB.int_shape(proposals) )\n",
    "    print('     gt_boxes.shape        :',  gt_boxes.shape ,    KB.int_shape(gt_boxes)   )\n",
    "    print('     gt_class_ids.shape    :',  gt_class_ids.shape, KB.int_shape(gt_class_ids))\n",
    "    print('     gt_masks.shape        :',  gt_masks.shape ,    KB.int_shape(gt_masks)   )\n",
    "\n",
    "    proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "    gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "    gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "    gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "    # print(tf.shape(proposals).eval())\n",
    "    # print(non_zeros.eval())\n",
    "    # print('gt_boxes :', tf.shape(gt_boxes).eval())\n",
    "\n",
    "    ###  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "\n",
    "    crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "    non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "    crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "    crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "    gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "    gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "    gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "    # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "    crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "    crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "    no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "    # print('crowd ixs: ', crowd_ix.eval())\n",
    "    # print('non_crowrd_ixs', non_crowd_ix.eval())\n",
    "    # print('non crowd bool', no_crowd_bool.eval())\n",
    "\n",
    "    overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "    print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "    \n",
    "    roi_iou_max            = tf.reduce_max(overlaps, axis=1)\n",
    "    print(' RoI/Gt max IoU')\n",
    "    # print(roi_iou_max.eval())\n",
    "    positive_roi_bool     = (roi_iou_max >= 0.5)\n",
    "    all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "    print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    print('Positive IoUs \\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "    ## current method\n",
    "    all_negative_indices     = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "#     print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "#     print('Negative IoUs \\n', tf.gather(roi_iou_max,all_negative_indices).eval())\n",
    "\n",
    "    ## method - suppress the proposals with 0 IoUs\n",
    "    # negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "    # negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "    # negative_nonzero_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "    # print('Negative indices')\n",
    "    # print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "    # print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "    ##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "    ##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    # print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "    # print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "    # print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "    positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "    negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "    print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "#     print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##  Select positive samples from amongst positive bounding boxes\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## current method\n",
    "    positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "    ## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "    ## New:\n",
    "    positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "    positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "    ##\n",
    "    ## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "    ## negative count, due to the fact that positive_count is cast to an int. \n",
    "    ## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "    ## \n",
    "    ## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "    ## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "    ## some of these will be used to introduce false positives/\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "    # print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "    # negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "    # print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "    # all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "    # print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## Here is the alterantive method\n",
    "    ## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "    ## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "    ##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "    false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "    false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "    false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "    \n",
    "    # print('Positive Count       : ', positive_count.eval())\n",
    "    # print('All Negative Count   : ', all_negative_count.eval())\n",
    "    # print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "    # print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "    # print(false_positive_indices.eval())\n",
    "    \n",
    "    negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "    negative_count     = tf.shape(negative_indices)[0]\n",
    "    # print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "    #       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "    # print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 5.   Gather selected positive and negative ROIs\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    positive_rois      = tf.gather(proposals, positive_indices)\n",
    "    false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "    negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "    # print(positive_rois.eval())\n",
    "    # print(false_positive_rois.eval())\n",
    "    # print(negative_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    # \n",
    "    #  Remember: The same class can have multiple gt_bounding boxes. So RoIs assiged to same class could have \n",
    "    #            DIFFERENT gt_bboxes (classes can have multple bounding boxes -- like when the same shape \n",
    "    #           appears twice in an image)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "    roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "    roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "    roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "    \n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' positive overlaps shape  :  ', sess.run(positive_overlaps, roi_gt_box_assignment))\n",
    "#     print(tf.reduce_max(positive_overlaps, axis = 1).eval())\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    ## 7.   Compute bbox delta \n",
    "    #  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "    deltas /= config.BBOX_STD_DEV\n",
    "    # print('deltas')\n",
    "    # print(deltas.eval())\n",
    "    # print(' Positive RoIs ')\n",
    "    # print(positive_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    #\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "    fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "    fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "    fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "#     print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "    # print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "    # print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "    # print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "    # print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "    return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:12:32.965718Z",
     "start_time": "2018-05-15T20:12:32.671907Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "def overlaps_graph(boxes1, boxes2):\n",
    "    '''\n",
    "    Computes IoU overlaps between two sets of boxes.in normalized coordinates\n",
    "    \n",
    "    boxes1 - proposals :  [batch_size,  proposal_counts, 4 (y1, x1, y2, x2)] <-- Region proposals\n",
    "    boxes2 - gt_boxes  :  [batch_size, max_gt_instances, 4 (y1, x1, y2, x2)] <-- input_normlzd_gt_boxes\n",
    "    \n",
    "    proposal_counts : 1000 or 2000 based on training or inference\n",
    "    max_gt_instances: 100\n",
    "    \n",
    "    returns :\n",
    "    ---------\n",
    "    overlaps :          [ proposal_counts, max_gt_instances] \n",
    "                        IoU of all proposal box / gt_box pairs\n",
    "    '''\n",
    "    # 1. Tile boxes2 and repeat boxes1. This allows us to compare every boxes1 against every boxes2 without loops.\n",
    "    #    TF doesn't have an equivalent to np.repeat() so simulate it using tf.tile() and tf.reshape.\n",
    "    \n",
    "#     print('\\t>>> detection_targets_graph - calculate Overlaps_graph')    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 before reshape: ',tf.shape(boxes1).eval())  # (?,?)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 before reshape: ',tf.shape(boxes2).eval())  # (?,?)\n",
    "    \n",
    "    # tf.expand_dims(boxes1, 1) : makes b1:[1, proposal_count_sz, 4] \n",
    "    b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "    b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 after reshape: ',tf.shape(b1).eval())  # (?,4)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 after reshape: ',tf.shape(b2).eval())  # (?,4)\n",
    "\n",
    "    # 2. Compute intersections\n",
    "    b1_y1, b1_x1, b1_y2, b1_x2 = tf.split(b1, 4, axis=1)\n",
    "    b2_y1, b2_x1, b2_y2, b2_x2 = tf.split(b2, 4, axis=1)\n",
    "    \n",
    "#     print('     overlaps_graph: shape of b1_y1 after split: ',tf.shape(b2_y1).eval())  # (?,4)\n",
    "    y1 = tf.maximum(b1_y1, b2_y1)\n",
    "    x1 = tf.maximum(b1_x1, b2_x1)\n",
    "    y2 = tf.minimum(b1_y2, b2_y2)\n",
    "    x2 = tf.minimum(b1_x2, b2_x2)\n",
    "    intersection = tf.maximum(x2 - x1, 0) * tf.maximum(y2 - y1, 0)\n",
    "\n",
    "    # 3. Compute unions\n",
    "    b1_area = (b1_y2 - b1_y1) * (b1_x2 - b1_x1)\n",
    "    b2_area = (b2_y2 - b2_y1) * (b2_x2 - b2_x1)\n",
    "    union = b1_area + b2_area - intersection\n",
    "    \n",
    "    # 4. Compute IoU and reshape to [boxes1, boxes2]\n",
    "    iou = intersection / union\n",
    "    overlaps = tf.reshape(iou, [tf.shape(boxes1)[0], tf.shape(boxes2)[0]])\n",
    "#     print('\\t     Overlaps_graph(): Shape of output overlaps', tf.shape(overlaps).eval(), overlaps.get_shape())\n",
    "    return overlaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ###  detetct_target_layer -- non function format\n",
    "\n",
    "#### Take inputs , layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:19:34.929213Z",
     "start_time": "2018-05-15T20:19:34.307055Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "proposals              = tf.identity(rpn_proposal_rois)[0]\n",
    "gt_class_ids           = tf.identity(input_gt_class_ids)[0]\n",
    "gt_boxes               = tf.identity(input_normlzd_gt_bboxes)[0]\n",
    "gt_masks               = tf.identity(input_gt_masks)[0]\n",
    "print(' normalized gt bboxes : ', input_normlzd_gt_bboxes.shape,gt_boxes.shape)\n",
    "print(' gt_class_ids         : ', input_gt_class_ids.shape, gt_class_ids.shape)\n",
    "print(' rpn_proposals        : ', rpn_proposal_rois.shape,proposals.shape)\n",
    "print(' gt_masks             : ', input_gt_masks.shape, gt_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:31:52.319021Z",
     "start_time": "2018-05-15T20:31:49.750639Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('>>> detection_targets_graph ')\n",
    "np.set_printoptions(linewidth=130,precision=4, threshold = 4000)\n",
    "\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('     gt_class_ids.shape    :',  tf.shape(gt_class_ids).eval())\n",
    "print('     gt_masks.shape        :',  tf.shape(gt_masks).eval() )\n",
    "\n",
    "proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('     gt_boxes              :\\n', gt_boxes.eval())\n",
    "# print('     rpn proposals         :\\n', rpn_proposal_rois)\n",
    "\n",
    "print(rpn_proposal_rois.shape)\n",
    "abs_props = rpn_proposal_rois * [128,128,128,128]\n",
    "area = (abs_props[...,2]-abs_props[...,0])*(abs_props[...,3]-abs_props[...,1])\n",
    "print(area.shape)\n",
    "print(np.argsort(area[0]))\n",
    "# print(abs_props[0,0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:45:52.881646Z",
     "start_time": "2018-05-15T20:45:52.630478Z"
    }
   },
   "outputs": [],
   "source": [
    "print(abs_props[0,329])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:05:39.600129Z",
     "start_time": "2018-05-15T21:05:39.327915Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.anchors[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(non_zeros.eval())\n",
    "\n",
    "###  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "\n",
    "crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "\n",
    "# get unique list of classes present in current image\n",
    "gt_classes_present, _ = tf.unique(gt_class_ids)\n",
    "\n",
    "# Compute overlaps with crowd boxes [anchors, crowds]\n",
    "crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "# print('crowd ixs: ', crowd_ix.eval())\n",
    "# print('non_crowd_ixs', non_crowd_ix.eval())\n",
    "# print('non crowd bool', no_crowd_bool.eval())\n",
    " \n",
    "overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "roi_iou_max     = tf.reduce_max(overlaps, axis=1)\n",
    "\n",
    "# print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "# print(overlaps.eval())\n",
    "# print(' RoI/Gt max IoU')\n",
    "# print(roi_iou_max.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 2. Identify RoIs that have an IoU >= 0.5 - these are positive RoIs\n",
    "##    RoIs that have a max IoU < 0.5 and are not a crowd RoI are considered negative RoIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_roi_bool         = (roi_iou_max >= 0.5)\n",
    "all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Positive IoUs    :\\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "## current method\n",
    "all_negative_indices     = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "# print('Negative IoUs \\n', tf.gather(roi_iou_max,all_negative_indices).eval())\n",
    "\n",
    "## method - suppress the proposals with 0 IoUs\n",
    "# negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "# negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "# negative_nonzero_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "# print('Negative indices')\n",
    "# print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "# print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "# print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "# print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "# print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "# print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##  Select positive samples from amongst positive bounding boxes\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## current method\n",
    "positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "## New:\n",
    "positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "##\n",
    "## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "## negative count, due to the fact that positive_count is cast to an int. \n",
    "## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "## \n",
    "## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "## some of these will be used to introduce false positives/\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "# print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "# negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "# print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "# all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "# print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## Here is the alterantive method\n",
    "## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "\n",
    "# print('Positive Count       : ', positive_count.eval())\n",
    "# print('All Negative Count   : ', all_negative_count.eval())\n",
    "# print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "# print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "# print(false_positive_indices.eval())\n",
    "\n",
    "negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "negative_count     = tf.shape(negative_indices)[0]\n",
    "# print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "#       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "# print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 5.   Gather selected positive and negative ROIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_rois      = tf.gather(proposals, positive_indices)\n",
    "false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "# print(positive_rois.eval())\n",
    "# print(false_positive_rois.eval())\n",
    "# print(negative_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "\n",
    "# print('Positive indices: \\n',positive_indices.eval())\n",
    "# print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "# print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 7.   Compute bbox delta \n",
    "#  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "deltas /= config.BBOX_STD_DEV\n",
    "# print('deltas')\n",
    "# print(deltas.eval())\n",
    "# print(' Positive RoIs ')\n",
    "# print(positive_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#  Idea -- instead of using arg_max, use arg_min \n",
    "#------------------------------------------------------------------------------------------------------\n",
    "fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "##--------------------------------------------------------------------------------\n",
    "## To Randomly assign classes to the false positive bounding boxes,\n",
    "## use the gt_class_id / OR the box_assignement to pick a class from the \n",
    "## shuffled <gt_classes_present> tensor\n",
    "##--------------------------------------------------------------------------------\n",
    "\n",
    "# print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "# print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "# print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "# print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "# print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 8.  prepare gt_masks \n",
    "#      transpose gt_masks from [h, w, N] to [N, height, width] and add 4th dim at end [N, height, width, 1]\n",
    "#      Pick the right mask for each ROI\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "transposed_masks = tf.expand_dims(tf.transpose(gt_masks, [2, 0, 1]), -1)\n",
    "roi_masks = tf.gather(transposed_masks, roi_gt_box_assignment)\n",
    "\n",
    "# Compute mask targets\n",
    "boxes = positive_rois\n",
    "\n",
    "if config.USE_MINI_MASK:\n",
    "    # Transform ROI corrdinates from normalized image space\n",
    "    # to normalized mini-mask space.\n",
    "    y1, x1, y2, x2 = tf.split(positive_rois, 4, axis=1)\n",
    "    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(roi_gt_boxes, 4, axis=1)\n",
    "    gt_h = gt_y2 - gt_y1\n",
    "    gt_w = gt_x2 - gt_x1\n",
    "    y1 = (y1 - gt_y1) / gt_h\n",
    "    x1 = (x1 - gt_x1) / gt_w\n",
    "    y2 = (y2 - gt_y1) / gt_h\n",
    "    x2 = (x2 - gt_x1) / gt_w\n",
    "    boxes = tf.concat([y1, x1, y2, x2], 1)\n",
    "\n",
    "box_ids = tf.range(0, tf.shape(roi_masks)[0])\n",
    "masks   = tf.image.crop_and_resize(tf.cast(roi_masks, tf.float32), \n",
    "                                   boxes,\n",
    "                                   box_ids,\n",
    "                                   config.MASK_SHAPE)\n",
    "# Remove the extra dimension from masks.\n",
    "masks = tf.squeeze(masks, axis=3)\n",
    "\n",
    "# Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with\n",
    "# binary cross entropy loss.\n",
    "masks = tf.round(masks)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# Append negative ROIs and pad bbox deltas and masks that\n",
    "# are not used for negative ROIs with zeros.\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "fp_rois          = tf.concat([positive_rois, false_positive_rois, negative_rois], axis=0)\n",
    "fp_roi_gt_boxes     = tf.concat([roi_gt_boxes,fp_gt_boxes], axis=0)\n",
    "fp_roi_gt_class_ids = tf.concat([roi_gt_class_ids, fp_gt_class_ids],axis=0)\n",
    "\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "\n",
    "\n",
    "rois             = tf.pad(rois            , [(0, P), (0, 0)])\n",
    "roi_gt_boxes     = tf.pad(roi_gt_boxes    , [(0, N + P), (0, 0)])\n",
    "roi_gt_class_ids = tf.pad(roi_gt_class_ids, [(0, N + P)])\n",
    "deltas           = tf.pad(deltas          , [(0, N + P), (0, 0)])\n",
    "masks            = tf.pad(masks           , [[0, N + P], (0, 0), (0, 0)])\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# SSetup False Positive structures\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "P1                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_rois)[0], 0)\n",
    "fp_rois             = tf.pad(rois            , [(0, P1), (0, 0)])\n",
    "\n",
    "\n",
    "P2                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_roi_gt_boxes)[0], 0)\n",
    "fp_roi_gt_boxes     = tf.pad(fp_roi_gt_boxes    , [(0, P2), (0, 0)])\n",
    "fp_roi_gt_class_ids = tf.pad(fp_roi_gt_class_ids, [(0, P2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.Session()\n",
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "FeedList = [false_positive_indices, fp_overlaps, fp_gt_box_assignment, fp_gt_boxes, fp_gt_class_ids, gt_class_ids,\n",
    "            fp_rois, fp_roi_gt_boxes, fp_roi_gt_class_ids,\n",
    "            rois   , roi_gt_boxes   , roi_gt_class_ids]\n",
    "tt = sess1.run(FeedList)\n",
    "print(type(tt), len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(' False Positive indices: \\n', tt[0])\n",
    "print(' shape of false positive overlaps is :', tt[1].shape)\n",
    "print(' FP overlaps             \\n', tt[1])\n",
    "print(' FP gt box assignemt:\\n', tt[2])\n",
    "print(' FP gt boxes        :\\n', tt[3])\n",
    "print(' FP gt class assign :\\n', tt[4])\n",
    "print(' gt class ids assign :\\n', tt[5])\n",
    "print()\n",
    "print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "print()\n",
    "print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "print()\n",
    "print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tt), len(tt))\n",
    "print(' Shuffled Positive indices:\\n', tt[0])\n",
    "print(' Positive indices:         \\n', tt[1])\n",
    "print(' positive overlaps shape  :  ', tt[2].shape)\n",
    "print(' positive overlaps        :\\n', tt[2])\n",
    "print(' Pos roi gt box assignment:\\n', tt[5])    \n",
    "print(' Pos roi gt class assign  :\\n', tt[3])\n",
    "print(' Pos roi gt boxes         :\\n', tt[4])\n",
    "\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Experimental Code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
