{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train FCN using MRCNN in Predict Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:45:48.766805Z",
     "start_time": "2018-12-24T16:45:48.759799Z"
    }
   },
   "outputs": [],
   "source": [
    "# np_format = {}\n",
    "# float_formatter = lambda x: \"%10.4f\" % x\n",
    "# int_formatter   = lambda x: \"%10d\" % x\n",
    "# np_format['float'] = float_formatter\n",
    "# np_format['int']   = int_formatter\n",
    "# np.set_printoptions(linewidth=195, precision=4, floatmode='fixed', threshold =10000, formatter = np_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:03.833513Z",
     "start_time": "2018-12-24T16:45:49.034994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir:  E:\\git_projs\\MRCNN3\\notebooks\n",
      "appending '..' to sys.path\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True) \n",
    "print('Current working dir: ', os.getcwd())\n",
    "if '..' not in sys.path:\n",
    "    print(\"appending '..' to sys.path\")\n",
    "    sys.path.append('..')\n",
    "    \n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.utils     as utils\n",
    "\n",
    "from mrcnn.prep_notebook import build_fcn_training_pipeline_newshapes\n",
    "from mrcnn.visualize     import display_training_batch\n",
    "from mrcnn.newshapes     import prep_newshape_dataset\n",
    "from mrcnn.datagen       import data_gen_simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:04.236782Z",
     "start_time": "2018-12-24T16:46:03.835515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "input_parms = \" --epochs 2 \" \n",
    "input_parms +=\" --steps_in_epoch  10 \"    \n",
    "input_parms +=\" --val_steps        5 \" \n",
    "input_parms +=\" --last_epoch       0 \"\n",
    "input_parms +=\" --batch_size       1 \"\n",
    "input_parms +=\" --lr          0.0001 \"\n",
    "input_parms +=\" --mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_l2_newshapes \"\n",
    "# input_parms +=\" --fcn_logs_dir   train_fcn32_newshapes \"\n",
    "input_parms +=\" --mrcnn_model    last \"\n",
    "input_parms +=\" --fcn_model      init \"\n",
    "input_parms +=\" --opt            adam \"\n",
    "input_parms +=\" --fcn_arch       fcn8L2 \" \n",
    "input_parms +=\" --fcn_layers     all \" \n",
    "input_parms +=\" --sysout         screen \"\n",
    "input_parms +=\" --scale_factor     1 \" \n",
    "input_parms +=\" --new_log_folder   \"        \n",
    "\n",
    "parser = utils.command_line_parser()\n",
    "args = parser.parse_args(input_parms.split())\n",
    "utils.display_input_parms(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:28.201039Z",
     "start_time": "2018-12-24T16:46:04.241785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  trainfcn\n",
      "   Model dir :  F:\\models_newshapes\\train_mrcnn_newshapes\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  trainfcn\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "\n",
      ">>> RPN Layer \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "    > CHMLayer Call()              :  list length: 3\n",
      "--------------------------------\n",
      ">>>  CHM Layer COMPUTE OUTPUT SHAPE \n",
      "--------------------------------\n",
      "<class 'list'> 3\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      "\n",
      " MRCNN Configuration Parameters \n",
      " ------------------------------ \n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        32\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            32\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            120\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             60\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_mrcnn_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        0\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      " MRCNN IO Layers \n",
      " --------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 128, 128, 7)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 128, 128, 7)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 32, 7)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      " layer: 11    output name: ROI/rpn_roi_proposals:0                    Type: float32           Shape: (1, ?, ?)\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n",
      "\n",
      "   Paths:\n",
      "   -------------------------\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_HEATMAP_PATH              F:\\MLDatasets\\coco2014_heatmaps\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_ROOT                       F:\\\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "FCN_TRAINING_PATH              F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "FCN_VGG16_MODEL_PATH           F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            F:\\models_newshapes\\train_mrcnn_newshapes\n",
      "PRED_CLASS_INFO_PATH           F:\\PretrainedModels\\predicted_classes_info.pkl\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                   NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN8L2\n",
      "    arch set to FCN8 - with L2 Regularization\n",
      "<function fcn8_l2_graph at 0x000000B5A38EB268>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      " Build FCN Model -  Arch:  FCN8L2  mode:  training\n",
      "---------------------------------------------------\n",
      "   active_class_ids  shape is :  (None, None)  Keras tensor  True\n",
      "\n",
      "---------------\n",
      ">>> FCN8 Layer With Regularization - mode: training\n",
      "---------------\n",
      "     feature map      : (?, 128, 128, 7)\n",
      "     height : 128 width : 128 classes : 7\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "     FCN L2 weight decay :  1e-06\n",
      "     Set learning phase to : 1\n",
      "   Input feature map                   :  (?, 128, 128, 7)\n",
      "   FCN Block 11 shape is               :  (None, 128, 128, 64)\n",
      "   FCN Block 12 shape is               :  (None, 128, 128, 64)\n",
      "   FCN Block 13 (Max pooling) shape is :  (None, 64, 64, 64)\n",
      "   FCN Block 21 shape is               :  (?, 64, 64, 128)\n",
      "   FCN Block 22 shape is               :  (None, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (None, 32, 32, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FCN Block 31 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 32 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 33 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 16, 16, 256)\n",
      "   FCN Block 41 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 42 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 43 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 51 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 52 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 53 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (None, 4, 4, 512)\n",
      "\n",
      "   --- FCN32 ----------------------------\n",
      "   FCN fully connected 1 (fc1) shape   :  (None, 4, 4, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n",
      "   FCN fully connected 2 (fc2) shape   :  (None, 4, 4, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n",
      "   FCN conv2d (fcn32_deconv2D) shape   :  (?, 4, 4, 7)  keras_tensor  True\n",
      "\n",
      "   --- FCN16 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape is                   :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling (Deconvolution2D(fcn32_classify)) shape :  (None, 10, 10, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 Add(score2_c, scorePool4) shape :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN upscore_pool4 (Deconv(fuse_Pool4)) shape              :  (None, 16, 16, 7)    keras_tensor  True\n",
      "\n",
      "   --- FCN8 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape                      :  (None, 16, 16, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 16, 16, 7)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 shape is                        :  (None, 16, 16, 7)    keras_tensor  True\n",
      "    FCN fcn8_classify/heatmap  (Deconv(fuse_Pool4)):  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    fcn_hm (final)                 :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "\n",
      "    fcn8_softmax                   :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    fcn_sm (final)                 :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "\n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer - mode: training\n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pr_hm_scores.shape             :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    detctions_per_image :  32 pr_scores shape (?, 7, 32, 23)\n",
      "    rois_per_image      :  32\n",
      "    config.DETECTION_MAX_INSTANCES   :  32\n",
      "    config.DETECTIONS_PER_CLASS      :  32\n",
      "    sequence_column                  :  6\n",
      "    norm_score_column                :  7\n",
      "    in_heatmap                     :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pr_scores.shape                :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    pt2_sum shape                  :  shape: (?, 7, 32)            KB.shape:(None, 7, 32)         Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 7, 128, 128) Keras tensor  False\n",
      "    normalizer shape   :  (?, 7, 1, 1)\n",
      "    normalized heatmap :  (?, 7, 128, 128)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: False\n",
      "    complete                       \n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer - mode: training\n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pr_hm_scores.shape             :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: False\n",
      "    detctions_per_image :  32 pr_scores shape (?, 7, 32, 23)\n",
      "    rois_per_image      :  32\n",
      "    config.DETECTION_MAX_INSTANCES   :  32\n",
      "    config.DETECTIONS_PER_CLASS      :  32\n",
      "    sequence_column                  :  6\n",
      "    norm_score_column                :  7\n",
      "    in_heatmap                     :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pr_scores.shape                :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: False\n",
      "    pt2_sum shape                  :  shape: (?, 7, 32)            KB.shape:(None, 7, 32)         Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 7, 128, 128) Keras tensor  False\n",
      "    normalizer shape   :  (?, 7, 1, 1)\n",
      "    normalized heatmap :  (?, 7, 128, 128)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: False\n",
      "    complete                       \n",
      "    * gt_hm_scores shape           :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    * pr_hm_scores shape           :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    * fcn_heatmap shape            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    * fcn_softmax shape            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    * fcn_scores shape             :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: True\n",
      "                                   \n",
      "    ---------------------------------------------------\n",
      "    building Loss Functions        \n",
      "    ---------------------------------------------------\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  True\n",
      "    pred_heatmap : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  True\n",
      "    loss         : (?, 128, 128) (None, 128, 128) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  False\n",
      "    pred_heatmap : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  False\n",
      "    loss         : (?, 128, 128) (None, 128, 128) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 128, 128, 7)\n",
      "    pred_class_logits : (None, 128, 128, 7)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 128, 128) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 128, 128) <dtype: 'int64'>\n",
      "    pred_active       : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss              : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 128, 128) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 128, 128, 7)\n",
      "    pred_class_logits : (None, 128, 128, 7)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 128, 128) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 128, 128) <dtype: 'int64'>\n",
      "    pred_active       : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss              : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 128, 128) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pred_class_logits :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 7)                KB.shape:(None, 7)             Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pred_class_logits :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 7)                KB.shape:(None, 7)             Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  21\n",
      "0      Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "1      Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "2      Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "3      Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "4      Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "5      Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "6      Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "7      Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "8      Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "9      Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "10      Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "11      Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12      Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "13      Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "14      Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "15      Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "16      Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "17      Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "18      Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "19      Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "20      Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n",
      "\n",
      " FCN Configuration Parameters \n",
      " ------------------------------ \n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_PERIOD              1\n",
      "DETECTION_MAX_INSTANCES        32\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            32\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           1e-07\n",
      "EARLY_STOP_PATIENCE            1000\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_MIN_DELTA            1e-06\n",
      "REDUCE_LR_PATIENCE             500\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_LAYERS                ['all']\n",
      "TRAINING_LOSSES                fcn_BCE_loss\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        1\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "WEIGHT_DECAY                   1e-06\n",
      "\n",
      "\n",
      "\n",
      " FCN IO Layers \n",
      " --------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 23)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 23)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap_lambda/fcn_hm:0                Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  1    output name: fcn_softmax_lambda/fcn_sm:0                Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  2    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: fcn_BCE_loss/fcn_BCE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  4    output name: fcn_scoring/fcn_hm_scores:0                Type: float32           Shape: (1, 7, 32, 23)\n",
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      " Exclude layers: \n",
      "-----------------------------------------------\n",
      " ---> last\n",
      ">>> load_weights() from : F:\\models_newshapes\\train_mrcnn_newshapes\\mrcnn20181216T0000\\mrcnn_0472.h5\n",
      "    Weights file loaded: F:\\models_newshapes\\train_mrcnn_newshapes\\mrcnn20181216T0000\\mrcnn_0472.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n",
      " FCN Training starting from randomly initialized weights ...\n"
     ]
    }
   ],
   "source": [
    "# del mrcnn_model, fcn_model\n",
    "mrcnn_model, fcn_model = build_fcn_training_pipeline_newshapes(args = args, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:43.903197Z",
     "start_time": "2018-12-24T16:46:28.205042Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepares complete\n",
      "Prepares complete\n",
      "5000 1000\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build & Load Training and Validation datasets\n",
    "##------------------------------------------------------------------------------------\n",
    "dataset_train, train_generator = prep_newshape_dataset( mrcnn_model.config, 5000, generator=True)\n",
    "dataset_val  , val_generator   = prep_newshape_dataset( mrcnn_model.config,  1000, generator=True)\n",
    "class_names = dataset_train.class_names\n",
    "print(len(dataset_train.image_ids), len(dataset_val.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display active classes of `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:46:25.288051Z",
     "start_time": "2018-12-20T18:46:24.956798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dataset_train.display_active_classes()\n",
    "# dataset_val.display_active_classes()\n",
    "print(len(dataset_train.image_ids), len(dataset_val.image_ids))\n",
    "print(mrcnn_model.config.BATCH_SIZE, fcn_model.config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Print model layer and weight information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:38:43.700653Z",
     "start_time": "2018-12-20T19:38:41.748709Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fcn_model.keras_model.summary()\n",
    "tr_ly = fcn_model.get_trainable_layers()\n",
    "for i in tr_ly:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:29:41.902326Z",
     "start_time": "2018-10-31T15:29:41.840211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in fcn_model.keras_model.layers:\n",
    "    print('layer: ', layer.name)\n",
    "    for weight in layer.weights:\n",
    "        print('   mapped_weight_name : ',weight.name)\n",
    "    if hasattr(layer, 'output'):\n",
    "        print('   layer output ', type(layer),' shape: ',layer.output.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:17:32.353508Z",
     "start_time": "2018-05-20T18:17:32.121048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model.keras_model.losses\n",
    "# print(model.keras_model.metrics_names)\n",
    "# model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load a specific image using image_id  with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T12:28:26.389169Z",
     "start_time": "2018-12-17T12:28:24.936137Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, _ =  data_gen_simulate(dataset_train, mrcnn_model.config, [417])\n",
    "# visualize.display_training_batch(dataset_train, train_batch_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:44.895887Z",
     "start_time": "2018-12-24T16:46:43.907185Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image id :  646\n",
      " Image_id    :  646  Reference:  [('sun', (17, 87, 183), (99, 10, 5, 5))] Coco Id: 646\n",
      " Image meta  :  [646 128 128   3   0   0 128 128]\n",
      " Class ids   :  (1,)    [3]\n",
      " Class Names :  ['sun']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5EAAAOICAYAAABPC3XsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2WqLDnI6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[646 128 128   3   0   0 128 128   1   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "IMAGE_IDS = [646]\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "train_batch_x, train_batch_y = data_gen_simulate(dataset_train, mrcnn_model.config, IMAGE_IDS)\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)\n",
    "print(train_batch_x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get training batch using generator and display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T10:34:39.848544Z",
     "start_time": "2018-12-21T10:34:39.174742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "display_training_batch(dataset_train, train_batch_x)\n",
    "# for i in train_batch_x:\n",
    "#     print(type(i), i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:45.724476Z",
     "start_time": "2018-12-24T16:46:44.900891Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_PERIOD              1\n",
      "DETECTION_MAX_INSTANCES        32\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            32\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           1e-07\n",
      "EARLY_STOP_PATIENCE            1000\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_MIN_DELTA            1e-06\n",
      "REDUCE_LR_PATIENCE             500\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_LAYERS                ['all']\n",
      "TRAINING_LOSSES                fcn_BCE_loss\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        1\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "WEIGHT_DECAY                   1e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mrcnn_model.config.display()\n",
    "fcn_model.config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T11:09:06.438486Z",
     "start_time": "2018-12-25T11:08:49.487437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last epoch ran  :  420\n",
      "    epochs to run   :  400\n",
      "    steps per epoch :  10\n",
      "    validation steps:  5\n",
      "    learning rate   :  0.0001\n",
      "    momentum        :  0.9\n",
      "    weight decay    :  1e-06\n"
     ]
    }
   ],
   "source": [
    "fcn_model.config.LAST_EPOCH_RAN  =  420\n",
    "fcn_model.config.EPOCHS_TO_RUN   =  400\n",
    "fcn_model.config.REDUCE_LR_PATIENCE = 200\n",
    "# fcn_model.config.LEARNING_RATE   = 1.0e-6\n",
    "# fcn_model.config.STEPS_PER_EPOCH = 10\n",
    "# fcn_model.config.SYSOUT = 'screen'\n",
    "\n",
    "print('    last epoch ran  : ',fcn_model.config.LAST_EPOCH_RAN)\n",
    "print('    epochs to run   : ',fcn_model.config.EPOCHS_TO_RUN)\n",
    "print('    steps per epoch : ',fcn_model.config.STEPS_PER_EPOCH)\n",
    "print('    validation steps: ',fcn_model.config.VALIDATION_STEPS)\n",
    "print('    learning rate   : ',fcn_model.config.LEARNING_RATE)\n",
    "print('    momentum        : ',fcn_model.config.LEARNING_MOMENTUM)\n",
    "print('    weight decay    : ',fcn_model.config.WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call to `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T20:07:28.309440Z",
     "start_time": "2018-12-25T11:11:54.517641Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block1+']\n",
      "['(block1\\\\_.*)|(block2\\\\_.*)|(block3\\\\_.*)|(block4\\\\_.*)|(block5\\\\_.*)|(fcn32\\\\_.*)|(fcn16\\\\_.*)|(fcn8\\\\_.*)']\n",
      "layers regex : (block1\\_.*)|(block2\\_.*)|(block3\\_.*)|(block4\\_.*)|(block5\\_.*)|(fcn32\\_.*)|(fcn16\\_.*)|(fcn8\\_.*)\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_pr_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "   1  block1_conv1           (Conv2D              )   TRAIN \n",
      "   2  block1_conv2           (Conv2D              )   TRAIN \n",
      "   3  block1_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   4  block2_conv1           (Conv2D              )   TRAIN \n",
      "   5  block2_conv2           (Conv2D              )   TRAIN \n",
      "   6  block2_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   7  block3_conv1           (Conv2D              )   TRAIN \n",
      "   8  block3_conv2           (Conv2D              )   TRAIN \n",
      "   9  block3_conv3           (Conv2D              )   TRAIN \n",
      "  10  block3_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  11  block4_conv1           (Conv2D              )   TRAIN \n",
      "  12  block4_conv2           (Conv2D              )   TRAIN \n",
      "  13  block4_conv3           (Conv2D              )   TRAIN \n",
      "  14  block4_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  15  block5_conv1           (Conv2D              )   TRAIN \n",
      "  16  block5_conv2           (Conv2D              )   TRAIN \n",
      "  17  block5_conv3           (Conv2D              )   TRAIN \n",
      "  18  block5_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  19  fcn32_fc1              (Conv2D              )   TRAIN \n",
      "  20  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      "  21  fcn32_fc2              (Conv2D              )   TRAIN \n",
      "  22  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      "  23  fcn32_deconv2D         (Conv2D              )   TRAIN \n",
      "  24  fcn16_score2           (Conv2DTranspose     )   TRAIN \n",
      "  25  fcn16_crop_score2      (Cropping2D          )   ............................no weights to train ]\n",
      "  26  fcn16_score_pool4      (Conv2D              )   TRAIN \n",
      "  27  fcn16_fuse_pool4       (Add                 )   ............................no weights to train ]\n",
      "  28  fcn16_upscore_pool4    (Conv2DTranspose     )   TRAIN \n",
      "  29  fcn8_crop_pool4        (Cropping2D          )   ............................no weights to train ]\n",
      "  30  fcn8_score_pool3       (Conv2D              )   TRAIN \n",
      "  31  fcn8_fuse_pool3        (Add                 )   ............................no weights to train ]\n",
      "  32  fcn8_heatmap           (Conv2DTranspose     )   TRAIN \n",
      "  33  fcn_heatmap_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  34  input_gt_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "  35  input_pr_hm_scores     (InputLayer          )   ............................no weights to train ]\n",
      "  36  fcn_softmax_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  37  fcn_MSE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  38  fcn_BCE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  39  fcn_scoring            (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      "  Compile Model :\n",
      " ----------------\n",
      "    losses        :  ['fcn_BCE_loss']\n",
      "    optimizer     :  <keras.optimizers.Adam object at 0x000000B68C5E4940>\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      " Initial self.keras_model.losses :\n",
      " ---------------------------------\n",
      " losses passed to compile :  ['fcn_BCE_loss']\n",
      " self.keras_model.losses  : \n",
      "      0    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      11    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Add loss_functions to self.keras_model.losses\n",
      " -------------------------------------\n",
      " --  Loss: fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add add loss for  Tensor(\"fcn_BCE_loss/fcn_BCE_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding loss_functions passed to compile() : \n",
      " ------------------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " --------------------\n",
      "      0    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      " Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      " ---------------------------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Compile \n",
      " --------\n",
      " Length of Keras_Model.outputs: 5\n",
      "\n",
      " Add Metrics for losses :\n",
      " -------------------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add metric  fcn_BCE_loss  with metric tensor:  fcn_BCE_loss/fcn_BCE_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names :\n",
      " --------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      " ----------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " ---------------------\n",
      "      0    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      "\n",
      " Post-compile out_labels from get_deduped_metrics_names() : \n",
      " ---------------------------------------------------------- \n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "\n",
      " Post-compile Callback metrics monitored by progbar :\n",
      " ----------------------------------------------------\n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "     - val_loss\n",
      "     - val_fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras metric_names :\n",
      " ---------------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras stateful_metric_names :\n",
      " ------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training Start Parameters:\n",
      "--------------------------\n",
      "Starting at epoch     420 of 820 epochs.\n",
      "Steps per epochs      10 \n",
      "Last epoch completed  420 \n",
      "Batch size            1 \n",
      "Learning Rate         0.0001 \n",
      "Momentum              0.9 \n",
      "Weight Decay:         1e-06 \n",
      "VALIDATION_STEPS      5 \n",
      "REDUCE_LR_FACTOR      0.5 \n",
      "REDUCE_LR_COOLDOWN    50 \n",
      "REDUCE_LR_PATIENCE    200 \n",
      "MIN_LR                1e-10 \n",
      "EARLY_STOP_PATIENCE   1000 \n",
      "Checkpoint Path:      F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_{epoch:04d}.h5 \n",
      "Epoch 421/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 420 , image ids: [2512] -- Retry with next sample\n",
      "10/10 [==============================] - 124s 12s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0096\n",
      "\n",
      "Epoch 00421: val_loss improved from inf to 0.01058, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0421.h5\n",
      "Epoch 422/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0224 - fcn_BCE_loss: 0.0215 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 421 , image ids: [858] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0217 - fcn_BCE_loss: 0.0207 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.01058\n",
      "Epoch 423/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.01058\n",
      "Epoch 424/820\n",
      " 6/10 [=================>............] - ETA: 31s - loss: 0.0213 - fcn_BCE_loss: 0.0204\n",
      " Bad train_batch_x encountered (training phase) - epoch 423 , image ids: [2890] -- Retry with next sample\n",
      "10/10 [==============================] - 93s 9s/step - loss: 0.0184 - fcn_BCE_loss: 0.0175 - val_loss: 0.0230 - val_fcn_BCE_loss: 0.0221\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.01058\n",
      "Epoch 425/820\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0275 - fcn_BCE_loss: 0.0265 - val_loss: 0.0150 - val_fcn_BCE_loss: 0.0141\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.01058\n",
      "Epoch 426/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0169 - fcn_BCE_loss: 0.0160 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.01058\n",
      "Epoch 427/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0162 - val_fcn_BCE_loss: 0.0152\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.01058\n",
      "Epoch 428/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.01058\n",
      "Epoch 429/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0253 - fcn_BCE_loss: 0.0243 - val_loss: 0.0193 - val_fcn_BCE_loss: 0.0184\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.01058\n",
      "Epoch 430/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.01058\n",
      "Epoch 431/820\n",
      " 2/10 [=====>........................] - ETA: 57s - loss: 0.0235 - fcn_BCE_loss: 0.0225 \n",
      " Bad train_batch_x encountered (training phase) - epoch 430 , image ids: [2991] -- Retry with next sample\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0161 - fcn_BCE_loss: 0.0151 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.01058\n",
      "Epoch 432/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0256 - val_fcn_BCE_loss: 0.0247\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.01058\n",
      "Epoch 433/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0207 - fcn_BCE_loss: 0.0197 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.01058\n",
      "Epoch 434/820\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0168 - fcn_BCE_loss: 0.0159 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0096\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.01058 to 0.01056, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0434.h5\n",
      "Epoch 435/820\n",
      " 1/10 [==>...........................] - ETA: 57s - loss: 0.0150 - fcn_BCE_loss: 0.0141\n",
      " Bad train_batch_x encountered (training phase) - epoch 434 , image ids: [2957] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.01056\n",
      "Epoch 436/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0264 - fcn_BCE_loss: 0.0254 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.01056\n",
      "Epoch 437/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0173 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 436 , image ids: [1332] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0186 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.01056\n",
      "Epoch 438/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0152 - fcn_BCE_loss: 0.0143 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 437 , image ids: [700] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0142\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.01056\n",
      "Epoch 439/820\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0148 - fcn_BCE_loss: 0.0139\n",
      " Bad train_batch_x encountered (training phase) - epoch 438 , image ids: [744] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0163 - val_loss: 0.0159 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.01056\n",
      "Epoch 440/820\n",
      " 1/10 [==>...........................] - ETA: 1:08 - loss: 0.0207 - fcn_BCE_loss: 0.0197\n",
      " Bad train_batch_x encountered (training phase) - epoch 439 , image ids: [3797] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0168 - val_fcn_BCE_loss: 0.0159\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.01056\n",
      "Epoch 441/820\n",
      " 6/10 [=================>............] - ETA: 26s - loss: 0.0209 - fcn_BCE_loss: 0.0200\n",
      " Bad train_batch_x encountered (training phase) - epoch 440 , image ids: [2342] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0199 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0115\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.01056\n",
      "Epoch 442/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0129 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.01056\n",
      "Epoch 443/820\n",
      " 2/10 [=====>........................] - ETA: 1:00 - loss: 0.0373 - fcn_BCE_loss: 0.0363\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [2094] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [2802] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [3490] -- Retry with next sample\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0176 - val_fcn_BCE_loss: 0.0167\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.01056\n",
      "Epoch 444/820\n",
      "10/10 [==============================] - 92s 9s/step - loss: 0.0189 - fcn_BCE_loss: 0.0180 - val_loss: 0.0191 - val_fcn_BCE_loss: 0.0182\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.01056\n",
      "Epoch 445/820\n",
      " 2/10 [=====>........................] - ETA: 59s - loss: 0.0121 - fcn_BCE_loss: 0.0112 \n",
      " Bad train_batch_x encountered (training phase) - epoch 444 , image ids: [2107] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0127 - fcn_BCE_loss: 0.0118 - val_loss: 0.0272 - val_fcn_BCE_loss: 0.0263\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.01056\n",
      "Epoch 446/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 85s 9s/step - loss: 0.0209 - fcn_BCE_loss: 0.0199 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.01056\n",
      "Epoch 447/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0182 - fcn_BCE_loss: 0.0173 - val_loss: 0.0292 - val_fcn_BCE_loss: 0.0283\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.01056\n",
      "Epoch 448/820\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0170 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0269\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.01056\n",
      "Epoch 449/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0170 - fcn_BCE_loss: 0.0160 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 448 , image ids: [891] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0164 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.01056\n",
      "Epoch 450/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.01056 to 0.01034, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0450.h5\n",
      "Epoch 451/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0217 - fcn_BCE_loss: 0.0208 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 450 , image ids: [213] -- Retry with next sample\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0249 - fcn_BCE_loss: 0.0240 - val_loss: 0.0302 - val_fcn_BCE_loss: 0.0293\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.01034\n",
      "Epoch 452/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0165 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.01034\n",
      "Epoch 453/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 452 , image ids: [409] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0179 - fcn_BCE_loss: 0.0170 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 452 , image ids: [268] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0189 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.01034\n",
      "Epoch 454/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0207 - fcn_BCE_loss: 0.0198 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 453 , image ids: [81] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 453 , image ids: [218] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0203 - val_fcn_BCE_loss: 0.0194\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.01034\n",
      "Epoch 455/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0203 - val_fcn_BCE_loss: 0.0194\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.01034\n",
      "Epoch 456/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0106 - fcn_BCE_loss: 0.0097\n",
      " Bad train_batch_x encountered (training phase) - epoch 455 , image ids: [3285] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0133 - fcn_BCE_loss: 0.0124 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0113\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.01034\n",
      "Epoch 457/820\n",
      "10/10 [==============================] - 86s 9s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0092\n",
      "\n",
      "Epoch 00457: val_loss improved from 0.01034 to 0.01010, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0457.h5\n",
      "Epoch 458/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0121 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.01010\n",
      "Epoch 459/820\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0139 - fcn_BCE_loss: 0.0130\n",
      " Bad train_batch_x encountered (training phase) - epoch 458 , image ids: [1849] -- Retry with next sample\n",
      " 8/10 [=======================>......] - ETA: 14s - loss: 0.0122 - fcn_BCE_loss: 0.0113\n",
      " Bad train_batch_x encountered (training phase) - epoch 458 , image ids: [1391] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0116 - fcn_BCE_loss: 0.0107 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 458 , image ids: [709] -- Retry with next sample\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0112 - fcn_BCE_loss: 0.0103 - val_loss: 0.0228 - val_fcn_BCE_loss: 0.0219\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.01010\n",
      "Epoch 460/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0144 - fcn_BCE_loss: 0.0135\n",
      " Bad train_batch_x encountered (training phase) - epoch 459 , image ids: [2015] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0122 - val_loss: 0.0193 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.01010\n",
      "Epoch 461/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0104 - fcn_BCE_loss: 0.0095 - val_loss: 0.0197 - val_fcn_BCE_loss: 0.0188\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.01010\n",
      "Epoch 462/820\n",
      " 2/10 [=====>........................] - ETA: 56s - loss: 0.0154 - fcn_BCE_loss: 0.0145 \n",
      " Bad train_batch_x encountered (training phase) - epoch 461 , image ids: [996] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0102 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.01010\n",
      "Epoch 463/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0157 - val_loss: 0.0237 - val_fcn_BCE_loss: 0.0228\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.01010\n",
      "Epoch 464/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 463 , image ids: [4969] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0128 - fcn_BCE_loss: 0.0119 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.01010\n",
      "Epoch 465/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.01010\n",
      "Epoch 466/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0204 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.01010\n",
      "Epoch 467/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0248 - fcn_BCE_loss: 0.0239 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0113\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.01010\n",
      "Epoch 468/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0208 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.01010\n",
      "Epoch 469/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0266 - fcn_BCE_loss: 0.0257\n",
      " Bad train_batch_x encountered (training phase) - epoch 468 , image ids: [796] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.01010\n",
      "Epoch 470/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0186 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.01010\n",
      "Epoch 471/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0090\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.01010 to 0.00992, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0471.h5\n",
      "Epoch 472/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00992\n",
      "Epoch 473/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 75s 7s/step - loss: 0.0256 - fcn_BCE_loss: 0.0247 - val_loss: 0.0183 - val_fcn_BCE_loss: 0.0174\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00992\n",
      "Epoch 474/820\n",
      " 1/10 [==>...........................] - ETA: 58s - loss: 0.0175 - fcn_BCE_loss: 0.0166\n",
      " Bad train_batch_x encountered (training phase) - epoch 473 , image ids: [2956] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0116 - fcn_BCE_loss: 0.0107 - val_loss: 0.0147 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00992\n",
      "Epoch 475/820\n",
      " 5/10 [==============>...............] - ETA: 33s - loss: 0.0289 - fcn_BCE_loss: 0.0280\n",
      " Bad train_batch_x encountered (training phase) - epoch 474 , image ids: [792] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0231 - fcn_BCE_loss: 0.0222 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00992\n",
      "Epoch 476/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0142 - fcn_BCE_loss: 0.0133 \n",
      " Bad train_batch_x encountered (training phase) - epoch 475 , image ids: [731] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 475 , image ids: [241] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00992\n",
      "Epoch 477/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0175 - fcn_BCE_loss: 0.0166 - val_loss: 0.0154 - val_fcn_BCE_loss: 0.0145\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00992\n",
      "Epoch 478/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00992\n",
      "Epoch 479/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0206 - fcn_BCE_loss: 0.0197 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0097\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00992\n",
      "Epoch 480/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0175 - fcn_BCE_loss: 0.0166 - val_loss: 0.0133 - val_fcn_BCE_loss: 0.0124\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00992\n",
      "Epoch 481/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00992\n",
      "Epoch 482/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0164 - fcn_BCE_loss: 0.0155 - val_loss: 0.0085 - val_fcn_BCE_loss: 0.0076\n",
      "\n",
      "Epoch 00482: val_loss improved from 0.00992 to 0.00847, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0482.h5\n",
      "Epoch 483/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0222 - fcn_BCE_loss: 0.0213 - val_loss: 0.0086 - val_fcn_BCE_loss: 0.0077\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00847\n",
      "Epoch 484/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00847\n",
      "Epoch 485/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0231 - val_fcn_BCE_loss: 0.0222\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00847\n",
      "Epoch 486/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0170 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00847\n",
      "Epoch 487/820\n",
      " 4/10 [===========>..................] - ETA: 42s - loss: 0.0227 - fcn_BCE_loss: 0.0218\n",
      " Bad train_batch_x encountered (training phase) - epoch 486 , image ids: [406] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0148 - fcn_BCE_loss: 0.0139 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 486 , image ids: [984] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0244 - val_fcn_BCE_loss: 0.0235\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00847\n",
      "Epoch 488/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0167 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00847\n",
      "Epoch 489/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00847\n",
      "Epoch 490/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00847\n",
      "Epoch 491/820\n",
      " 1/10 [==>...........................] - ETA: 58s - loss: 0.0100 - fcn_BCE_loss: 0.0091\n",
      " Bad train_batch_x encountered (training phase) - epoch 490 , image ids: [2601] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0136 - fcn_BCE_loss: 0.0127\n",
      " Bad train_batch_x encountered (training phase) - epoch 490 , image ids: [144] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00847\n",
      "Epoch 492/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0176 - val_fcn_BCE_loss: 0.0167\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00847\n",
      "Epoch 493/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0193 - fcn_BCE_loss: 0.0184 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 492 , image ids: [310] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00847\n",
      "Epoch 494/820\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0238 - fcn_BCE_loss: 0.0229\n",
      " Bad train_batch_x encountered (training phase) - epoch 493 , image ids: [3189] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0204 - val_loss: 0.0247 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00847\n",
      "Epoch 495/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 494 , image ids: [1983] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0227 - fcn_BCE_loss: 0.0218 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 494 , image ids: [429] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0203 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00847\n",
      "Epoch 496/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0122 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00847\n",
      "Epoch 497/820\n",
      " 4/10 [===========>..................] - ETA: 46s - loss: 0.0138 - fcn_BCE_loss: 0.0129\n",
      " Bad train_batch_x encountered (training phase) - epoch 496 , image ids: [2941] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0412 - val_fcn_BCE_loss: 0.0403\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00847\n",
      "Epoch 498/820\n",
      " 1/10 [==>...........................] - ETA: 1:02 - loss: 0.0088 - fcn_BCE_loss: 0.0079\n",
      " Bad train_batch_x encountered (training phase) - epoch 497 , image ids: [2968] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0089\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00847\n",
      "Epoch 499/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0070 - fcn_BCE_loss: 0.0061\n",
      " Bad train_batch_x encountered (training phase) - epoch 498 , image ids: [4968] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0084 - fcn_BCE_loss: 0.0075 - val_loss: 0.0196 - val_fcn_BCE_loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00847\n",
      "Epoch 500/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0169 - fcn_BCE_loss: 0.0160 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00847\n",
      "Epoch 501/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0287 - fcn_BCE_loss: 0.0278 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00847\n",
      "Epoch 502/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0187 - fcn_BCE_loss: 0.0178 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00847\n",
      "Epoch 503/820\n",
      " 3/10 [========>.....................] - ETA: 57s - loss: 0.0133 - fcn_BCE_loss: 0.0124 \n",
      " Bad train_batch_x encountered (training phase) - epoch 502 , image ids: [2234] -- Retry with next sample\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0139 - fcn_BCE_loss: 0.0131 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00847\n",
      "Epoch 504/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00847\n",
      "Epoch 505/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0121 - fcn_BCE_loss: 0.0112 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 504 , image ids: [766] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00847\n",
      "Epoch 506/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0142 - fcn_BCE_loss: 0.0133 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 505 , image ids: [736] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0201 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00847\n",
      "Epoch 507/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0232 - val_fcn_BCE_loss: 0.0223\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00847\n",
      "Epoch 508/820\n",
      " 3/10 [========>.....................] - ETA: 47s - loss: 0.0257 - fcn_BCE_loss: 0.0249\n",
      " Bad train_batch_x encountered (training phase) - epoch 507 , image ids: [953] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00847\n",
      "Epoch 509/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 508 , image ids: [650] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0105 - fcn_BCE_loss: 0.0097 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00847\n",
      "Epoch 510/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0137 - fcn_BCE_loss: 0.0128 \n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [2114] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 42s - loss: 0.0115 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [1468] -- Retry with next sample\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0119 - fcn_BCE_loss: 0.0110\n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [4291] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0149 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00847\n",
      "Epoch 511/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0131 - val_fcn_BCE_loss: 0.0122\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00847\n",
      "Epoch 512/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0118 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00847\n",
      "Epoch 513/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0247 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00847\n",
      "Epoch 514/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0176 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00847\n",
      "Epoch 515/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0182 - fcn_BCE_loss: 0.0173 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0099\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00847\n",
      "Epoch 516/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0193 - fcn_BCE_loss: 0.0185 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00847\n",
      "Epoch 517/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0247 - fcn_BCE_loss: 0.0238 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 516 , image ids: [207] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0196 - val_fcn_BCE_loss: 0.0188\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00847\n",
      "Epoch 518/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0190 - fcn_BCE_loss: 0.0181 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 517 , image ids: [539] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00847\n",
      "Epoch 519/820\n",
      " 1/10 [==>...........................] - ETA: 1:03 - loss: 0.0074 - fcn_BCE_loss: 0.0065\n",
      " Bad train_batch_x encountered (training phase) - epoch 518 , image ids: [4245] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 47s - loss: 0.0155 - fcn_BCE_loss: 0.0146\n",
      " Bad train_batch_x encountered (training phase) - epoch 518 , image ids: [936] -- Retry with next sample\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00847\n",
      "Epoch 520/820\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0189 - fcn_BCE_loss: 0.0181 - val_loss: 0.0171 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00847\n",
      "Epoch 521/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0071 - val_fcn_BCE_loss: 0.0062\n",
      "\n",
      "Epoch 00521: val_loss improved from 0.00847 to 0.00708, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0521.h5\n",
      "Epoch 522/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0127\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00708\n",
      "Epoch 523/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0234 - val_fcn_BCE_loss: 0.0225\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00708\n",
      "Epoch 524/820\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0172 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 523 , image ids: [2970] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0203 - val_loss: 0.0306 - val_fcn_BCE_loss: 0.0298\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.00708\n",
      "Epoch 525/820\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.0165 - fcn_BCE_loss: 0.0156 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.00708\n",
      "Epoch 526/820\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.00708\n",
      "Epoch 527/820\n",
      " 1/10 [==>...........................] - ETA: 2:03 - loss: 0.0078 - fcn_BCE_loss: 0.0070\n",
      " Bad train_batch_x encountered (training phase) - epoch 526 , image ids: [597] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 94s 9s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0127\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.00708\n",
      "Epoch 528/820\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.0183 - fcn_BCE_loss: 0.0174 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.00708\n",
      "Epoch 529/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 528 , image ids: [2116] -- Retry with next sample\n",
      "10/10 [==============================] - 150s 15s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0226 - val_fcn_BCE_loss: 0.0217\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.00708\n",
      "Epoch 530/820\n",
      "10/10 [==============================] - 146s 15s/step - loss: 0.0141 - fcn_BCE_loss: 0.0133 - val_loss: 0.0172 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.00708\n",
      "Epoch 531/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0200 - fcn_BCE_loss: 0.0192 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.00708\n",
      "Epoch 532/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0179 - val_fcn_BCE_loss: 0.0171\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.00708\n",
      "Epoch 533/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0234 - fcn_BCE_loss: 0.0225 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.00708\n",
      "Epoch 534/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0160 - fcn_BCE_loss: 0.0151 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 533 , image ids: [658] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0163 - fcn_BCE_loss: 0.0154 - val_loss: 0.0214 - val_fcn_BCE_loss: 0.0205\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.00708\n",
      "Epoch 535/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0317 - fcn_BCE_loss: 0.0308 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.00708\n",
      "Epoch 536/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0215 - fcn_BCE_loss: 0.0206 - val_loss: 0.0246 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.00708\n",
      "Epoch 537/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0157 - fcn_BCE_loss: 0.0148 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.00708\n",
      "Epoch 538/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0239 - val_fcn_BCE_loss: 0.0231\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.00708\n",
      "Epoch 539/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0176\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.00708\n",
      "Epoch 540/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0204 - fcn_BCE_loss: 0.0195 - val_loss: 0.0242 - val_fcn_BCE_loss: 0.0233\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.00708\n",
      "Epoch 541/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0214 - fcn_BCE_loss: 0.0205 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 540 , image ids: [747] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.00708\n",
      "Epoch 542/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0085 - fcn_BCE_loss: 0.0076 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0115\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.00708\n",
      "Epoch 543/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0150 - fcn_BCE_loss: 0.0142 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.00708\n",
      "Epoch 544/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0096 - fcn_BCE_loss: 0.0088 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.00708\n",
      "Epoch 545/820\n",
      " 7/10 [====================>.........] - ETA: 19s - loss: 0.0192 - fcn_BCE_loss: 0.0183\n",
      " Bad train_batch_x encountered (training phase) - epoch 544 , image ids: [3822] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0150 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0086\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.00708\n",
      "Epoch 546/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0284 - fcn_BCE_loss: 0.0275 - val_loss: 0.0269 - val_fcn_BCE_loss: 0.0260\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.00708\n",
      "Epoch 547/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0131 - val_fcn_BCE_loss: 0.0123\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.00708\n",
      "Epoch 548/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.00708\n",
      "Epoch 549/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0243 - fcn_BCE_loss: 0.0234 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.00708\n",
      "Epoch 550/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.00708\n",
      "Epoch 551/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.00708\n",
      "Epoch 552/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0242 - fcn_BCE_loss: 0.0233 - val_loss: 0.0232 - val_fcn_BCE_loss: 0.0224\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.00708\n",
      "Epoch 553/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0227 - fcn_BCE_loss: 0.0219 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.00708\n",
      "Epoch 554/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0124 - fcn_BCE_loss: 0.0116 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.00708\n",
      "Epoch 555/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0150 - fcn_BCE_loss: 0.0142 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0103\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.00708\n",
      "Epoch 556/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0221 - fcn_BCE_loss: 0.0212 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 555 , image ids: [746] -- Retry with next sample\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0171 - val_fcn_BCE_loss: 0.0162\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.00708\n",
      "Epoch 557/820\n",
      " 5/10 [==============>...............] - ETA: 31s - loss: 0.0183 - fcn_BCE_loss: 0.0174\n",
      " Bad train_batch_x encountered (training phase) - epoch 556 , image ids: [3903] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 19s - loss: 0.0162 - fcn_BCE_loss: 0.0153\n",
      " Bad train_batch_x encountered (training phase) - epoch 556 , image ids: [2869] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0216 - fcn_BCE_loss: 0.0207 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 556 , image ids: [379] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0225 - fcn_BCE_loss: 0.0217 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0202\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.00708\n",
      "Epoch 558/820\n",
      " 8/10 [=======================>......] - ETA: 12s - loss: 0.0126 - fcn_BCE_loss: 0.0117\n",
      " Bad train_batch_x encountered (training phase) - epoch 557 , image ids: [3218] -- Retry with next sample\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.00708\n",
      "Epoch 559/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 558 , image ids: [4658] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 76s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.00708\n",
      "Epoch 560/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0202 - fcn_BCE_loss: 0.0193\n",
      " Bad train_batch_x encountered (training phase) - epoch 559 , image ids: [4777] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0184 - fcn_BCE_loss: 0.0175 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.00708\n",
      "Epoch 561/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0237 - fcn_BCE_loss: 0.0228 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.00708\n",
      "Epoch 562/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.00708\n",
      "Epoch 563/820\n",
      " 3/10 [========>.....................] - ETA: 45s - loss: 0.0094 - fcn_BCE_loss: 0.0086\n",
      " Bad train_batch_x encountered (training phase) - epoch 562 , image ids: [3288] -- Retry with next sample\n",
      " 5/10 [==============>...............] - ETA: 33s - loss: 0.0124 - fcn_BCE_loss: 0.0115\n",
      " Bad train_batch_x encountered (training phase) - epoch 562 , image ids: [3351] -- Retry with next sample\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0120 - fcn_BCE_loss: 0.0111 - val_loss: 0.0159 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.00708\n",
      "Epoch 564/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0263 - fcn_BCE_loss: 0.0255 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.00708\n",
      "Epoch 565/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0162 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.00708\n",
      "Epoch 566/820\n",
      " 4/10 [===========>..................] - ETA: 38s - loss: 0.0116 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 565 , image ids: [1816] -- Retry with next sample\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0203 - fcn_BCE_loss: 0.0194 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.00708\n",
      "Epoch 567/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 566 , image ids: [2997] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0224 - fcn_BCE_loss: 0.0215 - val_loss: 0.0155 - val_fcn_BCE_loss: 0.0146\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.00708\n",
      "Epoch 568/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0113 - fcn_BCE_loss: 0.0104\n",
      " Bad train_batch_x encountered (training phase) - epoch 567 , image ids: [3211] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.00708\n",
      "Epoch 569/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0260 - val_fcn_BCE_loss: 0.0252\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.00708\n",
      "Epoch 570/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.00708\n",
      "Epoch 571/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0270\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.00708\n",
      "Epoch 572/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0125 - fcn_BCE_loss: 0.0116 - val_loss: 0.0184 - val_fcn_BCE_loss: 0.0175\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.00708\n",
      "Epoch 573/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0061 - fcn_BCE_loss: 0.0052 \n",
      " Bad train_batch_x encountered (training phase) - epoch 572 , image ids: [4650] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.00708\n",
      "Epoch 574/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0123 - fcn_BCE_loss: 0.0114 - val_loss: 0.0117 - val_fcn_BCE_loss: 0.0108\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.00708\n",
      "Epoch 575/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0166\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.00708\n",
      "Epoch 576/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0149 - fcn_BCE_loss: 0.0141\n",
      " Bad train_batch_x encountered (training phase) - epoch 575 , image ids: [4627] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0153 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.00708\n",
      "Epoch 577/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0130 - val_fcn_BCE_loss: 0.0122\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.00708\n",
      "Epoch 578/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0127 - fcn_BCE_loss: 0.0118 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.00708\n",
      "Epoch 579/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0127 - fcn_BCE_loss: 0.0119\n",
      " Bad train_batch_x encountered (training phase) - epoch 578 , image ids: [3168] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0100 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.00708\n",
      "Epoch 580/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0216 - fcn_BCE_loss: 0.0207 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.00708\n",
      "Epoch 581/820\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0109 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.00708\n",
      "Epoch 582/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0156 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.00708\n",
      "Epoch 583/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0089 - val_fcn_BCE_loss: 0.0081\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.00708\n",
      "Epoch 584/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0182 - fcn_BCE_loss: 0.0174 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [45] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [63] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [621] -- Retry with next sample\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.00708\n",
      "Epoch 585/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0099 - fcn_BCE_loss: 0.0090 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 584 , image ids: [431] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0098 - fcn_BCE_loss: 0.0089 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.00708\n",
      "Epoch 586/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.00708\n",
      "Epoch 587/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0223 - fcn_BCE_loss: 0.0215 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.00708\n",
      "Epoch 588/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 75s 7s/step - loss: 0.0130 - fcn_BCE_loss: 0.0121 - val_loss: 0.0169 - val_fcn_BCE_loss: 0.0160\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.00708\n",
      "Epoch 589/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0152 - fcn_BCE_loss: 0.0144 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.00708\n",
      "Epoch 590/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0138 - fcn_BCE_loss: 0.0129 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.00708\n",
      "Epoch 591/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0206 - fcn_BCE_loss: 0.0197\n",
      " Bad train_batch_x encountered (training phase) - epoch 590 , image ids: [4536] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0297 - val_fcn_BCE_loss: 0.0288\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.00708\n",
      "Epoch 592/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0118 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.00708\n",
      "Epoch 593/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0117 - fcn_BCE_loss: 0.0108 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.00708\n",
      "Epoch 594/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.00708\n",
      "Epoch 595/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 594 , image ids: [2229] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.00708\n",
      "Epoch 596/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0087 - fcn_BCE_loss: 0.0079 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 595 , image ids: [371] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0092 - fcn_BCE_loss: 0.0083 - val_loss: 0.0081 - val_fcn_BCE_loss: 0.0072\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.00708\n",
      "Epoch 597/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.00708\n",
      "Epoch 598/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0254 - fcn_BCE_loss: 0.0245 - val_loss: 0.0213 - val_fcn_BCE_loss: 0.0205\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.00708\n",
      "Epoch 599/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0116 - fcn_BCE_loss: 0.0108 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.00708\n",
      "Epoch 600/820\n",
      " 1/10 [==>...........................] - ETA: 1:00 - loss: 0.0428 - fcn_BCE_loss: 0.0420\n",
      " Bad train_batch_x encountered (training phase) - epoch 599 , image ids: [3466] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0157 - fcn_BCE_loss: 0.0149 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.00708\n",
      "Epoch 601/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0146 - fcn_BCE_loss: 0.0137 - val_loss: 0.0318 - val_fcn_BCE_loss: 0.0309\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.00708\n",
      "Epoch 602/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0234 - fcn_BCE_loss: 0.0226\n",
      " Bad train_batch_x encountered (training phase) - epoch 601 , image ids: [174] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 601 , image ids: [3080] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0238 - fcn_BCE_loss: 0.0229 - val_loss: 0.0388 - val_fcn_BCE_loss: 0.0379\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.00708\n",
      "Epoch 603/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0241 - fcn_BCE_loss: 0.0233 - val_loss: 0.0197 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.00708\n",
      "Epoch 604/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0116\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.00708\n",
      "Epoch 605/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0220 - fcn_BCE_loss: 0.0211 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.00708\n",
      "Epoch 606/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0125 - fcn_BCE_loss: 0.0117 \n",
      " Bad train_batch_x encountered (training phase) - epoch 605 , image ids: [413] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0160 - fcn_BCE_loss: 0.0152 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 605 , image ids: [738] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 605 , image ids: [710] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0080 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.00708\n",
      "Epoch 607/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0263 - fcn_BCE_loss: 0.0254 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.00708\n",
      "Epoch 608/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0090 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.00708\n",
      "Epoch 609/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0152 - fcn_BCE_loss: 0.0143\n",
      " Bad train_batch_x encountered (training phase) - epoch 608 , image ids: [202] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0172 - val_loss: 0.0238 - val_fcn_BCE_loss: 0.0230\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.00708\n",
      "Epoch 610/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0203 - fcn_BCE_loss: 0.0194 \n",
      " Bad train_batch_x encountered (training phase) - epoch 609 , image ids: [1715] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0070 - val_fcn_BCE_loss: 0.0062\n",
      "\n",
      "Epoch 00610: val_loss improved from 0.00708 to 0.00702, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0610.h5\n",
      "Epoch 611/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0107 - fcn_BCE_loss: 0.0099 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.00702\n",
      "Epoch 612/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0121 - val_loss: 0.0294 - val_fcn_BCE_loss: 0.0286\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.00702\n",
      "Epoch 613/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0138 - fcn_BCE_loss: 0.0130 \n",
      " Bad train_batch_x encountered (training phase) - epoch 612 , image ids: [937] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0171 - fcn_BCE_loss: 0.0162 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 612 , image ids: [356] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 612 , image ids: [764] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.00702\n",
      "Epoch 614/820\n",
      " 1/10 [==>...........................] - ETA: 59s - loss: 0.0041 - fcn_BCE_loss: 0.0032\n",
      " Bad train_batch_x encountered (training phase) - epoch 613 , image ids: [184] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0230 - val_fcn_BCE_loss: 0.0221\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.00702\n",
      "Epoch 615/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 80s 8s/step - loss: 0.0250 - fcn_BCE_loss: 0.0241 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.00702\n",
      "Epoch 616/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0179 - val_loss: 0.0084 - val_fcn_BCE_loss: 0.0076\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.00702\n",
      "Epoch 617/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.00702\n",
      "Epoch 618/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0181 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.00702\n",
      "Epoch 619/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0177 - fcn_BCE_loss: 0.0169\n",
      " Bad train_batch_x encountered (training phase) - epoch 618 , image ids: [4182] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0204 - fcn_BCE_loss: 0.0196\n",
      " Bad train_batch_x encountered (training phase) - epoch 618 , image ids: [1174] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0217 - fcn_BCE_loss: 0.0209 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.00702\n",
      "Epoch 620/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0136 - fcn_BCE_loss: 0.0127 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 619 , image ids: [155] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0157 - val_loss: 0.0081 - val_fcn_BCE_loss: 0.0073\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.00702\n",
      "Epoch 621/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0139 - fcn_BCE_loss: 0.0130 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 620 , image ids: [706] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0136 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.00702\n",
      "Epoch 622/820\n",
      " 3/10 [========>.....................] - ETA: 51s - loss: 0.0195 - fcn_BCE_loss: 0.0187\n",
      " Bad train_batch_x encountered (training phase) - epoch 621 , image ids: [1367] -- Retry with next sample\n",
      "10/10 [==============================] - 86s 9s/step - loss: 0.0223 - fcn_BCE_loss: 0.0214 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.00702\n",
      "Epoch 623/820\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0164 - val_fcn_BCE_loss: 0.0155\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.00702\n",
      "Epoch 624/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0265 - val_fcn_BCE_loss: 0.0257\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.00702\n",
      "Epoch 625/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0219 - fcn_BCE_loss: 0.0210\n",
      " Bad train_batch_x encountered (training phase) - epoch 624 , image ids: [3864] -- Retry with next sample\n",
      " 8/10 [=======================>......] - ETA: 14s - loss: 0.0201 - fcn_BCE_loss: 0.0193\n",
      " Bad train_batch_x encountered (training phase) - epoch 624 , image ids: [2710] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0185\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.00702\n",
      "Epoch 626/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0152 - fcn_BCE_loss: 0.0143 - val_loss: 0.0156 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.00702\n",
      "Epoch 627/820\n",
      " 1/10 [==>...........................] - ETA: 1:05 - loss: 0.0127 - fcn_BCE_loss: 0.0118\n",
      " Bad train_batch_x encountered (training phase) - epoch 626 , image ids: [2407] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.00702\n",
      "Epoch 628/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0118 - fcn_BCE_loss: 0.0109 - val_loss: 0.0200 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.00702\n",
      "Epoch 629/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 628 , image ids: [1255] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0116\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.00702\n",
      "Epoch 630/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0105 - fcn_BCE_loss: 0.0097 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 629 , image ids: [429] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0112 - fcn_BCE_loss: 0.0103 - val_loss: 0.0089 - val_fcn_BCE_loss: 0.0080\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.00702\n",
      "Epoch 631/820\n",
      " 3/10 [========>.....................] - ETA: 47s - loss: 0.0225 - fcn_BCE_loss: 0.0216\n",
      " Bad train_batch_x encountered (training phase) - epoch 630 , image ids: [3845] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0121 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.00702\n",
      "Epoch 632/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.00702\n",
      "Epoch 633/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0147 - fcn_BCE_loss: 0.0138 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.00702\n",
      "Epoch 634/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0293 - val_fcn_BCE_loss: 0.0284\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.00702\n",
      "Epoch 635/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0207 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 634 , image ids: [4049] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0205 - val_loss: 0.0094 - val_fcn_BCE_loss: 0.0085\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.00702\n",
      "Epoch 636/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0193 - fcn_BCE_loss: 0.0185 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 635 , image ids: [230] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0091 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.00702\n",
      "Epoch 637/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0226 - fcn_BCE_loss: 0.0218 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.00702\n",
      "Epoch 638/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0157 - fcn_BCE_loss: 0.0148 - val_loss: 0.0295 - val_fcn_BCE_loss: 0.0287\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.00702\n",
      "Epoch 639/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.00702\n",
      "Epoch 640/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0149 - fcn_BCE_loss: 0.0141 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.00702\n",
      "Epoch 641/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0172 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.00702\n",
      "Epoch 642/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.00702\n",
      "Epoch 643/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0289 - fcn_BCE_loss: 0.0280\n",
      " Bad train_batch_x encountered (training phase) - epoch 642 , image ids: [3790] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0287 - fcn_BCE_loss: 0.0278 - val_loss: 0.0113 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.00702\n",
      "Epoch 644/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0172 - fcn_BCE_loss: 0.0163 \n",
      " Bad train_batch_x encountered (training phase) - epoch 643 , image ids: [122] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0153 - val_loss: 0.0235 - val_fcn_BCE_loss: 0.0227\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.00702\n",
      "Epoch 645/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0224 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.00702\n",
      "Epoch 646/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0109 - fcn_BCE_loss: 0.0101 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 645 , image ids: [126] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0167 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.00702\n",
      "Epoch 647/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0157 - val_loss: 0.0115 - val_fcn_BCE_loss: 0.0106\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.00702\n",
      "Epoch 648/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.00702\n",
      "Epoch 649/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0208 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 648 , image ids: [3237] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0236 - fcn_BCE_loss: 0.0227 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.00702\n",
      "Epoch 650/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0167 - fcn_BCE_loss: 0.0159 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 649 , image ids: [278] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0147 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.00702\n",
      "Epoch 651/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0187 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.00702\n",
      "Epoch 652/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0207 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 651 , image ids: [4140] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0256 - fcn_BCE_loss: 0.0248 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 651 , image ids: [379] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0240 - fcn_BCE_loss: 0.0232 - val_loss: 0.0139 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.00702\n",
      "Epoch 653/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0070\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.00702\n",
      "Epoch 654/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0103 - fcn_BCE_loss: 0.0095 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.00702\n",
      "Epoch 655/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.00702\n",
      "Epoch 656/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0165 - val_loss: 0.0294 - val_fcn_BCE_loss: 0.0285\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.00702\n",
      "Epoch 657/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0115 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 656 , image ids: [3672] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.00702\n",
      "Epoch 658/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.00702\n",
      "Epoch 659/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0159 - fcn_BCE_loss: 0.0151\n",
      " Bad train_batch_x encountered (training phase) - epoch 658 , image ids: [2245] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0133 - val_fcn_BCE_loss: 0.0124\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.00702\n",
      "Epoch 660/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0208 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.00702\n",
      "Epoch 661/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0083 - fcn_BCE_loss: 0.0075 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 660 , image ids: [912] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 660 , image ids: [533] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0083 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.00702\n",
      "Epoch 662/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0132 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.00702\n",
      "Epoch 663/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0179 - val_loss: 0.0088 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.00702\n",
      "Epoch 664/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0166 - fcn_BCE_loss: 0.0158 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 663 , image ids: [736] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.00702\n",
      "Epoch 665/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.00702\n",
      "Epoch 666/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0148 - fcn_BCE_loss: 0.0139\n",
      " Bad train_batch_x encountered (training phase) - epoch 665 , image ids: [4718] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.00702\n",
      "Epoch 667/820\n",
      " 2/10 [=====>........................] - ETA: 1:01 - loss: 0.0244 - fcn_BCE_loss: 0.0236\n",
      " Bad train_batch_x encountered (training phase) - epoch 666 , image ids: [4900] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0080 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.00702\n",
      "Epoch 668/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.00702\n",
      "Epoch 669/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.00702\n",
      "Epoch 670/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0176 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00670: val_loss did not improve from 0.00702\n",
      "Epoch 671/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0299 - fcn_BCE_loss: 0.0290 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.00702\n",
      "Epoch 672/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0103 - fcn_BCE_loss: 0.0094 - val_loss: 0.0199 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.00702\n",
      "Epoch 673/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.00702\n",
      "Epoch 674/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0151 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0119\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.00702\n",
      "Epoch 675/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0280 - fcn_BCE_loss: 0.0271\n",
      " Bad train_batch_x encountered (training phase) - epoch 674 , image ids: [1363] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0251 - fcn_BCE_loss: 0.0242 - val_loss: 0.0113 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.00702\n",
      "Epoch 676/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.00702\n",
      "Epoch 677/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0175 - fcn_BCE_loss: 0.0166 \n",
      " Bad train_batch_x encountered (training phase) - epoch 676 , image ids: [1899] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0163 - val_loss: 0.0170 - val_fcn_BCE_loss: 0.0161\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.00702\n",
      "Epoch 678/820\n",
      " 1/10 [==>...........................] - ETA: 1:04 - loss: 0.0053 - fcn_BCE_loss: 0.0045\n",
      " Bad train_batch_x encountered (training phase) - epoch 677 , image ids: [541] -- Retry with next sample\n",
      " 3/10 [========>.....................] - ETA: 51s - loss: 0.0195 - fcn_BCE_loss: 0.0186 \n",
      " Bad train_batch_x encountered (training phase) - epoch 677 , image ids: [1389] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0253 - fcn_BCE_loss: 0.0245 - val_loss: 0.0217 - val_fcn_BCE_loss: 0.0209\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.00702\n",
      "Epoch 679/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.00702\n",
      "Epoch 680/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0198 - fcn_BCE_loss: 0.0189\n",
      " Bad train_batch_x encountered (training phase) - epoch 679 , image ids: [2327] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0176 - fcn_BCE_loss: 0.0168 \n",
      " Bad train_batch_x encountered (training phase) - epoch 679 , image ids: [1271] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0164 - fcn_BCE_loss: 0.0156 - val_loss: 0.0273 - val_fcn_BCE_loss: 0.0264\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.00702\n",
      "Epoch 681/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.00702\n",
      "Epoch 682/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0160 - fcn_BCE_loss: 0.0152\n",
      " Bad train_batch_x encountered (training phase) - epoch 681 , image ids: [1068] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0214 - fcn_BCE_loss: 0.0206 - val_loss: 0.0326 - val_fcn_BCE_loss: 0.0317\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.00702\n",
      "Epoch 683/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0106 - fcn_BCE_loss: 0.0098 - val_loss: 0.0078 - val_fcn_BCE_loss: 0.0070\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.00702\n",
      "Epoch 684/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.00702\n",
      "Epoch 685/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0235 - fcn_BCE_loss: 0.0226\n",
      " Bad train_batch_x encountered (training phase) - epoch 684 , image ids: [1252] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.00702\n",
      "Epoch 686/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0153 - fcn_BCE_loss: 0.0145\n",
      " Bad train_batch_x encountered (training phase) - epoch 685 , image ids: [2536] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.00702\n",
      "Epoch 687/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0224 - fcn_BCE_loss: 0.0216 - val_loss: 0.0066 - val_fcn_BCE_loss: 0.0058\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.00702 to 0.00660, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0687.h5\n",
      "Epoch 688/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0117 - fcn_BCE_loss: 0.0108 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 687 , image ids: [384] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.00660\n",
      "Epoch 689/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0097 - fcn_BCE_loss: 0.0089 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.00660\n",
      "Epoch 690/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.00660\n",
      "Epoch 691/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0156 - fcn_BCE_loss: 0.0148 \n",
      " Bad train_batch_x encountered (training phase) - epoch 690 , image ids: [4069] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0116 - val_loss: 0.0172 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.00660\n",
      "Epoch 692/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0200 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.00660\n",
      "Epoch 693/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0225 - fcn_BCE_loss: 0.0216 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 692 , image ids: [579] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0251 - val_fcn_BCE_loss: 0.0242\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.00660\n",
      "Epoch 694/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.00660\n",
      "Epoch 695/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0132 - fcn_BCE_loss: 0.0124 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 694 , image ids: [865] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0135 - fcn_BCE_loss: 0.0127 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0186\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.00660\n",
      "Epoch 696/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0250 - fcn_BCE_loss: 0.0241 - val_loss: 0.0269 - val_fcn_BCE_loss: 0.0260\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.00660\n",
      "Epoch 697/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 696 , image ids: [236] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 696 , image ids: [4909] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 79s 8s/step - loss: 0.0146 - fcn_BCE_loss: 0.0138 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.00660\n",
      "Epoch 698/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.00660\n",
      "Epoch 699/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0187 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.00660\n",
      "Epoch 700/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0190 - fcn_BCE_loss: 0.0182 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 699 , image ids: [718] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0222 - fcn_BCE_loss: 0.0214 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.00660\n",
      "Epoch 701/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 700 , image ids: [800] -- Retry with next sample\n",
      " 2/10 [=====>........................] - ETA: 59s - loss: 0.0213 - fcn_BCE_loss: 0.0204 \n",
      " Bad train_batch_x encountered (training phase) - epoch 700 , image ids: [1600] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0189 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0149\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.00660\n",
      "Epoch 702/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0156 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0142\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.00660\n",
      "Epoch 703/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0172 - fcn_BCE_loss: 0.0164 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 702 , image ids: [241] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.00660\n",
      "Epoch 704/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0245 - fcn_BCE_loss: 0.0237\n",
      " Bad train_batch_x encountered (training phase) - epoch 703 , image ids: [4890] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0230 - fcn_BCE_loss: 0.0221 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 703 , image ids: [709] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.00660\n",
      "Epoch 705/820\n",
      " 1/10 [==>...........................] - ETA: 1:05 - loss: 0.0241 - fcn_BCE_loss: 0.0232\n",
      " Bad train_batch_x encountered (training phase) - epoch 704 , image ids: [2863] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0181 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.00660\n",
      "Epoch 706/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0113 - fcn_BCE_loss: 0.0105 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0171\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.00660\n",
      "Epoch 707/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0095\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.00660\n",
      "Epoch 708/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0149 - fcn_BCE_loss: 0.0140 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.00660\n",
      "Epoch 709/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0153 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.00660\n",
      "Epoch 710/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0155\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.00660\n",
      "Epoch 711/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 710 , image ids: [3422] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.00660\n",
      "Epoch 712/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.00660\n",
      "Epoch 713/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0202 - fcn_BCE_loss: 0.0194 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0114\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.00660\n",
      "Epoch 714/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 713 , image ids: [532] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0203 - fcn_BCE_loss: 0.0195\n",
      " Bad train_batch_x encountered (training phase) - epoch 713 , image ids: [1369] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0091 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.00660\n",
      "Epoch 715/820\n",
      " 1/10 [==>...........................] - ETA: 1:02 - loss: 0.0253 - fcn_BCE_loss: 0.0245\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [4226] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 43s - loss: 0.0166 - fcn_BCE_loss: 0.0158\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [1394] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [2056] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 22s - loss: 0.0223 - fcn_BCE_loss: 0.0214\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [3569] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0270\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.00660\n",
      "Epoch 716/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0257 - fcn_BCE_loss: 0.0248 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.00660\n",
      "Epoch 717/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0133 - fcn_BCE_loss: 0.0125 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0119\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.00660\n",
      "Epoch 718/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0245 - fcn_BCE_loss: 0.0236 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.00660\n",
      "Epoch 719/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0216 - fcn_BCE_loss: 0.0208 \n",
      " Bad train_batch_x encountered (training phase) - epoch 718 , image ids: [1360] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 718 , image ids: [313] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0203 - fcn_BCE_loss: 0.0195 - val_loss: 0.0280 - val_fcn_BCE_loss: 0.0272\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.00660\n",
      "Epoch 720/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.00660\n",
      "Epoch 721/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0156 - fcn_BCE_loss: 0.0148\n",
      " Bad train_batch_x encountered (training phase) - epoch 720 , image ids: [3530] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0150 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.00660\n",
      "Epoch 722/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0205 - val_loss: 0.0074 - val_fcn_BCE_loss: 0.0065\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.00660\n",
      "Epoch 723/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/10 [=====>........................] - ETA: 53s - loss: 0.0151 - fcn_BCE_loss: 0.0143 \n",
      " Bad train_batch_x encountered (training phase) - epoch 722 , image ids: [1305] -- Retry with next sample\n",
      " 3/10 [========>.....................] - ETA: 49s - loss: 0.0130 - fcn_BCE_loss: 0.0121\n",
      " Bad train_batch_x encountered (training phase) - epoch 722 , image ids: [3914] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0177 - fcn_BCE_loss: 0.0169 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 722 , image ids: [192] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0183 - fcn_BCE_loss: 0.0174 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0185\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.00660\n",
      "Epoch 724/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0150 - fcn_BCE_loss: 0.0142 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 723 , image ids: [700] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0135 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.00660\n",
      "Epoch 725/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0247 - fcn_BCE_loss: 0.0239 - val_loss: 0.0173 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.00660\n",
      "Epoch 726/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0120 - fcn_BCE_loss: 0.0111 - val_loss: 0.0261 - val_fcn_BCE_loss: 0.0253\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.00660\n",
      "Epoch 727/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0114\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.00660\n",
      "Epoch 728/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.00660\n",
      "Epoch 729/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0241 - fcn_BCE_loss: 0.0232 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.00660\n",
      "Epoch 730/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0069 - val_fcn_BCE_loss: 0.0061\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.00660\n",
      "Epoch 731/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0160 - fcn_BCE_loss: 0.0152 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 730 , image ids: [337] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0151 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.00660\n",
      "Epoch 732/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.00660\n",
      "Epoch 733/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.00660\n",
      "Epoch 734/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0188 - fcn_BCE_loss: 0.0180 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 733 , image ids: [385] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0204 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.00660\n",
      "Epoch 735/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0176 - fcn_BCE_loss: 0.0167\n",
      " Bad train_batch_x encountered (training phase) - epoch 734 , image ids: [82] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0173 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.00660\n",
      "Epoch 736/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0104 - fcn_BCE_loss: 0.0096 - val_loss: 0.0164 - val_fcn_BCE_loss: 0.0156\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.00660\n",
      "Epoch 737/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0135 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.00660\n",
      "Epoch 738/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0099 - fcn_BCE_loss: 0.0091\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [299] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0097 - fcn_BCE_loss: 0.0089\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [2480] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [4737] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0080 - val_loss: 0.0207 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.00660\n",
      "Epoch 739/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0255 - fcn_BCE_loss: 0.0247 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.00660\n",
      "Epoch 740/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.00660\n",
      "Epoch 741/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.00660\n",
      "Epoch 742/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0105 - fcn_BCE_loss: 0.0097\n",
      " Bad train_batch_x encountered (training phase) - epoch 741 , image ids: [17] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.00660\n",
      "Epoch 743/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0119 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.00660\n",
      "Epoch 744/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0350 - val_fcn_BCE_loss: 0.0342\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.00660\n",
      "Epoch 745/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.00660\n",
      "Epoch 746/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.00660\n",
      "Epoch 747/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0251 - val_fcn_BCE_loss: 0.0242\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.00660\n",
      "Epoch 748/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0101 - fcn_BCE_loss: 0.0093\n",
      " Bad train_batch_x encountered (training phase) - epoch 747 , image ids: [1571] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0082 - val_loss: 0.0200 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.00660\n",
      "Epoch 749/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.00660\n",
      "Epoch 750/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0083 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.00660\n",
      "Epoch 751/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.00660\n",
      "Epoch 752/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 79s 8s/step - loss: 0.0184 - fcn_BCE_loss: 0.0176 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.00660\n",
      "Epoch 753/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0152 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.00660\n",
      "Epoch 754/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0080 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.00660\n",
      "Epoch 755/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0102 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.00660\n",
      "Epoch 756/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0254 - fcn_BCE_loss: 0.0245\n",
      " Bad train_batch_x encountered (training phase) - epoch 755 , image ids: [2971] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0236 - fcn_BCE_loss: 0.0227 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 755 , image ids: [143] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0219 - fcn_BCE_loss: 0.0210 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.00660\n",
      "Epoch 757/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0157 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.00660\n",
      "Epoch 758/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0105 - val_fcn_BCE_loss: 0.0097\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.00660\n",
      "Epoch 759/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0076 - val_fcn_BCE_loss: 0.0068\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.00660\n",
      "Epoch 760/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0121 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.00660\n",
      "Epoch 761/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0126 - fcn_BCE_loss: 0.0117 - val_loss: 0.0160 - val_fcn_BCE_loss: 0.0151\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.00660\n",
      "Epoch 762/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0180 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.00660\n",
      "Epoch 763/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0237 - fcn_BCE_loss: 0.0229 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.00660\n",
      "Epoch 764/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0191 - fcn_BCE_loss: 0.0183\n",
      " Bad train_batch_x encountered (training phase) - epoch 763 , image ids: [3784] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0190 - val_fcn_BCE_loss: 0.0181\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.00660\n",
      "Epoch 765/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0190 - fcn_BCE_loss: 0.0182\n",
      " Bad train_batch_x encountered (training phase) - epoch 764 , image ids: [1042] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0197 - fcn_BCE_loss: 0.0189\n",
      " Bad train_batch_x encountered (training phase) - epoch 764 , image ids: [2456] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0299 - val_fcn_BCE_loss: 0.0290\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.00660\n",
      "Epoch 766/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0189 - fcn_BCE_loss: 0.0181 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.00660\n",
      "Epoch 767/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0228 - fcn_BCE_loss: 0.0220 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.00660\n",
      "Epoch 768/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0171 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.00660\n",
      "Epoch 769/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0134 - fcn_BCE_loss: 0.0126 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0141\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.00660\n",
      "Epoch 770/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0247 - fcn_BCE_loss: 0.0239\n",
      " Bad train_batch_x encountered (training phase) - epoch 769 , image ids: [1712] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0200 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.00660\n",
      "Epoch 771/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0244 - fcn_BCE_loss: 0.0236 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.00660\n",
      "Epoch 772/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0177 - fcn_BCE_loss: 0.0169 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 771 , image ids: [664] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0108\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.00660\n",
      "Epoch 773/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0133 - val_loss: 0.0201 - val_fcn_BCE_loss: 0.0193\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.00660\n",
      "Epoch 774/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0253 - val_fcn_BCE_loss: 0.0244\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.00660\n",
      "Epoch 775/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0139 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.00660\n",
      "Epoch 776/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0151 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.00660\n",
      "Epoch 777/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0099\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.00660\n",
      "Epoch 778/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0075 - fcn_BCE_loss: 0.0066\n",
      " Bad train_batch_x encountered (training phase) - epoch 777 , image ids: [3932] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0126 - fcn_BCE_loss: 0.0118 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.00660\n",
      "Epoch 779/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 778 , image ids: [2603] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0129 - fcn_BCE_loss: 0.0121 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 778 , image ids: [457] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0122 - fcn_BCE_loss: 0.0114 - val_loss: 0.0199 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.00660\n",
      "Epoch 780/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0204 - fcn_BCE_loss: 0.0196 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.00660\n",
      "Epoch 781/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0060 - fcn_BCE_loss: 0.0051 \n",
      " Bad train_batch_x encountered (training phase) - epoch 780 , image ids: [3702] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.00660\n",
      "Epoch 782/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0204\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.00660\n",
      "Epoch 783/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0181 - fcn_BCE_loss: 0.0172\n",
      " Bad train_batch_x encountered (training phase) - epoch 782 , image ids: [1880] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0177\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.00660\n",
      "Epoch 784/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.00660\n",
      "Epoch 785/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0151 - fcn_BCE_loss: 0.0143\n",
      " Bad train_batch_x encountered (training phase) - epoch 784 , image ids: [3862] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.00660\n",
      "Epoch 786/820\n",
      " 1/10 [==>...........................] - ETA: 1:00 - loss: 0.0318 - fcn_BCE_loss: 0.0310\n",
      " Bad train_batch_x encountered (training phase) - epoch 785 , image ids: [4953] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0162 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.00660\n",
      "Epoch 787/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0155 - fcn_BCE_loss: 0.0147 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 786 , image ids: [266] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0117 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.00660\n",
      "Epoch 788/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0149 - fcn_BCE_loss: 0.0141 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 787 , image ids: [972] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0153 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.00660\n",
      "Epoch 789/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.00660\n",
      "Epoch 790/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0283 - fcn_BCE_loss: 0.0275 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 789 , image ids: [45] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0276 - fcn_BCE_loss: 0.0268 - val_loss: 0.0098 - val_fcn_BCE_loss: 0.0090\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.00660\n",
      "Epoch 791/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0093 - fcn_BCE_loss: 0.0085 - val_loss: 0.0224 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.00660\n",
      "Epoch 792/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 791 , image ids: [3969] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0270 - fcn_BCE_loss: 0.0262 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 791 , image ids: [63] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0255 - fcn_BCE_loss: 0.0247 - val_loss: 0.0366 - val_fcn_BCE_loss: 0.0358\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.00660\n",
      "Epoch 793/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0169 - fcn_BCE_loss: 0.0161 - val_loss: 0.0065 - val_fcn_BCE_loss: 0.0057\n",
      "\n",
      "Epoch 00793: val_loss improved from 0.00660 to 0.00651, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0793.h5\n",
      "Epoch 794/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0131 - fcn_BCE_loss: 0.0122 \n",
      " Bad train_batch_x encountered (training phase) - epoch 793 , image ids: [1457] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0067 - val_fcn_BCE_loss: 0.0059\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.00651\n",
      "Epoch 795/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0172 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 794 , image ids: [3331] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0172 - fcn_BCE_loss: 0.0164 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 794 , image ids: [672] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0166 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.00651\n",
      "Epoch 796/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.00651\n",
      "Epoch 797/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0129 - val_loss: 0.0155 - val_fcn_BCE_loss: 0.0147\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.00651\n",
      "Epoch 798/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0304 - fcn_BCE_loss: 0.0296 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 797 , image ids: [909] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0280 - fcn_BCE_loss: 0.0272 - val_loss: 0.0385 - val_fcn_BCE_loss: 0.0377\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.00651\n",
      "Epoch 799/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0158 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.00651\n",
      "Epoch 800/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0130 - fcn_BCE_loss: 0.0122\n",
      " Bad train_batch_x encountered (training phase) - epoch 799 , image ids: [4553] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0101 - fcn_BCE_loss: 0.0093 - val_loss: 0.0132 - val_fcn_BCE_loss: 0.0123\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.00651\n",
      "Epoch 801/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0167 - fcn_BCE_loss: 0.0159\n",
      " Bad train_batch_x encountered (training phase) - epoch 800 , image ids: [1572] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0329 - val_fcn_BCE_loss: 0.0321\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.00651\n",
      "Epoch 802/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.00651\n",
      "Epoch 803/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0221 - fcn_BCE_loss: 0.0213 - val_loss: 0.0160 - val_fcn_BCE_loss: 0.0152\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.00651\n",
      "Epoch 804/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0125 - fcn_BCE_loss: 0.0117\n",
      " Bad train_batch_x encountered (training phase) - epoch 803 , image ids: [3711] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.00651\n",
      "Epoch 805/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.00651\n",
      "Epoch 806/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0217\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.00651\n",
      "Epoch 807/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0108 - fcn_BCE_loss: 0.0100 \n",
      " Bad train_batch_x encountered (training phase) - epoch 806 , image ids: [2050] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0127 - fcn_BCE_loss: 0.0119 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 806 , image ids: [554] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0134 - fcn_BCE_loss: 0.0126 - val_loss: 0.0292 - val_fcn_BCE_loss: 0.0284\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.00651\n",
      "Epoch 808/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0176\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.00651\n",
      "Epoch 809/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0306 - fcn_BCE_loss: 0.0298\n",
      " Bad train_batch_x encountered (training phase) - epoch 808 , image ids: [2864] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0238 - fcn_BCE_loss: 0.0230 - val_loss: 0.0170 - val_fcn_BCE_loss: 0.0162\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.00651\n",
      "Epoch 810/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0148 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.00651\n",
      "Epoch 811/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0148 - fcn_BCE_loss: 0.0140 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 810 , image ids: [836] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 810 , image ids: [494] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.00651\n",
      "Epoch 812/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0143 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0177\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.00651\n",
      "Epoch 813/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0086 - fcn_BCE_loss: 0.0077\n",
      " Bad train_batch_x encountered (training phase) - epoch 812 , image ids: [3354] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0081 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.00651\n",
      "Epoch 814/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0127 - fcn_BCE_loss: 0.0119 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 813 , image ids: [381] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0128 - fcn_BCE_loss: 0.0120 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.00651\n",
      "Epoch 815/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0132 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.00651\n",
      "Epoch 816/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 815 , image ids: [2472] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0119 - fcn_BCE_loss: 0.0111 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.00651\n",
      "Epoch 817/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0215 - fcn_BCE_loss: 0.0207 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.00651\n",
      "Epoch 818/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0165 - fcn_BCE_loss: 0.0157\n",
      " Bad train_batch_x encountered (training phase) - epoch 817 , image ids: [1625] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0148 - fcn_BCE_loss: 0.0140 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 817 , image ids: [922] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.00651\n",
      "Epoch 819/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0163 - fcn_BCE_loss: 0.0155\n",
      " Bad train_batch_x encountered (training phase) - epoch 818 , image ids: [3282] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.00651\n",
      "Epoch 820/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0150 - fcn_BCE_loss: 0.0142\n",
      " Bad train_batch_x encountered (training phase) - epoch 819 , image ids: [1855] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0134 - fcn_BCE_loss: 0.0126 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 819 , image ids: [460] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0143 - val_loss: 0.0231 - val_fcn_BCE_loss: 0.0223\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.00651\n",
      "Final : self.epoch 820   epochs 820\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = ['block1+']   # args.fcn_layers\n",
    "loss_names   = ['fcn_BCE_loss']\n",
    "fcn_model.epoch = fcn_model.config.LAST_EPOCH_RAN\n",
    "\n",
    "fcn_model.train_in_batches(\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:36.427763Z",
     "start_time": "2018-12-20T19:10:36.127306Z"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(fcn_model.keras_model._feed_inputs)\n",
    "pp.pprint(fcn_model.keras_model._feed_targets)\n",
    "pp.pprint(fcn_model.keras_model._feed_loss_fns)\n",
    "pp.pprint(fcn_model.keras_model._feed_outputs)\n",
    "pp.pprint(fcn_model.keras_model._feed_sample_weights)\n",
    "pp.pprint(fcn_model.keras_model.updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:39.680073Z",
     "start_time": "2018-12-20T19:10:39.358322Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as KB\n",
    "fcn_hm_layer = fcn_model.keras_model.layers[32]\n",
    "fcn_sp3_layer = fcn_model.keras_model.layers[30]\n",
    "pp.pprint(fcn_hm_layer.__dict__ )\n",
    "pp.pprint(fcn_sp3_layer.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:51.790032Z",
     "start_time": "2018-12-20T19:10:51.229309Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    wght1 = fcn_hm_layer._trainable_weights[0].eval()\n",
    "    wght2 = fcn_sp3_layer._trainable_weights[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:11:00.618804Z",
     "start_time": "2018-12-20T19:11:00.311302Z"
    }
   },
   "outputs": [],
   "source": [
    "print(wght1.shape, wght2.shape)\n",
    "print(wght1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF]",
   "language": "python",
   "name": "conda-env-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
