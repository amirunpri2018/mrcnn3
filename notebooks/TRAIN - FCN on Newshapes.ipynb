{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train FCN using MRCNN in Predict Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:45:48.766805Z",
     "start_time": "2018-12-24T16:45:48.759799Z"
    }
   },
   "outputs": [],
   "source": [
    "# np_format = {}\n",
    "# float_formatter = lambda x: \"%10.4f\" % x\n",
    "# int_formatter   = lambda x: \"%10d\" % x\n",
    "# np_format['float'] = float_formatter\n",
    "# np_format['int']   = int_formatter\n",
    "# np.set_printoptions(linewidth=195, precision=4, floatmode='fixed', threshold =10000, formatter = np_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:22:18.684330Z",
     "start_time": "2019-01-15T20:22:18.302094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current working dir:  E:\\git_projs\\MRCNN3\\notebooks\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True) \n",
    "print('Current working dir: ', os.getcwd())\n",
    "if '..' not in sys.path:\n",
    "    print(\"appending '..' to sys.path\")\n",
    "    sys.path.append('..')\n",
    "    \n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.utils     as utils\n",
    "import mrcnn.prep_notebook as prep\n",
    "from mrcnn.prep_notebook import build_fcn_training_pipeline_newshapes\n",
    "from mrcnn.visualize     import display_training_batch\n",
    "from mrcnn.newshapes     import prep_newshape_dataset\n",
    "from mrcnn.datagen       import data_gen_simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:10:15.699834Z",
     "start_time": "2019-01-15T20:10:15.121553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   evaluate_method                1\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "input_parms = \" --epochs 2 \" \n",
    "input_parms +=\" --steps_in_epoch  10 \"    \n",
    "input_parms +=\" --val_steps        5 \" \n",
    "input_parms +=\" --last_epoch       0 \"\n",
    "input_parms +=\" --batch_size       1 \"\n",
    "input_parms +=\" --lr          0.0001 \"\n",
    "input_parms +=\" --mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_l2_newshapes \"\n",
    "# input_parms +=\" --fcn_logs_dir   train_fcn32_newshapes \"\n",
    "input_parms +=\" --mrcnn_model    last \"\n",
    "input_parms +=\" --fcn_model      init \"\n",
    "input_parms +=\" --opt            adam \"\n",
    "input_parms +=\" --fcn_arch       fcn8L2 \" \n",
    "input_parms +=\" --fcn_layers     all \" \n",
    "input_parms +=\" --sysout         screen \"\n",
    "input_parms +=\" --scale_factor     1 \" \n",
    "input_parms +=\" --new_log_folder   \"        \n",
    "\n",
    "parser = utils.command_line_parser()\n",
    "args = parser.parse_args(input_parms.split())\n",
    "utils.display_input_parms(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:11:03.274407Z",
     "start_time": "2019-01-15T20:10:15.702836Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   evaluate_method                1\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  trainfcn\n",
      "   Model dir :  F:\\models_newshapes\\train_mrcnn_newshapes\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  trainfcn\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "\n",
      ">>> RPN Layer \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "    > CHMLayer Call()              :  list length: 3\n",
      "--------------------------------\n",
      ">>>  CHM Layer COMPUTE OUTPUT SHAPE \n",
      "--------------------------------\n",
      "<class 'list'> 3\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      "\n",
      " MRCNN Configuration Parameters \n",
      " ------------------------------ \n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        64\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            64\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            120\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             60\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_mrcnn_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        0\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      " MRCNN IO Layers \n",
      " --------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 128, 128, 7)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 128, 128, 7)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 32, 7)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      " layer: 11    output name: ROI/rpn_roi_proposals:0                    Type: float32           Shape: (1, ?, ?)\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   evaluate_method                1\n",
      "   fcn_arch                       FCN8L2\n",
      "   fcn_layers                     ['all']\n",
      "   fcn_logs_dir                   train_fcn8_l2_newshapes\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      init\n",
      "   last_epoch                     0\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    last\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   1\n",
      "   steps_in_epoch                 10\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      5\n",
      "\n",
      "\n",
      "\n",
      "   Paths:\n",
      "   -------------------------\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_HEATMAP_PATH              F:\\MLDatasets\\coco2014_heatmaps\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_ROOT                       F:\\\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "FCN_TRAINING_PATH              F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "FCN_VGG16_MODEL_PATH           F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            F:\\models_newshapes\\train_mrcnn_newshapes\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                   NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20190115T2110\\fcn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20190115T2110 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN8L2\n",
      "    arch set to FCN8 - with L2 Regularization\n",
      "<function fcn8_l2_graph at 0x0000001B4AEEB840>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      " Build FCN Model -  Arch:  FCN8L2  mode:  training\n",
      "---------------------------------------------------\n",
      "   active_class_ids  shape is :  (None, None)  Keras tensor  True\n",
      "\n",
      "------------------------------------------------------\n",
      ">>> FCN8L2 Layer With Regularization - mode: training\n",
      "------------------------------------------------------\n",
      "     feature map      : (?, 128, 128, 7)\n",
      "     height : 128 width : 128 classes : 7\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "     FCN L2 weight decay :  1e-06\n",
      "     Set learning phase to : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Input feature map                   :  (?, 128, 128, 7)\n",
      "   FCN Block 11 shape is               :  (None, 128, 128, 64)\n",
      "   FCN Block 12 shape is               :  (None, 128, 128, 64)\n",
      "   FCN Block 13 (Max pooling) shape is :  (None, 64, 64, 64)\n",
      "   FCN Block 21 shape is               :  (?, 64, 64, 128)\n",
      "   FCN Block 22 shape is               :  (None, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (None, 32, 32, 128)\n",
      "   FCN Block 31 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 32 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 33 shape is               :  (None, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 16, 16, 256)\n",
      "   FCN Block 41 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 42 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 43 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 8, 8, 512)\n",
      "   FCN Block 51 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 52 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 53 shape is               :  (None, 8, 8, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (None, 4, 4, 512)\n",
      "\n",
      "   --- FCN32 ----------------------------\n",
      "   FCN fully connected 1 (fc1) shape   :  (None, 4, 4, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n",
      "   FCN fully connected 2 (fc2) shape   :  (None, 4, 4, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n",
      "   FCN conv2d (fcn32_deconv2D) shape   :  (?, 4, 4, 7)  keras_tensor  True\n",
      "\n",
      "   --- FCN16 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape is                   :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling (Deconvolution2D(fcn32_classify)) shape :  (None, 10, 10, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 Add(score2_c, scorePool4) shape :  (None, 8, 8, 7)    keras_tensor  True\n",
      "   FCN upscore_pool4 (Deconv(fuse_Pool4)) shape              :  (None, 16, 16, 7)    keras_tensor  True\n",
      "\n",
      "   --- FCN8 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape                      :  (None, 16, 16, 7)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 16, 16, 7)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 shape is                        :  (None, 16, 16, 7)    keras_tensor  True\n",
      "    FCN fcn8_classify/heatmap  (Deconv(fuse_Pool4)):  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    fcn_hm (final)                 :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "\n",
      "    fcn8_softmax                   :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    fcn_sm (final)                 :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "\n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer - mode: training\n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pr_hm_scores.shape             :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    detctions_per_image :  32 pr_scores shape (?, 7, 32, 23)\n",
      "    rois_per_image      :  32\n",
      "    config.DETECTION_MAX_INSTANCES   :  64\n",
      "    config.DETECTIONS_PER_CLASS      :  64\n",
      "    sequence_column                  :  6\n",
      "    norm_score_column                :  7\n",
      "    in_heatmap                     :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pr_scores.shape                :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    pt2_sum shape                  :  shape: (?, 7, 32)            KB.shape:(None, 7, 32)         Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 7, 128, 128) Keras tensor  False\n",
      "    normalizer shape   :  (?, 7, 1, 1)\n",
      "    normalized heatmap :  (?, 7, 128, 128)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: False\n",
      "    complete                       \n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer - mode: training\n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pr_hm_scores.shape             :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: False\n",
      "    detctions_per_image :  32 pr_scores shape (?, 7, 32, 23)\n",
      "    rois_per_image      :  32\n",
      "    config.DETECTION_MAX_INSTANCES   :  64\n",
      "    config.DETECTIONS_PER_CLASS      :  64\n",
      "    sequence_column                  :  6\n",
      "    norm_score_column                :  7\n",
      "    in_heatmap                     :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pr_scores.shape                :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: False\n",
      "    pt2_sum shape                  :  shape: (?, 7, 32)            KB.shape:(None, 7, 32)         Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 7, 128, 128) Keras tensor  False\n",
      "    normalizer shape   :  (?, 7, 1, 1)\n",
      "    normalized heatmap :  (?, 7, 128, 128)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 7, 32, 3)         KB.shape:(1, 7, 32, 3)         Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: False\n",
      "    complete                       \n",
      "    * gt_hm_scores shape           :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    * pr_hm_scores shape           :  shape: (?, 7, 32, 23)        KB.shape:(None, 7, 32, 23)     Keras Tensor: True\n",
      "    * fcn_heatmap shape            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    * fcn_softmax shape            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    * fcn_scores shape             :  shape: (1, 7, 32, 23)        KB.shape:(1, 7, 32, 23)        Keras Tensor: True\n",
      "                                   \n",
      "    ---------------------------------------------------\n",
      "    building Loss Functions        \n",
      "    ---------------------------------------------------\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  True\n",
      "    pred_heatmap : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  True\n",
      "    loss         : (?, 128, 128) (None, 128, 128) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  False\n",
      "    pred_heatmap : (?, 128, 128, 7) (None, 128, 128, 7) KerasTensor:  False\n",
      "    loss         : (?, 128, 128) (None, 128, 128) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 128, 128, 7)\n",
      "    pred_class_logits : (None, 128, 128, 7)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 128, 128) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 128, 128) <dtype: 'int64'>\n",
      "    pred_active       : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss              : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 128, 128) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 128, 128, 7)\n",
      "    pred_class_logits : (None, 128, 128, 7)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 128, 128) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 128, 128) <dtype: 'int64'>\n",
      "    pred_active       : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss              : (None, 128, 128) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 128, 128) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    pred_class_logits :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: True\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 7)                KB.shape:(None, 7)             Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    pred_class_logits :            :  shape: (?, 128, 128, 7)      KB.shape:(None, 128, 128, 7)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 7, 128, 128)      KB.shape:(None, 7, 128, 128)   Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 7)                KB.shape:(None, 7)             Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 128, 128)         KB.shape:(None, 128, 128)      Keras Tensor: False\n",
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  21\n",
      "0      Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "1      Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "2      Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "3      Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "4      Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "5      Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "6      Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "7      Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "8      Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "9      Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "10      Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "11      Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "12      Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "13      Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "14      Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "15      Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "16      Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "17      Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "18      Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "19      Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "20      Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n",
      "\n",
      " FCN Configuration Parameters \n",
      " ------------------------------ \n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_PERIOD              1\n",
      "DETECTION_MAX_INSTANCES        64\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            64\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           1e-07\n",
      "EARLY_STOP_PATIENCE            500\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_MIN_DELTA            1e-06\n",
      "REDUCE_LR_PATIENCE             350\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_LAYERS                ['all']\n",
      "TRAINING_LOSSES                fcn_BCE_loss\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        1\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "WEIGHT_DECAY                   1e-06\n",
      "\n",
      "\n",
      "\n",
      " FCN IO Layers \n",
      " --------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 23)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 128, 128, 7)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 7, 32, 23)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap_lambda/fcn_hm:0                Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  1    output name: fcn_softmax_lambda/fcn_sm:0                Type: float32           Shape: (?, 128, 128, 7)\n",
      " layer:  2    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: fcn_BCE_loss/fcn_BCE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  4    output name: fcn_scoring/fcn_hm_scores:0                Type: float32           Shape: (1, 7, 32, 23)\n",
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      " Exclude layers: \n",
      "-----------------------------------------------\n",
      " ---> last\n",
      "   Last file is : ('F:\\\\models_newshapes\\\\train_mrcnn_newshapes\\\\mrcnn20181216T0000', 'F:\\\\models_newshapes\\\\train_mrcnn_newshapes\\\\mrcnn20181216T0000\\\\mrcnn_0472.h5')\n",
      ">>> load_weights() from : F:\\models_newshapes\\train_mrcnn_newshapes\\mrcnn20181216T0000\\mrcnn_0472.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Weights file loaded: F:\\models_newshapes\\train_mrcnn_newshapes\\mrcnn20181216T0000\\mrcnn_0472.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n",
      " FCN Training starting from randomly initialized weights ...\n"
     ]
    }
   ],
   "source": [
    "# del mrcnn_model, fcn_model\n",
    "mrcnn_model, fcn_model = build_fcn_training_pipeline_newshapes(args = args, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:16:39.050008Z",
     "start_time": "2019-01-15T20:16:38.190664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2500\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build & Load Training and Validation datasets\n",
    "##------------------------------------------------------------------------------------\n",
    "# dataset_train, train_generator = prep_newshape_dataset( mrcnn_model.config, 10000, generator=True)\n",
    "# dataset_val  , val_generator   = prep_newshape_dataset( mrcnn_model.config,  2500, generator=True)\n",
    "# with open('E:\\\\git_projs\\\\MRCNN3\\\\train_newshapes\\\\newshapes_training_dataset_10000_A.pkl', 'wb') as outfile:\n",
    "#     pickle.dump(dataset_train, outfile)\n",
    "# with open('E:\\\\git_projs\\\\MRCNN3\\\\train_newshapes\\\\newshapes_validation_dataset_2500_A.pkl', 'wb') as outfile:\n",
    "#     pickle.dump(dataset_val, outfile)\n",
    "\n",
    "## -- OR --\n",
    "\n",
    "with open('E:\\\\git_projs\\\\MRCNN3\\\\train_newshapes\\\\newshapes_training_dataset_10000_A.pkl', 'rb') as outfile:\n",
    "    dataset_train = pickle.load(outfile)\n",
    "with open('E:\\\\git_projs\\\\MRCNN3\\\\train_newshapes\\\\newshapes_validation_dataset_2500_A.pkl', 'rb') as outfile:\n",
    "    dataset_val = pickle.load(outfile)\n",
    "## If we desire a generator, here it is:    \n",
    "## train_generator = data_generator(dataset_train, mrcnn_model.config, batch_size=mrcnn_model.config.BATCH_SIZE,\n",
    "#                                    shuffle = True, augment = False) \n",
    "## val_generator = data_generator(dataset_val, mrcnn_model.config, batch_size=mrcnn_model.config.BATCH_SIZE,\n",
    "#                                    shuffle = True, augment = False) \n",
    "class_names = dataset_train.class_names\n",
    "# dataset_train.display_active_classes()\n",
    "# dataset_val.display_active_classes()\n",
    "print(mrcnn_model.config.BATCH_SIZE, fcn_model.config.BATCH_SIZE)\n",
    "print(len(dataset_train.image_ids), len(dataset_val.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Display some images from training and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:22:28.113883Z",
     "start_time": "2019-01-15T20:22:24.193894Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWEAAANXCAYAAABUmp3MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAARibAAAAAAABGJsAAAAAAAEf1/1Y0kG6AjmdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1728x1296 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_list = list(range(0,40))\n",
    "image_titles = [str(i) for i in image_list]\n",
    "images = prep.get_image_batch(dataset_train, image_list)\n",
    "visualize.display_images(images, titles = image_titles, cols = 8, width = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:22:51.372251Z",
     "start_time": "2019-01-15T20:22:48.868486Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWMAAAIUCAYAAAB/1D6HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAkIAYCwAAAACQwP8DKwO0fv9a3eUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1728x648 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_list = list(range(0,20))\n",
    "image_titles = [str(i) for i in image_list]\n",
    "images = prep.get_image_batch(dataset_val, image_list)\n",
    "visualize.display_images(images, titles = image_titles, cols = 8, width = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Print model layer and weight information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:38:43.700653Z",
     "start_time": "2018-12-20T19:38:41.748709Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fcn_model.keras_model.summary()\n",
    "tr_ly = fcn_model.get_trainable_layers()\n",
    "for i in tr_ly:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:29:41.902326Z",
     "start_time": "2018-10-31T15:29:41.840211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in fcn_model.keras_model.layers:\n",
    "    print('layer: ', layer.name)\n",
    "    for weight in layer.weights:\n",
    "        print('   mapped_weight_name : ',weight.name)\n",
    "    if hasattr(layer, 'output'):\n",
    "        print('   layer output ', type(layer),' shape: ',layer.output.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:17:32.353508Z",
     "start_time": "2018-05-20T18:17:32.121048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model.keras_model.losses\n",
    "# print(model.keras_model.metrics_names)\n",
    "# model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a specific image using image_id  with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T12:28:26.389169Z",
     "start_time": "2018-12-17T12:28:24.936137Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, _ =  data_gen_simulate(dataset_train, mrcnn_model.config, [417])\n",
    "# visualize.display_training_batch(dataset_train, train_batch_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:44.895887Z",
     "start_time": "2018-12-24T16:46:43.907185Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image id :  646\n",
      " Image_id    :  646  Reference:  [('sun', (17, 87, 183), (99, 10, 5, 5))] Coco Id: 646\n",
      " Image meta  :  [646 128 128   3   0   0 128 128]\n",
      " Class ids   :  (1,)    [3]\n",
      " Class Names :  ['sun']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5EAAAOICAYAAABPC3XsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2WqLDnI6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[646 128 128   3   0   0 128 128   1   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "IMAGE_IDS = [646]\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "train_batch_x, train_batch_y = data_gen_simulate(dataset_train, mrcnn_model.config, IMAGE_IDS)\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)\n",
    "print(train_batch_x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training batch using generator and display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T10:34:39.848544Z",
     "start_time": "2018-12-21T10:34:39.174742Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "display_training_batch(dataset_train, train_batch_x)\n",
    "# for i in train_batch_x:\n",
    "#     print(type(i), i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T16:46:45.724476Z",
     "start_time": "2018-12-24T16:46:44.900891Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_PERIOD              1\n",
      "DETECTION_MAX_INSTANCES        32\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            32\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_TRAINING                   F:\\models_newshapes\n",
      "EARLY_STOP_MIN_DELTA           1e-07\n",
      "EARLY_STOP_PATIENCE            1000\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_MIN_DELTA            1e-06\n",
      "REDUCE_LR_PATIENCE             500\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_LAYERS                ['all']\n",
      "TRAINING_LOSSES                fcn_BCE_loss\n",
      "TRAINING_PATH                  F:\\models_newshapes\\train_fcn8_l2_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "VERBOSE                        1\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "WEIGHT_DECAY                   1e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mrcnn_model.config.display()\n",
    "fcn_model.config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T11:09:06.438486Z",
     "start_time": "2018-12-25T11:08:49.487437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last epoch ran  :  420\n",
      "    epochs to run   :  400\n",
      "    steps per epoch :  10\n",
      "    validation steps:  5\n",
      "    learning rate   :  0.0001\n",
      "    momentum        :  0.9\n",
      "    weight decay    :  1e-06\n"
     ]
    }
   ],
   "source": [
    "fcn_model.config.LAST_EPOCH_RAN  =  420\n",
    "fcn_model.config.EPOCHS_TO_RUN   =  400\n",
    "fcn_model.config.REDUCE_LR_PATIENCE = 200\n",
    "# fcn_model.config.LEARNING_RATE   = 1.0e-6\n",
    "# fcn_model.config.STEPS_PER_EPOCH = 10\n",
    "# fcn_model.config.SYSOUT = 'screen'\n",
    "\n",
    "print('    last epoch ran  : ',fcn_model.config.LAST_EPOCH_RAN)\n",
    "print('    epochs to run   : ',fcn_model.config.EPOCHS_TO_RUN)\n",
    "print('    steps per epoch : ',fcn_model.config.STEPS_PER_EPOCH)\n",
    "print('    validation steps: ',fcn_model.config.VALIDATION_STEPS)\n",
    "print('    learning rate   : ',fcn_model.config.LEARNING_RATE)\n",
    "print('    momentum        : ',fcn_model.config.LEARNING_MOMENTUM)\n",
    "print('    weight decay    : ',fcn_model.config.WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call to `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T20:07:28.309440Z",
     "start_time": "2018-12-25T11:11:54.517641Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block1+']\n",
      "['(block1\\\\_.*)|(block2\\\\_.*)|(block3\\\\_.*)|(block4\\\\_.*)|(block5\\\\_.*)|(fcn32\\\\_.*)|(fcn16\\\\_.*)|(fcn8\\\\_.*)']\n",
      "layers regex : (block1\\_.*)|(block2\\_.*)|(block3\\_.*)|(block4\\_.*)|(block5\\_.*)|(fcn32\\_.*)|(fcn16\\_.*)|(fcn8\\_.*)\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_pr_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "   1  block1_conv1           (Conv2D              )   TRAIN \n",
      "   2  block1_conv2           (Conv2D              )   TRAIN \n",
      "   3  block1_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   4  block2_conv1           (Conv2D              )   TRAIN \n",
      "   5  block2_conv2           (Conv2D              )   TRAIN \n",
      "   6  block2_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   7  block3_conv1           (Conv2D              )   TRAIN \n",
      "   8  block3_conv2           (Conv2D              )   TRAIN \n",
      "   9  block3_conv3           (Conv2D              )   TRAIN \n",
      "  10  block3_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  11  block4_conv1           (Conv2D              )   TRAIN \n",
      "  12  block4_conv2           (Conv2D              )   TRAIN \n",
      "  13  block4_conv3           (Conv2D              )   TRAIN \n",
      "  14  block4_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  15  block5_conv1           (Conv2D              )   TRAIN \n",
      "  16  block5_conv2           (Conv2D              )   TRAIN \n",
      "  17  block5_conv3           (Conv2D              )   TRAIN \n",
      "  18  block5_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  19  fcn32_fc1              (Conv2D              )   TRAIN \n",
      "  20  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      "  21  fcn32_fc2              (Conv2D              )   TRAIN \n",
      "  22  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      "  23  fcn32_deconv2D         (Conv2D              )   TRAIN \n",
      "  24  fcn16_score2           (Conv2DTranspose     )   TRAIN \n",
      "  25  fcn16_crop_score2      (Cropping2D          )   ............................no weights to train ]\n",
      "  26  fcn16_score_pool4      (Conv2D              )   TRAIN \n",
      "  27  fcn16_fuse_pool4       (Add                 )   ............................no weights to train ]\n",
      "  28  fcn16_upscore_pool4    (Conv2DTranspose     )   TRAIN \n",
      "  29  fcn8_crop_pool4        (Cropping2D          )   ............................no weights to train ]\n",
      "  30  fcn8_score_pool3       (Conv2D              )   TRAIN \n",
      "  31  fcn8_fuse_pool3        (Add                 )   ............................no weights to train ]\n",
      "  32  fcn8_heatmap           (Conv2DTranspose     )   TRAIN \n",
      "  33  fcn_heatmap_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  34  input_gt_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "  35  input_pr_hm_scores     (InputLayer          )   ............................no weights to train ]\n",
      "  36  fcn_softmax_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  37  fcn_MSE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  38  fcn_BCE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  39  fcn_scoring            (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      "  Compile Model :\n",
      " ----------------\n",
      "    losses        :  ['fcn_BCE_loss']\n",
      "    optimizer     :  <keras.optimizers.Adam object at 0x000000B68C5E4940>\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      " Initial self.keras_model.losses :\n",
      " ---------------------------------\n",
      " losses passed to compile :  ['fcn_BCE_loss']\n",
      " self.keras_model.losses  : \n",
      "      0    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      11    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Add loss_functions to self.keras_model.losses\n",
      " -------------------------------------\n",
      " --  Loss: fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add add loss for  Tensor(\"fcn_BCE_loss/fcn_BCE_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding loss_functions passed to compile() : \n",
      " ------------------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " --------------------\n",
      "      0    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      " Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      " ---------------------------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Compile \n",
      " --------\n",
      " Length of Keras_Model.outputs: 5\n",
      "\n",
      " Add Metrics for losses :\n",
      " -------------------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add metric  fcn_BCE_loss  with metric tensor:  fcn_BCE_loss/fcn_BCE_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names :\n",
      " --------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      " ----------------------------------------------------------------- \n",
      "      0    Tensor(\"block2_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      1    Tensor(\"block4_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      2    Tensor(\"block2_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      3    Tensor(\"block3_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      4    Tensor(\"block4_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      5    Tensor(\"block5_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      6    Tensor(\"block5_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      7    Tensor(\"fcn16_score_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      8    Tensor(\"block5_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      9    Tensor(\"fcn16_upscore_pool4/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      10    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "      11    Tensor(\"block1_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      12    Tensor(\"block3_conv3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      13    Tensor(\"block1_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      14    Tensor(\"fcn8_score_pool3/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      15    Tensor(\"block3_conv2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      16    Tensor(\"fcn8_heatmap/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      17    Tensor(\"block4_conv1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      18    Tensor(\"fcn32_deconv2D/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      19    Tensor(\"fcn32_fc1/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      20    Tensor(\"fcn32_fc2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "      21    Tensor(\"fcn16_score2/weight_regularizer/add:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " ---------------------\n",
      "      0    Tensor(\"Mean_6:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      "\n",
      " Post-compile out_labels from get_deduped_metrics_names() : \n",
      " ---------------------------------------------------------- \n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "\n",
      " Post-compile Callback metrics monitored by progbar :\n",
      " ----------------------------------------------------\n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "     - val_loss\n",
      "     - val_fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras metric_names :\n",
      " ---------------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras stateful_metric_names :\n",
      " ------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training Start Parameters:\n",
      "--------------------------\n",
      "Starting at epoch     420 of 820 epochs.\n",
      "Steps per epochs      10 \n",
      "Last epoch completed  420 \n",
      "Batch size            1 \n",
      "Learning Rate         0.0001 \n",
      "Momentum              0.9 \n",
      "Weight Decay:         1e-06 \n",
      "VALIDATION_STEPS      5 \n",
      "REDUCE_LR_FACTOR      0.5 \n",
      "REDUCE_LR_COOLDOWN    50 \n",
      "REDUCE_LR_PATIENCE    200 \n",
      "MIN_LR                1e-10 \n",
      "EARLY_STOP_PATIENCE   1000 \n",
      "Checkpoint Path:      F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_{epoch:04d}.h5 \n",
      "Epoch 421/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 420 , image ids: [2512] -- Retry with next sample\n",
      "10/10 [==============================] - 124s 12s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0096\n",
      "\n",
      "Epoch 00421: val_loss improved from inf to 0.01058, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0421.h5\n",
      "Epoch 422/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0224 - fcn_BCE_loss: 0.0215 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 421 , image ids: [858] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0217 - fcn_BCE_loss: 0.0207 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.01058\n",
      "Epoch 423/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.01058\n",
      "Epoch 424/820\n",
      " 6/10 [=================>............] - ETA: 31s - loss: 0.0213 - fcn_BCE_loss: 0.0204\n",
      " Bad train_batch_x encountered (training phase) - epoch 423 , image ids: [2890] -- Retry with next sample\n",
      "10/10 [==============================] - 93s 9s/step - loss: 0.0184 - fcn_BCE_loss: 0.0175 - val_loss: 0.0230 - val_fcn_BCE_loss: 0.0221\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.01058\n",
      "Epoch 425/820\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0275 - fcn_BCE_loss: 0.0265 - val_loss: 0.0150 - val_fcn_BCE_loss: 0.0141\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.01058\n",
      "Epoch 426/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0169 - fcn_BCE_loss: 0.0160 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.01058\n",
      "Epoch 427/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0162 - val_fcn_BCE_loss: 0.0152\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.01058\n",
      "Epoch 428/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.01058\n",
      "Epoch 429/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0253 - fcn_BCE_loss: 0.0243 - val_loss: 0.0193 - val_fcn_BCE_loss: 0.0184\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.01058\n",
      "Epoch 430/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.01058\n",
      "Epoch 431/820\n",
      " 2/10 [=====>........................] - ETA: 57s - loss: 0.0235 - fcn_BCE_loss: 0.0225 \n",
      " Bad train_batch_x encountered (training phase) - epoch 430 , image ids: [2991] -- Retry with next sample\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0161 - fcn_BCE_loss: 0.0151 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.01058\n",
      "Epoch 432/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0256 - val_fcn_BCE_loss: 0.0247\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.01058\n",
      "Epoch 433/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0207 - fcn_BCE_loss: 0.0197 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.01058\n",
      "Epoch 434/820\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0168 - fcn_BCE_loss: 0.0159 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0096\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.01058 to 0.01056, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0434.h5\n",
      "Epoch 435/820\n",
      " 1/10 [==>...........................] - ETA: 57s - loss: 0.0150 - fcn_BCE_loss: 0.0141\n",
      " Bad train_batch_x encountered (training phase) - epoch 434 , image ids: [2957] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.01056\n",
      "Epoch 436/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0264 - fcn_BCE_loss: 0.0254 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.01056\n",
      "Epoch 437/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0173 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 436 , image ids: [1332] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0186 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.01056\n",
      "Epoch 438/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0152 - fcn_BCE_loss: 0.0143 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 437 , image ids: [700] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0142\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.01056\n",
      "Epoch 439/820\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0148 - fcn_BCE_loss: 0.0139\n",
      " Bad train_batch_x encountered (training phase) - epoch 438 , image ids: [744] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0163 - val_loss: 0.0159 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.01056\n",
      "Epoch 440/820\n",
      " 1/10 [==>...........................] - ETA: 1:08 - loss: 0.0207 - fcn_BCE_loss: 0.0197\n",
      " Bad train_batch_x encountered (training phase) - epoch 439 , image ids: [3797] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0168 - val_fcn_BCE_loss: 0.0159\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.01056\n",
      "Epoch 441/820\n",
      " 6/10 [=================>............] - ETA: 26s - loss: 0.0209 - fcn_BCE_loss: 0.0200\n",
      " Bad train_batch_x encountered (training phase) - epoch 440 , image ids: [2342] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0199 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0115\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.01056\n",
      "Epoch 442/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0129 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.01056\n",
      "Epoch 443/820\n",
      " 2/10 [=====>........................] - ETA: 1:00 - loss: 0.0373 - fcn_BCE_loss: 0.0363\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [2094] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [2802] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 442 , image ids: [3490] -- Retry with next sample\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0176 - val_fcn_BCE_loss: 0.0167\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.01056\n",
      "Epoch 444/820\n",
      "10/10 [==============================] - 92s 9s/step - loss: 0.0189 - fcn_BCE_loss: 0.0180 - val_loss: 0.0191 - val_fcn_BCE_loss: 0.0182\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.01056\n",
      "Epoch 445/820\n",
      " 2/10 [=====>........................] - ETA: 59s - loss: 0.0121 - fcn_BCE_loss: 0.0112 \n",
      " Bad train_batch_x encountered (training phase) - epoch 444 , image ids: [2107] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0127 - fcn_BCE_loss: 0.0118 - val_loss: 0.0272 - val_fcn_BCE_loss: 0.0263\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.01056\n",
      "Epoch 446/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 85s 9s/step - loss: 0.0209 - fcn_BCE_loss: 0.0199 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.01056\n",
      "Epoch 447/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0182 - fcn_BCE_loss: 0.0173 - val_loss: 0.0292 - val_fcn_BCE_loss: 0.0283\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.01056\n",
      "Epoch 448/820\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0170 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0269\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.01056\n",
      "Epoch 449/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0170 - fcn_BCE_loss: 0.0160 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 448 , image ids: [891] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0164 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.01056\n",
      "Epoch 450/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.01056 to 0.01034, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0450.h5\n",
      "Epoch 451/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0217 - fcn_BCE_loss: 0.0208 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 450 , image ids: [213] -- Retry with next sample\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0249 - fcn_BCE_loss: 0.0240 - val_loss: 0.0302 - val_fcn_BCE_loss: 0.0293\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.01034\n",
      "Epoch 452/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0165 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.01034\n",
      "Epoch 453/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 452 , image ids: [409] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0179 - fcn_BCE_loss: 0.0170 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 452 , image ids: [268] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0189 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.01034\n",
      "Epoch 454/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0207 - fcn_BCE_loss: 0.0198 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 453 , image ids: [81] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 453 , image ids: [218] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0203 - val_fcn_BCE_loss: 0.0194\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.01034\n",
      "Epoch 455/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0203 - val_fcn_BCE_loss: 0.0194\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.01034\n",
      "Epoch 456/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0106 - fcn_BCE_loss: 0.0097\n",
      " Bad train_batch_x encountered (training phase) - epoch 455 , image ids: [3285] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0133 - fcn_BCE_loss: 0.0124 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0113\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.01034\n",
      "Epoch 457/820\n",
      "10/10 [==============================] - 86s 9s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0092\n",
      "\n",
      "Epoch 00457: val_loss improved from 0.01034 to 0.01010, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0457.h5\n",
      "Epoch 458/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0121 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.01010\n",
      "Epoch 459/820\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0139 - fcn_BCE_loss: 0.0130\n",
      " Bad train_batch_x encountered (training phase) - epoch 458 , image ids: [1849] -- Retry with next sample\n",
      " 8/10 [=======================>......] - ETA: 14s - loss: 0.0122 - fcn_BCE_loss: 0.0113\n",
      " Bad train_batch_x encountered (training phase) - epoch 458 , image ids: [1391] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0116 - fcn_BCE_loss: 0.0107 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 458 , image ids: [709] -- Retry with next sample\n",
      "10/10 [==============================] - 85s 9s/step - loss: 0.0112 - fcn_BCE_loss: 0.0103 - val_loss: 0.0228 - val_fcn_BCE_loss: 0.0219\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.01010\n",
      "Epoch 460/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0144 - fcn_BCE_loss: 0.0135\n",
      " Bad train_batch_x encountered (training phase) - epoch 459 , image ids: [2015] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0122 - val_loss: 0.0193 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.01010\n",
      "Epoch 461/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0104 - fcn_BCE_loss: 0.0095 - val_loss: 0.0197 - val_fcn_BCE_loss: 0.0188\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.01010\n",
      "Epoch 462/820\n",
      " 2/10 [=====>........................] - ETA: 56s - loss: 0.0154 - fcn_BCE_loss: 0.0145 \n",
      " Bad train_batch_x encountered (training phase) - epoch 461 , image ids: [996] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0102 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.01010\n",
      "Epoch 463/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0157 - val_loss: 0.0237 - val_fcn_BCE_loss: 0.0228\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.01010\n",
      "Epoch 464/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 463 , image ids: [4969] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0128 - fcn_BCE_loss: 0.0119 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.01010\n",
      "Epoch 465/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.01010\n",
      "Epoch 466/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0204 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.01010\n",
      "Epoch 467/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0248 - fcn_BCE_loss: 0.0239 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0113\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.01010\n",
      "Epoch 468/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0208 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.01010\n",
      "Epoch 469/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0266 - fcn_BCE_loss: 0.0257\n",
      " Bad train_batch_x encountered (training phase) - epoch 468 , image ids: [796] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.01010\n",
      "Epoch 470/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0186 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.01010\n",
      "Epoch 471/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0090\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.01010 to 0.00992, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0471.h5\n",
      "Epoch 472/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00992\n",
      "Epoch 473/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 75s 7s/step - loss: 0.0256 - fcn_BCE_loss: 0.0247 - val_loss: 0.0183 - val_fcn_BCE_loss: 0.0174\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00992\n",
      "Epoch 474/820\n",
      " 1/10 [==>...........................] - ETA: 58s - loss: 0.0175 - fcn_BCE_loss: 0.0166\n",
      " Bad train_batch_x encountered (training phase) - epoch 473 , image ids: [2956] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0116 - fcn_BCE_loss: 0.0107 - val_loss: 0.0147 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00992\n",
      "Epoch 475/820\n",
      " 5/10 [==============>...............] - ETA: 33s - loss: 0.0289 - fcn_BCE_loss: 0.0280\n",
      " Bad train_batch_x encountered (training phase) - epoch 474 , image ids: [792] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0231 - fcn_BCE_loss: 0.0222 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00992\n",
      "Epoch 476/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0142 - fcn_BCE_loss: 0.0133 \n",
      " Bad train_batch_x encountered (training phase) - epoch 475 , image ids: [731] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 475 , image ids: [241] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00992\n",
      "Epoch 477/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0175 - fcn_BCE_loss: 0.0166 - val_loss: 0.0154 - val_fcn_BCE_loss: 0.0145\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00992\n",
      "Epoch 478/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00992\n",
      "Epoch 479/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0206 - fcn_BCE_loss: 0.0197 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0097\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00992\n",
      "Epoch 480/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0175 - fcn_BCE_loss: 0.0166 - val_loss: 0.0133 - val_fcn_BCE_loss: 0.0124\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00992\n",
      "Epoch 481/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00992\n",
      "Epoch 482/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0164 - fcn_BCE_loss: 0.0155 - val_loss: 0.0085 - val_fcn_BCE_loss: 0.0076\n",
      "\n",
      "Epoch 00482: val_loss improved from 0.00992 to 0.00847, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0482.h5\n",
      "Epoch 483/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0222 - fcn_BCE_loss: 0.0213 - val_loss: 0.0086 - val_fcn_BCE_loss: 0.0077\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00847\n",
      "Epoch 484/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00847\n",
      "Epoch 485/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0231 - val_fcn_BCE_loss: 0.0222\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00847\n",
      "Epoch 486/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0170 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00847\n",
      "Epoch 487/820\n",
      " 4/10 [===========>..................] - ETA: 42s - loss: 0.0227 - fcn_BCE_loss: 0.0218\n",
      " Bad train_batch_x encountered (training phase) - epoch 486 , image ids: [406] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0148 - fcn_BCE_loss: 0.0139 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 486 , image ids: [984] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0244 - val_fcn_BCE_loss: 0.0235\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00847\n",
      "Epoch 488/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0167 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00847\n",
      "Epoch 489/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00847\n",
      "Epoch 490/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00847\n",
      "Epoch 491/820\n",
      " 1/10 [==>...........................] - ETA: 58s - loss: 0.0100 - fcn_BCE_loss: 0.0091\n",
      " Bad train_batch_x encountered (training phase) - epoch 490 , image ids: [2601] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0136 - fcn_BCE_loss: 0.0127\n",
      " Bad train_batch_x encountered (training phase) - epoch 490 , image ids: [144] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00847\n",
      "Epoch 492/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0176 - val_fcn_BCE_loss: 0.0167\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00847\n",
      "Epoch 493/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0193 - fcn_BCE_loss: 0.0184 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 492 , image ids: [310] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00847\n",
      "Epoch 494/820\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0238 - fcn_BCE_loss: 0.0229\n",
      " Bad train_batch_x encountered (training phase) - epoch 493 , image ids: [3189] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0204 - val_loss: 0.0247 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00847\n",
      "Epoch 495/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 494 , image ids: [1983] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0227 - fcn_BCE_loss: 0.0218 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 494 , image ids: [429] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0203 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00847\n",
      "Epoch 496/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0131 - fcn_BCE_loss: 0.0122 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00847\n",
      "Epoch 497/820\n",
      " 4/10 [===========>..................] - ETA: 46s - loss: 0.0138 - fcn_BCE_loss: 0.0129\n",
      " Bad train_batch_x encountered (training phase) - epoch 496 , image ids: [2941] -- Retry with next sample\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0412 - val_fcn_BCE_loss: 0.0403\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00847\n",
      "Epoch 498/820\n",
      " 1/10 [==>...........................] - ETA: 1:02 - loss: 0.0088 - fcn_BCE_loss: 0.0079\n",
      " Bad train_batch_x encountered (training phase) - epoch 497 , image ids: [2968] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0089\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00847\n",
      "Epoch 499/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0070 - fcn_BCE_loss: 0.0061\n",
      " Bad train_batch_x encountered (training phase) - epoch 498 , image ids: [4968] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0084 - fcn_BCE_loss: 0.0075 - val_loss: 0.0196 - val_fcn_BCE_loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00847\n",
      "Epoch 500/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0169 - fcn_BCE_loss: 0.0160 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00847\n",
      "Epoch 501/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0287 - fcn_BCE_loss: 0.0278 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00847\n",
      "Epoch 502/820\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.0187 - fcn_BCE_loss: 0.0178 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00847\n",
      "Epoch 503/820\n",
      " 3/10 [========>.....................] - ETA: 57s - loss: 0.0133 - fcn_BCE_loss: 0.0124 \n",
      " Bad train_batch_x encountered (training phase) - epoch 502 , image ids: [2234] -- Retry with next sample\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0139 - fcn_BCE_loss: 0.0131 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00847\n",
      "Epoch 504/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00847\n",
      "Epoch 505/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0121 - fcn_BCE_loss: 0.0112 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 504 , image ids: [766] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00847\n",
      "Epoch 506/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0142 - fcn_BCE_loss: 0.0133 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 505 , image ids: [736] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0201 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00847\n",
      "Epoch 507/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0232 - val_fcn_BCE_loss: 0.0223\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00847\n",
      "Epoch 508/820\n",
      " 3/10 [========>.....................] - ETA: 47s - loss: 0.0257 - fcn_BCE_loss: 0.0249\n",
      " Bad train_batch_x encountered (training phase) - epoch 507 , image ids: [953] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00847\n",
      "Epoch 509/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 508 , image ids: [650] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0105 - fcn_BCE_loss: 0.0097 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00847\n",
      "Epoch 510/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0137 - fcn_BCE_loss: 0.0128 \n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [2114] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 42s - loss: 0.0115 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [1468] -- Retry with next sample\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0119 - fcn_BCE_loss: 0.0110\n",
      " Bad train_batch_x encountered (training phase) - epoch 509 , image ids: [4291] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0149 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00847\n",
      "Epoch 511/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0131 - val_fcn_BCE_loss: 0.0122\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00847\n",
      "Epoch 512/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0118 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00847\n",
      "Epoch 513/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0247 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00847\n",
      "Epoch 514/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0176 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00847\n",
      "Epoch 515/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0182 - fcn_BCE_loss: 0.0173 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0099\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00847\n",
      "Epoch 516/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0193 - fcn_BCE_loss: 0.0185 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00847\n",
      "Epoch 517/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0247 - fcn_BCE_loss: 0.0238 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 516 , image ids: [207] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0196 - val_fcn_BCE_loss: 0.0188\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00847\n",
      "Epoch 518/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0190 - fcn_BCE_loss: 0.0181 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 517 , image ids: [539] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00847\n",
      "Epoch 519/820\n",
      " 1/10 [==>...........................] - ETA: 1:03 - loss: 0.0074 - fcn_BCE_loss: 0.0065\n",
      " Bad train_batch_x encountered (training phase) - epoch 518 , image ids: [4245] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 47s - loss: 0.0155 - fcn_BCE_loss: 0.0146\n",
      " Bad train_batch_x encountered (training phase) - epoch 518 , image ids: [936] -- Retry with next sample\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00847\n",
      "Epoch 520/820\n",
      "10/10 [==============================] - 90s 9s/step - loss: 0.0189 - fcn_BCE_loss: 0.0181 - val_loss: 0.0171 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00847\n",
      "Epoch 521/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0071 - val_fcn_BCE_loss: 0.0062\n",
      "\n",
      "Epoch 00521: val_loss improved from 0.00847 to 0.00708, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0521.h5\n",
      "Epoch 522/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0127\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00708\n",
      "Epoch 523/820\n",
      "10/10 [==============================] - 84s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0139 - val_loss: 0.0234 - val_fcn_BCE_loss: 0.0225\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00708\n",
      "Epoch 524/820\n",
      " 5/10 [==============>...............] - ETA: 36s - loss: 0.0172 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 523 , image ids: [2970] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0203 - val_loss: 0.0306 - val_fcn_BCE_loss: 0.0298\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.00708\n",
      "Epoch 525/820\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.0165 - fcn_BCE_loss: 0.0156 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.00708\n",
      "Epoch 526/820\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.00708\n",
      "Epoch 527/820\n",
      " 1/10 [==>...........................] - ETA: 2:03 - loss: 0.0078 - fcn_BCE_loss: 0.0070\n",
      " Bad train_batch_x encountered (training phase) - epoch 526 , image ids: [597] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 94s 9s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0127\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.00708\n",
      "Epoch 528/820\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.0183 - fcn_BCE_loss: 0.0174 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.00708\n",
      "Epoch 529/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 528 , image ids: [2116] -- Retry with next sample\n",
      "10/10 [==============================] - 150s 15s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0226 - val_fcn_BCE_loss: 0.0217\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.00708\n",
      "Epoch 530/820\n",
      "10/10 [==============================] - 146s 15s/step - loss: 0.0141 - fcn_BCE_loss: 0.0133 - val_loss: 0.0172 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.00708\n",
      "Epoch 531/820\n",
      "10/10 [==============================] - 87s 9s/step - loss: 0.0200 - fcn_BCE_loss: 0.0192 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.00708\n",
      "Epoch 532/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0179 - val_fcn_BCE_loss: 0.0171\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.00708\n",
      "Epoch 533/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0234 - fcn_BCE_loss: 0.0225 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.00708\n",
      "Epoch 534/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0160 - fcn_BCE_loss: 0.0151 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 533 , image ids: [658] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0163 - fcn_BCE_loss: 0.0154 - val_loss: 0.0214 - val_fcn_BCE_loss: 0.0205\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.00708\n",
      "Epoch 535/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0317 - fcn_BCE_loss: 0.0308 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.00708\n",
      "Epoch 536/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0215 - fcn_BCE_loss: 0.0206 - val_loss: 0.0246 - val_fcn_BCE_loss: 0.0238\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.00708\n",
      "Epoch 537/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0157 - fcn_BCE_loss: 0.0148 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.00708\n",
      "Epoch 538/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0239 - val_fcn_BCE_loss: 0.0231\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.00708\n",
      "Epoch 539/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0176 - fcn_BCE_loss: 0.0167 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0176\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.00708\n",
      "Epoch 540/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0204 - fcn_BCE_loss: 0.0195 - val_loss: 0.0242 - val_fcn_BCE_loss: 0.0233\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.00708\n",
      "Epoch 541/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0214 - fcn_BCE_loss: 0.0205 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 540 , image ids: [747] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.00708\n",
      "Epoch 542/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0085 - fcn_BCE_loss: 0.0076 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0115\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.00708\n",
      "Epoch 543/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0150 - fcn_BCE_loss: 0.0142 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.00708\n",
      "Epoch 544/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0096 - fcn_BCE_loss: 0.0088 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.00708\n",
      "Epoch 545/820\n",
      " 7/10 [====================>.........] - ETA: 19s - loss: 0.0192 - fcn_BCE_loss: 0.0183\n",
      " Bad train_batch_x encountered (training phase) - epoch 544 , image ids: [3822] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0150 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0086\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.00708\n",
      "Epoch 546/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0284 - fcn_BCE_loss: 0.0275 - val_loss: 0.0269 - val_fcn_BCE_loss: 0.0260\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.00708\n",
      "Epoch 547/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0131 - val_fcn_BCE_loss: 0.0123\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.00708\n",
      "Epoch 548/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.00708\n",
      "Epoch 549/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0243 - fcn_BCE_loss: 0.0234 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.00708\n",
      "Epoch 550/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.00708\n",
      "Epoch 551/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.00708\n",
      "Epoch 552/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0242 - fcn_BCE_loss: 0.0233 - val_loss: 0.0232 - val_fcn_BCE_loss: 0.0224\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.00708\n",
      "Epoch 553/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0227 - fcn_BCE_loss: 0.0219 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.00708\n",
      "Epoch 554/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0124 - fcn_BCE_loss: 0.0116 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.00708\n",
      "Epoch 555/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0150 - fcn_BCE_loss: 0.0142 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0103\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.00708\n",
      "Epoch 556/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0221 - fcn_BCE_loss: 0.0212 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 555 , image ids: [746] -- Retry with next sample\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0171 - val_fcn_BCE_loss: 0.0162\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.00708\n",
      "Epoch 557/820\n",
      " 5/10 [==============>...............] - ETA: 31s - loss: 0.0183 - fcn_BCE_loss: 0.0174\n",
      " Bad train_batch_x encountered (training phase) - epoch 556 , image ids: [3903] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 19s - loss: 0.0162 - fcn_BCE_loss: 0.0153\n",
      " Bad train_batch_x encountered (training phase) - epoch 556 , image ids: [2869] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0216 - fcn_BCE_loss: 0.0207 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 556 , image ids: [379] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0225 - fcn_BCE_loss: 0.0217 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0202\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.00708\n",
      "Epoch 558/820\n",
      " 8/10 [=======================>......] - ETA: 12s - loss: 0.0126 - fcn_BCE_loss: 0.0117\n",
      " Bad train_batch_x encountered (training phase) - epoch 557 , image ids: [3218] -- Retry with next sample\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.00708\n",
      "Epoch 559/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 558 , image ids: [4658] -- Retry with next sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 76s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0161 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.00708\n",
      "Epoch 560/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0202 - fcn_BCE_loss: 0.0193\n",
      " Bad train_batch_x encountered (training phase) - epoch 559 , image ids: [4777] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0184 - fcn_BCE_loss: 0.0175 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.00708\n",
      "Epoch 561/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0237 - fcn_BCE_loss: 0.0228 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.00708\n",
      "Epoch 562/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0194 - fcn_BCE_loss: 0.0185 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.00708\n",
      "Epoch 563/820\n",
      " 3/10 [========>.....................] - ETA: 45s - loss: 0.0094 - fcn_BCE_loss: 0.0086\n",
      " Bad train_batch_x encountered (training phase) - epoch 562 , image ids: [3288] -- Retry with next sample\n",
      " 5/10 [==============>...............] - ETA: 33s - loss: 0.0124 - fcn_BCE_loss: 0.0115\n",
      " Bad train_batch_x encountered (training phase) - epoch 562 , image ids: [3351] -- Retry with next sample\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0120 - fcn_BCE_loss: 0.0111 - val_loss: 0.0159 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.00708\n",
      "Epoch 564/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0263 - fcn_BCE_loss: 0.0255 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0143\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.00708\n",
      "Epoch 565/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0162 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.00708\n",
      "Epoch 566/820\n",
      " 4/10 [===========>..................] - ETA: 38s - loss: 0.0116 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 565 , image ids: [1816] -- Retry with next sample\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0203 - fcn_BCE_loss: 0.0194 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.00708\n",
      "Epoch 567/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 566 , image ids: [2997] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0224 - fcn_BCE_loss: 0.0215 - val_loss: 0.0155 - val_fcn_BCE_loss: 0.0146\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.00708\n",
      "Epoch 568/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0113 - fcn_BCE_loss: 0.0104\n",
      " Bad train_batch_x encountered (training phase) - epoch 567 , image ids: [3211] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.00708\n",
      "Epoch 569/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0260 - val_fcn_BCE_loss: 0.0252\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.00708\n",
      "Epoch 570/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.00708\n",
      "Epoch 571/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0270\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.00708\n",
      "Epoch 572/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0125 - fcn_BCE_loss: 0.0116 - val_loss: 0.0184 - val_fcn_BCE_loss: 0.0175\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.00708\n",
      "Epoch 573/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0061 - fcn_BCE_loss: 0.0052 \n",
      " Bad train_batch_x encountered (training phase) - epoch 572 , image ids: [4650] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0115 - fcn_BCE_loss: 0.0106 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.00708\n",
      "Epoch 574/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0123 - fcn_BCE_loss: 0.0114 - val_loss: 0.0117 - val_fcn_BCE_loss: 0.0108\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.00708\n",
      "Epoch 575/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0166\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.00708\n",
      "Epoch 576/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0149 - fcn_BCE_loss: 0.0141\n",
      " Bad train_batch_x encountered (training phase) - epoch 575 , image ids: [4627] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0136 - fcn_BCE_loss: 0.0127 - val_loss: 0.0153 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.00708\n",
      "Epoch 577/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0130 - val_fcn_BCE_loss: 0.0122\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.00708\n",
      "Epoch 578/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0127 - fcn_BCE_loss: 0.0118 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.00708\n",
      "Epoch 579/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0127 - fcn_BCE_loss: 0.0119\n",
      " Bad train_batch_x encountered (training phase) - epoch 578 , image ids: [3168] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0100 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.00708\n",
      "Epoch 580/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0216 - fcn_BCE_loss: 0.0207 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.00708\n",
      "Epoch 581/820\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0109 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.00708\n",
      "Epoch 582/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0156 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.00708\n",
      "Epoch 583/820\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0089 - val_fcn_BCE_loss: 0.0081\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.00708\n",
      "Epoch 584/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0182 - fcn_BCE_loss: 0.0174 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [45] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [63] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 583 , image ids: [621] -- Retry with next sample\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0164 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.00708\n",
      "Epoch 585/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0099 - fcn_BCE_loss: 0.0090 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 584 , image ids: [431] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0098 - fcn_BCE_loss: 0.0089 - val_loss: 0.0138 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.00708\n",
      "Epoch 586/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0200 - fcn_BCE_loss: 0.0191 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.00708\n",
      "Epoch 587/820\n",
      "10/10 [==============================] - 75s 8s/step - loss: 0.0223 - fcn_BCE_loss: 0.0215 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.00708\n",
      "Epoch 588/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0130 - fcn_BCE_loss: 0.0121 - val_loss: 0.0169 - val_fcn_BCE_loss: 0.0160\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.00708\n",
      "Epoch 589/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0152 - fcn_BCE_loss: 0.0144 - val_loss: 0.0192 - val_fcn_BCE_loss: 0.0183\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.00708\n",
      "Epoch 590/820\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0138 - fcn_BCE_loss: 0.0129 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.00708\n",
      "Epoch 591/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0206 - fcn_BCE_loss: 0.0197\n",
      " Bad train_batch_x encountered (training phase) - epoch 590 , image ids: [4536] -- Retry with next sample\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0297 - val_fcn_BCE_loss: 0.0288\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.00708\n",
      "Epoch 592/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0118 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.00708\n",
      "Epoch 593/820\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.0117 - fcn_BCE_loss: 0.0108 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.00708\n",
      "Epoch 594/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.00708\n",
      "Epoch 595/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 594 , image ids: [2229] -- Retry with next sample\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.00708\n",
      "Epoch 596/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0087 - fcn_BCE_loss: 0.0079 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 595 , image ids: [371] -- Retry with next sample\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0092 - fcn_BCE_loss: 0.0083 - val_loss: 0.0081 - val_fcn_BCE_loss: 0.0072\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.00708\n",
      "Epoch 597/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.00708\n",
      "Epoch 598/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0254 - fcn_BCE_loss: 0.0245 - val_loss: 0.0213 - val_fcn_BCE_loss: 0.0205\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.00708\n",
      "Epoch 599/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0116 - fcn_BCE_loss: 0.0108 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.00708\n",
      "Epoch 600/820\n",
      " 1/10 [==>...........................] - ETA: 1:00 - loss: 0.0428 - fcn_BCE_loss: 0.0420\n",
      " Bad train_batch_x encountered (training phase) - epoch 599 , image ids: [3466] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0157 - fcn_BCE_loss: 0.0149 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.00708\n",
      "Epoch 601/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0146 - fcn_BCE_loss: 0.0137 - val_loss: 0.0318 - val_fcn_BCE_loss: 0.0309\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.00708\n",
      "Epoch 602/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0234 - fcn_BCE_loss: 0.0226\n",
      " Bad train_batch_x encountered (training phase) - epoch 601 , image ids: [174] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 601 , image ids: [3080] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0238 - fcn_BCE_loss: 0.0229 - val_loss: 0.0388 - val_fcn_BCE_loss: 0.0379\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.00708\n",
      "Epoch 603/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0241 - fcn_BCE_loss: 0.0233 - val_loss: 0.0197 - val_fcn_BCE_loss: 0.0189\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.00708\n",
      "Epoch 604/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0124 - val_fcn_BCE_loss: 0.0116\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.00708\n",
      "Epoch 605/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0220 - fcn_BCE_loss: 0.0211 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.00708\n",
      "Epoch 606/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0125 - fcn_BCE_loss: 0.0117 \n",
      " Bad train_batch_x encountered (training phase) - epoch 605 , image ids: [413] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0160 - fcn_BCE_loss: 0.0152 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 605 , image ids: [738] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 605 , image ids: [710] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0080 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.00708\n",
      "Epoch 607/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0263 - fcn_BCE_loss: 0.0254 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.00708\n",
      "Epoch 608/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0090 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.00708\n",
      "Epoch 609/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0152 - fcn_BCE_loss: 0.0143\n",
      " Bad train_batch_x encountered (training phase) - epoch 608 , image ids: [202] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0172 - val_loss: 0.0238 - val_fcn_BCE_loss: 0.0230\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.00708\n",
      "Epoch 610/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0203 - fcn_BCE_loss: 0.0194 \n",
      " Bad train_batch_x encountered (training phase) - epoch 609 , image ids: [1715] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0070 - val_fcn_BCE_loss: 0.0062\n",
      "\n",
      "Epoch 00610: val_loss improved from 0.00708 to 0.00702, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0610.h5\n",
      "Epoch 611/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0107 - fcn_BCE_loss: 0.0099 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.00702\n",
      "Epoch 612/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0121 - val_loss: 0.0294 - val_fcn_BCE_loss: 0.0286\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.00702\n",
      "Epoch 613/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0138 - fcn_BCE_loss: 0.0130 \n",
      " Bad train_batch_x encountered (training phase) - epoch 612 , image ids: [937] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0171 - fcn_BCE_loss: 0.0162 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 612 , image ids: [356] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 612 , image ids: [764] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.00702\n",
      "Epoch 614/820\n",
      " 1/10 [==>...........................] - ETA: 59s - loss: 0.0041 - fcn_BCE_loss: 0.0032\n",
      " Bad train_batch_x encountered (training phase) - epoch 613 , image ids: [184] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0230 - val_fcn_BCE_loss: 0.0221\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.00702\n",
      "Epoch 615/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 80s 8s/step - loss: 0.0250 - fcn_BCE_loss: 0.0241 - val_loss: 0.0198 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.00702\n",
      "Epoch 616/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0179 - val_loss: 0.0084 - val_fcn_BCE_loss: 0.0076\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.00702\n",
      "Epoch 617/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.00702\n",
      "Epoch 618/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0181 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0133\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.00702\n",
      "Epoch 619/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0177 - fcn_BCE_loss: 0.0169\n",
      " Bad train_batch_x encountered (training phase) - epoch 618 , image ids: [4182] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0204 - fcn_BCE_loss: 0.0196\n",
      " Bad train_batch_x encountered (training phase) - epoch 618 , image ids: [1174] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0217 - fcn_BCE_loss: 0.0209 - val_loss: 0.0111 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.00702\n",
      "Epoch 620/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0136 - fcn_BCE_loss: 0.0127 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 619 , image ids: [155] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0157 - val_loss: 0.0081 - val_fcn_BCE_loss: 0.0073\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.00702\n",
      "Epoch 621/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0139 - fcn_BCE_loss: 0.0130 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 620 , image ids: [706] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0136 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.00702\n",
      "Epoch 622/820\n",
      " 3/10 [========>.....................] - ETA: 51s - loss: 0.0195 - fcn_BCE_loss: 0.0187\n",
      " Bad train_batch_x encountered (training phase) - epoch 621 , image ids: [1367] -- Retry with next sample\n",
      "10/10 [==============================] - 86s 9s/step - loss: 0.0223 - fcn_BCE_loss: 0.0214 - val_loss: 0.0099 - val_fcn_BCE_loss: 0.0091\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.00702\n",
      "Epoch 623/820\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0171 - fcn_BCE_loss: 0.0162 - val_loss: 0.0164 - val_fcn_BCE_loss: 0.0155\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.00702\n",
      "Epoch 624/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0134 - val_loss: 0.0265 - val_fcn_BCE_loss: 0.0257\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.00702\n",
      "Epoch 625/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0219 - fcn_BCE_loss: 0.0210\n",
      " Bad train_batch_x encountered (training phase) - epoch 624 , image ids: [3864] -- Retry with next sample\n",
      " 8/10 [=======================>......] - ETA: 14s - loss: 0.0201 - fcn_BCE_loss: 0.0193\n",
      " Bad train_batch_x encountered (training phase) - epoch 624 , image ids: [2710] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0188 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0185\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.00702\n",
      "Epoch 626/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0152 - fcn_BCE_loss: 0.0143 - val_loss: 0.0156 - val_fcn_BCE_loss: 0.0148\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.00702\n",
      "Epoch 627/820\n",
      " 1/10 [==>...........................] - ETA: 1:05 - loss: 0.0127 - fcn_BCE_loss: 0.0118\n",
      " Bad train_batch_x encountered (training phase) - epoch 626 , image ids: [2407] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0182 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.00702\n",
      "Epoch 628/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0118 - fcn_BCE_loss: 0.0109 - val_loss: 0.0200 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.00702\n",
      "Epoch 629/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 628 , image ids: [1255] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0116\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.00702\n",
      "Epoch 630/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0105 - fcn_BCE_loss: 0.0097 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 629 , image ids: [429] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0112 - fcn_BCE_loss: 0.0103 - val_loss: 0.0089 - val_fcn_BCE_loss: 0.0080\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.00702\n",
      "Epoch 631/820\n",
      " 3/10 [========>.....................] - ETA: 47s - loss: 0.0225 - fcn_BCE_loss: 0.0216\n",
      " Bad train_batch_x encountered (training phase) - epoch 630 , image ids: [3845] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0121 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.00702\n",
      "Epoch 632/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.00702\n",
      "Epoch 633/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0147 - fcn_BCE_loss: 0.0138 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.00702\n",
      "Epoch 634/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0293 - val_fcn_BCE_loss: 0.0284\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.00702\n",
      "Epoch 635/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0207 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 634 , image ids: [4049] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0205 - val_loss: 0.0094 - val_fcn_BCE_loss: 0.0085\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.00702\n",
      "Epoch 636/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0193 - fcn_BCE_loss: 0.0185 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 635 , image ids: [230] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0091 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.00702\n",
      "Epoch 637/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0226 - fcn_BCE_loss: 0.0218 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.00702\n",
      "Epoch 638/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0157 - fcn_BCE_loss: 0.0148 - val_loss: 0.0295 - val_fcn_BCE_loss: 0.0287\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.00702\n",
      "Epoch 639/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.00702\n",
      "Epoch 640/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0149 - fcn_BCE_loss: 0.0141 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.00702\n",
      "Epoch 641/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0172 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.00702\n",
      "Epoch 642/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.00702\n",
      "Epoch 643/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0289 - fcn_BCE_loss: 0.0280\n",
      " Bad train_batch_x encountered (training phase) - epoch 642 , image ids: [3790] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0287 - fcn_BCE_loss: 0.0278 - val_loss: 0.0113 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.00702\n",
      "Epoch 644/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0172 - fcn_BCE_loss: 0.0163 \n",
      " Bad train_batch_x encountered (training phase) - epoch 643 , image ids: [122] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0153 - val_loss: 0.0235 - val_fcn_BCE_loss: 0.0227\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.00702\n",
      "Epoch 645/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0224 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.00702\n",
      "Epoch 646/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0109 - fcn_BCE_loss: 0.0101 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 645 , image ids: [126] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0167 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.00702\n",
      "Epoch 647/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0157 - val_loss: 0.0115 - val_fcn_BCE_loss: 0.0106\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.00702\n",
      "Epoch 648/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0186 - fcn_BCE_loss: 0.0177 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.00702\n",
      "Epoch 649/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0208 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 648 , image ids: [3237] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0236 - fcn_BCE_loss: 0.0227 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.00702\n",
      "Epoch 650/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0167 - fcn_BCE_loss: 0.0159 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 649 , image ids: [278] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0147 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.00702\n",
      "Epoch 651/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0187 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.00702\n",
      "Epoch 652/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0207 - fcn_BCE_loss: 0.0199\n",
      " Bad train_batch_x encountered (training phase) - epoch 651 , image ids: [4140] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0256 - fcn_BCE_loss: 0.0248 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 651 , image ids: [379] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0240 - fcn_BCE_loss: 0.0232 - val_loss: 0.0139 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.00702\n",
      "Epoch 653/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0070\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.00702\n",
      "Epoch 654/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0103 - fcn_BCE_loss: 0.0095 - val_loss: 0.0110 - val_fcn_BCE_loss: 0.0102\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.00702\n",
      "Epoch 655/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0204 - val_fcn_BCE_loss: 0.0195\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.00702\n",
      "Epoch 656/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0165 - val_loss: 0.0294 - val_fcn_BCE_loss: 0.0285\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.00702\n",
      "Epoch 657/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0115 - fcn_BCE_loss: 0.0107\n",
      " Bad train_batch_x encountered (training phase) - epoch 656 , image ids: [3672] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0120 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.00702\n",
      "Epoch 658/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.00702\n",
      "Epoch 659/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0159 - fcn_BCE_loss: 0.0151\n",
      " Bad train_batch_x encountered (training phase) - epoch 658 , image ids: [2245] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0133 - val_fcn_BCE_loss: 0.0124\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.00702\n",
      "Epoch 660/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0115 - val_loss: 0.0208 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.00702\n",
      "Epoch 661/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0083 - fcn_BCE_loss: 0.0075 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 660 , image ids: [912] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 660 , image ids: [533] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0083 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.00702\n",
      "Epoch 662/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0132 - val_loss: 0.0136 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.00702\n",
      "Epoch 663/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0179 - val_loss: 0.0088 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.00702\n",
      "Epoch 664/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0166 - fcn_BCE_loss: 0.0158 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 663 , image ids: [736] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.00702\n",
      "Epoch 665/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.00702\n",
      "Epoch 666/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0148 - fcn_BCE_loss: 0.0139\n",
      " Bad train_batch_x encountered (training phase) - epoch 665 , image ids: [4718] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0147 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.00702\n",
      "Epoch 667/820\n",
      " 2/10 [=====>........................] - ETA: 1:01 - loss: 0.0244 - fcn_BCE_loss: 0.0236\n",
      " Bad train_batch_x encountered (training phase) - epoch 666 , image ids: [4900] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0080 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.00702\n",
      "Epoch 668/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.00702\n",
      "Epoch 669/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0131 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.00702\n",
      "Epoch 670/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0176 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00670: val_loss did not improve from 0.00702\n",
      "Epoch 671/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0299 - fcn_BCE_loss: 0.0290 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.00702\n",
      "Epoch 672/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0103 - fcn_BCE_loss: 0.0094 - val_loss: 0.0199 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.00702\n",
      "Epoch 673/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.00702\n",
      "Epoch 674/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0151 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0119\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.00702\n",
      "Epoch 675/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0280 - fcn_BCE_loss: 0.0271\n",
      " Bad train_batch_x encountered (training phase) - epoch 674 , image ids: [1363] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0251 - fcn_BCE_loss: 0.0242 - val_loss: 0.0113 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.00702\n",
      "Epoch 676/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0205 - fcn_BCE_loss: 0.0196 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0138\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.00702\n",
      "Epoch 677/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0175 - fcn_BCE_loss: 0.0166 \n",
      " Bad train_batch_x encountered (training phase) - epoch 676 , image ids: [1899] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0163 - val_loss: 0.0170 - val_fcn_BCE_loss: 0.0161\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.00702\n",
      "Epoch 678/820\n",
      " 1/10 [==>...........................] - ETA: 1:04 - loss: 0.0053 - fcn_BCE_loss: 0.0045\n",
      " Bad train_batch_x encountered (training phase) - epoch 677 , image ids: [541] -- Retry with next sample\n",
      " 3/10 [========>.....................] - ETA: 51s - loss: 0.0195 - fcn_BCE_loss: 0.0186 \n",
      " Bad train_batch_x encountered (training phase) - epoch 677 , image ids: [1389] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0253 - fcn_BCE_loss: 0.0245 - val_loss: 0.0217 - val_fcn_BCE_loss: 0.0209\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.00702\n",
      "Epoch 679/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.00702\n",
      "Epoch 680/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0198 - fcn_BCE_loss: 0.0189\n",
      " Bad train_batch_x encountered (training phase) - epoch 679 , image ids: [2327] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0176 - fcn_BCE_loss: 0.0168 \n",
      " Bad train_batch_x encountered (training phase) - epoch 679 , image ids: [1271] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0164 - fcn_BCE_loss: 0.0156 - val_loss: 0.0273 - val_fcn_BCE_loss: 0.0264\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.00702\n",
      "Epoch 681/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.00702\n",
      "Epoch 682/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0160 - fcn_BCE_loss: 0.0152\n",
      " Bad train_batch_x encountered (training phase) - epoch 681 , image ids: [1068] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0214 - fcn_BCE_loss: 0.0206 - val_loss: 0.0326 - val_fcn_BCE_loss: 0.0317\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.00702\n",
      "Epoch 683/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0106 - fcn_BCE_loss: 0.0098 - val_loss: 0.0078 - val_fcn_BCE_loss: 0.0070\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.00702\n",
      "Epoch 684/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0135 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.00702\n",
      "Epoch 685/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0235 - fcn_BCE_loss: 0.0226\n",
      " Bad train_batch_x encountered (training phase) - epoch 684 , image ids: [1252] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.00702\n",
      "Epoch 686/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0153 - fcn_BCE_loss: 0.0145\n",
      " Bad train_batch_x encountered (training phase) - epoch 685 , image ids: [2536] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0128 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.00702\n",
      "Epoch 687/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0224 - fcn_BCE_loss: 0.0216 - val_loss: 0.0066 - val_fcn_BCE_loss: 0.0058\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.00702 to 0.00660, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0687.h5\n",
      "Epoch 688/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0117 - fcn_BCE_loss: 0.0108 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 687 , image ids: [384] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0073 - val_fcn_BCE_loss: 0.0064\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.00660\n",
      "Epoch 689/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0097 - fcn_BCE_loss: 0.0089 - val_loss: 0.0106 - val_fcn_BCE_loss: 0.0098\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.00660\n",
      "Epoch 690/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0128\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.00660\n",
      "Epoch 691/820\n",
      " 2/10 [=====>........................] - ETA: 54s - loss: 0.0156 - fcn_BCE_loss: 0.0148 \n",
      " Bad train_batch_x encountered (training phase) - epoch 690 , image ids: [4069] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0124 - fcn_BCE_loss: 0.0116 - val_loss: 0.0172 - val_fcn_BCE_loss: 0.0163\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.00660\n",
      "Epoch 692/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0200 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.00660\n",
      "Epoch 693/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0225 - fcn_BCE_loss: 0.0216 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 692 , image ids: [579] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0251 - val_fcn_BCE_loss: 0.0242\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.00660\n",
      "Epoch 694/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0150 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.00660\n",
      "Epoch 695/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0132 - fcn_BCE_loss: 0.0124 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 694 , image ids: [865] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0135 - fcn_BCE_loss: 0.0127 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0186\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.00660\n",
      "Epoch 696/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0250 - fcn_BCE_loss: 0.0241 - val_loss: 0.0269 - val_fcn_BCE_loss: 0.0260\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.00660\n",
      "Epoch 697/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 696 , image ids: [236] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 696 , image ids: [4909] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0146 - fcn_BCE_loss: 0.0138 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.00660\n",
      "Epoch 698/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0162 - fcn_BCE_loss: 0.0153 - val_loss: 0.0128 - val_fcn_BCE_loss: 0.0120\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.00660\n",
      "Epoch 699/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0195 - fcn_BCE_loss: 0.0187 - val_loss: 0.0140 - val_fcn_BCE_loss: 0.0131\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.00660\n",
      "Epoch 700/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0190 - fcn_BCE_loss: 0.0182 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 699 , image ids: [718] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0222 - fcn_BCE_loss: 0.0214 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.00660\n",
      "Epoch 701/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 700 , image ids: [800] -- Retry with next sample\n",
      " 2/10 [=====>........................] - ETA: 59s - loss: 0.0213 - fcn_BCE_loss: 0.0204 \n",
      " Bad train_batch_x encountered (training phase) - epoch 700 , image ids: [1600] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0197 - fcn_BCE_loss: 0.0189 - val_loss: 0.0157 - val_fcn_BCE_loss: 0.0149\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.00660\n",
      "Epoch 702/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0156 - val_loss: 0.0151 - val_fcn_BCE_loss: 0.0142\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.00660\n",
      "Epoch 703/820\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0172 - fcn_BCE_loss: 0.0164 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 702 , image ids: [241] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.00660\n",
      "Epoch 704/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0245 - fcn_BCE_loss: 0.0237\n",
      " Bad train_batch_x encountered (training phase) - epoch 703 , image ids: [4890] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0230 - fcn_BCE_loss: 0.0221 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 703 , image ids: [709] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0230 - fcn_BCE_loss: 0.0222 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.00660\n",
      "Epoch 705/820\n",
      " 1/10 [==>...........................] - ETA: 1:05 - loss: 0.0241 - fcn_BCE_loss: 0.0232\n",
      " Bad train_batch_x encountered (training phase) - epoch 704 , image ids: [2863] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0181 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.00660\n",
      "Epoch 706/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0113 - fcn_BCE_loss: 0.0105 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0171\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.00660\n",
      "Epoch 707/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0095\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.00660\n",
      "Epoch 708/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0149 - fcn_BCE_loss: 0.0140 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.00660\n",
      "Epoch 709/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0153 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.00660\n",
      "Epoch 710/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0121 - fcn_BCE_loss: 0.0113 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0155\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.00660\n",
      "Epoch 711/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 710 , image ids: [3422] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.00660\n",
      "Epoch 712/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0163 - val_fcn_BCE_loss: 0.0154\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.00660\n",
      "Epoch 713/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0202 - fcn_BCE_loss: 0.0194 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0114\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.00660\n",
      "Epoch 714/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 713 , image ids: [532] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0203 - fcn_BCE_loss: 0.0195\n",
      " Bad train_batch_x encountered (training phase) - epoch 713 , image ids: [1369] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0091 - val_fcn_BCE_loss: 0.0082\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.00660\n",
      "Epoch 715/820\n",
      " 1/10 [==>...........................] - ETA: 1:02 - loss: 0.0253 - fcn_BCE_loss: 0.0245\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [4226] -- Retry with next sample\n",
      " 4/10 [===========>..................] - ETA: 43s - loss: 0.0166 - fcn_BCE_loss: 0.0158\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [1394] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [2056] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 22s - loss: 0.0223 - fcn_BCE_loss: 0.0214\n",
      " Bad train_batch_x encountered (training phase) - epoch 714 , image ids: [3569] -- Retry with next sample\n",
      "10/10 [==============================] - 83s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0278 - val_fcn_BCE_loss: 0.0270\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.00660\n",
      "Epoch 716/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0257 - fcn_BCE_loss: 0.0248 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.00660\n",
      "Epoch 717/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0133 - fcn_BCE_loss: 0.0125 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0119\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.00660\n",
      "Epoch 718/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0245 - fcn_BCE_loss: 0.0236 - val_loss: 0.0103 - val_fcn_BCE_loss: 0.0094\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.00660\n",
      "Epoch 719/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0216 - fcn_BCE_loss: 0.0208 \n",
      " Bad train_batch_x encountered (training phase) - epoch 718 , image ids: [1360] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 718 , image ids: [313] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0203 - fcn_BCE_loss: 0.0195 - val_loss: 0.0280 - val_fcn_BCE_loss: 0.0272\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.00660\n",
      "Epoch 720/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0199 - fcn_BCE_loss: 0.0190 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.00660\n",
      "Epoch 721/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0156 - fcn_BCE_loss: 0.0148\n",
      " Bad train_batch_x encountered (training phase) - epoch 720 , image ids: [3530] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0158 - fcn_BCE_loss: 0.0150 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.00660\n",
      "Epoch 722/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0213 - fcn_BCE_loss: 0.0205 - val_loss: 0.0074 - val_fcn_BCE_loss: 0.0065\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.00660\n",
      "Epoch 723/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/10 [=====>........................] - ETA: 53s - loss: 0.0151 - fcn_BCE_loss: 0.0143 \n",
      " Bad train_batch_x encountered (training phase) - epoch 722 , image ids: [1305] -- Retry with next sample\n",
      " 3/10 [========>.....................] - ETA: 49s - loss: 0.0130 - fcn_BCE_loss: 0.0121\n",
      " Bad train_batch_x encountered (training phase) - epoch 722 , image ids: [3914] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0177 - fcn_BCE_loss: 0.0169 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 722 , image ids: [192] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0183 - fcn_BCE_loss: 0.0174 - val_loss: 0.0194 - val_fcn_BCE_loss: 0.0185\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.00660\n",
      "Epoch 724/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0150 - fcn_BCE_loss: 0.0142 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 723 , image ids: [700] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0135 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.00660\n",
      "Epoch 725/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0247 - fcn_BCE_loss: 0.0239 - val_loss: 0.0173 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.00660\n",
      "Epoch 726/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0120 - fcn_BCE_loss: 0.0111 - val_loss: 0.0261 - val_fcn_BCE_loss: 0.0253\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.00660\n",
      "Epoch 727/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0120 - val_loss: 0.0122 - val_fcn_BCE_loss: 0.0114\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.00660\n",
      "Epoch 728/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0134 - val_fcn_BCE_loss: 0.0125\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.00660\n",
      "Epoch 729/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0241 - fcn_BCE_loss: 0.0232 - val_loss: 0.0216 - val_fcn_BCE_loss: 0.0207\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.00660\n",
      "Epoch 730/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0069 - val_fcn_BCE_loss: 0.0061\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.00660\n",
      "Epoch 731/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0160 - fcn_BCE_loss: 0.0152 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 730 , image ids: [337] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0151 - val_loss: 0.0211 - val_fcn_BCE_loss: 0.0203\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.00660\n",
      "Epoch 732/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.00660\n",
      "Epoch 733/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0211 - fcn_BCE_loss: 0.0202 - val_loss: 0.0141 - val_fcn_BCE_loss: 0.0132\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.00660\n",
      "Epoch 734/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0188 - fcn_BCE_loss: 0.0180 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 733 , image ids: [385] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0212 - fcn_BCE_loss: 0.0204 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.00660\n",
      "Epoch 735/820\n",
      " 4/10 [===========>..................] - ETA: 40s - loss: 0.0176 - fcn_BCE_loss: 0.0167\n",
      " Bad train_batch_x encountered (training phase) - epoch 734 , image ids: [82] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0173 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.00660\n",
      "Epoch 736/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0104 - fcn_BCE_loss: 0.0096 - val_loss: 0.0164 - val_fcn_BCE_loss: 0.0156\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.00660\n",
      "Epoch 737/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0143 - fcn_BCE_loss: 0.0135 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.00660\n",
      "Epoch 738/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0099 - fcn_BCE_loss: 0.0091\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [299] -- Retry with next sample\n",
      " 7/10 [====================>.........] - ETA: 21s - loss: 0.0097 - fcn_BCE_loss: 0.0089\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [2480] -- Retry with next sample\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 737 , image ids: [4737] -- Retry with next sample\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0080 - val_loss: 0.0207 - val_fcn_BCE_loss: 0.0199\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.00660\n",
      "Epoch 739/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0255 - fcn_BCE_loss: 0.0247 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.00660\n",
      "Epoch 740/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0166 - fcn_BCE_loss: 0.0158 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.00660\n",
      "Epoch 741/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.00660\n",
      "Epoch 742/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0105 - fcn_BCE_loss: 0.0097\n",
      " Bad train_batch_x encountered (training phase) - epoch 741 , image ids: [17] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0112 - val_fcn_BCE_loss: 0.0104\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.00660\n",
      "Epoch 743/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0142 - val_loss: 0.0119 - val_fcn_BCE_loss: 0.0111\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.00660\n",
      "Epoch 744/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0350 - val_fcn_BCE_loss: 0.0342\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.00660\n",
      "Epoch 745/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0190 - fcn_BCE_loss: 0.0182 - val_loss: 0.0126 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.00660\n",
      "Epoch 746/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0101 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.00660\n",
      "Epoch 747/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0251 - val_fcn_BCE_loss: 0.0242\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.00660\n",
      "Epoch 748/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0101 - fcn_BCE_loss: 0.0093\n",
      " Bad train_batch_x encountered (training phase) - epoch 747 , image ids: [1571] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0082 - val_loss: 0.0200 - val_fcn_BCE_loss: 0.0192\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.00660\n",
      "Epoch 749/820\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.00660\n",
      "Epoch 750/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0091 - fcn_BCE_loss: 0.0083 - val_loss: 0.0097 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.00660\n",
      "Epoch 751/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0135 - val_fcn_BCE_loss: 0.0126\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.00660\n",
      "Epoch 752/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0184 - fcn_BCE_loss: 0.0176 - val_loss: 0.0152 - val_fcn_BCE_loss: 0.0144\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.00660\n",
      "Epoch 753/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0152 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.00660\n",
      "Epoch 754/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0080 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0157\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.00660\n",
      "Epoch 755/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0110 - fcn_BCE_loss: 0.0102 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0078\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.00660\n",
      "Epoch 756/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0254 - fcn_BCE_loss: 0.0245\n",
      " Bad train_batch_x encountered (training phase) - epoch 755 , image ids: [2971] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0236 - fcn_BCE_loss: 0.0227 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 755 , image ids: [143] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0219 - fcn_BCE_loss: 0.0210 - val_loss: 0.0087 - val_fcn_BCE_loss: 0.0079\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.00660\n",
      "Epoch 757/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0165 - fcn_BCE_loss: 0.0157 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.00660\n",
      "Epoch 758/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0141 - fcn_BCE_loss: 0.0132 - val_loss: 0.0105 - val_fcn_BCE_loss: 0.0097\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.00660\n",
      "Epoch 759/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0185 - fcn_BCE_loss: 0.0177 - val_loss: 0.0076 - val_fcn_BCE_loss: 0.0068\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.00660\n",
      "Epoch 760/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0129 - fcn_BCE_loss: 0.0121 - val_loss: 0.0300 - val_fcn_BCE_loss: 0.0291\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.00660\n",
      "Epoch 761/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0126 - fcn_BCE_loss: 0.0117 - val_loss: 0.0160 - val_fcn_BCE_loss: 0.0151\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.00660\n",
      "Epoch 762/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0188 - fcn_BCE_loss: 0.0180 - val_loss: 0.0181 - val_fcn_BCE_loss: 0.0173\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.00660\n",
      "Epoch 763/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0237 - fcn_BCE_loss: 0.0229 - val_loss: 0.0186 - val_fcn_BCE_loss: 0.0178\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.00660\n",
      "Epoch 764/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0191 - fcn_BCE_loss: 0.0183\n",
      " Bad train_batch_x encountered (training phase) - epoch 763 , image ids: [3784] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0180 - fcn_BCE_loss: 0.0171 - val_loss: 0.0190 - val_fcn_BCE_loss: 0.0181\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.00660\n",
      "Epoch 765/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0190 - fcn_BCE_loss: 0.0182\n",
      " Bad train_batch_x encountered (training phase) - epoch 764 , image ids: [1042] -- Retry with next sample\n",
      " 6/10 [=================>............] - ETA: 28s - loss: 0.0197 - fcn_BCE_loss: 0.0189\n",
      " Bad train_batch_x encountered (training phase) - epoch 764 , image ids: [2456] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0299 - val_fcn_BCE_loss: 0.0290\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.00660\n",
      "Epoch 766/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0189 - fcn_BCE_loss: 0.0181 - val_loss: 0.0210 - val_fcn_BCE_loss: 0.0201\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.00660\n",
      "Epoch 767/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0228 - fcn_BCE_loss: 0.0220 - val_loss: 0.0127 - val_fcn_BCE_loss: 0.0118\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.00660\n",
      "Epoch 768/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0179 - fcn_BCE_loss: 0.0171 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.00660\n",
      "Epoch 769/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0134 - fcn_BCE_loss: 0.0126 - val_loss: 0.0149 - val_fcn_BCE_loss: 0.0141\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.00660\n",
      "Epoch 770/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0247 - fcn_BCE_loss: 0.0239\n",
      " Bad train_batch_x encountered (training phase) - epoch 769 , image ids: [1712] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0208 - fcn_BCE_loss: 0.0200 - val_loss: 0.0096 - val_fcn_BCE_loss: 0.0088\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.00660\n",
      "Epoch 771/820\n",
      "10/10 [==============================] - 82s 8s/step - loss: 0.0244 - fcn_BCE_loss: 0.0236 - val_loss: 0.0101 - val_fcn_BCE_loss: 0.0093\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.00660\n",
      "Epoch 772/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0177 - fcn_BCE_loss: 0.0169 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 771 , image ids: [664] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0108\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.00660\n",
      "Epoch 773/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0133 - val_loss: 0.0201 - val_fcn_BCE_loss: 0.0193\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.00660\n",
      "Epoch 774/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0253 - val_fcn_BCE_loss: 0.0244\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.00660\n",
      "Epoch 775/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0139 - val_fcn_BCE_loss: 0.0130\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.00660\n",
      "Epoch 776/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0159 - fcn_BCE_loss: 0.0151 - val_loss: 0.0146 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.00660\n",
      "Epoch 777/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0181 - fcn_BCE_loss: 0.0173 - val_loss: 0.0107 - val_fcn_BCE_loss: 0.0099\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.00660\n",
      "Epoch 778/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0075 - fcn_BCE_loss: 0.0066\n",
      " Bad train_batch_x encountered (training phase) - epoch 777 , image ids: [3932] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0126 - fcn_BCE_loss: 0.0118 - val_loss: 0.0095 - val_fcn_BCE_loss: 0.0087\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.00660\n",
      "Epoch 779/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 778 , image ids: [2603] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0129 - fcn_BCE_loss: 0.0121 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 778 , image ids: [457] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0122 - fcn_BCE_loss: 0.0114 - val_loss: 0.0199 - val_fcn_BCE_loss: 0.0190\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.00660\n",
      "Epoch 780/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0204 - fcn_BCE_loss: 0.0196 - val_loss: 0.0187 - val_fcn_BCE_loss: 0.0179\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.00660\n",
      "Epoch 781/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0060 - fcn_BCE_loss: 0.0051 \n",
      " Bad train_batch_x encountered (training phase) - epoch 780 , image ids: [3702] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0145 - val_loss: 0.0142 - val_fcn_BCE_loss: 0.0134\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.00660\n",
      "Epoch 782/820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 79s 8s/step - loss: 0.0153 - fcn_BCE_loss: 0.0144 - val_loss: 0.0212 - val_fcn_BCE_loss: 0.0204\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.00660\n",
      "Epoch 783/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0181 - fcn_BCE_loss: 0.0172\n",
      " Bad train_batch_x encountered (training phase) - epoch 782 , image ids: [1880] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0173 - fcn_BCE_loss: 0.0165 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0177\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.00660\n",
      "Epoch 784/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0137 - val_fcn_BCE_loss: 0.0129\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.00660\n",
      "Epoch 785/820\n",
      " 8/10 [=======================>......] - ETA: 13s - loss: 0.0151 - fcn_BCE_loss: 0.0143\n",
      " Bad train_batch_x encountered (training phase) - epoch 784 , image ids: [3862] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.00660\n",
      "Epoch 786/820\n",
      " 1/10 [==>...........................] - ETA: 1:00 - loss: 0.0318 - fcn_BCE_loss: 0.0310\n",
      " Bad train_batch_x encountered (training phase) - epoch 785 , image ids: [4953] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0170 - fcn_BCE_loss: 0.0162 - val_loss: 0.0180 - val_fcn_BCE_loss: 0.0172\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.00660\n",
      "Epoch 787/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0155 - fcn_BCE_loss: 0.0147 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 786 , image ids: [266] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0145 - fcn_BCE_loss: 0.0137 - val_loss: 0.0117 - val_fcn_BCE_loss: 0.0109\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.00660\n",
      "Epoch 788/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0149 - fcn_BCE_loss: 0.0141 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 787 , image ids: [972] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0161 - fcn_BCE_loss: 0.0153 - val_loss: 0.0079 - val_fcn_BCE_loss: 0.0071\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.00660\n",
      "Epoch 789/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0155 - fcn_BCE_loss: 0.0146 - val_loss: 0.0116 - val_fcn_BCE_loss: 0.0107\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.00660\n",
      "Epoch 790/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0283 - fcn_BCE_loss: 0.0275 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 789 , image ids: [45] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0276 - fcn_BCE_loss: 0.0268 - val_loss: 0.0098 - val_fcn_BCE_loss: 0.0090\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.00660\n",
      "Epoch 791/820\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0093 - fcn_BCE_loss: 0.0085 - val_loss: 0.0224 - val_fcn_BCE_loss: 0.0216\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.00660\n",
      "Epoch 792/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 791 , image ids: [3969] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0270 - fcn_BCE_loss: 0.0262 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 791 , image ids: [63] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0255 - fcn_BCE_loss: 0.0247 - val_loss: 0.0366 - val_fcn_BCE_loss: 0.0358\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.00660\n",
      "Epoch 793/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0169 - fcn_BCE_loss: 0.0161 - val_loss: 0.0065 - val_fcn_BCE_loss: 0.0057\n",
      "\n",
      "Epoch 00793: val_loss improved from 0.00660 to 0.00651, saving model to F:\\models_newshapes\\train_fcn8_l2_newshapes\\fcn20181224T1746\\fcn_0793.h5\n",
      "Epoch 794/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0131 - fcn_BCE_loss: 0.0122 \n",
      " Bad train_batch_x encountered (training phase) - epoch 793 , image ids: [1457] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0130 - fcn_BCE_loss: 0.0122 - val_loss: 0.0067 - val_fcn_BCE_loss: 0.0059\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.00651\n",
      "Epoch 795/820\n",
      " 4/10 [===========>..................] - ETA: 41s - loss: 0.0172 - fcn_BCE_loss: 0.0163\n",
      " Bad train_batch_x encountered (training phase) - epoch 794 , image ids: [3331] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0172 - fcn_BCE_loss: 0.0164 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 794 , image ids: [672] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0174 - fcn_BCE_loss: 0.0166 - val_loss: 0.0174 - val_fcn_BCE_loss: 0.0165\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.00651\n",
      "Epoch 796/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0154 - fcn_BCE_loss: 0.0146 - val_loss: 0.0125 - val_fcn_BCE_loss: 0.0117\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.00651\n",
      "Epoch 797/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0137 - fcn_BCE_loss: 0.0129 - val_loss: 0.0155 - val_fcn_BCE_loss: 0.0147\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.00651\n",
      "Epoch 798/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0304 - fcn_BCE_loss: 0.0296 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 797 , image ids: [909] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0280 - fcn_BCE_loss: 0.0272 - val_loss: 0.0385 - val_fcn_BCE_loss: 0.0377\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.00651\n",
      "Epoch 799/820\n",
      "10/10 [==============================] - 77s 8s/step - loss: 0.0177 - fcn_BCE_loss: 0.0168 - val_loss: 0.0158 - val_fcn_BCE_loss: 0.0150\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.00651\n",
      "Epoch 800/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0130 - fcn_BCE_loss: 0.0122\n",
      " Bad train_batch_x encountered (training phase) - epoch 799 , image ids: [4553] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0101 - fcn_BCE_loss: 0.0093 - val_loss: 0.0132 - val_fcn_BCE_loss: 0.0123\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.00651\n",
      "Epoch 801/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0167 - fcn_BCE_loss: 0.0159\n",
      " Bad train_batch_x encountered (training phase) - epoch 800 , image ids: [1572] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0172 - fcn_BCE_loss: 0.0164 - val_loss: 0.0329 - val_fcn_BCE_loss: 0.0321\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.00651\n",
      "Epoch 802/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0150 - fcn_BCE_loss: 0.0141 - val_loss: 0.0108 - val_fcn_BCE_loss: 0.0100\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.00651\n",
      "Epoch 803/820\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0221 - fcn_BCE_loss: 0.0213 - val_loss: 0.0160 - val_fcn_BCE_loss: 0.0152\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.00651\n",
      "Epoch 804/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0125 - fcn_BCE_loss: 0.0117\n",
      " Bad train_batch_x encountered (training phase) - epoch 803 , image ids: [3711] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0156 - fcn_BCE_loss: 0.0148 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.00651\n",
      "Epoch 805/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0148 - fcn_BCE_loss: 0.0140 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.00651\n",
      "Epoch 806/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0178 - fcn_BCE_loss: 0.0170 - val_loss: 0.0225 - val_fcn_BCE_loss: 0.0217\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.00651\n",
      "Epoch 807/820\n",
      " 2/10 [=====>........................] - ETA: 55s - loss: 0.0108 - fcn_BCE_loss: 0.0100 \n",
      " Bad train_batch_x encountered (training phase) - epoch 806 , image ids: [2050] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0127 - fcn_BCE_loss: 0.0119 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 806 , image ids: [554] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0134 - fcn_BCE_loss: 0.0126 - val_loss: 0.0292 - val_fcn_BCE_loss: 0.0284\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.00651\n",
      "Epoch 808/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0176\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.00651\n",
      "Epoch 809/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0306 - fcn_BCE_loss: 0.0298\n",
      " Bad train_batch_x encountered (training phase) - epoch 808 , image ids: [2864] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0238 - fcn_BCE_loss: 0.0230 - val_loss: 0.0170 - val_fcn_BCE_loss: 0.0162\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.00651\n",
      "Epoch 810/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0144 - fcn_BCE_loss: 0.0136 - val_loss: 0.0148 - val_fcn_BCE_loss: 0.0140\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.00651\n",
      "Epoch 811/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0148 - fcn_BCE_loss: 0.0140 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 810 , image ids: [836] -- Retry with next sample\n",
      "\n",
      " Bad val_batch_x encountered (validation phase) - epoch 810 , image ids: [494] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0142 - fcn_BCE_loss: 0.0134 - val_loss: 0.0166 - val_fcn_BCE_loss: 0.0158\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.00651\n",
      "Epoch 812/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0143 - val_loss: 0.0185 - val_fcn_BCE_loss: 0.0177\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.00651\n",
      "Epoch 813/820\n",
      " 3/10 [========>.....................] - ETA: 48s - loss: 0.0086 - fcn_BCE_loss: 0.0077\n",
      " Bad train_batch_x encountered (training phase) - epoch 812 , image ids: [3354] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0089 - fcn_BCE_loss: 0.0081 - val_loss: 0.0144 - val_fcn_BCE_loss: 0.0136\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.00651\n",
      "Epoch 814/820\n",
      " 9/10 [==========================>...] - ETA: 6s - loss: 0.0127 - fcn_BCE_loss: 0.0119 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 813 , image ids: [381] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0128 - fcn_BCE_loss: 0.0120 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.00651\n",
      "Epoch 815/820\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0140 - fcn_BCE_loss: 0.0132 - val_loss: 0.0178 - val_fcn_BCE_loss: 0.0170\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.00651\n",
      "Epoch 816/820\n",
      "\n",
      " Bad train_batch_x encountered (training phase) - epoch 815 , image ids: [2472] -- Retry with next sample\n",
      "10/10 [==============================] - 80s 8s/step - loss: 0.0119 - fcn_BCE_loss: 0.0111 - val_loss: 0.0177 - val_fcn_BCE_loss: 0.0169\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.00651\n",
      "Epoch 817/820\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.0215 - fcn_BCE_loss: 0.0207 - val_loss: 0.0143 - val_fcn_BCE_loss: 0.0135\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.00651\n",
      "Epoch 818/820\n",
      " 5/10 [==============>...............] - ETA: 34s - loss: 0.0165 - fcn_BCE_loss: 0.0157\n",
      " Bad train_batch_x encountered (training phase) - epoch 817 , image ids: [1625] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0148 - fcn_BCE_loss: 0.0140 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 817 , image ids: [922] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0167 - fcn_BCE_loss: 0.0159 - val_loss: 0.0145 - val_fcn_BCE_loss: 0.0137\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.00651\n",
      "Epoch 819/820\n",
      " 6/10 [=================>............] - ETA: 27s - loss: 0.0163 - fcn_BCE_loss: 0.0155\n",
      " Bad train_batch_x encountered (training phase) - epoch 818 , image ids: [3282] -- Retry with next sample\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.0160 - fcn_BCE_loss: 0.0152 - val_loss: 0.0188 - val_fcn_BCE_loss: 0.0180\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.00651\n",
      "Epoch 820/820\n",
      " 7/10 [====================>.........] - ETA: 20s - loss: 0.0150 - fcn_BCE_loss: 0.0142\n",
      " Bad train_batch_x encountered (training phase) - epoch 819 , image ids: [1855] -- Retry with next sample\n",
      " 9/10 [==========================>...] - ETA: 7s - loss: 0.0134 - fcn_BCE_loss: 0.0126 \n",
      " Bad val_batch_x encountered (validation phase) - epoch 819 , image ids: [460] -- Retry with next sample\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0151 - fcn_BCE_loss: 0.0143 - val_loss: 0.0231 - val_fcn_BCE_loss: 0.0223\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.00651\n",
      "Final : self.epoch 820   epochs 820\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = ['block1+']   # args.fcn_layers\n",
    "loss_names   = ['fcn_BCE_loss']\n",
    "fcn_model.epoch = fcn_model.config.LAST_EPOCH_RAN\n",
    "\n",
    "fcn_model.train_in_batches(\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:36.427763Z",
     "start_time": "2018-12-20T19:10:36.127306Z"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(fcn_model.keras_model._feed_inputs)\n",
    "pp.pprint(fcn_model.keras_model._feed_targets)\n",
    "pp.pprint(fcn_model.keras_model._feed_loss_fns)\n",
    "pp.pprint(fcn_model.keras_model._feed_outputs)\n",
    "pp.pprint(fcn_model.keras_model._feed_sample_weights)\n",
    "pp.pprint(fcn_model.keras_model.updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:39.680073Z",
     "start_time": "2018-12-20T19:10:39.358322Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as KB\n",
    "fcn_hm_layer = fcn_model.keras_model.layers[32]\n",
    "fcn_sp3_layer = fcn_model.keras_model.layers[30]\n",
    "pp.pprint(fcn_hm_layer.__dict__ )\n",
    "pp.pprint(fcn_sp3_layer.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:10:51.790032Z",
     "start_time": "2018-12-20T19:10:51.229309Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    wght1 = fcn_hm_layer._trainable_weights[0].eval()\n",
    "    wght2 = fcn_sp3_layer._trainable_weights[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T19:11:00.618804Z",
     "start_time": "2018-12-20T19:11:00.311302Z"
    }
   },
   "outputs": [],
   "source": [
    "print(wght1.shape, wght2.shape)\n",
    "print(wght1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF]",
   "language": "python",
   "name": "conda-env-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
