{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Compare ouptuts from Heatmap layer and FCN layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:46:23.145856Z",
     "start_time": "2018-05-19T13:46:02.162800Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_development_logs\\shapes20180519T1546\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> Generate pyramid anchors \n",
      "      Anchor  scales:   (8, 16, 32, 64, 128)\n",
      "      Anchor  ratios:   [0.5, 1, 2]\n",
      "      Anchor  stride:   1\n",
      "      Feature shapes:   [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "      Feature strides:  [4, 8, 16, 32, 64]\n",
      ">>> generate_anchors()   Scale(s):  [8 8 8] Ratios:  [0.5 1.  2. ]  Heights:  [11.3137  8.      5.6569] Widths:  [ 5.6569  8.     11.3137]\n",
      ">>> generate_anchors()   Scale(s):  [16 16 16] Ratios:  [0.5 1.  2. ]  Heights:  [22.6274 16.     11.3137] Widths:  [11.3137 16.     22.6274]\n",
      ">>> generate_anchors()   Scale(s):  [32 32 32] Ratios:  [0.5 1.  2. ]  Heights:  [45.2548 32.     22.6274] Widths:  [22.6274 32.     45.2548]\n",
      ">>> generate_anchors()   Scale(s):  [64 64 64] Ratios:  [0.5 1.  2. ]  Heights:  [90.5097 64.     45.2548] Widths:  [45.2548 64.     90.5097]\n",
      ">>> generate_anchors()   Scale(s):  [128 128 128] Ratios:  [0.5 1.  2. ]  Heights:  [181.0193 128.      90.5097] Widths:  [ 90.5097 128.     181.0193]\n",
      "    Size of anchor array is : (4092, 4)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (5, 4092)\n",
      "     Deltas :  (5, 4092, 4)\n",
      "     Anchors:  (5, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (5, ?, ?) (5, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (5, ?, ?) (5, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (5, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (5, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  6\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (5, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (5, ?) (None, 32)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (5, None, 4)\n",
      "    mrcnn_class :  (?, 32, 4) Tensor(\"mrcnn_class/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "    gather_ind  :  (5, 32, 3) Tensor(\"cntxt_layer/stack:0\", shape=(5, 32, 3), dtype=int32)\n",
      "    pred_scores :  (5, 32)\n",
      "    pred_deltas :  (5, 32, 4)\n",
      "    output_rois :  (5, ?, 4) Tensor(\"cntxt_layer/mul:0\", shape=(5, ?, 4), dtype=float32)\n",
      "    refined rois:  (5, 32, 4) Tensor(\"cntxt_layer/stack_1:0\", shape=(5, 32, 4), dtype=float32)\n",
      "    refined rois clipped:  (5, 32, 4) Tensor(\"cntxt_layer/Select_1:0\", shape=(5, 32, 4), dtype=float32)\n",
      "    pred_array        (5, 32, 6)\n",
      "scatter_ind <class 'tensorflow.python.framework.ops.Tensor'> shape (5, 32, 3)\n",
      "    pred_scatter shape is  (5, 4, 32, 6)\n",
      "(5, 4, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)\n",
      "    gt_bboxes.shape    :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    gt_scores_exp shape  (?, ?, 1)\n",
      "    gt_array shape : (5, 100, 7) (5, 100, 7)\n",
      "     gt_tensor final shape  :  (5, 4, 100, 6)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (5, 4, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (5, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (5, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (5, 4, 128, 128) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss_norm   :  (5, 4, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (5, 4, 32, 6)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap expanded shape : (5, 4, 1, 128, 128)\n",
      "    heatmap original shape  :  (5, 4, 128, 128)\n",
      "    heatmap replicated      :  (5, 4, 32, 128, 128)\n",
      "    heatmap flattened       :  (640, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (640, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (5, 128, 128, 4)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (5, 4, 100, 6)\n",
      "    num of bboxes per class is :  100\n",
      "    pt2_sum shape  (5, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (5, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (5, 4, 128, 128) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss_norm   :  (5, 4, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (5, 4, 100, 6)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  100\n",
      "    heatmap expanded shape : (5, 4, 1, 128, 128)\n",
      "    heatmap original shape  :  (5, 4, 128, 128)\n",
      "    heatmap replicated      :  (5, 4, 100, 128, 128)\n",
      "    heatmap flattened       :  (2000, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (2000, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (5, 128, 128, 4)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (5, 4) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (5, 4) Keras tensor  True\n",
      "\n",
      "    Output build_heatmap \n",
      "     pred_heatmap_norm  :  (5, 128, 128, 4) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (5, 128, 128, 4) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (5, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (5, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (5, 128, 128, 4)\n",
      "     height : 128 width : 128 classes : 4\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (5, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (5, 32, 32, 128)\n",
      "   FCN Block 31 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 33 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (5, 16, 16, 256)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (5, 16, 16, 1024)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (5, 16, 16, 1024)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (5, 16, 16, 4)  keras_tensor  True\n",
      "   h_factor :  8.0 w_factor :  8.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (8.0, 8.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (8.0, 8.0)\n",
      "     CHANNELS LAST: X:  (5, 16, 16, 4)  KB.int_shape() :  (None, 16, 16, 4)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (5, ?, ?, 4)\n",
      "     Dimensions of X after set_shape() :  (5, 128, 128, 4)\n",
      "     BilinearUpSampling2D. compute_output_shape()\n",
      "     Bilinear output shape is: None , 128 , 128 , 4\n",
      "   FCN Bilinear upsmapling layer  shape is :  (5, 128, 128, 4) Keras tensor  True\n",
      "\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    fcn_heatmap:  (5, 16, 16, 4)  Keras tensor  True\n",
      "    fcn_heatmap_norm:  (5, 128, 128, 4)  Keras tensor  True\n",
      "   fcn_heatmap      :  (None, 16, 16, 4)  Keras tensor  True\n",
      "   fcn_heatmap_norm :  (None, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> FCN Scoring Layer \n",
      "   > FCNScoreLayer Call()  2\n",
      "     fcn_heatmap.shape    : (5, 128, 128, 4) (None, 128, 128, 4)\n",
      "      chm_scores.shape    : (?, ?, ?, ?) (None, 4, 32, 10)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  <mrcnn.shapes.ShapesConfig object at 0x000001967B870EF0>\n",
      "    orignal in_heatmap shape :  (5, 128, 128, 4)\n",
      "    num of bboxes per class is :  32\n",
      "    Rois per image  :  32\n",
      "    heatmap original shape   :  (5, 128, 128, 4)\n",
      "    heatmap transposed shape : (5, 4, 128, 128)\n",
      "    heatmap tiled            :  (5, 4, 32, 128, 128)\n",
      "    fcn_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    Output build_fcn_score \n",
      "     pred_heatmap_norm  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (5, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    Adding  FCN loss layers\n",
      "---------------------------------------------------\n",
      " fcn_heatmap_norm  : True\n",
      " fcn_scores   : True\n",
      " output_rois       : True\n",
      " pred_heatmap      : True\n",
      " gt_heatmap        : True\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_development_logs\n",
      " Model Parent Path     :  E:\\Models\n",
      " Resent Model Path     :  E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "-----------------------------------------------\n",
      "Load model with init parm:  last\n",
      "-----------------------------------------------\n",
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_development_logs\n",
      "('E:\\\\Models\\\\mrcnn_development_logs\\\\shapes20180513T1946', 'E:\\\\Models\\\\mrcnn_development_logs\\\\shapes20180513T1946\\\\mask_rcnn_shapes_3666.h5')\n",
      "load model with <init_with> =  last\n",
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_development_logs\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_3666.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_3666.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 3667 \n",
      "    Load weights complete :  E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_3666.h5\n",
      "Load weights complete E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_3666.h5\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     5\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 5\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                4\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string, parse_image_meta, apply_box_deltas_tf\n",
    "from mrcnn.visualize   import display_gt_bboxes, display_roi_proposals, plot_gaussian, plot_gaussian2\n",
    "from mrcnn.visualize   import display_gt_bboxes, display_roi_proposals\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_oldshapes_dev\n",
    "\n",
    "model, dataset_train, train_generator, config = prep_oldshapes_dev(init_with = 'last', FCN_layers = True)\n",
    "model_info = [model, config, dataset_train, train_generator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:47:06.432984Z",
     "start_time": "2018-05-19T13:47:06.148760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Generate pyramid anchors \n",
      "      Anchor  scales:   (8, 16, 32, 64, 128)\n",
      "      Anchor  ratios:   [0.5, 1, 2]\n",
      "      Anchor  stride:   1\n",
      "      Feature shapes:   [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "      Feature strides:  [4, 8, 16, 32, 64]\n",
      ">>> generate_anchors()   Scale(s):  [8 8 8] Ratios:  [0.5 1.  2. ]  Heights:  [11.3137  8.      5.6569] Widths:  [ 5.6569  8.     11.3137]\n",
      ">>> generate_anchors()   Scale(s):  [16 16 16] Ratios:  [0.5 1.  2. ]  Heights:  [22.6274 16.     11.3137] Widths:  [11.3137 16.     22.6274]\n",
      ">>> generate_anchors()   Scale(s):  [32 32 32] Ratios:  [0.5 1.  2. ]  Heights:  [45.2548 32.     22.6274] Widths:  [22.6274 32.     45.2548]\n",
      ">>> generate_anchors()   Scale(s):  [64 64 64] Ratios:  [0.5 1.  2. ]  Heights:  [90.5097 64.     45.2548] Widths:  [45.2548 64.     90.5097]\n",
      ">>> generate_anchors()   Scale(s):  [128 128 128] Ratios:  [0.5 1.  2. ]  Heights:  [181.0193 128.      90.5097] Widths:  [ 90.5097 128.     181.0193]\n",
      "    Size of anchor array is : (4092, 4)\n"
     ]
    }
   ],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:47:18.732303Z",
     "start_time": "2018-05-19T13:47:16.883369Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  99\n",
      "Image meta [ 99 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2 1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19679ae2898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  109\n",
      "Image meta [109 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 2 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAysAAACoCAYAAADgm3G3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAD2FJREFUeJzt3X2sJWddB/Dv2vIqKEWIvMSaCIECaipSKBaGUYgjSMNLRJB3CVGDXSitwTSKaLC0NCLVrooEUw2+ACU0AUMYFZgOYIoLpTEaIlregrQFQwtF3kp7/WPOcU9vd+/e7d57zzMzn0+y2btzzpn7e05m5zzf+T1z776NjY0AAACU5nvWXQAAAMDhCCsAAECRhBUAAKBIwgoAAFAkYQUAACiSsAIAABTpxHUXsG511dRJnt717dkr267u+vbUbb7+I0me2fXt9XXVvCTJ73d9+4DFY3+S5F1d377/CK+9S5IuyZO7vr2xrpqHJnlzkhOS/GvXty+rq+bBSf5qse3tXd++cYtanpak7vr2lYt/vzbJzyTZl2R/17cfr6vm95L8XJJvJHle17df3M44Gb+6at7S9e1Lj/KcFye5V9e3F+9NVQA7q66aeyd5XNe3717ZdtTz3zb222WYL9x4nCUCx0Bn5fhdkeQxi69/OslH66p5xOLfj0zyz4d7UV01Jyd5f5IfWdn8miTndn37uCTfV1fN6UnOSvL6JI9N8ry6au5xhP2dk+SiDMEkddU8JMmpXd+ekeSFSc6vq+ZeSZ6a5PQklyR5+R0aMaN0vB/UACPx4xku1P0/5z8Yr9l3VrajrppXZwgBf5zkH5M0Xd9+ZfHwFUmqJO9O8oAkb0ryxLpqPpvkG13ffnNxNWbV2Um+neQlGTopS69I8j+Lr09McnOSq5KclOTOi+0311XzD0nOX+zj1V3f/nySTyV5WZIzF8/7TIaQsrqvrya5drGveyS56ZjfDEajrprvS/I3Se6b5LokD+369mF11VyZ4VhoMxwP52Q4Rn5n5bX7kvxpkodncax2ffuFvR0BY7ToVl+YZCPJO5LcmGR/kmuSnNz17WNWr1Avv07y4MXr7pTh3PS0JK/OcKEmSZ6f5NIM567PZzgmv7s3o2JkXpHktLpqHp/hM7VN8sKub09ddI9fmOE4em/Xt79bV80/Jfm3DBfyDnZ9u7+umudnODd+PsmPdX37oOXOFyse/jzDsXqw69tz93BsMDs6K4NfqKumW/45zOMXJHlykrcmec1KUEmSjyT5ybpqTknyHxmWddVJTkvy4STp+rbe9Ofqrm8/2fXtp1a/Sde3X+76dqOummcnuXvXtx9P8qUMHZNPJrmi69tvJ/mVDB/qb1x8na5v/z7JLSv7urnr2xsWnZi3ZAg3d0py62Jfr0/y13fw/WIcXpzkfV3fnp7kPTnUxfvBJC/q+vYPk/xmkscneWKSH1157ZlJ/rfr2ydk6Pi9Zq+KZvTOzHBuOiNDUDknyU9lmED+0BavOyXDcfmEDBdXHr7Y/sGub5sk5yV5U9e3dYZz2LN3pXqm4I+SvDPJvXPoXLd0nyRPynB8Pmex7cTF8x+b5El11dw9ybkZjttfTXL/Tfu/KMkrur6tktyjrpozdmsggLCy9M7VMLH5wcXVu79M8ogk79v02NczvI9PTPKBrm+/nOR7M1yh6ZJhneumP0e8H6aumhdkODk+b7Hp/AzLyx6c5OS6as7o+vazST6b5FNd3/73Fvs6Kcl7k1zc9e2VGe5V+XqSBy2+fvORXsskPDTJx5Kk69u/yDDBS5Kbur69rq6a+ya5tuvbb3V9+5Wuby9Yee0pSZ68CO8XJvmBPaybcbswQwD+QIau3hcWx9gXk3z6MM/ft/j72iRvrKvm0gznqBMW25cXdU5Jct5KJ+aBu1M+E3JT17fXbdr2nSR/m+RAkrusbP/3rm83klyf4TP8usVxe32Sz23ax0OSHFgci49K8sO7UTzzU1fNRYt54kXrrqUkloFtQ10135/kpUneluSVSd6w6SlXJ3lBhvtBkqHD8pQkFydDZ2Wb3+fMJC9K8tSub7+x2PzVJF/v+vbWumq+lOFelkdnOJnes66aR3d9+y+H2dcJGa6mv77r2/csNt+U4Wr5Rl0112dogzNdn05yaob7qM7JocnfrYu/v5LkAXXV3DlD1+3SDOE2GZbsvK3r29fWVfOgDEsdYTuek+ECyX/VVfOJDOesuyW5a5KTF8/5VpL71VXznRzq+L0hSZPhuPxoDoWY5fF6TZJ3dH37obpqlhde4HA2Mhw/t65uXNy3+Wtd3z68rpoHJnnGptcs3Zrh3HiXJPfMoeN26ZokL+/69nN11Tw3wxwAjlvXt69adw0lEla25w1J/iDJu5J8uK6ad3d9+58rj1+R5Ge7vl3eb/LBDGtcv3WM3+d1Sb6b5L111STD0ptXJfm7umqWy7fen2Hp2S9mOBm/fdFt+c6mfT09Qyfo3Lpqzk3yma5vf7mummcufoJZkvzGMdbHuLw5yVvrqvmlDFcLb9NJ7fr2lrpqzs9w/O7LcLwtlztcnuQpddVckeRuSX59z6pm7K5O8s66am7McC68IkOX+doMV7WT5M8yLLu5JkOXOEkuy9CNuSHJ15Lcb9N+L0jylrpqXpfhpxk+d9dGwNh9OsNSr7tu2v61JNfUVXNw8fWXjvBDa27J0CH8cIZ7VjYH4/OSXFpXzV2TfCHD3ADYJfs2NjaO/iwAOE7H8mPhYZ3qqjm769uL66q5T5IPdX37sHXXBHOlswIAcFt3r6vmYxl+euZvr7sYmDOdFQAAoEh+GhgAAFAkYQUAACiSsAIAABSpmBvs9//WzW6emZFLzr/TvqM/a+/d7SfOchzOyDc/caC449AxOC8lHoOJ43BuSjwOHYPzstUxqLMCAAAUSVgBAACKJKwAAABFElYAAIAiCSsAAECRhBUAAKBIwgoAAFAkYQUAACiSsAIAABRJWAEAAIokrAAAAEUSVgAAgCIJKwAAQJGElWN03i1XrrsEyA0HD6y7BACAXXfiugso0dECyZEev+CE03ejHGbqaIHkSI+fdNpZu1EOAMCeE1YWdqJjsroPwYU7Yic6Jqv7EFwAgDGbdVjZzSVdggvbtZtLugQXAGDMZhlW9vq+k+X3E1pYtdf3nSy/n9ACAIzF7G6wX+cN8m7OZ2mdN8i7OR8AGIvZdFZKCQq6LPNWSlDQZQEAxmAWnZVSgsqqEmtid5USVFaVWBMAwNLkw0rJoaDk2thZJYeCkmsDAOZt0mFlDGFgDDVyfMYQBsZQIwAwP5MNK2MKAWOqlWMzphAwploBgHmYZFgZ4+R/jDWztTFO/sdYMwAwXZMLK2Oe9I+5dm5rzJP+MdcOAEzLpMLKFCb7UxjD3E1hsj+FMQAA4zepsAIAAEzHZMLKlDoSUxrL3EypIzGlsQAA4zSJsDLFyf0UxzR1U5zcT3FMAMB4TCKsAAAA0yOsFEx3hRLorgAA6yKsAAAARRJWAACAIo0+rEx9qdTUxzcVU18qNfXxAQBlGn1YAQAApklYAQAAijTqsDKXJVJzGedYzWWJ1FzGCQCUY9RhBQAAmC5hBQAAKJKwAgAAFElYAQAAiiSsAAAARRJWAACAIgkrAABAkYQVAACgSMIKAABQJGEFAAAokrACAAAUSVgBAACKJKwAAABFGnVYueCE09ddwp6YyzjH6qTTzlp3CXtiLuMEAMox6rACAABMl7ACAAAUafRhZepLpKY+vqmY+hKpqY8PACjT6MMKAAAwTcIKAABQJGGlYJaAUQJLwACAdRFWAACAIk0irEyxAzHFMU3dFDsQUxwTADAekwgrybQm91May9xMaXI/pbEAAOM0mbACAABMy6TCyhQ6ElMYw9xNoSMxhTEAAOM3qbCSjHuyP+baua0xT/bHXDsAMC2TCyvJOCf9Y6yZrY1x0j/GmgGA6ZpkWEnGNfkfU60cmzFN/sdUKwAwDyeuu4DddMEJp+e8W65cdxlb2m5QufpRj9nlSvbaVesuYM+cdNpZueHggXWXsSVBhbEo/f8SADtrsp2VpZK7FiXXxs4qOQyUXBsAMG+TDytJmaGgxJrYXSWGghJrAgBYmvQysFXLcLDuZWFCyrwtw8G6l7IIKQDAGMyis7J02f7L88izr13b9xdUWFpnWBBUgBLccPDA2i/cAOWbTWdl1TKwXHXx/ffk+wkpHM5ed1mEFKBEy3OgcxRwOLMJK5ftv/x221a7LDsdXAQUtmv1A3qng4sPf6BEhzvXrW5z7gKWZhNWjmYngssjz742z7rkGTtVEjO0E8HFhzwwdjsRXG44eMD5ECZgFmHlcF2VrWx1X8tVF99/y8cv23+5wMKO2OpD1ocwMFbHeiFmq+cf7fdYOVfC+E3+BvtjDSpHs50b9Hf6e8JmPnyBMdrppa7b2Z+b+GHcJh1WhAYAKIPQANwRkw4r6yQoAUAZBCUYr8mGFWEBAMogLAB31GTDSgkEJgAog8AE4zTJsCIkAEAZhATgeEwurJQWVEqrBwD2SmlBpbR6gKObXFgpkcACAGUQWGBcJhVWhAIAKINQAOyESYWVkglSAFAGQQrGYzJhRRgAgDIIA8BOmUxYGQOBCgDKIFDBOEwirAgBAFAGIQDYSZMIK2MiWAFAGQQrKJ+wsgYCCwCUQWCBso0+rJj4A0AZTPyBnTb6sDJWQhYAlEHIgnKNOqyY8ANAGUz4gd0w2rAyhaAyhTEAwBSCyhTGAFM02rACAABM2yjDypQ6ElMaCwDzM6WOxJTGAlMxyrAyNQILAJRBYIGyjC6smNgDQBlM7IHdNrqwMlVCGACUQQiDcowqrJjQA0AZTOiBvTCasDKHoDKHMQIwfnMIKnMYI4zBaMIKAAAwL6MIK3PqOMxprACMz5w6DnMaK5RqFGEFAACYn+LDyhw7DXMcMwDlm2OnYY5jhpIUHVbmPGmf89gBKM+cJ+1zHjusW7FhxWTdewBAGUzWvQewLsWGFQAAYN6KDCs6Cod4LwBYJx2FQ7wXsPeKDCsAAADFhRWdhNvzngCwDjoJt+c9gb114roL2OxZlzxj3SUU6epHXbjuEgCYmZNOO2vdJQAzV1xnBQAAIBFWAACAQgkrAABAkYQVAACgSMIKAABQJGEFAAAokrACAAAUqbjfs8Lhnfqxj667hJ3l1+kAd8DUfu/HNz/hFwwCbEVnBQAAKJKwAgAAFGnfxsbGumsAAAC4HZ0VAACgSMIKAABQJGEFAAAokrACAAAUSVgBAACKJKwAAABFElYAAIAiCSsAAECRhBUAAKBIwgoAAFAkYQUAACiSsAIAABRJWAEAAIokrAAAAEUSVgAAgCIJKwAAQJGEFQAAoEjCCgAAUCRhBQAAKJKwAgAAFElYAQAAiiSsAAAARRJWAACAIgkrAABAkf4P41dgiKc0Z5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x196784fb2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  107\n",
      "Image meta [107 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 3 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19679b03588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  88\n",
      "Image meta [ 88 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAysAAACoCAYAAADgm3G3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAC7xJREFUeJzt3W2sJXVhx/HfCkXBx9UQzZoQU7GgvsEmKxp1HPTFFLtEUow2wadQbROzqKAx8QUSowgSEaJQLdFgXzRahZIoMU4N7uxQGymtEtPESHwgRsGngAoCgnJ9MbNyc929e9m9e89/5nw+yebeex7m/v+byTnzPf85525bWVkJAABAaR6z6AEAAADsj1gBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIp09KIHsGh11dRJzuz69p2rLru169tTNnj/ryf5u65vf1ZXzTlJPtj17Y7xuquS/EfXtzce4L6PTdIlOb3r21/VVXNSkquTHJXk213fvq2umhOT/Ot42b93fXv5OmN5dZK669vzxp8/kOQVSbYlObfr2/+rq+b9Sf4myX1Jzu769o6NzBNgM9RV86mub99ykNu8OclTur69YmtGBUCprKwcvr1JTh2/Py3JzXXVPH/8+a+T/Pf+7lRXzQlJbkzyl6suvjDJu7q+fWmSJ9VV86Iku5N8OMmLk5xdV80TDrC985NcmiFMUlfNXyU5pevblyR5Y5KL6qp5SpJdSV6U5ONJ3n5IMwY4RAcLFQBYbelXVjairpoLMkTAx5J8NUnT9e1d49V7k1RJvphkR5JPJnllXTW3J7mv69v766rp1mzynUl+l+ScDCsp+7wjyS/H749O8lCSbybZnuSY8fKH6qr5zyQXjdu4oOvbv01yW5K3JTljvN0PM0TK6m39Osmd47aekOSeR/2fQdHGlcJLkqwk+XySXyU5N8n3k5zQ9e2p4/545ria1yU5M8mJ4/3+IsN+8eokF2SI5CR5fZJrMuw3P0pyTte3v9+aWTFlddU8Kcm/JTk+yU+TnNT17XPrqvlGhsekNsPj0vkZHqvet+q+25L8c5LnZXzM7Pr2x1s7AwAWSawMXlNXzXqnfV2c5KYkO5NcuCpUkuTrSc6rq+bkJN/NcFrXvyT5dpL/SpKub+sDbbiumj993/XtL8bLXpfkuPG0reMznAZ2YZLru779XV01/5jks/vGPt73hvFAdd+2Hkpy97gS86kk785wIPpwku8kOTbDCgvzckaSy5N8IcmbMhwA7kzy1CT/u879Tk7ypq5vf1JXzfUZDg6TZE/Xt5fUVfPRJJ8c97P3JnldhgNQOJg3J/lK17dX1VXzD0lOHy9/eoZo/mldNbdmeDw6Lsk/ZYiXZNiff9v17cvrqnlxhsfBt27p6AFYKKeBDa7t+rbe92/tleMryJ9J8vwkX1lz3b0Z/h9fmeRrY3A8PsMTb5ckddV0a/4dMIzqqnlDhifrs8eLLspwetmJSU6oq+YlXd/enuT2JLd1ffuTdba1PcmXk1zR9e03MrxX5d4kzx6/v/pA92WyLknysiRfy/BK9o+7vn1gfG/SD/Zz+23j1zuTXF5XzTUZ9o+jxstvG7+enOS9q1Zinnlkhs8MnZQxlLu+/XSGF0uS5J4xVI5Pcue4n97V9e3Fq+57cpLTx/3ukiRP28Jxs0Tqqrl0fH6+dNFjYXnZD/fPysoG1FXz5CRvSfK5JOcluWzNTW5N8oYM7wdJhhWWVyW5Ill/ZWXN7zkjw6vhu7q+vW+8+NdJ7u369uG6an6e4b0sL8wQRE+sq+aFXd/+z362dVSSLyX5cNe3XxovvifDq5QrddX8LMMpPczL32eI0+/VVfOtDPvLsUkel+SE8TYPJHlGXTUP5pH3TF2WpElyV5Kb80jEPDx+/X6Sz3d9e1NdNfuiFzbiB0lOyfB+vvPzSAjv27fuSrKjrppjMqz+XpPhRZZk2O8+1/XtB+qqeXaGU25h03V9+55FjwHsh/tnZWVjLkvykQynILy2rprnrLl+b5LHdX277/0me5L8oevbBx7l7/lQhlcOvzyW9cuTvCfJZ+uquSnDE/mNSa7K8P6Wtye5anySX+vMDCtB7xq3dU3Xt3uSPDB+gtl1GU4NY15uTXLt+Er0ngyngXUZDgAfHG/ziSTXZjiV8Pbxsi9kWI3Zk+Q3SZ6xZrsXZ1hZuSlDsH8nsDFX55HVkVOz5nmn69s/ZFhB3pvh8e3Tq66+Psmz6qrZm2F//f+tGDAA5di2srKy6DEAW+DRfCQ3AEAJrKwAAABFsrICAAAUycoKAABQJLECAAAUSawAAABFKubvrDx43M2H9eaZHWftOviNCnDHdTcseghFOOa+U7cd/FZb79gX7PYmriVy/7euLG4/PNx98O5brtysoRxR23fuXvQQilDiPph4LFw2Je6H9sHlst4+OIuVlamESjKtsQLTMpVQSaY1VgAWZxaxMjWCBUCwAHBwk4+VqR74T3XcQJmmeuA/1XEDsDUmHysAAMA8TTpWpr46MfXxA2WY+urE1McPwJEz6VgBAADma7KxMpdVibnMA1iMuaxKzGUeAGyuScbK3A7w5zYfYGvM7QB/bvMB4PBNMlYAAID5EysAAECRJhcrcz1laq7zAo6MuZ4yNdd5AXBoJhcrAADAchArAABAkSYVK3M/VWru8wM2x9xPlZr7/ADYuEnFCgAAsDzECgAAUCSxAgAAFEmsAAAARRIrAABAkSYTK8vySVnLMk/g0CzLJ2UtyzwBWN9kYuWO625Y9BC2xLLMEzg023fuXvQQtsSyzBOA9U0mVgAAgOUiVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIk0qVub+sb5znx+wOeb+sb5znx8AGzepWAEAAJaHWAEAAIo0uViZ66lSc50XcGTM9VSpuc4LgEMzuVgBAACWg1gBAACKNMlYmdspU3ObD7A15nbK1NzmA8Dhm2SsJPM5wJ/LPIDFmMsB/lzmAcDmmmysAAAA8zbpWJn6qsTUxw+UYeqrElMfPwBHzqRjBQAAmK/Jx8pUVyemOm6gTFNdnZjquAHYGpOPlSkSKgBCBYCDm0WsTOngf0pjBaZlSgf/UxorAIszi1hJphEBUxgjMG1TiIApjBGAMswmVpKyY6DksQHzUnIMlDw2AMozq1hJyoyCEscEzFuJUVDimAAo29GLHsCRsDYOdpy1a6G/H2AR1sbB3bdcudDfDwCP1uxWVvZnK+NBqACl2sp4ECoAbIZZrqzsz+qI2OyVFoECTMXqiNjslRaBAsBmW5pYWW2zwkWkAFO2WeEiUgA4UpYyVlZbLzh2nLVLkABLYb3guPuWKwUJAAuxFO9ZOVRCBcDKCQCLI1YAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhL/3dW9nz82EUPYWFOO/f+RQ+B0Wb/JfEp8bG4AMCBWFkBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIokVAACgSGIFAAAoklgBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIokVAACgSGIFAAAoklgBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIokVAACgSGIFAAAoklgBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIokVAACgSGIFAAAoklgBAACKJFYAAIAiiRUAAKBIYgUAACiSWAEAAIokVgAAgCKJFQAAoEhiBQAAKJJYAQAAiiRWAACAIokVAACgSGIFAAAoklgBAACKJFYAAIAiHb3oASzaaefev+ghQLbv3L3oIQAAFMfKCgAAUCSxAgAAFGnbysrKoscAAADwZ6ysAAAARRIrAABAkcQKAABQJLECAAAUSawAAABFEisAAECRxAoAAFAksQIAABRJrAAAAEUSKwAAQJHECgAAUCSxAgAAFEmsAAAARRIrAABAkcQKAABQJLECAAAUSawAAABFEisAAECRxAoAAFAksQIAABRJrAAAAEUSKwAAQJHECgAAUCSxAgAAFOmPP5usDNFL0ioAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19678a8b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  34\n",
      "Image meta [ 34 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x196795d99e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:47:20.646845Z",
     "start_time": "2018-05-19T13:47:20.395002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " layer:  0    output : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " layer:  1    output : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " layer:  2    output : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " layer:  3    output : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  4    output : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " layer:  5    output : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  6    output : input_gt_masks:0                           Type: bool              Shape: (?, 56, 56, ?)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output : rpn_class_logits/concat:0                  Type: float32           Shape: (?, ?, 2)\n",
      " layer:  1    output : rpn_class/concat:0                         Type: float32           Shape: (?, ?, 2)\n",
      " layer:  2    output : rpn_bbox/concat:0                          Type: float32           Shape: (?, ?, 4)\n",
      " layer:  3    output : rpn_proposal_rois/packed_2:0               Type: float32           Shape: (5, ?, ?)\n",
      " layer:  4    output : proposal_targets/output_rois:0             Type: float32           Shape: (5, ?, ?)\n",
      " layer:  5    output : proposal_targets/target_class_ids:0        Type: int32             Shape: (5, ?)\n",
      " layer:  6    output : proposal_targets/target_bbox_deltas:0      Type: float32           Shape: (5, ?, ?)\n",
      " layer:  7    output : proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (5, ?, ?)\n",
      " layer:  8    output : mrcnn_class_logits_0/Reshape_1:0           Type: float32           Shape: (?, 32, 4)\n",
      " layer:  9    output : mrcnn_class/Reshape_1:0                    Type: float32           Shape: (?, 32, 4)\n",
      " layer: 10    output : mrcnn_bbox/Reshape:0                       Type: float32           Shape: (?, 32, 4, 4)\n",
      " layer: 11    output : rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer: 12    output : rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer: 13    output : mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer: 14    output : mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n",
      " layer: 15    output : cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (5, 128, 128, 4)\n",
      " layer: 16    output : cntxt_layer/gt_heatmap_norm:0              Type: float32           Shape: (5, 128, 128, 4)\n",
      " layer: 17    output : cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer: 18    output : cntxt_layer/gt_heatmap_scores:0            Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer: 19    output : cntxt_layer/pred_tensor:0                  Type: float32           Shape: (5, 4, 32, 6)\n",
      " layer: 20    output : cntxt_layer/gt_tensor:0                    Type: float32           Shape: (5, 4, 100, 6)\n",
      " layer: 21    output : fcn_heatmap/Identity:0                     Type: float32           Shape: (5, 16, 16, 4)\n",
      " layer: 22    output : fcn_heatmap_norm/fcn_heatmap_norm:0        Type: float32           Shape: (5, 128, 128, 4)\n",
      " layer: 23    output : fcn_scoring/fcn_scores_1:0                 Type: float32           Shape: (?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "model.layer_info()\n",
    "# model.keras_model.outputs[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:50:07.462738Z",
     "start_time": "2018-05-19T13:50:04.659755Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input  0:  (input_image:0                           ) \t  Input shape: (5, 128, 128, 3)\n",
      "Input  1:  (input_image_meta:0                      ) \t  Input shape: (5, 12)\n",
      "Input  2:  (input_rpn_match:0                       ) \t  Input shape: (5, 4092, 1)\n",
      "Input  3:  (input_rpn_bbox:0                        ) \t  Input shape: (5, 256, 4)\n",
      "Input  4:  (input_gt_class_ids:0                    ) \t  Input shape: (5, 100)\n",
      "Input  5:  (input_gt_boxes:0                        ) \t  Input shape: (5, 100, 4)\n",
      "Input  6:  (input_gt_masks:0                        ) \t  Input shape: (5, 56, 56, 100)\n",
      "\n",
      "/* Outputs */\n",
      "Output idx:  0    Layer: 15: (cntxt_layer/pred_heatmap_norm:0         ) \t  Output shape: (5, 128, 128, 4)\n",
      "Output idx:  1    Layer: 16: (cntxt_layer/gt_heatmap_norm:0           ) \t  Output shape: (5, 128, 128, 4)\n",
      "Output idx:  2    Layer: 17: (cntxt_layer/pred_heatmap_scores:0       ) \t  Output shape: (5, 4, 32, 10)\n",
      "Output idx:  3    Layer: 18: (cntxt_layer/gt_heatmap_scores:0         ) \t  Output shape: (5, 4, 100, 10)\n",
      "Output idx:  4    Layer: 19: (cntxt_layer/pred_tensor:0               ) \t  Output shape: (5, 4, 32, 6)\n",
      "Output idx:  5    Layer: 20: (cntxt_layer/gt_tensor:0                 ) \t  Output shape: (5, 4, 100, 6)\n",
      "Output idx:  6    Layer: 21: (fcn_heatmap/Identity:0                  ) \t  Output shape: (5, 16, 16, 4)\n",
      "Output idx:  7    Layer: 22: (fcn_heatmap_norm/fcn_heatmap_norm:0     ) \t  Output shape: (5, 128, 128, 4)\n",
      "Output idx:  8    Layer: 23: (fcn_scoring/fcn_scores_1:0              ) \t  Output shape: (5, 4, 32, 13)\n",
      "\n",
      "Number of layers generated:  9 \n",
      "\n",
      "pred_heatmap_norm         = model_output[0]          # layer: 15   shape: (5, 128, 128, 4)\n",
      "gt_heatmap_norm           = model_output[1]          # layer: 16   shape: (5, 128, 128, 4)\n",
      "pred_heatmap_scores       = model_output[2]          # layer: 17   shape: (5, 4, 32, 10)\n",
      "gt_heatmap_scores         = model_output[3]          # layer: 18   shape: (5, 4, 100, 10)\n",
      "pred_tensor               = model_output[4]          # layer: 19   shape: (5, 4, 32, 6)\n",
      "gt_tensor                 = model_output[5]          # layer: 20   shape: (5, 4, 100, 6)\n",
      "Identity                  = model_output[6]          # layer: 21   shape: (5, 16, 16, 4)\n",
      "fcn_heatmap_norm          = model_output[7]          # layer: 22   shape: (5, 128, 128, 4)\n",
      "fcn_scores_1              = model_output[8]          # layer: 23   shape: (5, 4, 32, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 15,16,17,18,19,20,21,22,23], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:05:11.852960Z",
     "start_time": "2018-05-19T11:05:11.617302Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
    "# 1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
    "# 2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
    "# 3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
    "# 5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
    "\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes = train_batch_x[5]\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:51:37.487968Z",
     "start_time": "2018-05-19T13:51:37.242802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(5, 128, 128, 4)\n",
      "(5, 128, 128, 4)\n",
      "(5, 4, 32, 10)\n",
      "(5, 4, 100, 10)\n",
      "(5, 4, 32, 6)\n",
      "(5, 4, 100, 6)\n",
      "(5, 16, 16, 4)\n",
      "(5, 128, 128, 4)\n",
      "(5, 4, 32, 13)\n"
     ]
    }
   ],
   "source": [
    "print(len(model_output))\n",
    "pred_heatmap_norm         = model_output[0]          # layer: 15   shape: (5, 128, 128, 4)\n",
    "gt_heatmap_norm           = model_output[1]          # layer: 16   shape: (5, 128, 128, 4)\n",
    "pred_heatmap_scores       = model_output[2]          # layer: 17   shape: (5, 4, 32, 10)\n",
    "gt_heatmap_scores         = model_output[3]          # layer: 18   shape: (5, 4, 100, 10)\n",
    "pred_tensor               = model_output[4]          # layer: 19   shape: (5, 4, 32, 6)\n",
    "gt_tensor                 = model_output[5]          # layer: 20   shape: (5, 4, 100, 6)\n",
    "fcn_heatmap               = model_output[6]          # layer: 21   shape: (5, 16, 16, 4)\n",
    "fcn_heatmap_norm          = model_output[7]          # layer: 22   shape: (5, 128, 128, 4)\n",
    "fcn_scores                = model_output[8]          # layer: 23   shape: (5, 4, 32, 13)\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)\n",
    "# print(output_rois[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:05:42.156519Z",
     "start_time": "2018-05-19T11:05:40.407838Z"
    },
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mrcnn.visualize import plot_gaussian\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap_norm.shape, ' pred_gaussian heatmap shape: ', pred_heatmap_norm.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = input_image_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap_norm[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap_norm[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap_norm[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap_norm[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:04:44.230335Z",
     "start_time": "2018-05-19T13:04:43.989683Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print *_tensor / *_heatmap_scores\n",
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "# print(' Pred tensor: ', pred_tensor.shape, 'gt_tensor:', gt_tensor.shape)\n",
    "print(' Pred tensor: ', pred_heatmap_scores.shape, 'gt_tensor:', gt_heatmap_scores.shape)\n",
    "# pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-1]), axis=-1)\n",
    "# print(pred_tensor[2])\n",
    "# print(gt_tensor[2])\n",
    "# print(gt_heatmap_scores[2])\n",
    "print(pred_heatmap_scores[2,0])\n",
    "print(fcn_scores[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T20:22:28.695670Z",
     "start_time": "2018-04-30T20:22:23.406687Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in [2]:\n",
    "    for cls in range(4):\n",
    "        pred_tst = pred_heatmap[img,:,:,cls]\n",
    "        gt_tst = gt_heatmap[img,:,:,cls]\n",
    "        print(pred_tst.shape, gt_tst.shape)\n",
    "        print('img/cls :', img,cls, 'pred sum : ',tf.reduce_sum(pred_tst).eval(), 'gt sum : ',tf.reduce_sum(gt_tst).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Plot heatmap produced by network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T12:09:02.042277Z",
     "start_time": "2018-05-19T12:08:59.971775Z"
    },
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "img = 3\n",
    "image_id = input_image_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "Zout  = pred_heatmap_norm     # gt_gaussiam \n",
    "Zout2 = fcn_heatmap  # fcn_bilinear\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "width = 9\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'FR-CNN      - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl, width = width)\n",
    "    \n",
    "    ttl = 'FCN_Bilinear - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl, width = width)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:03:17.009403Z",
     "start_time": "2018-05-19T13:03:16.778767Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "width = 12\n",
    "plot_gaussian2([pred_heatmap_norm, fcn_heatmap_norm], image_idx = 0, title = ttl, width = width)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Compute mean/min/max of regular and  L2 normalized Pred, GT, and FCN heatmap tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:29:39.204426Z",
     "start_time": "2018-05-19T11:29:33.701469Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    fcn_masks  = KB.identity(fcn_heatmap)\n",
    "    pred_masks = KB.identity(pred_heatmap_norm)\n",
    "    gt_masks   = KB.identity(gt_heatmap_norm)\n",
    "    shape = KB.int_shape(pred_masks)\n",
    "    print(shape)\n",
    "\n",
    "    pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "    fcn_masks_r = tf.reshape(fcn_masks, [shape[0], -1, shape[-1]])\n",
    "    gt_masks_r  = tf.reshape(gt_masks, [shape[0], -1, shape[-1]])\n",
    "\n",
    "    print(gt_masks_r.shape, fcn_masks_r.shape)\n",
    "\n",
    "    pred_mean2 = KB.mean(pred_masks_r, axis = 1).eval()\n",
    "    pred_max2  =  KB.max(pred_masks_r, axis=1).eval()\n",
    "    pred_min2  =  KB.min(pred_masks_r, axis=1).eval()\n",
    "\n",
    "    gt_mean2 = KB.mean(gt_masks_r, axis = 1).eval()\n",
    "    gt_max2  =  KB.max(gt_masks_r, axis=1).eval()\n",
    "    gt_min2  =  KB.min(gt_masks_r, axis=1).eval()\n",
    "\n",
    "    fcn_mean2 = KB.mean(fcn_masks_r, axis = 1).eval()\n",
    "    fcn_max2  =  KB.max(fcn_masks_r, axis=1).eval()\n",
    "    fcn_min2  =  KB.min(fcn_masks_r, axis=1).eval()    \n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## Compute L2 Normalizationof Pred, GT, and FCN tensors\n",
    "    ##---------------------------------------------------------------------------------------------    \n",
    "    pred_l2      = KB.l2_normalize(pred_masks_r, axis = 1)\n",
    "    gt_l2        = KB.l2_normalize(gt_masks_r, axis = 1)\n",
    "    fcn_l2       = KB.l2_normalize(fcn_masks_r, axis = 1)\n",
    "    pred_l2_min  = KB.min(pred_l2, axis = 1).eval()\n",
    "    pred_l2_max  = KB.max(pred_l2, axis = 1).eval()\n",
    "    pred_l2_mean = KB.mean(pred_l2, axis = 1).eval()\n",
    "    gt_l2_min    = KB.min(gt_l2, axis = 1).eval()\n",
    "    gt_l2_max    = KB.max(gt_l2, axis = 1).eval()\n",
    "    gt_l2_mean   = KB.mean(gt_l2, axis = 1).eval()\n",
    "    fcn_l2_min   = KB.min(fcn_l2, axis = 1).eval()\n",
    "    fcn_l2_max   = KB.max(fcn_l2, axis = 1).eval()\n",
    "    fcn_l2_mean  = KB.mean(fcn_l2, axis = 1).eval()\n",
    "\n",
    "    print(' Shape of L2 normalized tensor: ',pred_l2.shape, gt_l2.shape, fcn_l2.shape)\n",
    "    print(' Shape of L2 min tensor       : ',pred_l2_min.shape, gt_l2_min.shape, fcn_l2_min.shape)\n",
    "    print(' Shape of L2 max tensor       : ',pred_l2_max.shape, gt_l2_max.shape, fcn_l2_max.shape)\n",
    "    print(' Shape of L2 mean tensor      : ',pred_l2_mean.shape, gt_l2_mean.shape, fcn_l2_mean.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Print results of L2 normalization (Mean, Min , Max) vs. Original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:29:55.224012Z",
     "start_time": "2018-05-19T11:29:54.979394Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('\\n I/C:{}/{} '.format(img, cls))\n",
    "        print('             Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls]))\n",
    "        print('          L2 Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_l2_mean[img,cls], fcn_l2_mean[img,cls], pred_l2_mean[img,cls]))\n",
    "        print('             MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))\n",
    "        print('          L2 MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_l2_max[img,cls], fcn_l2_max[img,cls], pred_l2_max[img,cls]))\n",
    "        print('             MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_min2[img,cls], fcn_min2[img,cls], pred_min2[img,cls]))              \n",
    "        print('          L2 MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_l2_min[img,cls], fcn_l2_min[img,cls], pred_l2_min[img,cls]))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print (Mean, Min , Max)  values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:30:31.422397Z",
     "start_time": "2018-05-19T11:30:31.180775Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C: {}/{}  min/max     gt: [{:.5e} , {:.5e}]       pred: [{:.5e} , {:.5e}]     fcn:[{:.5e} , {:.5e}]   '\\\n",
    "              .format(img, cls,    gt_min2[img,cls], gt_max2[img,cls], pred_min2[img,cls], pred_max2[img,cls] ,\n",
    "                                  fcn_min2[img,cls], fcn_max2[img,cls] ))    \n",
    "        \n",
    "print('\\n\\n')        \n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C:{}/{}  Mean:  gt: {:.5e}   fcn : {:9.5e}   pred : {:.6f}   \\t MAX: gt:{:.5e}  fcn:{:.5e}  pred: {:.5e}'\\\n",
    "              .format(img, cls, gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls], \n",
    "                      gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:32:39.602595Z",
     "start_time": "2018-05-19T11:32:38.245064Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(tf.shape(pred_masks).eval())\n",
    "    shape = tf.shape(pred_masks).eval()\n",
    "    pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "    means = KB.mean(pred_masks_r, axis = 1)\n",
    "    maxs  = KB.max(pred_masks_r, axis=1)\n",
    "\n",
    "    # norms, means2, var = KB.normalize_batch_in_training(pred_masks[, 1.0, 0.0,[0,3])\n",
    "    l2_norm = KB.l2_normalize (pred_masks_r,axis = 1)\n",
    "    print(pred_masks.shape,pred_masks_r.shape)\n",
    "    print(means.shape, maxs.shape)\n",
    "    # print(' Shape of BN tensor: ', norms.shape)\n",
    "    # print(' Shape of means2 tensor: ', means2.shape)\n",
    "    # print(' Shape of var tensor: ', var.shape)\n",
    "    print(' Shape of L2 normalized tensor: ',l2_norm.shape)\n",
    "    print()\n",
    "    np.set_printoptions(linewidth=130, threshold=20000, precision=6)\n",
    "#     print('norms')\n",
    "#     print(norms.eval())\n",
    "    print('means')\n",
    "    print(means.eval())\n",
    "    print('maxs')\n",
    "    print(maxs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T13:12:19.679083Z",
     "start_time": "2018-04-27T13:12:19.086002Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pt   = layers_out[4]   # pred_gaussian \n",
    "# pt2  = layers_out[10]  # pred_gaussian_2\n",
    "np.set_printoptions(linewidth=130, threshold=20000)\n",
    "gt   =  np.transpose(pred_masks.eval(), [0,3,1,2])\n",
    "gt2  =  np.transpose(p2.eval(), [0,3,1,2])\n",
    "# gt   = np.where(gt > 1e-6,gt,0)\n",
    "# gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "#     print(' from np ')\n",
    "#     print(pt[img])\n",
    "#     print(' from tensorflow')\n",
    "#     print(pt2[img])\n",
    "    for cls in range(4):\n",
    "        equal = np.equal(gt2[img,cls,:,:] , gt[img, cls,:,:])\n",
    "        print(equal.shape)\n",
    "        print( 'Image ',img,' Class ',cls, '  all equal: ',equal.all())        \n",
    "        print(equal.shape)\n",
    "        \n",
    "        if (~equal.all()):\n",
    "            print('Not Equal: ',~equal)\n",
    "            print( 'Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#             print('\\n -- using numpy      \\n',  gt[img, cls, ~equal])\n",
    "#             print('\\n -- using tensorflow \\n', gt2[img, cls, ~equal])\n",
    "# if not equal display the different between the mismatching rows\n",
    "            for i in range(equal.shape[0]):\n",
    "                if ~equal[i]:\n",
    "                    diff = np.abs(gt2[img, cls, i] - gt[img, cls, i])\n",
    "                    big_error = np.any(diff > 3.0e-9, axis = -1)\n",
    "                    print('   row = ', i, ' rows equal = ',equal[i], '   Big Error (larger than 7.0e-8): ' ,big_error)\n",
    "                    if big_error:\n",
    "                        print(' difference  :', diff )\n",
    "#                     print(' -- using numpy      \\n',gt[img,cls,i])            \n",
    "#                     print(' -- using tensorflow \\n',gt2[img,cls,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T11:47:15.359937Z",
     "start_time": "2018-05-19T11:47:15.058136Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import display_gt_bboxes, dispaly_roi_bboxes\n",
    "model_info = [model, config, dataset_train, train_generator]\n",
    "display_gt_bboxes(model_info, input_image_meta, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T12:05:13.013862Z",
     "start_time": "2018-05-19T12:05:12.762188Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[23][img])\n",
    "\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T12:04:10.024238Z",
     "start_time": "2018-05-19T12:04:09.578076Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_info = [model, config, dataset_train, train_generator]\n",
    "display_roi_proposals(model_info, input_image_meta, pred_tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
