{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T09:57:15.070813Z",
     "start_time": "2018-05-10T09:57:10.765248Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pprint\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model        as modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "# import mrcnn.new_shapes   as shapes\n",
    "import mrcnn.new_shapes  as new_shapes\n",
    "# from mrcnn.new_shapes  import NewShapesDataset, NewShapesConfig\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "# from mrcnn.pc_prototype import PCTensor\n",
    "# from mrcnn.pcn_layer    import PCNLayer, PCILayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = new_shapes.NewShapesConfig()\n",
    "config.BATCH_SIZE      = 2                    #Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 2\n",
    "config.STEPS_PER_EPOCH = 7\n",
    "config.IMAGES_PER_GPU  = 1\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "\n",
    "# from mrcnn.datagen import data_generator, load_image_gt\n",
    "\n",
    "# Training dataset generate 500 shapes \n",
    "dataset_test = new_shapes.NewShapesDataset()\n",
    "dataset_test.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_test.prepare()\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "class InferenceConfig(new_shapes.NewShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display() \n",
    "\n",
    "# Configurations\n",
    "\n",
    "# import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# tf_config = tf.ConfigProto()\n",
    "# tf_config.gpu_options.per_process_gpu_memory_fraction = 0.55\n",
    "# set_session(tf.Session(config=tf_config))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.55)\n",
    "set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "print(' Build complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T09:58:35.859007Z",
     "start_time": "2018-05-10T09:58:35.629897Z"
    }
   },
   "outputs": [],
   "source": [
    "# for layer in model.keras_model.layers\n",
    "#     print layer.name \n",
    "mdl = model.keras_model\n",
    "layers    = [layer for layer in mdl.layers]          # all layer outputs\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:00:21.747792Z",
     "start_time": "2018-05-10T10:00:21.503548Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(' layer {} :  {}'.format(idx,layers[idx]))\n",
    "pp.pprint(len(layers[idx]._inbound_nodes))\n",
    "pp.pprint(layers[idx].__dict__)\n",
    "print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:02:00.826548Z",
     "start_time": "2018-05-10T10:02:00.588430Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,layer in enumerate(layers):\n",
    "    print('>layer {} : name : {:40s}  type: {}'.format(idx,layer.name,layer))\n",
    "#     pp.pprint(layer._inbound_nodes[0].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T09:58:50.167967Z",
     "start_time": "2018-05-10T09:58:49.449455Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for idx,layer in enumerate(layers):\n",
    "    print('>layer {} : name : {}  type: {}'.format(idx,layer.name,layer))\n",
    "#     pp.pprint(layer._inbound_nodes[0].__dict__)\n",
    "    print(\">> input_shape {} inbound node {} \".format(layer._inbound_nodes[0].input_shapes,layer._inbound_nodes[0]))\n",
    "#     print('>> inbound node output_shape {}'.format(layer._inbound_nodes[0].output_shapes))\n",
    "#     if isinstance(\"layer\", mrcnn.model.BatchNorm):\n",
    "#         print('Batch Nomraliation layer')\n",
    "    if 'padding' in layer.__dict__:\n",
    "        print('\\t padding : ',layer.padding)\n",
    "    if 'filters' in layer.__dict__:\n",
    "        print('\\t Filters : ',layer.filters, ' Kernel Size :', layer.kernel_size, 'Stride:', layer.strides, ' Shape',layer.kernel.shape)\n",
    "    \n",
    "    if 'activation' in layer.__dict__:\n",
    "        print('\\t ',layer.activation)\n",
    "    if 'pool_size' in layer.__dict__:\n",
    "        print('\\t poolsize : ',layer.pool_size,'Stride:', layer.strides)\n",
    "\n",
    "#     pp.pprint(layer.__dict__)\n",
    "    print(\"<< outbound shape{} input_shape {}\".format(layer._outbound_nodes[0].input_shapes,layer._outbound_nodes[0]))\n",
    "#     print('<< outbound node output_shape {}'.format(layer._outbound_nodes[0].output_shapes))\n",
    "    print('-------------------------------------------')\n",
    "    #layer.name, layer.input._keras_shape, layer.output._keras_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:07:25.512736Z",
     "start_time": "2018-05-10T10:07:24.712848Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import keras\n",
    "\n",
    "# for layer in model.keras_model.layers\n",
    "#     print layer.name \n",
    "mdl = model.keras_model\n",
    "print(' Total number of layers ', len(model.keras_model.layers), type(mdl))\n",
    "\n",
    "print('\\n Inputs')    \n",
    "for i, inp in enumerate(mdl.input):\n",
    "    print(' {}   {:35s}  {}  '.format(i, inp.name, inp.shape))\n",
    "    \n",
    "print('\\n Outputs')    \n",
    "for i, outp in enumerate(mdl.output):\n",
    "    print(' {}   {:35s}  {}  '.format(i, outp.name, outp.shape))\n",
    "\n",
    "\n",
    "# pp = pprint.PrettyPrinter()\n",
    "for idx,layer in enumerate(mdl.layers): \n",
    "    if idx > 25  : \n",
    "        break\n",
    "    print()    \n",
    "    print('#'*100)\n",
    "    print('#  Layer {} :  Name : {}  Type: {}'.format(idx,layer.name,layer))\n",
    "    print('#'*100)\n",
    "    if isinstance(layer, keras.engine.training.Model):\n",
    "        print('#  MODEL LAYER ')    \n",
    "#         print('\\n Inputs')    \n",
    "#         for i, inp in enumerate(layer.input):\n",
    "#             print(' {}   {:35s}  {}  '.format(i, inp.name, inp.shape))\n",
    "\n",
    "#         print('\\n Outputs')    \n",
    "#         for i, outp in enumerate(layer.output):\n",
    "#             print(' {}   {:35s}  {}  '.format(i, outp.name, outp.shape))\n",
    "            \n",
    "    pp.pprint(layer.__dict__)\n",
    "    num_inbound  = len(layer._inbound_nodes)\n",
    "    print('  >>>','-'*85)   \n",
    "    print('  >>>  Number of inbound nodes ', num_inbound)    \n",
    "    print('  >>>','-'*85)   \n",
    "    if num_inbound > 0:\n",
    "\n",
    "        for i, ib_node in enumerate(layer._inbound_nodes):\n",
    "            print('\\t','-'*70)\n",
    "            print(\"\\t >> {}  {}  \".format(i, ib_node))            \n",
    "            for j in ib_node.input_tensors:\n",
    "                print('\\t    incoming tensor(s): {:25s}  shape {}'.format(j.name, j.shape))\n",
    "            print('\\t','-'*70)\n",
    "                \n",
    "            pp.pprint(ib_node.__dict__, indent=10, width=140)\n",
    "    #       print('<< outbound node output_shape {}'.format(layer._outbound_nodes[0].output_shapes))\n",
    "    \n",
    "    \n",
    "\n",
    "#     if isinstance(\"layer\", model.Keras_BatchNorm):\n",
    "#         print('Batch Nomraliation layer')\n",
    "    if 'padding' in layer.__dict__:\n",
    "        print('\\t padding : ',layer.padding)\n",
    "    if 'filters' in layer.__dict__:\n",
    "        print('\\t Filters : ',layer.filters, ' Kernel Size :', layer.kernel_size, 'Stride:', layer.strides, ' Shape',layer.kernel.shape)\n",
    "    \n",
    "    if 'activation' in layer.__dict__:\n",
    "        print('\\t ',layer.activation)\n",
    "    if 'pool_size' in layer.__dict__:\n",
    "        print('\\t poolsize : ',layer.pool_size,'Stride:', layer.strides)\n",
    "        \n",
    "    num_outbound = len(layer._outbound_nodes)\n",
    "    print('  <<<','-'*85)       \n",
    "    print('  <<<   Number of outbound nodes ', num_outbound)\n",
    "    print('  <<<','-'*85)       \n",
    "#     pp.pprint(layer.__dict__)\n",
    "    if num_outbound > 0:\n",
    "\n",
    "        for i, ob_node in enumerate(layer._outbound_nodes):\n",
    "            print(\"<< outbound {} input_shape {}\".format(i,ob_node.input_shapes))\n",
    "            for j in ob_node.input_tensors:\n",
    "                print(' from layer: ', j.name, j.shape)\n",
    "    #         for j in ob_node.outbound_layer:\n",
    "    #             print(' to layer: ',j.name)\n",
    "            pp.pprint(ob_node.__dict__, indent=10, width=140)\n",
    "    #       print('<< outbound node output_shape {}'.format(layer._outbound_nodes[0].output_shapes))\n",
    "        \n",
    "    #layer.name, layer.input._keras_shape, layer.output._keras_shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
