{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Simulate the `DetectionTargetLayer` Process\n",
    "\n",
    "We generate the inputs to `DetectTargetLayer` , to manipulate and modify the layer to procduce a modified `output_rois` \n",
    "containing false positives. \n",
    "This will be passed on the the heatmap layer, and through there will become the input to FCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:47:26.641263Z",
     "start_time": "2018-05-16T17:47:15.279387Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180516T1947\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> Generate pyramid anchors \n",
      "      Anchor  scales:   (8, 16, 32, 64, 128)\n",
      "      Anchor  ratios:   [0.5, 1, 2]\n",
      "      Anchor  stride:   1\n",
      "      Feature shapes:   [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "      Feature strides:  [4, 8, 16, 32, 64]\n",
      ">>> generate_anchors()\n",
      "    scales:  8 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [11.3137  8.      5.6569]  widths   [ 5.6569  8.     11.3137]\n",
      ">>> generate_anchors()\n",
      "    scales:  16 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [22.6274 16.     11.3137]  widths   [11.3137 16.     22.6274]\n",
      ">>> generate_anchors()\n",
      "    scales:  32 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [45.2548 32.     22.6274]  widths   [22.6274 32.     45.2548]\n",
      ">>> generate_anchors()\n",
      "    scales:  64 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [90.5097 64.     45.2548]  widths   [45.2548 64.     90.5097]\n",
      ">>> generate_anchors()\n",
      "    scales:  128 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [181.0193 128.      90.5097]  widths   [ 90.5097 128.     181.0193]\n",
      "    Size of anchor array is : (4092, 4)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (3, 4092)\n",
      "     Deltas :  (3, 4092, 4)\n",
      "     Anchors:  (3, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (3, ?, ?) (3, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (3, ?, ?) (3, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (3, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (3, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  6\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (3, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (3, ?) (None, 32)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(3,), dtype=int32) (3, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (3, 32)\n",
      "    roi_grid         :  (3, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)\n",
      "    gt_bboxes.shape    :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    gt_scores_exp shape  (?, ?, 1)\n",
      "    gt_array shape : (3, 100, 7) (3, 100, 7)\n",
      "     gt_tensor final shape  :  (3, 4, 100, 6)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (3, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (3, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (3, 4, 128, 128) Keras tensor  False\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_heatmap:0 pred_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss-sum.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_4:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "    gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "    scatter_flattened is  (384, 6)\n",
      "    boxes shape           (384, 4)\n",
      "    gaussian scatter shape :  (3, 4, 32, 128, 128)\n",
      "    gaussian scatter reshaped :  (384, 128, 128)\n",
      "    Scatter Flattened shape :  (384, 6)\n",
      "    Scores shape :             (384, 2)\n",
      "    gaussian_boxes_scores initial shape:  (384, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gaussian_bbox_scores final shape   :  (?, ?, ?, ?)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 100, 6)\n",
      "    num of bboxes per class is :  100\n",
      "    pt2_sum shape  (3, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (3, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (3, 4, 128, 128) Keras tensor  False\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_heatmap:0 gt_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "    gauss-sum.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_9:0\", shape=(4,), dtype=int32)\n",
      "    gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "    gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "    scatter_flattened is  (1200, 6)\n",
      "    boxes shape           (1200, 4)\n",
      "    gaussian scatter shape :  (3, 4, 100, 128, 128)\n",
      "    gaussian scatter reshaped :  (1200, 128, 128)\n",
      "    Scatter Flattened shape :  (1200, 6)\n",
      "    Scores shape :             (1200, 2)\n",
      "    gaussian_boxes_scores initial shape:  (1200, 8)\n",
      "    gaussian_bbox_scores final shape   :  (?, ?, ?, ?)\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (3, 4) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (3, 4) Keras tensor  True\n",
      "\n",
      "    Output build_heatmap \n",
      "     pred_heatmap_norm  :  (3, 128, 128, 4) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (3, 128, 128, 4) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (3, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (3, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (3, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      " output_rois       : True\n",
      " pred_heatmap      : True\n",
      " gt_heatmap        : True\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      " Model Parent Path     :  E:\\Models\n",
      " Resent Model Path     :  E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "-----------------------------------------------\n",
      "Load model with init parm:  init\n",
      "-----------------------------------------------\n",
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_logs\n",
      "('E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928', 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2500.h5')\n",
      "Load weights complete\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     3\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    2\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_dev_notebook\n",
    "\n",
    "model, dataset_train, train_generator, config = prep_dev_notebook(init_with = 'init', FCN_layers = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:47:31.011908Z",
     "start_time": "2018-05-16T17:47:30.759264Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Generate pyramid anchors \n",
      "      Anchor  scales:   (8, 16, 32, 64, 128)\n",
      "      Anchor  ratios:   [0.5, 1, 2]\n",
      "      Anchor  stride:   1\n",
      "      Feature shapes:   [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "      Feature strides:  [4, 8, 16, 32, 64]\n",
      ">>> generate_anchors()\n",
      "    scales:  8 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [11.3137  8.      5.6569]  widths   [ 5.6569  8.     11.3137]\n",
      ">>> generate_anchors()\n",
      "    scales:  16 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [22.6274 16.     11.3137]  widths   [11.3137 16.     22.6274]\n",
      ">>> generate_anchors()\n",
      "    scales:  32 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [45.2548 32.     22.6274]  widths   [22.6274 32.     45.2548]\n",
      ">>> generate_anchors()\n",
      "    scales:  64 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [90.5097 64.     45.2548]  widths   [45.2548 64.     90.5097]\n",
      ">>> generate_anchors()\n",
      "    scales:  128 ratios:  [0.5, 1, 2]\n",
      "    meshgrid scales:  (3, 1) ratios:  (3, 1)\n",
      "    flattened meshgrid scales and ratios:  (3,) (3,)\n",
      "    Heights  [181.0193 128.      90.5097]  widths   [ 90.5097 128.     181.0193]\n",
      "    Size of anchor array is : (4092, 4)\n"
     ]
    }
   ],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:49:03.530611Z",
     "start_time": "2018-05-16T17:49:02.489249Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  36\n",
      "Image meta [ 36 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19183ecdf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  135\n",
      "Image meta [135 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191846cfc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  116\n",
      "Image meta [116 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 1 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191848cae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Display loaded shapes\n",
    "\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:49:09.585024Z",
     "start_time": "2018-05-16T17:49:09.350858Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " layer:  0    output : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " layer:  1    output : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " layer:  2    output : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " layer:  3    output : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  4    output : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " layer:  5    output : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " layer:  6    output : input_gt_masks:0                           Type: bool              Shape: (?, 56, 56, ?)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output : rpn_class_logits/concat:0                  Type: float32           Shape: (?, ?, 2)\n",
      " layer:  1    output : rpn_class/concat:0                         Type: float32           Shape: (?, ?, 2)\n",
      " layer:  2    output : rpn_bbox/concat:0                          Type: float32           Shape: (?, ?, 4)\n",
      " layer:  3    output : rpn_proposal_rois/packed_2:0               Type: float32           Shape: (3, ?, ?)\n",
      " layer:  4    output : proposal_targets/output_rois:0             Type: float32           Shape: (3, ?, ?)\n",
      " layer:  5    output : proposal_targets/target_class_ids:0        Type: int32             Shape: (3, ?)\n",
      " layer:  6    output : proposal_targets/target_bbox_deltas:0      Type: float32           Shape: (3, ?, ?)\n",
      " layer:  7    output : proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (3, ?, ?)\n",
      " layer:  8    output : mrcnn_class_logits/Reshape_1:0             Type: float32           Shape: (?, 32, 4)\n",
      " layer:  9    output : mrcnn_class/Reshape_1:0                    Type: float32           Shape: (?, 32, 4)\n",
      " layer: 10    output : mrcnn_bbox/Reshape:0                       Type: float32           Shape: (?, 32, 4, 4)\n",
      " layer: 11    output : rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer: 12    output : rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer: 13    output : mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer: 14    output : mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n",
      " layer: 15    output : cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (3, 128, 128, 4)\n",
      " layer: 16    output : cntxt_layer/gt_heatmap_norm:0              Type: float32           Shape: (3, 128, 128, 4)\n",
      " layer: 17    output : cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer: 18    output : cntxt_layer/gt_heatmap_scores:0            Type: float32           Shape: (?, ?, ?, ?)\n",
      " layer: 19    output : cntxt_layer/pred_tensor:0                  Type: float32           Shape: (3, 4, 32, 6)\n",
      " layer: 20    output : cntxt_layer/gt_tensor:0                    Type: float32           Shape: (3, 4, 100, 6)\n"
     ]
    }
   ],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:49:23.453008Z",
     "start_time": "2018-05-16T17:49:15.223717Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input  0:  (input_image:0                           ) \t  Input shape: (3, 128, 128, 3)\n",
      "Input  1:  (input_image_meta:0                      ) \t  Input shape: (3, 12)\n",
      "Input  2:  (input_rpn_match:0                       ) \t  Input shape: (3, 4092, 1)\n",
      "Input  3:  (input_rpn_bbox:0                        ) \t  Input shape: (3, 256, 4)\n",
      "Input  4:  (input_gt_class_ids:0                    ) \t  Input shape: (3, 100)\n",
      "Input  5:  (input_gt_boxes:0                        ) \t  Input shape: (3, 100, 4)\n",
      "Input  6:  (input_gt_masks:0                        ) \t  Input shape: (3, 56, 56, 100)\n",
      "\n",
      "/* Outputs */\n",
      "Output idx:  0    Layer:  3: (rpn_proposal_rois/packed_2:0            ) \t  Output shape: (3, 2000, 4)\n",
      "Output idx:  1    Layer:  4: (proposal_targets/output_rois:0          ) \t  Output shape: (3, 32, 4)\n",
      "Output idx:  2    Layer: 17: (cntxt_layer/pred_heatmap_scores:0       ) \t  Output shape: (3, 4, 32, 8)\n",
      "Output idx:  3    Layer: 19: (cntxt_layer/pred_tensor:0               ) \t  Output shape: (3, 4, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "\n",
    "model_output = get_layer_output_1(model.keras_model, train_batch_x, [3,4, 17,19], verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:49:45.018475Z",
     "start_time": "2018-05-16T17:49:44.783825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 128, 128, 3)\n",
      "height/width 128 128\n",
      " input_gt_class_ids    (3, 100)\n",
      "[[2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]]\n",
      " input_gt_bboxes       (3, 100, 4)\n",
      "[[[ 47   0  98  49]\n",
      "  [ 76  48 127 106]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]\n",
      "\n",
      " [[ 56  11 113  68]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]\n",
      "\n",
      " [[  0   0  57  73]\n",
      "  [  7  51  50  94]\n",
      "  [ 75  21 120  66]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]]\n",
      " input_gt_bboxes_norm  (3, 100, 4)\n",
      "[[[0.3672 0.     0.7656 0.3828]\n",
      "  [0.5938 0.375  0.9922 0.8281]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  ...\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]]\n",
      "\n",
      " [[0.4375 0.0859 0.8828 0.5312]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  ...\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]]\n",
      "\n",
      " [[0.     0.     0.4453 0.5703]\n",
      "  [0.0547 0.3984 0.3906 0.7344]\n",
      "  [0.5859 0.1641 0.9375 0.5156]\n",
      "  ...\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.    ]]]\n"
     ]
    }
   ],
   "source": [
    "# del input_image, input_image_meta, input_gt_class_ids, input_gt_bboxes #, input_gt_bboxes_norm\n",
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "# input_rpn_match  =  train_batch_x[2]\n",
    "# input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "# input_gt_masks     = train_batch_x[6]\n",
    "print(input_image.shape)\n",
    "h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "print('height/width', h,w)\n",
    "input_gt_bboxes_norm = input_gt_bboxes / [h,w,h,w]\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "# print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "# print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids   ', input_gt_class_ids.shape)\n",
    "print(input_gt_class_ids)\n",
    "print(' input_gt_bboxes      ', input_gt_bboxes.shape)\n",
    "print(input_gt_bboxes)  \n",
    "print(' input_gt_bboxes_norm ', input_gt_bboxes_norm.shape)\n",
    "print( input_gt_bboxes_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:50:07.960016Z",
     "start_time": "2018-05-16T17:50:07.726397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(3, 2000, 4)\n",
      "(3, 32, 4)\n",
      "(3, 4, 32, 8)\n",
      "(3, 4, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "# rpn_class          = model_output[0]\n",
    "# rpn_bbox           = model_output[1]\n",
    "rpn_proposal_rois  = model_output[0]\n",
    "output_rois        = model_output[1]\n",
    "# target_class_ids   = model_output[5]\n",
    "# target_bbox_deltas = model_output[6]\n",
    "# roi_gt_boxes       = model_output[7]\n",
    "# mrcnn_class_logits = model_output[8]\n",
    "# mrcnn_class        = model_output[0]\n",
    "# mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "# fcn_bbox_loss      = model_output[15]\n",
    "# pred_hm            = model_output[1]\n",
    "# gt_hm              = model_output[17]\n",
    "# pred_hm_norm       = model_output[1]\n",
    "# gt_hm_norm         = model_output[2]\n",
    "# pred_hm_scores     = model_output[3]\n",
    "# gt_hm_scores       = model_output[4]\n",
    "# pred_tensor        = model_output[5]\n",
    "# fcn_heatmap        = model_output[23]\n",
    "# fcn_class_logits   = model_output[24]\n",
    "# fcn_scores         = model_output[25]\n",
    "# fcn_bbox_deltas    = model_output[26]\n",
    "# pred_hm2            = model_output[2]\n",
    "# pred_hm2_norm       = model_output[3]\n",
    "# rpn_proposal_rois  = model_output[0]\n",
    "# output_rois        = model_output[1]\n",
    "# pred_hm_norm       = model_output[1]\n",
    "# gt_hm_norm         = model_output[3]\n",
    "pred_hm_scores     = model_output[2]\n",
    "# gt_hm_scores       = model_output[5]\n",
    "pred_tensor        = model_output[3]\n",
    "\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:50:12.469962Z",
     "start_time": "2018-05-16T17:50:12.238347Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7732 0.225  1.     0.6652]\n",
      " [0.7909 0.3989 1.     0.8573]\n",
      " [0.     0.     1.     1.    ]\n",
      " ...\n",
      " [0.1877 0.0054 0.2105 0.2402]\n",
      " [0.5644 0.     0.5847 1.    ]\n",
      " [0.0453 0.4127 0.11   0.6564]]\n"
     ]
    }
   ],
   "source": [
    "print(rpn_proposal_rois[0])\n",
    "# print(output_rois[0])\n",
    "# print(pred_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:15:14.006398Z",
     "start_time": "2018-05-06T20:15:13.767740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(input_gt_boxes.shape, input_image.shape)\n",
    "print(rpn_proposal_rois.shape)\n",
    "print((rpn_proposal_rois[0,:5,:]*[128,128,128,128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Setup tensors to be passed to `detections_target_graph()`\n",
    "\n",
    "This is passed to the DetectionTargetLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:06:01.171383Z",
     "start_time": "2018-05-16T18:05:58.078634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session was deleted \n",
      "<dtype: 'float32'> <dtype: 'int32'> <dtype: 'float32'>\n",
      "(2000, 4)\n",
      "[[0.     0.     0.0482 0.44  ]\n",
      " [0.0145 0.     0.017  0.1724]\n",
      " [0.1483 0.138  0.1715 0.2534]\n",
      " ...\n",
      " [0.174  0.5101 0.1922 0.5183]\n",
      " [0.     0.2143 1.     0.2311]\n",
      " [0.8634 0.8752 0.9407 0.907 ]]\n",
      "(100,)\n",
      "[3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "(100, 4)\n",
      "[[0.     0.     0.4453 0.5703]\n",
      " [0.0547 0.3984 0.3906 0.7344]\n",
      " [0.5859 0.1641 0.9375 0.5156]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "import mrcnn.utils  as utils\n",
    "from mrcnn.detect_tgt_layer import overlaps_graph\n",
    "# sess = KB.get_session()\n",
    "# with  sess.as_default():\n",
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "image_id = 2\n",
    "\n",
    "proposals    = KB.identity(rpn_proposal_rois)[image_id]\n",
    "gt_class_ids = KB.identity(input_gt_class_ids)[image_id]\n",
    "gt_boxes     = KB.cast(KB.identity(input_gt_bboxes_norm), dtype='float32')[image_id]\n",
    "# gt_masks     = KB.identity(input_gt_masks)\n",
    "print(proposals.dtype, gt_class_ids.dtype, gt_boxes.dtype)\n",
    "print(proposals.shape)\n",
    "print(proposals.eval())\n",
    "print(gt_class_ids.shape)\n",
    "print(gt_class_ids.eval())\n",
    "print(gt_boxes.shape)\n",
    "print(gt_boxes.eval())\n",
    "# proposals    = rpn_proposal_rois[1]\n",
    "# gt_class_ids = input_gt_class_ids[1]\n",
    "# gt_boxes     = input_normlzd_gt_boxes[1]\n",
    "# gt_masks     = input_gt_masks[1]\n",
    "# config       = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def `dev_detection_targets_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:10:26.630811Z",
     "start_time": "2018-05-16T18:10:22.487577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[2000    4]\n",
      "[ True  True  True]\n",
      "[3 4]\n",
      "[[0.     0.     0.4453 0.5703]\n",
      " [0.0547 0.3984 0.3906 0.7344]\n",
      " [0.5859 0.1641 0.9375 0.5156]]\n",
      "[0 1 2]\n",
      "[[0.     0.     0.4453 0.5703]\n",
      " [0.0547 0.3984 0.3906 0.7344]\n",
      " [0.5859 0.1641 0.9375 0.5156]]\n",
      "     overlaps.shape        : [2000    3]\n",
      "[[0.0836 0.     0.    ]\n",
      " [0.0017 0.     0.    ]\n",
      " [0.0105 0.     0.    ]\n",
      " ...\n",
      " [0.0006 0.0013 0.    ]\n",
      " [0.0285 0.     0.044 ]\n",
      " [0.     0.     0.    ]]\n",
      "[8 2]\n",
      "[2000]\n",
      "[8]\n",
      "[ 257  365  420  432  661  798  991 1264]\n",
      "[1264  432  661  991  420  798  257  365]\n",
      "8\n",
      "[[0.5462 0.26   1.     0.5613]\n",
      " [0.     0.     0.3301 0.7111]\n",
      " [0.     0.     0.4078 0.4211]\n",
      " [0.     0.     0.675  0.5631]\n",
      " [0.6335 0.0174 0.8874 0.4826]\n",
      " [0.5844 0.     1.     0.5543]\n",
      " [0.     0.009  0.6593 0.411 ]\n",
      " [0.     0.14   0.3856 0.6639]]\n",
      "     shape of positive overlaps is : (?, ?)\n",
      "[0 0 2 0 2 0 2 0]\n",
      "[[0.     0.     0.5028]\n",
      " [0.6266 0.3293 0.    ]\n",
      " [0.     0.     0.5365]\n",
      " [0.5266 0.0113 0.0489]\n",
      " [0.6542 0.1264 0.0663]\n",
      " [0.     0.     0.5272]\n",
      " [0.6762 0.0275 0.    ]\n",
      " [0.5721 0.3869 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# def dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):\n",
    " \n",
    "'''\n",
    "as of 16-0-2018\n",
    "Generates detection targets for one image. Subsamples proposals and\n",
    "generates target class IDs, bounding box deltas, and masks for each.\n",
    "\n",
    "Inputs:\n",
    "-------\n",
    "proposals:          [N, 2000, (y1, x1, y2, x2)] in normalized coordinates. \n",
    "                         Might be zero padded if there are not enough proposals.\n",
    "gt_class_ids:       [MAX_GT_INSTANCES] int class IDsMx2)] in normalized coordinates.\n",
    "gt_masks:           [height, width, MAX_GT_INSTANCES] of boolean type.\n",
    "\n",
    "Returns:            Target ROIs and corresponding class IDs, bounding box shifts, and masks.\n",
    "--------\n",
    "rois:               [TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized coordinates\n",
    "class_ids:          [TRAIN_ROIS_PER_IMAGE]. Integer class IDs. Zero padded.\n",
    "deltas:             [TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (dy, dx, log(dh), log(dw))]\n",
    "                    Class-specific bbox refinments.\n",
    "masks:              [TRAIN_ROIS_PER_IMAGE, height, width). Masks cropped to bbox\n",
    "                    boundaries and resized to neural network output size.\n",
    "\n",
    "Note: Returned arrays might be zero padded if not enough target ROIs.\n",
    "\n",
    "''' \n",
    "# Assertions\n",
    "asserts = [\n",
    "    tf.Assert(tf.greater(tf.shape(proposals)[0], 0), [proposals], name=\"roi_assertion\"),\n",
    "]\n",
    "\n",
    "with tf.control_dependencies(asserts):\n",
    "    proposals = tf.identity(proposals)\n",
    "# print('>>> detection_targets_graph ')\n",
    "# print('     propsals.shape        :',  proposals.shape, proposals.get_shape(), KB.int_shape(proposals) )\n",
    "# print('     gt_boxes.shape        :',  gt_boxes.shape ,    KB.int_shape(gt_boxes)   )\n",
    "# print('     gt_class_ids.shape    :',  gt_class_ids.shape, KB.int_shape(gt_class_ids))\n",
    "# print('     gt_masks.shape        :',  gt_masks.shape ,    KB.int_shape(gt_masks)   )\n",
    "\n",
    "# Remove zero padding   \n",
    "# non_zeros returns indicies to valid bboxes, which we use to index gt_class_ids, and gt_masks\n",
    "proposals, non_zeros1= utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "# gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "print(tf.reduce_all(non_zeros1).eval())\n",
    "print(tf.shape(proposals).eval())\n",
    "print(non_zeros.eval())\n",
    "print(tf.shape(gt_boxes).eval())\n",
    "print(gt_boxes.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Handle COCO crowds\n",
    "# A crowd box in COCO is a bounding box around several instances. Exclude\n",
    "# them from training. A crowd box is given a negative class ID.\n",
    "#------------------------------------------------------------------------------------------\n",
    "# tf.where : returns the coordinates of true elements of  the specified conditon.\n",
    "#            The coordinates are returned in a 2-D tensor where the first dimension (rows) \n",
    "#            represents the number of true elements, and the second dimension (columns) \n",
    "#            represents the coordinates of the true elements. \n",
    "#            Keep in mind, the shape of the output tensor can vary depending on how many \n",
    "#            true values there are in input. Indices are output in row-major order.\n",
    "#\n",
    "# tf.gather: Gather slices from params axis (default = 0) according to indices.\n",
    "#            indices must be an integer tensor of any dimension (usually 0-D or 1-D). \n",
    "#            Produces an output tensor with shape:\n",
    "#                   params.shape[:axis] + indices.shape + params.shape[axis + 1:] \n",
    "#\n",
    "# tf.squeeze: Removes dimensions of size 1 from the shape of a tensor.\n",
    "#            Given a tensor input, this operation returns a tensor of the same type with \n",
    "#            all dimensions of size 1 removed. If you don't want to remove all size 1 \n",
    "#            dimensions, you can remove specific size 1 dimensions by specifying axis.\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "# crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "# gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "print(non_crowd_ix.eval())\n",
    "print(gt_boxes.eval())\n",
    "\n",
    "# Compute overlaps with crowd boxes [anchors, crowds]\n",
    "crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "# Compute overlaps matrix [proposals, gt_boxes] - The IoU between \n",
    "# proposals and gt_boxes (non-crowd gt boxes, designated by classId < 0 in Coco)\n",
    "# overlaps is \n",
    "# compute max of elements across axis 1 of overlaps tensor. \n",
    "overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "roi_iou_max     = tf.reduce_max(overlaps, axis=1)\n",
    "print('     overlaps.shape        :',  tf.shape(overlaps).eval())\n",
    "print(overlaps.eval())\n",
    "zero_idxs = tf.where(tf.greater_equal(overlaps,0.5))\n",
    "print(tf.shape(zero_idxs).eval())\n",
    "\n",
    "## 1. Determine indices of postive ROI propsal boxes\n",
    "#    Identify ROI proposal boxes that have an IoU >= 05 overlap with some gt_box, and store \n",
    "#    indices into positive_indices\n",
    "positive_roi_bool     = (roi_iou_max >= 0.5)\n",
    "positive_indices      = tf.where(positive_roi_bool)[:,0]\n",
    "print(tf.shape(positive_roi_bool).eval())\n",
    "print(tf.shape(positive_indices).eval())\n",
    "print(positive_indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "## 2. Determine indices of negative ROI proposal boxes\n",
    "#    those with < 0.5 with every GT box and are not crowds bboxes \n",
    "# the where creates a array with shape [# of answers, 1] so we use [:, 0] after\n",
    "## current method\n",
    "negative_indices      = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "\n",
    "## new method\n",
    "# this modification will determine negative ROI proposal boxes but in addition, \n",
    "# will suppress the zero RoIs from the indicies \n",
    "# note that   ( negative_bool         = ~positive_roi_bool)\n",
    "# negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "# negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "# negative_indices2     = tf.where(negative_nonzero_bool) [:, 0]\n",
    "\n",
    "## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "#    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "#    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE ~  11\n",
    "positive_count        = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "positive_indices      = tf.random_shuffle(positive_indices)[:positive_count]\n",
    "positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "print(positive_indices.eval())\n",
    "print(positive_count.eval())\n",
    "\n",
    "## 4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "#     negative_count = int((positive_count / config.ROI_POSITIVE_RATIO) - positive_count)\n",
    "r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "negative_count        = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "negative_indices      = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "\n",
    "## 5.   Gather selected positive and negative ROIs\n",
    "positive_rois         = tf.gather(proposals, positive_indices)\n",
    "negative_rois         = tf.gather(proposals, negative_indices)\n",
    "print(positive_rois.eval())\n",
    "\n",
    "## 6.   Assign positive ROIs to GT boxes.\n",
    "#      roi_gt_box_assignment shows for each positive overlap, which class has the maximum overlap\n",
    "positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "\n",
    "print('     shape of positive overlaps is :', positive_overlaps.get_shape())\n",
    "print(roi_gt_box_assignment.eval())\n",
    "print(positive_overlaps.eval())\n",
    "\n",
    "## 7.   Compute bbox delta \n",
    "# calculate refinement (difference b/w positive rois and gt_boxes) for positive ROIs\n",
    "roi_gt_deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "roi_gt_deltas /= config.BBOX_STD_DEV\n",
    "\n",
    "## 8.  prepare gt_masks \n",
    "#      transpose gt_masks from [h, w, N] to [N, height, width] and add 4th dim at end [N, height, width, 1]\n",
    "#      Pick the right mask for each ROI\n",
    "# transposed_masks = tf.expand_dims(tf.transpose(gt_masks, [2, 0, 1]), -1)\n",
    "# roi_masks = tf.gather(transposed_masks, roi_gt_box_assignment)\n",
    "\n",
    "# Compute mask targets\n",
    "# boxes = positive_rois\n",
    "\n",
    "# if config.USE_MINI_MASK:\n",
    "    # Transform ROI corrdinates from normalized image space\n",
    "    # to normalized mini-mask space.\n",
    "    # y1, x1, y2, x2 = tf.split(positive_rois, 4, axis=1)\n",
    "    # gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(roi_gt_boxes, 4, axis=1)\n",
    "    # gt_h = gt_y2 - gt_y1\n",
    "    # gt_w = gt_x2 - gt_x1\n",
    "    # y1 = (y1 - gt_y1) / gt_h\n",
    "    # x1 = (x1 - gt_x1) / gt_w\n",
    "    # y2 = (y2 - gt_y1) / gt_h\n",
    "    # x2 = (x2 - gt_x1) / gt_w\n",
    "    # boxes = tf.concat([y1, x1, y2, x2], 1)\n",
    "\n",
    "# box_ids = tf.range(0, tf.shape(roi_masks)[0])\n",
    "# masks   = tf.image.crop_and_resize(tf.cast(roi_masks, tf.float32), \n",
    "                                   # boxes,\n",
    "                                   # box_ids,\n",
    "                                   # config.MASK_SHAPE)\n",
    "\n",
    "# Remove the extra dimension from masks.\n",
    "# masks = tf.squeeze(masks, axis=3)\n",
    "\n",
    "# Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with\n",
    "# binary cross entropy loss.\n",
    "# masks = tf.round(masks)\n",
    "\n",
    "# Append negative ROIs and pad bbox roi_gt_deltas and masks that\n",
    "# are not used for negative ROIs with zeros.\n",
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "rois             = tf.pad(rois            , [(0, P ), (0, 0)])\n",
    "\n",
    "roi_gt_boxes     = tf.pad(roi_gt_boxes    , [(0, N + P), (0, 0)])\n",
    "roi_gt_class_ids = tf.pad(roi_gt_class_ids, [(0, N + P)])\n",
    "roi_gt_deltas    = tf.pad(roi_gt_deltas   , [(0, N + P), (0, 0)])\n",
    "# masks            = tf.pad(masks           , [[0, N + P], (0, 0), (0, 0)])\n",
    "\n",
    "# print(' roi_gt_boxes :  ' , tf.shape(roi_gt_boxes) )\n",
    "# print(' P:  ' , P,  ' N :    ', N)   \n",
    "# print('     roi.shape             :',  rois.shape            , tf.shape(rois))\n",
    "# print('     roi_gt_class_ids.shape:',  roi_gt_class_ids.shape, tf.shape(roi_gt_class_ids))\n",
    "# print('     roi_gt_deltas.shape   :',  roi_gt_deltas.shape   , tf.shape(roi_gt_deltas))\n",
    "# print('     masks.shape           :',  masks.shape           , tf.shape(masks))\n",
    "# print('     roi_gt_boxes.shape    :',  roi_gt_boxes.shape    , tf.shape(roi_gt_boxes))\n",
    "\n",
    "#     return rois, roi_gt_class_ids,  roi_gt_deltas, roi_gt_boxes\n",
    "#     return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment, roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:10:29.663188Z",
     "start_time": "2018-05-16T18:10:28.767292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32  4]\n",
      "[[0.     0.009  0.6593 0.411 ]\n",
      " [0.     0.     0.4078 0.4211]\n",
      " [0.5844 0.     1.     0.5543]\n",
      " [0.     0.     0.3301 0.7111]\n",
      " [0.     0.14   0.3856 0.6639]\n",
      " [0.     0.     0.675  0.5631]\n",
      " [0.5462 0.26   1.     0.5613]\n",
      " [0.6335 0.0174 0.8874 0.4826]\n",
      " [0.839  0.8305 0.8725 1.    ]\n",
      " [0.1631 0.     0.1806 1.    ]\n",
      " [0.7655 0.243  0.7746 0.3374]\n",
      " [0.6634 0.5396 1.     0.7281]\n",
      " [0.7141 0.     0.7545 0.2554]\n",
      " [0.7191 0.5918 0.7327 0.6084]\n",
      " [0.4712 0.5419 0.4856 0.6111]\n",
      " [0.6941 0.     0.6949 0.2061]\n",
      " [0.5169 0.7898 0.5645 0.9762]\n",
      " [0.4413 0.6359 0.4546 0.6652]\n",
      " [0.7702 0.5834 0.7789 0.6279]\n",
      " [0.     0.2835 1.     0.2866]\n",
      " [0.6075 0.5479 0.6343 0.5728]\n",
      " [0.7316 0.     0.7514 1.    ]\n",
      " [0.7996 0.0625 0.8021 0.438 ]\n",
      " [0.3737 0.3375 0.383  0.3528]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "[3 3 2 2 2 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[3 1 2]\n",
      "[[0.     0.     0.4453 0.5703]\n",
      " [0.0547 0.3984 0.3906 0.7344]\n",
      " [0.5859 0.1641 0.9375 0.5156]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(rois).eval())\n",
    "print(rois.eval())\n",
    "print(roi_gt_class_ids.eval())\n",
    "print(gt_class_ids.eval())\n",
    "print(gt_boxes.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:27:23.804160Z",
     "start_time": "2018-05-16T17:27:22.912263Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "FeedList = [ rois, roi_gt_class_ids,  roi_gt_deltas, roi_gt_boxes]\n",
    "tt = sess.run(FeedList)\n",
    "print(type(tt), len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T17:27:27.334896Z",
     "start_time": "2018-05-16T17:27:27.087670Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print('rois shape     : ', tt[0].shape, '\\n',tt[0])\n",
    "print('roi_gt_class_ids ', tt[1].shape, '\\n',tt[1])\n",
    "print('roi_gt_deltas    ', tt[2].shape, '\\n',tt[2])\n",
    "print('roi_gt_boxes     ', tt[3].shape, '\\n',tt[3])\n",
    "print()\n",
    "# print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "# print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "# print()\n",
    "# print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "# print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "# print()\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids\n",
    "# print(' FP overlaps             \\n', tt[1])\n",
    "# print(' FP gt box assignemt:\\n', tt[2])\n",
    "# print(' FP gt boxes        :\\n', tt[3])\n",
    "# print(' FP gt class assign :\\n', tt[4])\n",
    "# print(' gt class ids assign :\\n', tt[5])\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:44:28.696521Z",
     "start_time": "2018-05-06T18:44:28.453845Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(tt), len(tt))\n",
    "print(' Shuffled Positive indices:\\n', tt[0])\n",
    "print(' Positive indices:         \\n', tt[1])\n",
    "print(' positive overlaps shape  :  ', tt[2].shape)\n",
    "print(' positive overlaps        :\\n', tt[2])\n",
    "print(' Pos roi gt box assignment:\\n', tt[5])    \n",
    "print(' Pos roi gt class assign  :\\n', tt[3])\n",
    "print(' Pos roi gt boxes         :\\n', tt[4])\n",
    "\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:19:41.273566Z",
     "start_time": "2018-05-06T20:19:40.064308Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# def dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):\n",
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "\n",
    "    print('>>> detection_targets_graph ')\n",
    "    print('     propsals.shape        :',  proposals.shape, proposals.get_shape(), KB.int_shape(proposals) )\n",
    "    print('     gt_boxes.shape        :',  gt_boxes.shape ,    KB.int_shape(gt_boxes)   )\n",
    "    print('     gt_class_ids.shape    :',  gt_class_ids.shape, KB.int_shape(gt_class_ids))\n",
    "    print('     gt_masks.shape        :',  gt_masks.shape ,    KB.int_shape(gt_masks)   )\n",
    "\n",
    "    proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "    gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "    gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "    gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "    # print(tf.shape(proposals).eval())\n",
    "    # print(non_zeros.eval())\n",
    "    # print('gt_boxes :', tf.shape(gt_boxes).eval())\n",
    "\n",
    "    ###  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "\n",
    "    crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "    non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "    crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "    crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "    gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "    gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "    gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "    # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "    crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "    crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "    no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "    # print('crowd ixs: ', crowd_ix.eval())\n",
    "    # print('non_crowrd_ixs', non_crowd_ix.eval())\n",
    "    # print('non crowd bool', no_crowd_bool.eval())\n",
    "\n",
    "    overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "    print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "    \n",
    "    roi_iou_max            = tf.reduce_max(overlaps, axis=1)\n",
    "    print(' RoI/Gt max IoU')\n",
    "    # print(roi_iou_max.eval())\n",
    "    positive_roi_bool     = (roi_iou_max >= 0.5)\n",
    "    all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "    print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    print('Positive IoUs \\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "    ## current method\n",
    "    all_negative_indices     = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "#     print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "#     print('Negative IoUs \\n', tf.gather(roi_iou_max,all_negative_indices).eval())\n",
    "\n",
    "    ## method - suppress the proposals with 0 IoUs\n",
    "    # negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "    # negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "    # negative_nonzero_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "    # print('Negative indices')\n",
    "    # print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "    # print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "    ##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "    ##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    # print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "    # print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "    # print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "    positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "    negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "    print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "#     print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##  Select positive samples from amongst positive bounding boxes\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## current method\n",
    "    positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "    ## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "    ## New:\n",
    "    positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "    positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "    ##\n",
    "    ## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "    ## negative count, due to the fact that positive_count is cast to an int. \n",
    "    ## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "    ## \n",
    "    ## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "    ## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "    ## some of these will be used to introduce false positives/\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "    # print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "    # negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "    # print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "    # all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "    # print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## Here is the alterantive method\n",
    "    ## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "    ## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "    ##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "    false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "    false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "    false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "    \n",
    "    # print('Positive Count       : ', positive_count.eval())\n",
    "    # print('All Negative Count   : ', all_negative_count.eval())\n",
    "    # print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "    # print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "    # print(false_positive_indices.eval())\n",
    "    \n",
    "    negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "    negative_count     = tf.shape(negative_indices)[0]\n",
    "    # print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "    #       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "    # print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 5.   Gather selected positive and negative ROIs\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    positive_rois      = tf.gather(proposals, positive_indices)\n",
    "    false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "    negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "    # print(positive_rois.eval())\n",
    "    # print(false_positive_rois.eval())\n",
    "    # print(negative_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    # \n",
    "    #  Remember: The same class can have multiple gt_bounding boxes. So RoIs assiged to same class could have \n",
    "    #            DIFFERENT gt_bboxes (classes can have multple bounding boxes -- like when the same shape \n",
    "    #           appears twice in an image)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "    roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "    roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "    roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "    \n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' positive overlaps shape  :  ', sess.run(positive_overlaps, roi_gt_box_assignment))\n",
    "#     print(tf.reduce_max(positive_overlaps, axis = 1).eval())\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    ## 7.   Compute bbox delta \n",
    "    #  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "    deltas /= config.BBOX_STD_DEV\n",
    "    # print('deltas')\n",
    "    # print(deltas.eval())\n",
    "    # print(' Positive RoIs ')\n",
    "    # print(positive_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    #\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "    fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "    fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "    fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "#     print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "    # print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "    # print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "    # print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "    # print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "    return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T16:56:05.360927Z",
     "start_time": "2018-05-16T16:56:05.107701Z"
    }
   },
   "outputs": [],
   "source": [
    "def overlaps_graph_mod(boxes1, boxes2):\n",
    "    '''\n",
    "    Computes IoU overlaps between two sets of boxes.in normalized coordinates\n",
    "    \n",
    "    boxes1 - proposals :  [batch_size,  proposal_counts, 4 (y1, x1, y2, x2)] <-- Region proposals\n",
    "    boxes2 - gt_boxes  :  [batch_size, max_gt_instances, 4 (y1, x1, y2, x2)] <-- input_normlzd_gt_boxes\n",
    "    \n",
    "    proposal_counts : 1000 or 2000 based on training or inference\n",
    "    max_gt_instances: 100\n",
    "    \n",
    "    returns :\n",
    "    ---------\n",
    "    overlaps :          [ proposal_counts, max_gt_instances] \n",
    "                        IoU of all proposal box / gt_box pairs\n",
    "    '''\n",
    "    # 1. Tile boxes2 and repeat boxes1. This allows us to compare every boxes1 against every boxes2 without loops.\n",
    "    #    TF doesn't have an equivalent to np.repeat() so simulate it using tf.tile() and tf.reshape.\n",
    "    \n",
    "#     print('\\t>>> detection_targets_graph - calculate Overlaps_graph')    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 before reshape: ',tf.shape(boxes1).eval())  # (?,?)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 before reshape: ',tf.shape(boxes2).eval())  # (?,?)\n",
    "    \n",
    "    # tf.expand_dims(boxes1, 1) : makes b1:[1, proposal_count_sz, 4] \n",
    "    b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "    b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 after reshape: ',tf.shape(b1).eval())  # (?,4)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 after reshape: ',tf.shape(b2).eval())  # (?,4)\n",
    "\n",
    "    # 2. Compute intersections\n",
    "    b1_y1, b1_x1, b1_y2, b1_x2 = tf.split(b1, 4, axis=1)\n",
    "    b2_y1, b2_x1, b2_y2, b2_x2 = tf.split(b2, 4, axis=1)\n",
    "    \n",
    "#     print('     overlaps_graph: shape of b1_y1 after split: ',tf.shape(b2_y1).eval())  # (?,4)\n",
    "    y1 = tf.maximum(b1_y1, b2_y1)\n",
    "    x1 = tf.maximum(b1_x1, b2_x1)\n",
    "    y2 = tf.minimum(b1_y2, b2_y2)\n",
    "    x2 = tf.minimum(b1_x2, b2_x2)\n",
    "    intersection = tf.maximum(x2 - x1, 0) * tf.maximum(y2 - y1, 0)\n",
    "\n",
    "    # 3. Compute unions\n",
    "    b1_area = (b1_y2 - b1_y1) * (b1_x2 - b1_x1)\n",
    "    b2_area = (b2_y2 - b2_y1) * (b2_x2 - b2_x1)\n",
    "    union = b1_area + b2_area - intersection\n",
    "    \n",
    "    # 4. Compute IoU and reshape to [boxes1, boxes2]\n",
    "    iou = intersection / union\n",
    "    overlaps = tf.reshape(iou, [tf.shape(boxes1)[0], tf.shape(boxes2)[0]])\n",
    "#     print('\\t     Overlaps_graph(): Shape of output overlaps', tf.shape(overlaps).eval(), overlaps.get_shape())\n",
    "    return overlaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:49:46.246720Z",
     "start_time": "2018-05-06T18:49:46.019140Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids \\\n",
    "#         = dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T17:58:00.775508Z",
     "start_time": "2018-05-06T17:58:00.140788Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.set_random_seed(1)\n",
    "# print(' Shuffled Positive indices: \\n',positive_ind_shuffled.eval())\n",
    "# print(' Positive indices:         \\n', positive_indices.eval())\n",
    "# print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "# print(' positive overlaps shape  :  ', tf.shape(positive_overlaps).eval())\n",
    "# print(  positive_overlaps.eval())\n",
    "# print(' Pos roi gt class assign  :\\n', roi_gt_class_ids)\n",
    "# print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval)\n",
    "# print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment)\n",
    "# print(' positive overlaps        :\\n', positive_overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  detetct_target_layer -- non function format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T16:57:27.221460Z",
     "start_time": "2018-05-16T16:57:26.971296Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "\n",
    "    proposals              = tf.identity(rpn_proposal_rois)[0]\n",
    "    gt_class_ids           = tf.identity(input_gt_class_ids)[0]\n",
    "    gt_boxes               = tf.identity(input_gt_bboxes_norm)[0]\n",
    "    \n",
    "    print(rpn_proposal_rois.shape)\n",
    "    print(proposals.shape)\n",
    "    print(input_gt_bboxes_norm.shape)\n",
    "    print(gt_boxes.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:13.004981Z",
     "start_time": "2018-05-06T21:01:07.059401Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('>>> detection_targets_graph ')\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('     gt_class_ids.shape    :',  tf.shape(gt_class_ids).eval())\n",
    "print('     gt_masks.shape        :',  tf.shape(gt_masks).eval() )\n",
    "\n",
    "proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('   ####  gt_boxes :\\n', gt_boxes.eval())\n",
    "# print(non_zeros.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "##  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "#------------------------------------------------------------------------------------------\n",
    "crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "# crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "# gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# get unique list of classes present in current image\n",
    "#------------------------------------------------------------------------------------------\n",
    "gt_classes_present, _ = tf.unique(gt_class_ids)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Compute overlaps with crowd boxes [anchors, crowds]\n",
    "#------------------------------------------------------------------------------------------\n",
    "crowd_overlaps  = overlaps_graph_mod(proposals, crowd_boxes)\n",
    "crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "\n",
    "# print('crowd ixs: ', crowd_ix.eval())\n",
    "# print('non_crowd_ixs', non_crowd_ix.eval())\n",
    "# print('non crowd bool', no_crowd_bool.eval())\n",
    " \n",
    "#------------------------------------------------------------------------------------------\n",
    "# Compute overlaps matrix [proposals, gt_boxes] - The IoU between \n",
    "# proposals and gt_boxes (non-crowd gt boxes, designated by classId < 0 in Coco)\n",
    "# overlaps is \n",
    "# compute max of elements across axis 1 of overlaps tensor. \n",
    "#------------------------------------------------------------------------------------------\n",
    "overlaps        = overlaps_graph_mod(proposals, gt_boxes)\n",
    "roi_iou_max     = tf.reduce_max(overlaps, axis=1)\n",
    "# print('     overlaps.shape        :',  overlaps.shape, KB.int_shape(overlaps)   )\n",
    "# print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "# print(overlaps.eval())\n",
    "# print(' RoI/Gt max IoU')\n",
    "# print(roi_iou_max.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 1. Determine indices of postive ROI propsal boxes\n",
    "##    Identify RoIs that have an IoU >= 0.5 - these are positive RoIs\n",
    "##    RoIs that have a max IoU < 0.5 and are not a crowd RoI are considered negative RoIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_roi_bool         = (roi_iou_max >= 0.5)\n",
    "all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Positive IoUs    :\\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "## 2. Determine indices of negative ROI proposal boxes\n",
    "#------------------------------------------------------------------------------------------\n",
    "#    those with < 0.5 with every GT box and are not crowds bboxes \n",
    "# the where creates a array with shape [# of answers, 1] so we use [:, 0] after\n",
    "## current method\n",
    "negative_indices      = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "\n",
    "## new method\n",
    "# this modification will determine negative ROI proposal boxes but in addition, \n",
    "# will suppress the zero RoIs from the indicies \n",
    "# note that   ( negative_bool         = ~positive_roi_bool)\n",
    "# negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "# negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "# negative_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "# print('Negative indices')\n",
    "# print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "# print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "# print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "# print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "# print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "# print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##  Select positive samples from amongst positive bounding boxes\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## current method\n",
    "positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "## New:\n",
    "positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "##\n",
    "## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "## negative count, due to the fact that positive_count is cast to an int. \n",
    "## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "## \n",
    "## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "## some of these will be used to introduce false positives/\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "# print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "# negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "# print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "# all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "# print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## Here is the alterantive method\n",
    "## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "\n",
    "# print('Positive Count       : ', positive_count.eval())\n",
    "# print('All Negative Count   : ', all_negative_count.eval())\n",
    "# print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "# print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "# print(false_positive_indices.eval())\n",
    "\n",
    "negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "negative_count     = tf.shape(negative_indices)[0]\n",
    "# print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "#       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "# print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 5.   Gather selected positive and negative ROIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_rois      = tf.gather(proposals, positive_indices)\n",
    "false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "# print(positive_rois.eval())\n",
    "# print(false_positive_rois.eval())\n",
    "# print(negative_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "\n",
    "# print('Positive indices: \\n',positive_indices.eval())\n",
    "# print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "# print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 7.   Compute bbox delta \n",
    "#  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "deltas /= config.BBOX_STD_DEV\n",
    "# print('deltas')\n",
    "# print(deltas.eval())\n",
    "# print(' Positive RoIs ')\n",
    "# print(positive_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#  Idea -- instead of using arg_max, use arg_min \n",
    "#------------------------------------------------------------------------------------------------------\n",
    "fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "##--------------------------------------------------------------------------------\n",
    "## To Randomly assign classes to the false positive bounding boxes,\n",
    "## use the gt_class_id / OR the box_assignement to pick a class from the \n",
    "## shuffled <gt_classes_present> tensor\n",
    "##--------------------------------------------------------------------------------\n",
    "\n",
    "# print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "# print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "# print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "# print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "# print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 8.  prepare gt_masks \n",
    "#      transpose gt_masks from [h, w, N] to [N, height, width] and add 4th dim at end [N, height, width, 1]\n",
    "#      Pick the right mask for each ROI\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "transposed_masks = tf.expand_dims(tf.transpose(gt_masks, [2, 0, 1]), -1)\n",
    "roi_masks = tf.gather(transposed_masks, roi_gt_box_assignment)\n",
    "\n",
    "# Compute mask targets\n",
    "boxes = positive_rois\n",
    "\n",
    "if config.USE_MINI_MASK:\n",
    "    # Transform ROI corrdinates from normalized image space\n",
    "    # to normalized mini-mask space.\n",
    "    y1, x1, y2, x2 = tf.split(positive_rois, 4, axis=1)\n",
    "    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(roi_gt_boxes, 4, axis=1)\n",
    "    gt_h = gt_y2 - gt_y1\n",
    "    gt_w = gt_x2 - gt_x1\n",
    "    y1 = (y1 - gt_y1) / gt_h\n",
    "    x1 = (x1 - gt_x1) / gt_w\n",
    "    y2 = (y2 - gt_y1) / gt_h\n",
    "    x2 = (x2 - gt_x1) / gt_w\n",
    "    boxes = tf.concat([y1, x1, y2, x2], 1)\n",
    "\n",
    "box_ids = tf.range(0, tf.shape(roi_masks)[0])\n",
    "masks   = tf.image.crop_and_resize(tf.cast(roi_masks, tf.float32), \n",
    "                                   boxes,\n",
    "                                   box_ids,\n",
    "                                   config.MASK_SHAPE)\n",
    "# Remove the extra dimension from masks.\n",
    "masks = tf.squeeze(masks, axis=3)\n",
    "\n",
    "# Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with\n",
    "# binary cross entropy loss.\n",
    "masks = tf.round(masks)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# Append negative ROIs and pad bbox deltas and masks that\n",
    "# are not used for negative ROIs with zeros.\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "fp_rois          = tf.concat([positive_rois, false_positive_rois, negative_rois], axis=0)\n",
    "fp_roi_gt_boxes     = tf.concat([roi_gt_boxes,fp_gt_boxes], axis=0)\n",
    "fp_roi_gt_class_ids = tf.concat([roi_gt_class_ids, fp_gt_class_ids],axis=0)\n",
    "\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "\n",
    "\n",
    "rois             = tf.pad(rois            , [(0, P), (0, 0)])\n",
    "roi_gt_boxes     = tf.pad(roi_gt_boxes    , [(0, N + P), (0, 0)])\n",
    "roi_gt_class_ids = tf.pad(roi_gt_class_ids, [(0, N + P)])\n",
    "deltas           = tf.pad(deltas          , [(0, N + P), (0, 0)])\n",
    "masks            = tf.pad(masks           , [[0, N + P], (0, 0), (0, 0)])\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# SSetup False Positive structures\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "P1                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_rois)[0], 0)\n",
    "fp_rois             = tf.pad(rois            , [(0, P1), (0, 0)])\n",
    "\n",
    "\n",
    "P2                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_roi_gt_boxes)[0], 0)\n",
    "fp_roi_gt_boxes     = tf.pad(fp_roi_gt_boxes    , [(0, P2), (0, 0)])\n",
    "fp_roi_gt_class_ids = tf.pad(fp_roi_gt_class_ids, [(0, P2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:21.161696Z",
     "start_time": "2018-05-06T21:01:15.939765Z"
    }
   },
   "outputs": [],
   "source": [
    "sess1 = tf.Session()\n",
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "FeedList = [false_positive_indices, fp_overlaps, fp_gt_box_assignment, fp_gt_boxes, fp_gt_class_ids, gt_class_ids,\n",
    "            fp_rois, fp_roi_gt_boxes, fp_roi_gt_class_ids,\n",
    "            rois   , roi_gt_boxes   , roi_gt_class_ids]\n",
    "tt = sess1.run(FeedList)\n",
    "print(type(tt), len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:30.008198Z",
     "start_time": "2018-05-06T21:01:29.754526Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(' False Positive indices: \\n', tt[0])\n",
    "print(' shape of false positive overlaps is :', tt[1].shape)\n",
    "print(' FP overlaps             \\n', tt[1])\n",
    "print(' FP gt box assignemt:\\n', tt[2])\n",
    "print(' FP gt boxes        :\\n', tt[3])\n",
    "print(' FP gt class assign :\\n', tt[4])\n",
    "print(' gt class ids assign :\\n', tt[5])\n",
    "print()\n",
    "print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "print()\n",
    "print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "print()\n",
    "print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:44:28.696521Z",
     "start_time": "2018-05-06T18:44:28.453845Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(tt), len(tt))\n",
    "print(' Shuffled Positive indices:\\n', tt[0])\n",
    "print(' Positive indices:         \\n', tt[1])\n",
    "print(' positive overlaps shape  :  ', tt[2].shape)\n",
    "print(' positive overlaps        :\\n', tt[2])\n",
    "print(' Pos roi gt box assignment:\\n', tt[5])    \n",
    "print(' Pos roi gt class assign  :\\n', tt[3])\n",
    "print(' Pos roi gt boxes         :\\n', tt[4])\n",
    "\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:24:33.788471Z",
     "start_time": "2018-05-06T20:24:33.549836Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(input_gt_class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "    negative_count = int((positive_count / config.ROI_POSITIVE_RATIO) - positive_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T16:29:56.648968Z",
     "start_time": "2018-05-06T16:29:55.701753Z"
    }
   },
   "outputs": [],
   "source": [
    "### 5.   Gather selected positive and negative ROIs\n",
    "# positive_rois      = tf.gather(proposals, positive_indices)\n",
    "# false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "# negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "# print(positive_rois.eval())\n",
    "# print(false_positive_rois.eval())\n",
    "# print(negative_rois.eval())\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# for each positive RoI, gather IoUs between the RoI and all gt bboxes, \n",
    "# find the index correwsponding to the gt_box with the maximum overlap, \n",
    "# and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#---------------------------------------------------------------------------------\n",
    "# positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "# roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "# roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "# roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "# print(' shape of positive overlaps is :', positive_overlaps.get_shape())\n",
    "# print(' positive overlaps \\n', positive_overlaps.eval())\n",
    "# print(' roi gt box assignment', roi_gt_box_assignment.eval())\n",
    "\n",
    "## 7.   Compute bbox delta \n",
    "# calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "# deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "# deltas /= config.BBOX_STD_DEV\n",
    "# print(deltas.eval())\n",
    "# print(positive_rois.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_overlaps     = tf.gather(overlaps, false_positive_indices)\n",
    "fp_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "fp_gt_boxes          = tf.gather(gt_boxes    , fp_box_assignment)\n",
    "fp_gt_class_ids      = tf.gather(gt_class_ids, fp_box_assignment)\n",
    "# print('     shape of positive overlaps is :', positive_overlaps.get_shape())\n",
    "print('positive overlaps \\n', fp_overlaps.eval())\n",
    "print('roi gt box assignemt', fp_box_assignment.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "rois             = tf.pad(rois            , [(0, P), (0, 0)])\n",
    "print(rois.eval())\n",
    "print(tf.shape(rois).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control  xxxxxxx / yyyyyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:43:43.392596Z",
     "start_time": "2018-04-17T10:43:43.123879Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt   = layers_out[4]   # pred_tensor\n",
    "pt2  = layers_out[12] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "        print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "        if (~equal.all()):\n",
    "#             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "            print(equal)\n",
    "            print('\\n -- using numpy (pt) \\n',pt[img][cls,~equal,:-1])\n",
    "            print('\\n -- using tensorflow (pt2) \\n',pt2[img][cls,~equal])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
