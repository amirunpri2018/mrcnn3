{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train FCN using MRCNN in Predict Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:46:55.814257Z",
     "start_time": "2018-10-31T16:46:48.283170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.8.0   Keras Version : 2.1.6 \n",
      "\n",
      "--> Execution started at: 10-31-2018 @ 16:46:55\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.1.6 \n",
      "--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 --mrcnn_logs_dir train_mrcnn_coco --fcn_logs_dir   train_fcn8_coco --mrcnn_model    last --fcn_model      init --opt            adagrad --fcn_arch       fcn8 --fcn_layers     all --sysout        screen --new_log_folder    \n",
      "    MRCNN Model        :  last\n",
      "    FCN Model          :  init\n",
      "    MRCNN Log Dir      :  train_mrcnn_coco\n",
      "    FCN Log Dir        :  train_fcn8_coco\n",
      "    FCN Arch           :  FCN8\n",
      "    FCN Log Dir        :  ['all']\n",
      "    Last Epoch         :  0\n",
      "    Epochs to run      :  2\n",
      "    Steps in each epoch:  32\n",
      "    Validation steps   :  8\n",
      "    Batch Size         :  1\n",
      "    Optimizer          :  ADAGRAD\n",
      "    sysout             :  SCREEN\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "from datetime import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "from mrcnn.config       import Config\n",
    "from mrcnn.dataset      import Dataset \n",
    "from mrcnn.utils        import log, stack_tensors, stack_tensors_3d, write_stdout\n",
    "from mrcnn.datagen      import data_generator, load_image_gt\n",
    "from mrcnn.callbacks    import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "from mrcnn.prep_notebook import mrcnn_coco_train, prep_coco_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "####  Pass input parameters to argparse\n",
    "\n",
    "# args = parser.parse_args(\"--epochs 100 --steps_in_epoch 128  --last_epoch 1264 --batch_size 8  --lr 0.5               --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model init\".split())\n",
    "# input_parms = \"--epochs 100 --steps_in_epoch 100  --last_epoch 1264 --batch_size 25 --lr 0.8 --val_steps 5 --logs_dir train_fcn_adagrad --model /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 --fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "# input_parms +=\" --model     /home/kbardool/models/train_mrcnn/shapes20180621T1554/mask_rcnn_shapes_1119.h5 \"\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \"--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 \" \n",
    "input_parms +=\"--mrcnn_logs_dir train_mrcnn_coco \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn8_coco \"\n",
    "input_parms +=\"--mrcnn_model    last \"\n",
    "input_parms +=\"--fcn_model      init \"\n",
    "input_parms +=\"--opt            adagrad \"\n",
    "input_parms +=\"--fcn_arch       fcn8 \" \n",
    "input_parms +=\"--fcn_layers     all \" \n",
    "input_parms +=\"--sysout        screen \"\n",
    "input_parms +=\"--new_log_folder    \"\n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "## if debug is true set stdout destination to stringIO\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "# debug = False\n",
    "if args.sysout == 'FILE':\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "# print(\"    Dataset            : \", args.dataset)\n",
    "# print(\"    Logs               : \", args.logs)\n",
    "# print(\"    Limit              : \", args.limit)\n",
    "print(\"    MRCNN Model        : \", args.mrcnn_model)\n",
    "print(\"    FCN Model          : \", args.fcn_model)\n",
    "print(\"    MRCNN Log Dir      : \", args.mrcnn_logs_dir)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_logs_dir)\n",
    "print(\"    FCN Arch           : \", args.fcn_arch)\n",
    "print(\"    FCN Log Dir        : \", args.fcn_layers)\n",
    "print(\"    Last Epoch         : \", args.last_epoch)\n",
    "print(\"    Epochs to run      : \", args.epochs)\n",
    "print(\"    Steps in each epoch: \", args.steps_in_epoch)\n",
    "print(\"    Validation steps   : \", args.val_steps)\n",
    "print(\"    Batch Size         : \", args.batch_size)\n",
    "print(\"    Optimizer          : \", args.opt)\n",
    "print(\"    sysout             : \", args.sysout)\n",
    "# print(\"    OS Platform        : \", syst)\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## setup project directories\n",
    "##   ROOT_DIR         : Root directory of the project \n",
    "##   MODEL_DIR        : Directory to save logs and trained model\n",
    "##   COCO_MODEL_PATH  : Path to COCO trained weights\n",
    "##---------------------------------------------------------------------------------\n",
    "paths = Paths(fcn_training_folder = args.fcn_logs_dir, mrcnn_training_folder = args.mrcnn_logs_dir)\n",
    "paths.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:09.312725Z",
     "start_time": "2018-10-31T16:47:09.129728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [1024 1024]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 False\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                32\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  /home/kbardool/models/train_mrcnn_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------                          \n",
    "mrcnn_config                    = CocoConfig()\n",
    "mrcnn_config.NAME               = 'mrcnn'              \n",
    "mrcnn_config.TRAINING_PATH      = paths.MRCNN_TRAINING_PATH\n",
    "mrcnn_config.COCO_DATASET_PATH  = paths.COCO_DATASET_PATH \n",
    "mrcnn_config.COCO_MODEL_PATH    = paths.COCO_MODEL_PATH   \n",
    "mrcnn_config.RESNET_MODEL_PATH  = paths.RESNET_MODEL_PATH \n",
    "mrcnn_config.VGG16_MODEL_PATH   = paths.VGG16_MODEL_PATH  \n",
    "mrcnn_config.COCO_CLASSES       = None \n",
    "mrcnn_config.DETECTION_PER_CLASS = 200\n",
    "mrcnn_config.HEATMAP_SCALE_FACTOR = 4\n",
    "mrcnn_config.BATCH_SIZE         = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "mrcnn_config.IMAGES_PER_GPU     = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "\n",
    "mrcnn_config.STEPS_PER_EPOCH    = int(args.steps_in_epoch)\n",
    "mrcnn_config.LEARNING_RATE      = float(args.lr)\n",
    "mrcnn_config.EPOCHS_TO_RUN      = int(args.epochs)\n",
    "mrcnn_config.FCN_INPUT_SHAPE    = mrcnn_config.IMAGE_SHAPE[0:2]\n",
    "mrcnn_config.LAST_EPOCH_RAN     = int(args.last_epoch)\n",
    "\n",
    "# mrcnn_config.WEIGHT_DECAY       = 2.0e-4\n",
    "# mrcnn_config.VALIDATION_STEPS   = int(args.val_steps)\n",
    "# mrcnn_config.REDUCE_LR_FACTOR   = 0.5\n",
    "# mrcnn_config.REDUCE_LR_COOLDOWN = 30\n",
    "# mrcnn_config.REDUCE_LR_PATIENCE = 40\n",
    "# mrcnn_config.EARLY_STOP_PATIENCE= 80\n",
    "# mrcnn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "# mrcnn_config.MIN_LR             = 1.0e-10\n",
    "# mrcnn_config.OPTIMIZER          = args.opt.upper()\n",
    "# mrcnn_model.config.OPTIMIZER    = 'ADAGRAD'\n",
    "mrcnn_config.NEW_LOG_FOLDER       = False\n",
    "mrcnn_config.SYSOUT               = args.sysout\n",
    "mrcnn_config.display() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:21.736417Z",
     "start_time": "2018-10-31T16:47:14.907356Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize ModelBase model \n",
      "   Mode      :  trainfcn\n",
      "   Model dir :  /home/kbardool/models/train_mrcnn_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  trainfcn\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 1024, 1024, 3)\n",
      "     After ZeroPadding2D  : (?, 1030, 1030, 3) (?, 1030, 1030, 3)\n",
      "     After Conv2D padding : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     After BatchNorm      : (?, 512, 512, 64) (?, 512, 512, 64)\n",
      "     C1 Shape: (?, 256, 256, 64) (?, 256, 256, 64)\n",
      "     C2 Shape:  (?, 256, 256, 256) (?, 256, 256, 256)\n",
      "     C3 Shape:  (?, 128, 128, 512) (?, 128, 128, 512)\n",
      "     C4 Shape:  (?, 64, 64, 1024) (?, 64, 64, 1024)\n",
      "     C5 Shape:  (?, 32, 32, 2048) (?, 32, 32, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 256, 256, 256)\n",
      "     FPN P3 shape : (None, 128, 128, 256)\n",
      "     FPN P4 shape : (None, 64, 64, 256)\n",
      "     FPN P5 shape : (None, 32, 32, 256)\n",
      "     FPN P6 shape : (None, 16, 16, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "     append Tensor(\"fpn_p2/BiasAdd:0\", shape=(?, 256, 256, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p3/BiasAdd:0\", shape=(?, 128, 128, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p4/BiasAdd:0\", shape=(?, 64, 64, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p5/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p6/MaxPool:0\", shape=(?, 16, 16, 256), dtype=float32) to layer_outputs \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (261888, 4)\n",
      "     Scores :  (1, 6000)\n",
      "     Deltas :  (1, 6000, 4)\n",
      "     Anchors:  (1, 6000, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (1, ?, ?) (1, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (1, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     INPUT: rois shape          : (1, ?, ?)\n",
      "     INPUT: No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 256, 256, 256)\n",
      "        feature_maps shape  : (?, 128, 128, 256)\n",
      "        feature_maps shape  : (?, 64, 64, 256)\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "     INPUT: image_shape         : [1024 1024    3]\n",
      "     INPUT: pool_size           : 7\n",
      "     INPUT: num_classes         : 81\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 200, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 200, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 200, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 200, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 200, 81)\n",
      "     mrcnn_class_probs    output shape is :  (?, 200, 81)\n",
      "     mrcnn_bbox_fc        output shape is :  (?, 200, 324)\n",
      "     mrcnn_bbox_fc        reshaped output :  (?, 200, 324)\n",
      "     mrcnn_bbox           output shape is :  (?, 200, 81, 4)\n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "  > CHMLayer Call()  3\n",
      "    mrcnn_class.shape    : (?, 200, 81) (None, 200, 81)\n",
      "    mrcnn_bbox.shape     : (?, 200, 81, 4) (None, 200, 81, 4)\n",
      "    output_rois.shape    : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois               :  200\n",
      "    norm_input_rois.shape  :  <class 'tensorflow.python.framework.ops.Tensor'> (None, 200, 4)\n",
      "    scale.shape            :  <class 'tensorflow.python.framework.ops.Tensor'> (4,) (4,)\n",
      "    dup_scale.shape        :  <class 'tensorflow.python.framework.ops.Tensor'> (1, 200, 4) (1, 200, 4)\n",
      "\n",
      "    mrcnn_class shape      :  (None, 200, 81)\n",
      "    mrcnn_bbox.shape       :  (None, 200, 81, 4) (?, 200, 81, 4)\n",
      "    config image shape     :  [1024 1024    3] h: 1024 w: 1024\n",
      "    refined rois clipped   :  (1, 200, 4)\n",
      "    input_rois.shape       :  (1, 200, 4) (1, 200, 4)\n",
      "    refined_rois.shape     :  (1, 200, 4) (1, 200, 4)\n",
      "    shape of sequence      :  (?, 200, 1)\n",
      "    pred_array             :  (1, 200, 7)\n",
      "    scatter_ind            :  <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 200, 3)\n",
      "    pred_scatter           :  (1, 81, 200, 7)\n",
      "    - Add normalized score --\n",
      "\n",
      "    normalizer             :  (1, 81, 1)\n",
      "    norm_score             :  (1, 81, 200, 1)\n",
      "    pred_scatter           :  (1, 81, 200, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    roi_grid shape         :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    roi_grid_exp           :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200, 1)\n",
      "    gather_inds            :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200, 3)\n",
      "    pred_tensor            :  (1, 81, 200, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['pred_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "    X/Y shapes : (256, 256) (256, 256)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    ones_exp * Y (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    pos_grid before transpse :  (?, 256, 256, 2)\n",
      "    pos_grid after transpose :  (256, 256, ?, 2)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (256, 256, ?, 2)\n",
      "     Prob_grid shape from mvn.probe:  (256, 256, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 256, 256)\n",
      "    << output probabilities shape  :  (?, 256, 256)\n",
      "    scores_scattered shape :  (1, 81, 200, 3)\n",
      "    gauss_scores  (FINAL)  :  (1, 81, 200, 11)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer     :  (?, 1, 1)\n",
      "    prob_grid_norm_scaled :  (?, 256, 256)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape      :  (?, 3)\n",
      "    prob_grid_clippped :  (?, 256, 256)\n",
      "    gauss_heatmap      :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 81, 256, 256) Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer shape   :  (1, 81, 1, 1)\n",
      "    normalized heatmap :  (1, 81, 256, 256)  Keras tensor  False\n",
      "    reshaped heatmap :  (1, 256, 256, 81)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    pred_refined_heatmap        :  (1, 256, 256, 81) Keras tensor  False\n",
      "    pred_refnined_heatmap_scores:  (1, 81, 200, 11) Keras tensor  False\n",
      "    complete\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "  > CHMLayerTgt Call()  2\n",
      "    tgt_class_ids.shape  : (1, ?) (None, 200)\n",
      "    tgt_bboxes.shape     : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    num_bboxes             :  200 (building  gt_tensor )\n",
      "    gt_class_ids shape     :  (1, ?)    (None, 200)\n",
      "    norm_gt_bboxes.shape   :  (1, ?, ?)    (None, 200, 4)\n",
      "    gt_bboxes.shape        :  (1, 200, 4)    (1, 200, 4)\n",
      "    gt_classes_exp         :  (1, ?, 1)\n",
      "    gt_scores_exp          :  (1, ?, 1)\n",
      "    gt_array shape         :  (1, 200, 8) (1, 200, 8)\n",
      "    scatter_ind shape      :  (1, 200, 3) (1, 200, 3)\n",
      "    tf.shape(gt_array)[-1] :  8 (1, 200, 8)\n",
      "    gt_scatter shape       :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    gather_inds            :  (1, 81, 200, 3)\n",
      "    gt_tensor.shape        :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "     Prob_grid shape :  (?, 256, 256)\n",
      "    prob_grid_clipped      :  (?, 256, 256)\n",
      "    scores_scattered shape :  (1, 81, 200, 3)\n",
      "    gauss_scores           :  (1, 81, 200, 11)  Name:    cntxt_layer_gt/gt_heatmap_scores:0\n",
      "    gauss_scores  (FINAL)  :  (1, 81, 200, 11)  Keras tensor  False\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 256, 256)\n",
      "    gauss_heatmap   :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce MAX based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 81, 256, 256) Keras tensor  False\n",
      "    gauss_heatmap :  (1, 256, 256, 81)  Keras tensor  False\n",
      "\n",
      "    gt_heatmap                  :  (1, 256, 256, 81) Keras tensor  False\n",
      "    gt_heatmap_scores           :  (1, 81, 200, 11) Keras tensor  False\n",
      "    complete\n",
      "<<<  shape of pred_heatmap   :  (1, 256, 256, 81)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (1, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 1024, 1024, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap_norm:0            Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 81, 200, 11)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 81, 200, 11)\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build Mask RCNN Model in TRAINFCN mode\n",
    "##------------------------------------------------------------------------------------\n",
    "mrcnn_model,mrcnn_config = mrcnn_coco_train(mode = 'trainfcn', mrcnn_config = mrcnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:31.431472Z",
     "start_time": "2018-10-31T16:47:31.344924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_PERIOD              1\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            200\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            15\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [256 256]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-05\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    81\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             5\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_MIN_DELTA            1e-05\n",
      "REDUCE_LR_PATIENCE             5\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                32\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  /home/kbardool/models/train_fcn8_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration for FCN model\n",
    "##------------------------------------------------------------------------------------\n",
    "fcn_config = CocoConfig()\n",
    "# fcn_config.IMAGE_MAX_DIM        = 600\n",
    "# fcn_config.IMAGE_MIN_DIM        = 480      \n",
    "# mrcnn_config.COCO_DATASET_PATH  = COCO_DATASET_PATH \n",
    "# mrcnn_config.COCO_MODEL_PATH    = COCO_MODEL_PATH   \n",
    "# mrcnn_config.RESNET_MODEL_PATH  = RESNET_MODEL_PATH \n",
    "fcn_config.NAME                 = 'fcn'              \n",
    "fcn_config.TRAINING_PATH        = paths.FCN_TRAINING_PATH\n",
    "fcn_config.VGG16_MODEL_PATH     = paths.FCN_VGG16_MODEL_PATH\n",
    "fcn_config.FCN_INPUT_SHAPE      = mrcnn_config.IMAGE_SHAPE[0:2] // mrcnn_config.HEATMAP_SCALE_FACTOR \n",
    "\n",
    "fcn_config.BATCH_SIZE           = int(args.batch_size)                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "fcn_config.IMAGES_PER_GPU       = int(args.batch_size)                  # Must match BATCH_SIZE\n",
    "fcn_config.EPOCHS_TO_RUN        = int(args.epochs)\n",
    "fcn_config.STEPS_PER_EPOCH      = int(args.steps_in_epoch)\n",
    "fcn_config.LEARNING_RATE        = float(args.lr)\n",
    "fcn_config.LAST_EPOCH_RAN       = int(args.last_epoch)\n",
    "fcn_config.VALIDATION_STEPS     = int(args.val_steps)\n",
    "\n",
    "fcn_config.WEIGHT_DECAY         = 2.0e-4     ## FCN Weight decays are 5.0e-4 or 2.0e-4\n",
    "fcn_config.BATCH_MOMENTUM       = 0.9\n",
    "fcn_config.REDUCE_LR_FACTOR     = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN   = 5\n",
    "fcn_config.REDUCE_LR_PATIENCE   = 5\n",
    "fcn_config.REDUCE_LR_MIN_DELTA  = 1e-5\n",
    "fcn_config.EARLY_STOP_PATIENCE  = 15\n",
    "fcn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "fcn_config.MIN_LR               = 1.0e-10\n",
    "fcn_config.CHECKPOINT_PERIOD    = 1\n",
    "\n",
    "fcn_config.NEW_LOG_FOLDER       = args.new_log_folder\n",
    "fcn_config.OPTIMIZER            = args.opt.upper()\n",
    "fcn_config.SYSOUT               = args.sysout\n",
    "\n",
    "fcn_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:34.818203Z",
     "start_time": "2018-10-31T16:47:34.203684Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  /home/kbardool/models/train_fcn8_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN8\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                  NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): /home/kbardool/models/train_fcn8_coco/fcn20181031T1647/fcn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : /home/kbardool/models/train_fcn8_coco/fcn20181031T1647 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      "arch set to FCN8\n",
      "<function fcn8_graph at 0x7f1928db4f28>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "   Arch:  FCN8  Adding  FCN layers\n",
      "---------------------------------------------------\n",
      "\n",
      "---------------\n",
      ">>> FCN8 Layer \n",
      "---------------\n",
      "     feature map      : (?, 256, 256, 81)\n",
      "     height : 256 width : 256 classes : 81\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   Input feature map                   :  (?, 256, 256, 81)\n",
      "   FCN Block 11 shape is               :  (None, 256, 256, 64)\n",
      "   FCN Block 12 shape is               :  (None, 256, 256, 64)\n",
      "   FCN Block 13 (Max pooling) shape is :  (None, 128, 128, 64)\n",
      "   FCN Block 21 shape is               :  (?, 128, 128, 128)\n",
      "   FCN Block 22 shape is               :  (None, 128, 128, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (None, 64, 64, 128)\n",
      "   FCN Block 31 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 32 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 33 shape is               :  (None, 64, 64, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 41 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 42 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 43 shape is               :  (None, 32, 32, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 51 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 52 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 53 shape is               :  (None, 16, 16, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (None, 8, 8, 512)\n",
      "\n",
      "   --- FCN32 ----------------------------\n",
      "   FCN fully connected 1 (fc1) shape   :  (None, 8, 8, 4096)\n",
      "   FCN fully connected 2 (fc2) shape   :  (None, 8, 8, 4096)\n",
      "   FCN conv2d (fcn32_deconv2D) shape   :  (?, 8, 8, 81)  keras_tensor  True\n",
      "\n",
      "   --- FCN16 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape is                   :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling (Deconvolution2D(fcn32_classify)) shape :  (None, 18, 18, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 Add(score2_c, scorePool4) shape :  (None, 16, 16, 81)    keras_tensor  True\n",
      "   FCN upscore_pool4 (Deconv(fuse_Pool4)) shape              :  (None, 32, 32, 81)    keras_tensor  True\n",
      "\n",
      "   --- FCN8 ----------------------------\n",
      "   FCN scorePool4 (Conv2D(Pool4)) shape                      :  (None, 32, 32, 81)    keras_tensor  True\n",
      "   FCN 2x Upsampling/Cropped (Cropped2D(score2)) shape       :  (None, 32, 32, 81)    keras_tensor  True\n",
      "   FCN Add Score2,scorePool4 shape is                        :  (None, 32, 32, 81)    keras_tensor  True\n",
      "\n",
      "   FCN fcn8_classify  (Deconv(fuse_Pool4)) shape is     :  (None, 256, 256, 81)    keras_tensor  True\n",
      "   fcn_classify_shape: (None, 256, 256, 81)    h_factor :  1.0   w_factor :  1.0\n",
      "   FCN fcn_heatmap Lambda(fcn8_classify)                :  (None, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      "   fcn_heatmap      :  (None, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      ">>> fcn_heatmap_loss_graph \n",
      "---------------------------\n",
      "    target_masks : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss/Shape:0\", shape=(4,), dtype=int32) KerasTensor:  True\n",
      "    pred_heatmap : (?, ?, ?, 81) Tensor(\"fcn_heatmap_loss/Shape_1:0\", shape=(4,), dtype=int32) KerasTensor:  True\n",
      "    loss      : (?, 256, 256) Tensor(\"fcn_heatmap_loss/Shape_2:0\", shape=(3,), dtype=int32) KerasTensor:  False\n",
      "    loss mean : () Tensor(\"fcn_heatmap_loss/Shape_3:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "\n",
      "---------------------------\n",
      ">>> fcn_heatmap_loss_graph \n",
      "---------------------------\n",
      "    target_masks : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss/Shape_4:0\", shape=(4,), dtype=int32) KerasTensor:  False\n",
      "    pred_heatmap : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss/Shape_5:0\", shape=(4,), dtype=int32) KerasTensor:  False\n",
      "    loss      : (?, 256, 256) Tensor(\"fcn_heatmap_loss/Shape_6:0\", shape=(3,), dtype=int32) KerasTensor:  False\n",
      "    loss mean : () Tensor(\"fcn_heatmap_loss/Shape_7:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 11)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 11)\n",
      "\n",
      "\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap/BiasAdd:0                      Type: float32           Shape: (?, ?, ?, 81)\n",
      " layer:  1    output name: fcn_heatmap_loss/Mean_1:0                  Type: float32           Shape: ()\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build FCN Model in Training Mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del fcn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass    \n",
    "fcn_model = fcn_modellib.FCN(mode=\"training\", arch = args.fcn_arch, config=fcn_config)\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Display model configuration information\n",
    "##------------------------------------------------------------------------------------\n",
    "# paths.display()\n",
    "# fcn_config.display()  \n",
    "fcn_model.layer_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:43.827468Z",
     "start_time": "2018-10-31T16:47:37.904120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      " Exclude layers: \n",
      "-----------------------------------------------\n",
      " ---> last\n",
      ">>> find_last checkpoint in :  /home/kbardool/models/train_mrcnn_coco\n",
      "    Key : > mrcnn <\n",
      "    Dir names:  ['mrcnn20181011T1100']\n",
      "    Folder:  /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100\n",
      "    Checkpoints:  ['mrcnn_0103.h5']\n",
      "    find_last():   dir_name: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100\n",
      "    find_  last(): checkpoint: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      "   Last file is : /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      ">>> find_last checkpoint in :  /home/kbardool/models/train_mrcnn_coco\n",
      "    Key : > mrcnn <\n",
      "    Dir names:  ['mrcnn20181011T1100']\n",
      "    Folder:  /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100\n",
      "    Checkpoints:  ['mrcnn_0103.h5']\n",
      "    find_last():   dir_name: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100\n",
      "    find_  last(): checkpoint: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      ">>> load_weights() from : /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5\n",
      "   Weights file loaded: /home/kbardool/models/train_mrcnn_coco/mrcnn20181011T1100/mrcnn_0103.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load Mask RCNN Model Weight file\n",
    "##------------------------------------------------------------------------------------\n",
    "# exclude_list = [\"mrcnn_class_logits\"]\n",
    "#load_model(model, init_with = args.model)   \n",
    "exclude_list = []\n",
    "mrcnn_model.load_model_weights(init_with = args.mrcnn_model, exclude = exclude_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:43.875561Z",
     "start_time": "2018-10-31T16:47:43.829954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FCN Training starting from randomly initialized weights ...\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load FCN Model weights  \n",
    "##------------------------------------------------------------------------------------\n",
    "if args.fcn_model != 'init':\n",
    "    fcn_model.load_model_weights(init_with = args.fcn_model, verbose = 1)\n",
    "else:\n",
    "    print(' FCN Training starting from randomly initialized weights ...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:47:53.203539Z",
     "start_time": "2018-10-31T16:47:45.785903Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.72s)\n",
      "creating index...\n",
      "index created!\n",
      " image dir        :  /home/kbardool/MLDatasets/coco2014/val2014\n",
      " json_path_dir    :  /home/kbardool/MLDatasets/coco2014/annotations/instances_valminusminival2014.json\n",
      " number of images :  35185\n",
      "loading annotations into memory...\n",
      "Done (t=1.33s)\n",
      "creating index...\n",
      "index created!\n",
      " image dir        :  /home/kbardool/MLDatasets/coco2014/val2014\n",
      " json_path_dir    :  /home/kbardool/MLDatasets/coco2014/annotations/instances_minival2014.json\n",
      " number of images :  4952\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build & Load Training and Validation datasets\n",
    "##------------------------------------------------------------------------------------\n",
    "# dataset_train = prep_coco_dataset([\"train\",  \"val35k\"], mrcnn_config, generator = False)\n",
    "# dataset_val   = prep_coco_dataset([\"minival\"]         , mrcnn_config, generator = False)\n",
    "from mrcnn.prep_notebook import coco_dataset\n",
    "dataset_train = coco_dataset([\"val35k\"], mrcnn_config)\n",
    "dataset_val   = coco_dataset([\"minival\"], mrcnn_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:57:10.043609Z",
     "start_time": "2018-10-31T15:57:09.999469Z"
    }
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------------\n",
    "## Data generators\n",
    "##--------------------------------------------------------------------------------\n",
    "# train_generator = data_generator(dataset_train, mrcnn_model.config, shuffle=True,\n",
    "#                                  batch_size=mrcnn_config.BATCH_SIZE)\n",
    "# val_generator   = data_generator(dataset_val, mrcnn_model.config, shuffle=True,\n",
    "#                                  batch_size=mrcnn_config.BATCH_SIZE,\n",
    "#                                  augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:25:13.863453Z",
     "start_time": "2018-10-31T16:25:13.631407Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "for i in train_batch_x:\n",
    "    print(type(i), i.shape)\n",
    "for i in train_batch_y:\n",
    "    print(type(i), i.shape)\n",
    "print(train_batch_y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Print model layer and weight information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:29:41.902326Z",
     "start_time": "2018-10-31T15:29:41.840211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in fcn_model.keras_model.layers:\n",
    "    print('layer: ', layer.name)\n",
    "    for weight in layer.weights:\n",
    "        print('   mapped_weight_name : ',weight.name)\n",
    "    if hasattr(layer, 'output'):\n",
    "        print('   layer output ', type(layer),' shape: ',layer.output.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:50:55.243362Z",
     "start_time": "2018-10-31T16:48:07.746557Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all']\n",
      "['.*']\n",
      "layers regex : .*\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_pr_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "   1  block1_conv1           (Conv2D              )   TRAIN \n",
      "   2  block1_conv2           (Conv2D              )   TRAIN \n",
      "   3  block1_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   4  block2_conv1           (Conv2D              )   TRAIN \n",
      "   5  block2_conv2           (Conv2D              )   TRAIN \n",
      "   6  block2_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   7  block3_conv1           (Conv2D              )   TRAIN \n",
      "   8  block3_conv2           (Conv2D              )   TRAIN \n",
      "   9  block3_conv3           (Conv2D              )   TRAIN \n",
      "  10  block3_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  11  block4_conv1           (Conv2D              )   TRAIN \n",
      "  12  block4_conv2           (Conv2D              )   TRAIN \n",
      "  13  block4_conv3           (Conv2D              )   TRAIN \n",
      "  14  block4_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  15  block5_conv1           (Conv2D              )   TRAIN \n",
      "  16  block5_conv2           (Conv2D              )   TRAIN \n",
      "  17  block5_conv3           (Conv2D              )   TRAIN \n",
      "  18  block5_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  19  fcn32_fc1              (Conv2D              )   TRAIN \n",
      "  20  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      "  21  fcn32_fc2              (Conv2D              )   TRAIN \n",
      "  22  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      "  23  fcn32_deconv2D         (Conv2D              )   TRAIN \n",
      "  24  fcn16_score2           (Conv2DTranspose     )   TRAIN \n",
      "  25  fcn16_crop_score2      (Cropping2D          )   ............................no weights to train ]\n",
      "  26  fcn16_score_pool4      (Conv2D              )   TRAIN \n",
      "  27  fcn16_fuse_pool4       (Add                 )   ............................no weights to train ]\n",
      "  28  fcn16_upscore_pool4    (Conv2DTranspose     )   TRAIN \n",
      "  29  fcn8_crop_pool4        (Cropping2D          )   ............................no weights to train ]\n",
      "  30  fcn8_score_pool3       (Conv2D              )   TRAIN \n",
      "  31  fcn8_fuse_pool3        (Add                 )   ............................no weights to train ]\n",
      "  32  fcn_heatmap            (Conv2DTranspose     )   TRAIN \n",
      "  33  input_gt_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "  34  fcn_heatmap_loss       (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      "  Compile Model :\n",
      " ----------------\n",
      "    losses        :  ['fcn_heatmap_loss']\n",
      "    optimizer     :  <keras.optimizers.Adagrad object at 0x7f18d25cddd8>\n",
      "    learning rate :  1e-05\n",
      "    momentum      :  0.9\n",
      "\n",
      " Initial self.keras_model.losses :\n",
      " ---------------------------------\n",
      " losses passed to compile :  ['fcn_heatmap_loss']\n",
      " self.keras_model.losses  : \n",
      "\n",
      " Add loss_functions to self.keras_model.losses\n",
      " -------------------------------------\n",
      " --  Loss: fcn_heatmap_loss  Related Layer is : fcn_heatmap_loss\n",
      "    >> Add add loss for  Tensor(\"fcn_heatmap_loss/Mean_1:0\", shape=(), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding loss_functions passed to compile() : \n",
      " ------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " --------------------\n",
      "      0    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      " Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      " ---------------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      " Compile \n",
      " --------\n",
      " Length of Keras_Model.outputs: 2\n",
      "\n",
      " Add Metrics for losses :\n",
      " -------------------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_heatmap_loss  Related Layer is : fcn_heatmap_loss\n",
      "    >> Add metric  fcn_heatmap_loss  with metric tensor:  fcn_heatmap_loss/Mean_1:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names :\n",
      " --------------------------\n",
      "      0    loss\n",
      "      1    fcn_heatmap_loss\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      " ----------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " ---------------------\n",
      "      0    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      "\n",
      " Post-compile out_labels from get_deduped_metrics_names() : \n",
      " ---------------------------------------------------------- \n",
      "     - loss\n",
      "     - fcn_heatmap_loss\n",
      "\n",
      " Post-compile Callback metrics monitored by progbar :\n",
      " ----------------------------------------------------\n",
      "     - loss\n",
      "     - fcn_heatmap_loss\n",
      "     - val_loss\n",
      "     - val_fcn_heatmap_loss\n",
      "\n",
      " Post-compile Keras metric_names :\n",
      " ---------------------------------\n",
      "      0    loss\n",
      "      1    fcn_heatmap_loss\n",
      "\n",
      " Post-compile Keras stateful_metric_names :\n",
      " ------------------------------------------\n",
      " \n",
      "Training Start Parameters:\n",
      "--------------------------\n",
      "Starting at epoch     0 of 2 epochs.\n",
      "Steps per epochs      32 \n",
      "Last epoch completed  0 \n",
      "Batch size            1 \n",
      "Learning Rate         1e-05 \n",
      "Momentum              0.9 \n",
      "Weight Decay:         0.0002 \n",
      "VALIDATION_STEPS      8 \n",
      "REDUCE_LR_FACTOR      0.5 \n",
      "REDUCE_LR_COOLDOWN    5 \n",
      "REDUCE_LR_PATIENCE    5 \n",
      "MIN_LR                1e-10 \n",
      "EARLY_STOP_PATIENCE   15 \n",
      "Checkpoint Path:      /home/kbardool/models/train_fcn8_coco/fcn20181031T1647/fcn_{epoch:04d}.h5 \n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      " 7/32 [=====>........................] - ETA: 1:21 - loss: 9.3628e-05 - fcn_heatmap_loss: 9.3628e-05failure on mrcnn predict - epoch 0 , image ids: [29731] \n",
      "Exception information:\n",
      "Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n",
      "\t [[Node: cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/DistributionShape/make_batch_of_event_sample_matrices/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/sub, cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/DistributionShape/make_batch_of_event_sample_matrices/concat)]]\n",
      "\t [[Node: cntxt_layer/pred_heatmap_norm/_4307 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_6385_cntxt_layer/pred_heatmap_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Caused by op 'cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/DistributionShape/make_batch_of_event_sample_matrices/Reshape', defined at:\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-158cdb7a6120>\", line 4, in <module>\n",
      "    mrcnn_model,mrcnn_config = mrcnn_coco_train(mode = 'trainfcn', mrcnn_config = mrcnn_config)\n",
      "  File \"../mrcnn/prep_notebook.py\", line 137, in mrcnn_coco_train\n",
      "    mrcnn_model = mrcnn_modellib.MaskRCNN(mode=mode, config=mrcnn_config)\n",
      "  File \"../mrcnn/model_mrcnn.py\", line 117, in __init__\n",
      "    self.keras_model = self.build(mode=mode, config=config)\n",
      "  File \"../mrcnn/model_mrcnn.py\", line 359, in build\n",
      "    =  CHMLayer(config, name = 'cntxt_layer' ) ([mrcnn_class, mrcnn_bbox, output_rois])\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n",
      "    output = self.call(inputs, **kwargs)\n",
      "  File \"../mrcnn/chm_layer.py\", line 511, in call\n",
      "    pr_hm_norm, pr_hm_scores  = build_heatmap(pred_tensor, self.config, names = ['pred_heatmap'])\n",
      "  File \"../mrcnn/chm_layer.py\", line 291, in build_heatmap\n",
      "    prob_grid = mvn.prob(pos_grid)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/distribution.py\", line 764, in prob\n",
      "    return self._call_prob(value, name)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/distribution.py\", line 746, in _call_prob\n",
      "    return self._prob(value, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/util.py\", line 1330, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py\", line 214, in _prob\n",
      "    return super(MultivariateNormalLinearOperator, self)._prob(x)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\", line 444, in _prob\n",
      "    x = self.bijector.inverse(y)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\", line 653, in inverse\n",
      "    return self._call_inverse(y, name)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\", line 632, in _call_inverse\n",
      "    mapping = mapping.merge(x=self._inverse(y, **kwargs))\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py\", line 209, in _inverse\n",
      "    x, expand_batch_dim=False)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/contrib/distributions/python/ops/shape.py\", line 398, in make_batch_of_event_sample_matrices\n",
      "    x = array_ops.reshape(x, shape=new_shape)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6113, in reshape\n",
      "    \"Reshape\", tensor=tensor, shape=shape, name=name)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n",
      "\t [[Node: cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/DistributionShape/make_batch_of_event_sample_matrices/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/sub, cntxt_layer/MultivariateNormalDiag_3/prob/affine_linear_operator/inverse/DistributionShape/make_batch_of_event_sample_matrices/concat)]]\n",
      "\t [[Node: cntxt_layer/pred_heatmap_norm/_4307 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_6385_cntxt_layer/pred_heatmap_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/32 [======>.......................] - ETA: 1:12 - loss: 9.7756e-05 - fcn_heatmap_loss: 9.7756e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/anaconda3/envs/TFG/lib/python3.5/site-packages/scipy/ndimage/interpolation.py:616: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 2s - loss: 9.6426e-05 - fcn_heatmap_loss: 9.6426e-05    len(val_batch_sizes): 8  len(val_outs_per_batch): 8\n",
      "    val_batch_sizes     :  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "    val_outs_per_batch - shape : (8, 2)\n",
      "        batch:  0    [6.523567e-05, 6.523567e-05]\n",
      "        batch:  1    [0.00013274401, 0.00013274401]\n",
      "        batch:  2    [0.00019663242, 0.00019663242]\n",
      "        batch:  3    [3.7198046e-05, 3.7198046e-05]\n",
      "        batch:  4    [6.409755e-05, 6.409755e-05]\n",
      "        batch:  5    [5.188294e-05, 5.188294e-05]\n",
      "        batch:  6    [4.3492804e-05, 4.3492804e-05]\n",
      "        batch:  7    [5.7984664e-05, 5.7984664e-05]\n",
      "val_averages : [8.115851278489572e-05, 8.115851278489572e-05]\n",
      "32/32 [==============================] - 86s 3s/step - loss: 9.6369e-05 - fcn_heatmap_loss: 9.6369e-05 - val_loss: 8.1159e-05 - val_fcn_heatmap_loss: 8.1159e-05\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.0000812, saving model to /home/kbardool/models/train_fcn8_coco/fcn20181031T1647/fcn_0001.h5\n",
      "Epoch 2/2\n",
      "31/32 [============================>.] - ETA: 1s - loss: 1.2710e-04 - fcn_heatmap_loss: 1.2710e-04    len(val_batch_sizes): 8  len(val_outs_per_batch): 8\n",
      "    val_batch_sizes     :  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "    val_outs_per_batch - shape : (8, 2)\n",
      "        batch:  0    [0.00017297259, 0.00017297259]\n",
      "        batch:  1    [0.00012016448, 0.00012016448]\n",
      "        batch:  2    [0.00022886808, 0.00022886808]\n",
      "        batch:  3    [2.2509123e-05, 2.2509123e-05]\n",
      "        batch:  4    [0.00022467306, 0.00022467306]\n",
      "        batch:  5    [0.00041690285, 0.00041690285]\n",
      "        batch:  6    [0.00011406197, 0.00011406197]\n",
      "        batch:  7    [0.00011884388, 0.00011884388]\n",
      "val_averages : [0.0001773745045738906, 0.0001773745045738906]\n",
      "32/32 [==============================] - 78s 2s/step - loss: 1.3188e-04 - fcn_heatmap_loss: 1.3188e-04 - val_loss: 1.7737e-04 - val_fcn_heatmap_loss: 1.7737e-04\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.0000812\n",
      "Final : self.epoch 2   epochs 2\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = args.fcn_layers\n",
    "loss_names   = ['fcn_heatmap_loss']\n",
    "fcn_model.epoch                  = fcn_config.LAST_EPOCH_RAN\n",
    "\n",
    "fcn_model.train_in_batches(\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            # learning_rate   = fcn_config.LEARNING_RATE,  \n",
    "            # epochs          = 25,                             # total number of epochs to run (accross multiple trainings)\n",
    "            # epochs_to_run   = fcn_config.EPOCHS_TO_RUN,\n",
    "            # batch_size      = fcn_config.BATCH_SIZE,          # gets value from self.config.BATCH_SIZE\n",
    "            # steps_per_epoch = fcn_config.STEPS_PER_EPOCH ,    # gets value form self.config.STEPS_PER_EPOCH\n",
    "            # min_LR          = fcn_config.MIN_LR\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `train_in_batches` development code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:49:50.082013Z",
     "start_time": "2018-07-09T15:49:49.100851Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_in_batches_dev(self,\n",
    "          mrcnn_model,\n",
    "          train_dataset, \n",
    "          val_dataset, \n",
    "          learning_rate, \n",
    "          layers            = None,\n",
    "          losses            = None,              \n",
    "          epochs            = 0,\n",
    "          epochs_to_run     = 1, \n",
    "          batch_size        = 0, \n",
    "          steps_per_epoch   = 0,\n",
    "          min_LR            = 0.00001):\n",
    "\n",
    "    '''\n",
    "    Train the model.\n",
    "    train_dataset, \n",
    "    val_dataset:    Training and validation Dataset objects.\n",
    "\n",
    "    learning_rate:  The learning rate to train with\n",
    "\n",
    "    epochs:         Number of training epochs. Note that previous training epochs\n",
    "                    are considered to be done already, so this actually determines\n",
    "                    the epochs to train in total rather than in this particaular\n",
    "                    call.\n",
    "\n",
    "    layers:         Allows selecting wich layers to train. It can be:\n",
    "                    - A regular expression to match layer names to train\n",
    "                    - One of these predefined values:\n",
    "                    heads: The RPN, classifier and mask heads of the network\n",
    "                    all: All the layers\n",
    "                    3+: Train Resnet stage 3 and up\n",
    "                    4+: Train Resnet stage 4 and up\n",
    "                    5+: Train Resnet stage 5 and up\n",
    "    '''\n",
    "    assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "\n",
    "    if batch_size == 0 :\n",
    "        batch_size = self.config.BATCH_SIZE\n",
    "\n",
    "    # if epochs_to_run > 0 :\n",
    "    epochs = self.epoch + epochs_to_run\n",
    "\n",
    "    if steps_per_epoch == 0:\n",
    "        steps_per_epoch = self.config.STEPS_PER_EPOCH\n",
    "\n",
    "    # use Pre-defined layer regular expressions\n",
    "    # if layers in self.layer_regex.keys():\n",
    "        # layers = self.layer_regex[layers]\n",
    "    print(layers)\n",
    "    # train_regex_list = []\n",
    "    # for x in layers:\n",
    "        # print( ' layers ias : ',x)\n",
    "        # train_regex_list.append(x)\n",
    "    train_regex_list = [self.layer_regex[x] for x in layers]\n",
    "    print(train_regex_list)\n",
    "    layers = '|'.join(train_regex_list)        \n",
    "    print('layers regex :', layers)\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Data generators\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    train_generator = data_generator(train_dataset, self.config, shuffle=True,\n",
    "                                     batch_size=batch_size)\n",
    "    val_generator   = data_generator(val_dataset, self.config, shuffle=True,\n",
    "                                     batch_size=batch_size,\n",
    "                                     augment=False)\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Set trainable layers and compile\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    self.set_trainable(layers)            \n",
    "    self.compile(learning_rate, self.config.LEARNING_MOMENTUM, losses)        \n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Create checkpoint folder if it doesn't exists\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    from tensorflow.python.platform import gfile\n",
    "    if not gfile.IsDirectory(self.log_dir):\n",
    "        log('Creating checkpoint folder : {}'.format(self.log_dir))\n",
    "        gfile.MakeDirs(self.log_dir)\n",
    "    else:\n",
    "        log('Checkpoint folder already exists: {}'.format(self.log_dir))                                   \n",
    "    # my_callback = MyCallback()\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Callbacks\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    # call back for model checkpoint was originally (?) loss. chanegd to val_loss (which is default) 2-5-18\n",
    "\n",
    "    # copied from \\keras\\engine\\training.py\n",
    "    # def _get_deduped_metrics_names(self):\n",
    "    ## get metrics from keras_model.metrics_names\n",
    "    out_labels = self.get_deduped_metrics_names()\n",
    "    print()\n",
    "    print(' out_labels from get_deduped_metrics_names() : ')\n",
    "    print(' --------------------------------------------- ')\n",
    "    print(out_labels)\n",
    "\n",
    "    ## setup Progress Bar callback\n",
    "    callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "    print()\n",
    "    print(' Callback metrics monitored by progbar :')\n",
    "    print(' ---------------------------------------')\n",
    "    pp.pprint(callback_metrics)\n",
    "\n",
    "    # progbar = keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "    # progbar.set_model(self.keras_model)\n",
    "    # progbar.set_params({\n",
    "        # 'epochs': epochs,\n",
    "        # 'steps': steps_per_epoch,\n",
    "        # 'verbose': 1,\n",
    "        # 'do_validation': False,\n",
    "        # 'metrics': callback_metrics,\n",
    "    # })\n",
    "\n",
    "\n",
    "    # progbar.set_model(self.keras_model) \n",
    "\n",
    "    ## setup Checkpoint callback\n",
    "    # chkpoint = keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                               # monitor='val_loss', \n",
    "                                               # verbose=1, \n",
    "                                               # save_best_only = True, \n",
    "                                               # save_weights_only=True)\n",
    "    # chkpoint.set_model(self.keras_model)\n",
    "\n",
    "    # progbar.on_train_begin()\n",
    "\n",
    "\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ProgbarLogger(count_mode='steps'),\n",
    "\n",
    "        keras.callbacks.TensorBoard(log_dir=self.log_dir,\n",
    "                                      histogram_freq=0,\n",
    "                                      batch_size=32,\n",
    "                                      write_graph=True,\n",
    "                                      write_grads=False,\n",
    "                                      write_images=True,\n",
    "                                      embeddings_freq=0,\n",
    "                                      embeddings_layer_names=None,\n",
    "                                      embeddings_metadata=None)\n",
    "\n",
    "        , keras.callbacks.ModelCheckpoint(self.checkpoint_path, \n",
    "                                          mode = 'auto', \n",
    "                                          period = 1, \n",
    "                                          monitor='val_loss', \n",
    "                                          verbose=1, \n",
    "                                          save_best_only = True, \n",
    "                                          save_weights_only=True)\n",
    "\n",
    "        , keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            mode     = 'auto', \n",
    "                                            factor   = self.config.REDUCE_LR_FACTOR,   \n",
    "                                            cooldown = self.config.REDUCE_LR_COOLDOWN,\n",
    "                                            patience = self.config.REDUCE_LR_PATIENCE,\n",
    "                                            min_lr   = self.config.MIN_LR, \n",
    "                                            verbose  = 1)                                            \n",
    "\n",
    "        , keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                            mode      = 'auto', \n",
    "                                            min_delta = 0.00001, \n",
    "                                            patience  = self.config.EARLY_STOP_PATIENCE, \n",
    "                                            verbose   = 1)                                            \n",
    "        # , my_callback\n",
    "    ]\n",
    "\n",
    "\n",
    "    callbacks =  keras.callbacks.CallbackList(callbacks = callbacks_list)\n",
    "    callbacks.set_model(self.keras_model)\n",
    "    callbacks.set_params({\n",
    "        'epochs': epochs,\n",
    "        'steps': steps_per_epoch,\n",
    "        'verbose': 1,\n",
    "        'do_validation': False,\n",
    "        'metrics': callback_metrics,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    log(\"Starting at epoch {} of {} epochs. LR={}\\n\".format(self.epoch, epochs, learning_rate))\n",
    "    log(\"Steps per epochs {} \".format(steps_per_epoch))\n",
    "    log(\"    Last epoch completed : {} \".format(self.epoch))\n",
    "    log(\"    Starting from epoch  : {} for {} epochs\".format(self.epoch, epochs_to_run))\n",
    "    log(\"    Learning Rate        : {} \".format(learning_rate))\n",
    "    log(\"    Steps per epoch      : {} \".format(steps_per_epoch))\n",
    "    log(\"    Batch Size           : {} \".format(batch_size))\n",
    "    log(\"    Checkpoint Folder    : {} \".format(self.checkpoint_path))\n",
    "\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## Start main training loop\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    epoch_idx = self.epoch\n",
    "    # progbar.on_train_begin()\n",
    "    callbacks.on_train_begin()\n",
    "\n",
    "    if epoch_idx >= epochs:\n",
    "        print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "    else:\n",
    "\n",
    "        while epoch_idx < epochs :\n",
    "            # progbar.on_epoch_begin(epoch_idx)\n",
    "            callbacks.on_epoch_begin(epoch_idx)\n",
    "\n",
    "            for steps_index in range(steps_per_epoch):\n",
    "\n",
    "                batch_logs = {}\n",
    "                print(' self.epoch {}   epochs {}  step {} '.format(self.epoch, epochs, steps_index))\n",
    "                batch_logs['batch'] = steps_index\n",
    "                batch_logs['size']  = batch_size\n",
    "                # progbar.on_batch_begin(steps_index, batch_logs)\n",
    "                callbacks.on_batch_begin(steps_index, batch_logs)\n",
    "\n",
    "                train_batch_x, train_batch_y = next(train_generator)\n",
    "                # print('length of train_batch_x:', len(train_batch_x))\n",
    "                # print('length of train_batch_y:', len(train_batch_y))\n",
    "\n",
    "\n",
    "                # # model_output   = get_layer_output_2(mrcnn_model.keras_model, train_batch_x, training_flag = False)\n",
    "                # # model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "                # print(len(model_output))\n",
    "                # # print(type(output_rois))\n",
    "                # for i in model_output:\n",
    "                    # print( i.shape)                    \n",
    "\n",
    "                results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "#                 print('# of items in results:', len(results))\n",
    "\n",
    "\n",
    "                pr_hm_norm, gt_hm_norm, pr_hm_scores, gt_hm_scores = results[11:]                 \n",
    "\n",
    "                # print('pr_hm_norm shape   :', pr_hm_norm.shape)\n",
    "                # print('pr_hm_scores shape :', pr_hm_scores.shape)\n",
    "                # print('gt_hm_norm shape   :', gt_hm_norm.shape)\n",
    "                # print('gt_hm_scores shape :', gt_hm_scores.shape)\n",
    "\n",
    "                outs = self.keras_model.train_on_batch([pr_hm_norm,  pr_hm_scores,gt_hm_norm, gt_hm_scores], train_batch_y)\n",
    "\n",
    "#                 print(' outs: ', outs)\n",
    "                if not isinstance(outs, list):\n",
    "                    outs = [outs]\n",
    "                for l, o in zip(out_labels, outs):\n",
    "                    batch_logs[l] = o\n",
    "\n",
    "                # progbar.on_batch_end(steps_index, batch_logs)\n",
    "                callbacks.on_batch_end(steps_index, batch_logs)\n",
    "\n",
    "                # print(outs)\n",
    "\n",
    "            ## end of epoch operations     \n",
    "            ##-------------------------------\n",
    "            val_batch_x, val_batch_y = next(val_generator)\n",
    "            val_outs = self.keras_model.test_on_batch(X_val, Y_val)\n",
    "            # write_log(callback, val_names, logs, batch_no//10)\n",
    "            print(' validation logs output: ', val_outs)\n",
    "            if not isinstance(val_outs, list):\n",
    "                val_outs = [val_outs]\n",
    "            for l, o in zip(out_labels, outs):\n",
    "                batch_logs[l] = o\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # progbar.on_epoch_end(epoch_idx, {})\n",
    "            # if (epoch_idx % 10) == 0:\n",
    "            # chkpoint.on_epoch_end(epoch_idx  , batch_logs)\n",
    "            callbacks.on_epoch_end(epoch_idx, batch_logs)\n",
    "            epoch_idx += 1\n",
    "\n",
    "        ## end of all epochs operations\n",
    "        ##--------------------------------\n",
    "        # if epoch_idx != self.epoch:\n",
    "        # chkpoint.on_epoch_end(epoch_idx -1, batch_logs)\n",
    "        callbacks.on_train_end()\n",
    "        self.epoch = max(epoch_idx - 1, epochs)\n",
    "        print('Final : self.epoch {}   epochs {}'.format(self.epoch, epochs))\n",
    "\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## End main training loop\n",
    "    ##--------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `train_in_batches` step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:38:11.488298Z",
     "start_time": "2018-07-09T15:40:38.570Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(train_layers)\n",
    "# train_regex_list = []\n",
    "# for x in layers:\n",
    "    # print( ' layers ias : ',x)\n",
    "    # train_regex_list.append(x)\n",
    "train_regex_list = [fcn_model.layer_regex[x] for x in train_layers]\n",
    "print(train_regex_list)\n",
    "layers = '|'.join(train_regex_list)        \n",
    "print('layers regex :', layers)\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Set trainable layers and compile\n",
    "##--------------------------------------------------------------------------------\n",
    "fcn_model.set_trainable(layers)            \n",
    "fcn_model.compile(learning_rate, fcn_model.config.LEARNING_MOMENTUM, loss_names)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:13:22.946697Z",
     "start_time": "2018-07-09T15:13:22.906821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_labels = fcn_model.get_deduped_metrics_names()\n",
    "print()\n",
    "print(' out_labels from get_deduped_metrics_names() : ')\n",
    "print(' --------------------------------------------- ')\n",
    "print(out_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:27.449382Z",
     "start_time": "2018-07-09T15:09:27.396705Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------------\n",
    "## Data generators\n",
    "##--------------------------------------------------------------------------------\n",
    "train_generator = data_generator(dataset_train, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "val_generator   = data_generator(dataset_val, mrcnn_model.config, shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fcn_config.EPOCHS_TO_RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:30.828699Z",
     "start_time": "2018-07-09T15:09:30.786146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = fcn_model.epoch + epochs_to_run\n",
    "log(\"Starting at epoch {} of {} epochs. LR={}\\n\".format(fcn_model.epoch, epochs, learning_rate))\n",
    "log(\"Steps per epochs {} \".format(steps_per_epoch))\n",
    "log(\"    Last epoch completed : {} \".format(fcn_model.epoch))\n",
    "log(\"    Starting from epoch  : {} for {} epochs\".format(fcn_model.epoch, epochs_to_run))\n",
    "log(\"    Learning Rate        : {} \".format(learning_rate))\n",
    "log(\"    Steps per epoch      : {} \".format(steps_per_epoch))\n",
    "log(\"    Batch Size           : {} \".format(batch_size))\n",
    "log(\"    Checkpoint Folder    : {} \".format(fcn_model.checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:15:38.298611Z",
     "start_time": "2018-07-09T15:15:38.262121Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps_index = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:15:39.537649Z",
     "start_time": "2018-07-09T15:15:39.488679Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_logs = {}\n",
    "print(' self.epoch {}   epochs {}  step {} '.format(fcn_model.epoch, epochs, steps_index))\n",
    "batch_logs['batch'] = steps_index\n",
    "batch_logs['size']  = batch_size\n",
    "# progbar.on_batch_begin(steps_index, batch_logs)\n",
    "callbacks.on_batch_begin(steps_index, batch_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:35.323441Z",
     "start_time": "2018-07-09T15:09:35.225145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "for i in train_batch_x:\n",
    "    print( i.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:44.907473Z",
     "start_time": "2018-07-09T15:09:40.245616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = mrcnn_model.keras_model.predict(train_batch_x)\n",
    "print('# of items in results:', len(results))\n",
    "\n",
    "for i in results:\n",
    "    print( i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:09:49.417601Z",
     "start_time": "2018-07-09T15:09:49.377184Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pr_hm_norm, gt_hm_norm, pr_hm_scores, gt_hm_scores = results[11:]                 \n",
    "print(pr_hm_norm.shape)\n",
    "print(gt_hm_norm.shape)\n",
    "print(pr_hm_scores.shape)\n",
    "print(gt_hm_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:10:05.116891Z",
     "start_time": "2018-07-09T15:09:55.156786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outs = fcn_model.keras_model.train_on_batch([pr_hm_norm,  pr_hm_scores,gt_hm_norm, gt_hm_scores], train_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T15:13:32.839825Z",
     "start_time": "2018-07-09T15:13:32.787299Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(outs)\n",
    "print(' outs: ', outs)\n",
    "if not isinstance(outs, list):\n",
    "    outs = [outs]\n",
    "for l, o in zip(out_labels, outs):\n",
    "    batch_logs[l] = o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fcn_model.keras_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:17:32.353508Z",
     "start_time": "2018-05-20T18:17:32.121048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.keras_model.losses\n",
    "print(model.keras_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:25:16.962148Z",
     "start_time": "2018-05-20T18:25:16.737938Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
