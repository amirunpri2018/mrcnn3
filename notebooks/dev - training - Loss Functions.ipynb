{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Loss Fucntions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:18:19.669335Z",
     "start_time": "2018-05-28T16:17:48.084787Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string, parse_image_meta, apply_box_deltas_tf\n",
    "from mrcnn.visualize   import display_gt_bboxes, display_roi_proposals, plot_3d_heatmap, plot_gaussian2\n",
    "from mrcnn.visualize   import plot_bbox_heatmaps, plot_one_bbox_heatmap\n",
    "from mrcnn.visualize   import display_gt_bboxes, display_roi_proposals\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_oldshapes_dev, prep_oldshapes_train\n",
    "\n",
    "model_info = prep_oldshapes_train(init_with = 'last', FCN_layers = True, batch_sz = 16)\n",
    "model, dataset_train, dataset_val, train_generator, val_generator, config =  model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:18:19.976578Z",
     "start_time": "2018-05-28T16:18:19.671316Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:18:24.462535Z",
     "start_time": "2018-05-28T16:18:19.978496Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:18:24.730786Z",
     "start_time": "2018-05-28T16:18:24.465497Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.layer_info()\n",
    "# model.keras_model.outputs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:20:19.991556Z",
     "start_time": "2018-05-28T16:20:12.728981Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(model.keras_model, train_batch_x, [0,1,2,3,4,5,6,7], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:21:09.506144Z",
     "start_time": "2018-05-28T16:21:09.275763Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "\n",
    "rpn_class_logits          = model_output[0]          # layer:  0   shape: (16, 4092, 2)\n",
    "rpn_class                 = model_output[1]          # layer:  1   shape: (16, 4092, 2)\n",
    "rpn_bbox                  = model_output[2]          # layer:  2   shape: (16, 4092, 4)\n",
    "rpn_roi_proposals         = model_output[3]          # layer:  3   shape: (16, 2000, 4)\n",
    "output_rois               = model_output[4]          # layer:  4   shape: (16, 32, 4)\n",
    "target_class_ids          = model_output[5]          # layer:  5   shape: (16, 32)\n",
    "target_bbox_deltas        = model_output[6]          # layer:  6   shape: (16, 32, 4)\n",
    "roi_gt_boxes              = model_output[7]          # layer:  7   shape: (16, 32, 4)\n",
    "mrcnn_class_logits                 = model_output[8]          # layer:  8   shape: (16, 32, 4)\n",
    "mrcnn_class                 = model_output[9]          # layer:  9   shape: (16, 32, 4)\n",
    "mrcnn_bbox                = model_output[10]          # layer: 10   shape: (16, 32, 4, 4)\n",
    "rpn_class_loss            = model_output[11]          # layer: 11   shape: (1, 1)\n",
    "rpn_bbox_loss             = model_output[12]          # layer: 12   shape: (1, 1)\n",
    "mrcnn_class_loss          = model_output[13]          # layer: 13   shape: (1, 1)\n",
    "mrcnn_bbox_loss           = model_output[14]          # layer: 14   shape: (1, 1)\n",
    "pred_heatmap_norm         = model_output[15]          # layer: 15   shape: (16, 128, 128, 4)\n",
    "gt_heatmap_norm           = model_output[16]          # layer: 16   shape: (16, 128, 128, 4)\n",
    "pred_heatmap_scores       = model_output[17]          # layer: 17   shape: (16, 4, 32, 11)\n",
    "gt_heatmap_scores         = model_output[18]          # layer: 18   shape: (16, 4, 32, 11)\n",
    "pred_tensor               = model_output[19]          # layer: 19   shape: (16, 4, 32, 6)\n",
    "gt_tensor                 = model_output[20]          # layer: 20   shape: (16, 4, 32, 6)\n",
    "pred_heatmap              = model_output[21]          # layer: 21   shape: (16, 128, 128, 4)\n",
    "gt_heatmap                = model_output[22]          # layer: 22   shape: (16, 128, 128, 4)\n",
    "fcn_heatmap_norm          = model_output[23]          # layer: 23   shape: (16, 128, 128, 4)\n",
    "fcn_heatmap_scores        = model_output[24]          # layer: 24   shape: (16, 4, 32, 16)\n",
    "fcn_heatmap               = model_output[25]          # layer: 25   shape: (16, 128, 128, 4)\n",
    "fcn_norm_loss             = model_output[26]          # layer: 26   shape: (1, 1)\n",
    "\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:21:14.137758Z",
     "start_time": "2018-05-28T16:21:13.912364Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "input_gt_masks     = train_batch_x[6]\n",
    "print(' Input image shape is :', input_image.shape)\n",
    "h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Review values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  display Pred_Tensor, Pred_heatmap, mrcnn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T19:47:17.855571Z",
     "start_time": "2018-05-20T19:47:17.612926Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=120, suppress=True)\n",
    "img = 1\n",
    "print('input_gt_class_ids')\n",
    "print(input_gt_class_ids.shape)\n",
    "print(input_gt_class_ids)\n",
    "\n",
    "\n",
    "print('input_gt_bboxes')\n",
    "print(input_gt_bboxes.shape)\n",
    "print(input_gt_bboxes[img,:5]/[128,128,128,128])\n",
    "\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids)\n",
    "# print(input_gt_class_ids[0])\n",
    "\n",
    "print(' roi_gt_bboxes')\n",
    "print(roi_gt_boxes.shape)\n",
    "print(roi_gt_boxes[img, :20])\n",
    "\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "\n",
    "# print(' output_rois')\n",
    "# print(output_rois.shape)\n",
    "# print(output_rois[img,:15] * [128, 128,128,128])\n",
    "\n",
    "\n",
    "# print(' roi_gt_boxes')\n",
    "# print(roi_gt_boxes.shape)\n",
    "# print(roi_gt_boxes[img,:15] * [128, 128,128,128])\n",
    "\n",
    "# print(' Pred Heatmap Scores')\n",
    "# print(pred_heatmap_scores.dtype)\n",
    "# print(pred_heatmap_scores[img,:,:10])\n",
    "\n",
    "# print(' FCN Scores')\n",
    "# print(fcn_scores.dtype)\n",
    "# print(fcn_scores[img,:,:10, 4:])\n",
    "\n",
    "# img = 2\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:33:12.884723Z",
     "start_time": "2018-05-17T19:33:12.640572Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in range(5):\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T16:37:19.550437Z",
     "start_time": "2018-05-18T16:37:19.304787Z"
    },
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor shape is ', pred_tensor.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T15:40:10.515199Z",
     "start_time": "2018-05-19T15:40:10.270557Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "print('gt_tensor shape is ', gt_tensor.shape)\n",
    "img = 1\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_tensor[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_heatmap_scores` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T15:21:37.062061Z",
     "start_time": "2018-05-28T15:21:36.810727Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_score shape is ', pred_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_heatmap_scores` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T15:35:48.171025Z",
     "start_time": "2018-05-28T15:35:47.934656Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('gt_heatmap_score shape is ', gt_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `fcn_heatmap_scores` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T15:35:21.497354Z",
     "start_time": "2018-05-28T15:35:21.257017Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=4)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('fcn_heatmap_score shape is ', fcn_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(fcn_heatmap_scores[img,k,:,4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_heatmap_scores`  and `fcn_heatmap_scores` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T20:01:28.251086Z",
     "start_time": "2018-05-20T20:01:27.923729Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "\n",
    "img = 0\n",
    "for i in [1,2,3]:\n",
    "    for j in range(32):\n",
    "        print('Image ', img , '/ Class ',i,' ------------')\n",
    "\n",
    "        print(gt_heatmap_scores[img,i,j])\n",
    "        print(pred_heatmap_scores[img,i,j])\n",
    "        print(fcn_heatmap_scores[img,i,j,[0,1,2,3,4,5,11,12,13,14,15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:41:01.276701Z",
     "start_time": "2018-05-20T17:41:01.030033Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    \"\"\"Implements Smooth-L1 loss.\n",
    "    y_true and y_pred are typicallly: [N, 4], but could be any shape.\n",
    "    \"\"\"\n",
    "    diff = KB.abs(y_true - y_pred)\n",
    "    less_than_one = KB.cast(KB.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:41:03.447875Z",
     "start_time": "2018-05-20T17:41:03.156120Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------\n",
    "## setup input values\n",
    "input_target = tf.identity(gt_heatmap_scores)\n",
    "input_pred   = tf.identity(fcn_scores)\n",
    "# in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "sess = KB.get_session()\n",
    "config = model.config\n",
    "names = ['Dev']\n",
    "##--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "##-----------------------------------------------------------------------\n",
    "##  FCN loss\n",
    "##-----------------------------------------------------------------------    \n",
    "# def fcn_norm_loss_graph(input_target,  input_pred):\n",
    "with sess.as_default():\n",
    "    '''\n",
    "    Generate Loss based on Normalized score in PRED_HEATMAP_SCORES and FCN_HEATMAP_SCORES \n",
    "    \n",
    "    Inputs:            \n",
    "    gt_heatmap_scores   [batch, num_classes, num_rois, 11 ] --> column 9 contains normalized score.\n",
    "    pred_heatmap:       [batch, num_classes, num_rois, 16 ] --> column 14 contains normalized score\n",
    "    '''\n",
    "    pred_scores   = input_pred[...,14]\n",
    "    target_scores = input_target[...,9]\n",
    "    # Reshape for simplicity. Merge first two dimensions into one.\n",
    "    print('\\n>>> fcn_norm_loss_graph ' )\n",
    "    print('    target_scores shape :', target_scores.shape)\n",
    "    print('    pred_scores   shape :', pred_scores.shape)    \n",
    "\n",
    "    target_scores1 = KB.reshape(target_scores, (-1,1))\n",
    "    print('    target_scores1 shape :', target_scores1.get_shape(), KB.int_shape(target_scores1))        \n",
    "    pred_scores1   = KB.reshape(pred_scores  , (-1,1))\n",
    "    print('    pred_scores1  shape :', pred_scores1.get_shape())        \n",
    "\n",
    "#     # Compute binary cross entropy. If no positive ROIs, then return 0.\n",
    "#     # shape: [batch, roi, num_classes]\n",
    "#     # Smooth-L1 Loss\n",
    "    loss        = KB.switch(tf.size(target_scores1) > 0,\n",
    "                    smooth_l1_loss(y_true=target_scores1, y_pred=pred_scores1),\n",
    "                    tf.constant(0.0))\n",
    "    loss        = KB.mean(loss)\n",
    "    loss        = tf.reshape(loss, [1, 1], name = 'fcn_normalized_loss')\n",
    "    print('    loss type is :', type(loss))\n",
    "    return loss\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "###  Softmax Sparse Cross Entropy Ignoring Last Label -- Used in Keras FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T07:53:31.114036Z",
     "start_time": "2018-04-27T07:53:30.853311Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "\n",
    "y_pred = tf.placeholder(dtype=tf.float32, shape=(16,320,320,20))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(16,320,320,1))\n",
    "print(K.int_shape(y_pred), K.int_shape(y_true))\n",
    "y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "print(K.int_shape(y_pred))\n",
    "log_softmax = tf.nn.log_softmax(y_pred)\n",
    "print(K.int_shape(log_softmax)) \n",
    "\n",
    "y_true = K.flatten(y_true)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "y_true = K.one_hot(tf.to_int32(y_true), K.int_shape(y_pred)[-1]+1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "unpacked = tf.unstack(y_true, axis=-1)\n",
    "print(len(unpacked), unpacked[0].shape)\n",
    "\n",
    "y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "\n",
    "cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "print(K.int_shape(cross_entropy))\n",
    "\n",
    "cross_entropy_mean = K.mean(cross_entropy)\n",
    "print(K.int_shape(cross_entropy_mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import keras.backend as K\n",
    "# print(K.int_shape(bef_pos)[-1])\n",
    "# unpacked  = K.flatten(test)\n",
    "# unpacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate FCN bbox loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate FCN Norm loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate FCN bbox loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate FCN bbox loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:42:34.454067Z",
     "start_time": "2018-05-13T17:42:34.215432Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "target_bbox_deltas = gt_deltas \n",
    "from mrcnn.loss import smooth_l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:43:22.002655Z",
     "start_time": "2018-05-13T17:43:21.710880Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fcn_bbox_loss_graph(target_bbox_deltas, target_class_ids, fcn_bbox_deltas):\n",
    "    print('\\n>>> fcn_bbox_loss_graph ' )\n",
    "    print('    target_class_ids  :', target_class_ids.shape)\n",
    "    print('    fcn_bbox_deltas   :', fcn_bbox_deltas.shape)\n",
    "    print('    target_bbox_deltas    :', target_bbox_deltas.shape)    \n",
    "\n",
    "    ## Reshape to merge batch and roi dimensions for simplicity.\n",
    "    class_array   = KB.reshape(target_bbox_deltas[...,-2]  , (-1, 1))\n",
    "    tgt_bbox      = KB.reshape(target_bbox_deltas[...,:-2] , (-1, 4))\n",
    "    pred_bbox     = KB.reshape(fcn_bbox_deltas, (-1, 4))\n",
    "    print('    reshaped class_array            :', class_array.shape)\n",
    "    print('    reshaped pred_bbox size         :', pred_bbox.shape)\n",
    "    print('    reshaped target_bbox size       :', tgt_bbox.shape)    \n",
    "\n",
    "    ## Only positive ROIs contribute to the loss. And only the right \n",
    "    ## class_id of each ROI. Get their indicies.\n",
    "\n",
    "    pos_ix = tf.where(target_bbox_deltas[...,-2] > 0)\n",
    "\n",
    "    ## Gather the deltas (predicted and true) that contribute to loss\n",
    "\n",
    "    # IMPORTANT: THE :-2 IS TO PREVENT ADDITIONAL ELEMENTS FROM BEING COPIED\n",
    "    y_true = tf.gather_nd(target_bbox_deltas[...,:-2], pos_ix)\n",
    "    y_pred = tf.gather_nd(fcn_bbox_deltas, pos_ix)\n",
    "    # print(y_pred.eval(session=sess))\n",
    "    # print(tf.shape(y_pred).eval(session=sess), tf.shape(y_true).eval(session=sess))    \n",
    "    print('    y_true shape:', y_true.get_shape())\n",
    "    print('    y_pred shape:', y_pred.get_shape())\n",
    "\n",
    "\n",
    "    ## Smooth-L1 Loss\n",
    "    loss        = KB.switch(tf.size(y_true) > 0,\n",
    "                    smooth_l1_loss(y_true=y_true, y_pred=y_pred),\n",
    "                    tf.constant(0.0))\n",
    "    loss        = KB.mean(loss)\n",
    "    loss        = KB.reshape(loss, [1, 1])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:43:52.940228Z",
     "start_time": "2018-05-13T17:43:52.141105Z"
    }
   },
   "outputs": [],
   "source": [
    "loss  = fcn_bbox_loss_graph(target_bbox_deltas, target_class_ids, fcn_bbox_deltas)\n",
    "print(loss.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:35:30.372069Z",
     "start_time": "2018-05-13T17:35:30.118348Z"
    }
   },
   "outputs": [],
   "source": [
    "input_tgt_bbox_deltas = gt_deltas\n",
    "input_pred_bbox_deltas = fcn_bbox_deltas\n",
    "input_target_class_ids = target_class_ids\n",
    "print(input_target_class_ids.shape)\n",
    "print(input_target_class_ids)\n",
    "print(input_tgt_bbox_deltas.shape)\n",
    "# print(input_tgt_bbox_deltas[...,-2])\n",
    "print(input_tgt_bbox_deltas[0,1,0:10])\n",
    "class_array = input_tgt_bbox_deltas[...,-2]\n",
    "print('class array: ', class_array.shape )\n",
    "print(class_array[0] )\n",
    "print(input_tgt_bbox_deltas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:35:27.745834Z",
     "start_time": "2018-05-13T17:35:25.965Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "print('\\n>>> fcn_bbox_loss_graph ' )\n",
    "print('    target_class_ids  :', input_target_class_ids.shape)\n",
    "print('    fcn_bbox_deltas   :', input_pred_bbox_deltas.shape)\n",
    "print('    gt_bbox_deltas    :', input_tgt_bbox_deltas.shape)    \n",
    "# class_array = input_tgt_bbox_deltas[...,-2] \n",
    "print('    class-array       :', class_array.shape )\n",
    " \n",
    "cls_arr       = KB.reshape(input_tgt_bbox_deltas[...,-2]  , (-1, 1))\n",
    "tgt_bbox      = KB.reshape(input_tgt_bbox_deltas[...,:-2] , (-1, 4))\n",
    "pred_bbox     = KB.reshape(input_pred_bbox_deltas, (-1, 4))\n",
    "print('    reshaped class_array            :', cls_arr.shape)\n",
    "print('    reshaped pred_bbox size         :', pred_bbox.shape)\n",
    "print('    reshaped target_bbox size       :', tgt_bbox.shape)    \n",
    "print(cls_arr.eval(session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:19:10.902498Z",
     "start_time": "2018-05-13T17:19:09.320193Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pos_ix = tf.where(input_target_class_ids > 0)\n",
    "# print(pos_ix.eval(session=sess))\n",
    "# pos_roi_cls_ids = tf.gather_nd(input_target_class_ids, pos_ix)\n",
    "# print(pos_roi_cls_ids.eval(session=sess))\n",
    "# pos_roi_cls_ids = tf.expand_dims(pos_roi_cls_ids, axis = -1)\n",
    "# print(tf.shape(pos_roi_cls_ids).eval(session=sess))\n",
    "# ind = tf.concat([tf.to_int32(pos_ix), pos_roi_cls_ids], axis=-1)\n",
    "# print(ind.eval(session=sess))\n",
    "# tst_ix = tf.where(cls_arr > 0)\n",
    "# print(tst_ix.eval(session=sess))\n",
    "\n",
    "pos_ix = tf.where(input_tgt_bbox_deltas[...,-2] > 0)\n",
    "print(pos_ix.eval(session=sess))\n",
    "tgt_pos_cls_deltas = tf.gather_nd(input_tgt_bbox_deltas[...,:-2], pos_ix)\n",
    "print(tgt_pos_cls_deltas.eval(session=sess))\n",
    "pred_pos_cls_deltas = tf.gather_nd(input_pred_bbox_deltas, pos_ix)\n",
    "print(pred_pos_cls_deltas.eval(session=sess))\n",
    "print(tf.shape(pred_pos_cls_deltas).eval(session=sess), tf.shape(tgt_pos_cls_deltas).eval(session=sess))\n",
    "# pos_roi_cls_ids = tf.expand_dims(pos_roi_cls_ids, axis = -1)\n",
    "# print(tf.shape(pos_roi_cls_ids).eval(session=sess))\n",
    "# ind = tf.concat([tf.to_int32(pos_ix), pos_roi_cls_ids], axis=-1)\n",
    "# print(ind.eval(session=sess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T16:30:14.731033Z",
     "start_time": "2018-05-13T16:30:14.476883Z"
    }
   },
   "outputs": [],
   "source": [
    "print(input_pred_bbox_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:55:53.553054Z",
     "start_time": "2018-05-13T13:55:52.471176Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Reshape to merge batch and roi dimensions for simplicity.\n",
    "# tgt_class_ids = KB.reshape(target_class_ids, (-1,))\n",
    "pred_shape = KB.int_shape(pred_bbox_deltas)\n",
    "tgt_shape = KB.int_shape(tgt_bbox_deltas)\n",
    "print('    transposed fcn_bbox_deltas   :', pred_shape)\n",
    "print('    transposed gt_bbox_deltas    :', tgt_shape)    \n",
    "\n",
    "tgt_bbox      = KB.reshape(tgt_bbox_deltas, (tgt_shape[0],  -1))\n",
    "pred_bbox     = KB.reshape(pred_bbox_deltas   , (pred_shape[0] ,  -1))\n",
    "print('    pred_bbox size         :', pred_bbox.shape)\n",
    "print('    target_bbox size       :', tgt_bbox.shape)    \n",
    "\n",
    "# # Only positive ROIs contribute to the loss. And only\n",
    "# # the right class_id of each ROI. Get their indicies.\n",
    "print(target_class_ids)\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:,0] \n",
    "print(positive_roi_ix.eval(session=sess))\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval(session=sess))\n",
    "# indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "# # Gather the deltas (predicted and true) that contribute to loss\n",
    "# target_bbox = tf.gather(gt_bbox_deltas, positive_roi_ix)\n",
    "# pred_bbox   = tf.gather_nd(fcn_bbox_deltas, indices)\n",
    "# print('    pred_bbox size         :', pred_bbox.shape)\n",
    "# print('    target_bbox size       :', target_bbox.shape)    \n",
    "\n",
    "# # Smooth-L1 Loss\n",
    "# loss        = KB.switch(tf.size(target_bbox) > 0,\n",
    "                # smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                # tf.constant(0.0))\n",
    "loss        = KB.constant(0.0)                    \n",
    "loss        = KB.mean(loss)\n",
    "loss        = KB.reshape(loss, [1, 1])\n",
    "# return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T16:25:19.223533Z",
     "start_time": "2018-05-13T16:25:18.952315Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "target_class_ids   = model_output[5]\n",
    "target_bbox        = model_output[6]\n",
    "mrcnn_bbox          = model_output[10] \n",
    "\n",
    "# target_bbox      = layers_out[2][0:1]\n",
    "# mrcnn_class        = model_output[9]\n",
    "# mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(model_output[9],axis = -1)     # mrcnn_class_ids\n",
    "print('target_class_ids ', target_class_ids.shape)\n",
    "print(target_class_ids[0])\n",
    "print('target_bbox: ',target_bbox.shape)\n",
    "print(target_bbox[0])\n",
    "print('mrcnn_bbox : ',mrcnn_bbox.shape)\n",
    "print(mrcnn_bbox[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T16:25:24.033184Z",
     "start_time": "2018-05-13T16:25:23.774992Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "# print(' class with max probability', mrcnn_class_ids.shape)\n",
    "# print(mrcnn_class_ids)\n",
    "print('target_bboxes shape', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes shape',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T16:25:29.696341Z",
     "start_time": "2018-05-13T16:25:28.919326Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('target_class_ids shape: ', target_class_ids.shape)\n",
    "print(target_class_ids.eval(session=sess))\n",
    "\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bbox: ', target_bbox.shape)\n",
    "\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T16:27:05.501759Z",
     "start_time": "2018-05-13T16:27:03.793155Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# test_ix        = tf.where(target_class_ids > 0)\n",
    "# print('test_ix',test_ix.shape)\n",
    "# print(test_ix.eval(session=sess))\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print('postivie roi ix')\n",
    "print(positive_roi_ix.eval(session=sess))\n",
    "\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print('postivie roi class_ids')\n",
    "print(positive_roi_class_ids.eval(session=sess))\n",
    "\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print('indices for gathering from mrcnn_bbox')\n",
    "print(indices.eval(session=sess))\n",
    "\n",
    "\n",
    "target_bbox2 = tf.gather(target_bbox, positive_roi_ix)\n",
    "print('target bbox 2', tf.shape(target_bbox2).eval(session=sess))\n",
    "print(target_bbox2.eval(session=sess))\n",
    "\n",
    "pred_bbox2   = tf.gather_nd(pred_bbox, indices)\n",
    "print('pred_bbox 2 ', tf.shape(pred_bbox2).eval(session=sess))\n",
    "print(pred_bbox2.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T14:28:55.943369Z",
     "start_time": "2018-05-13T14:28:53.291675Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('tf.size ',tf.size(target_bbox2).eval(session=sess))\n",
    "\n",
    "diff = K.abs(target_bbox2 - pred_bbox2)\n",
    "print(diff.eval(session=sess))\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T19:56:22.310929Z",
     "start_time": "2018-04-26T19:56:13.583609Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]   # fcn_predictions \n",
    "target_masks        = layers_out[19][0:3]   # gt_gaussians\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print('   less_than_one     shape :', tf.shape(less_than_one).eval(), K.sum(less_than_one).eval())\n",
    "\n",
    "more_than_one = 1 - less_than_one\n",
    "print('   more_than_one     shape :', tf.shape(more_than_one).eval(), K.sum(more_than_one).eval())\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (more_than_one * (diff - 0.5))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:56:40.181058Z",
     "start_time": "2018-04-24T09:56:39.956461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 0\n",
    "fcn_out = layers_out[12][img]\n",
    "fcn_sum = np.sum(fcn_out, axis=(0,1))\n",
    "print(fcn_sum)\n",
    "for cls in range(4):\n",
    "    print('min :', np.min(fcn_out[:,:,cls]), 'max :', np.max(fcn_out[:,:,cls]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:55:21.917361Z",
     "start_time": "2018-04-23T20:55:21.676734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_batch_x[4][2])\n",
    "print(train_batch_x[5][2]/[128,128,128,128])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
