{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on NewShapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T18:58:00.672817Z",
     "start_time": "2018-07-01T18:57:13.885973Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " windows  Windows\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " Min Shapes Per Image:  1\n",
      " Max Shapes Per Image:  15\n",
      " Min Shapes Per Image:  1\n",
      " Max Shapes Per Image:  15\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\newshape_fcn\\shapes20180701T2057\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     C1 Shape: (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "     C2 Shape:  (?, 32, 32, 256) (?, 32, 32, 256)\n",
      "     C3 Shape:  (?, 16, 16, 512) (?, 16, 16, 512)\n",
      "     C4 Shape:  (?, 8, 8, 1024) (?, 8, 8, 1024)\n",
      "     C5 Shape:  (?, 4, 4, 2048) (?, 4, 4, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (2, 4092)\n",
      "     Deltas :  (2, 4092, 4)\n",
      "     Anchors:  (2, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (2, ?, ?) (2, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (2, ?, ?) (2, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (2, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (2, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 7)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 7)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 28)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 7, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 7) (None, 32, 7)\n",
      "     mrcnn_bbox.shape     : (?, 32, 7, 4) (None, 32, 7, 4)\n",
      "     output_rois.shape    : (2, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (2, ?) (None, 32)\n",
      "     gt_bboxes.shape      : (2, ?, ?) (None, 32, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 7)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 7, 4) (?, 32, 7, 4)\n",
      "    input_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (2, None, 4)\n",
      "    pred_array        (2, 32, 6)\n",
      "scatter_ind <class 'tensorflow.python.framework.ops.Tensor'> shape (2, 32, 3)\n",
      "    pred_scatter shape is  (2, 7, 32, 6)\n",
      "(2, 7, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "\n",
      "    num_rois           :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape :  (2, ?)\n",
      "    gt_bboxes.shape    :  (2, ?, 4)\n",
      "    gt_classes_exp shape  (2, ?, 1)\n",
      "    gt_scores_exp shape  (2, ?, 1)\n",
      "    gt_array shape : (2, 32, 7) (2, 32, 7)\n",
      "     gt_tensor final shape  :  (2, 7, 32, ?)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (2, 7, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (2, 7, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (2, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (2, 7, 128, 128) Keras tensor  False\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "    gauss L2 norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (2, 7, 32, 6)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (2, 7, 128, 128)\n",
      "    heatmap replicated      :  (2, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (448, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (448, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (2, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (2, 7, 32, ?)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (2, 7, 32)\n",
      "    dense shape  (?, ?)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (2, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (2, 7, 128, 128) Keras tensor  False\n",
      "    gauss L2 norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (2, 7, 32, ?)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (2, 7, 128, 128)\n",
      "    heatmap replicated      :  (2, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (448, 128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (448, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (2, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (2, 7) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (2, 7) Keras tensor  True\n",
      "     pred_heatmap_norm  :  (2, 128, 128, 7) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (2, 128, 128, 7) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (2, 128, 128, 7)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (2, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (2, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      " Keras Tensors?? \n",
      " output_rois : True\n",
      " pr_hm       : True\n",
      " gt_heatmap  : True\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      "[]\n",
      " ================================================================\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n",
      "MODEL_PATH        :  E:\\models\n",
      "COCO_MODEL_PATH   :  E:\\models\\mask_rcnn_coco.h5\n",
      "RESNET_MODEL_PATH :  E:\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "CHECKPOINT_DIR    :  E:\\models\\newshape_fcn\n",
      ">>> find_last checkpoint in :  E:\\models\\newshape_fcn\n",
      "Last Saved Model  :  ('E:\\\\models\\\\newshape_fcn\\\\shapes20180621T1554', None)\n",
      "-----------------------------------------------\n",
      " Load model with init parm:  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      " Eclude layers: \n",
      "None\n",
      "-----------------------------------------------\n",
      "Loading weights from  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      " List of all Layers  \n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      ">layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x00000278C7635EF0>\n",
      ">layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x00000278CAB31518>\n",
      ">layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x00000278CAB26AC8>\n",
      ">layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAB0E0B8>\n",
      ">layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x00000278CAB4CC50>\n",
      ">layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x00000278CAB68358>\n",
      ">layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAB73048>\n",
      ">layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAB8EF98>\n",
      ">layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x00000278CABA8630>\n",
      ">layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CABD00F0>\n",
      ">layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CABB8EB8>\n",
      ">layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x00000278CAC0FDD8>\n",
      ">layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAC2EAC8>\n",
      ">layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CAC5F9B0>\n",
      ">layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAC38EB8>\n",
      ">layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAC88F60>\n",
      ">layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x00000278CACAD588>\n",
      ">layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x00000278CACBAEF0>\n",
      ">layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CACBAF28>\n",
      ">layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CACF30B8>\n",
      ">layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x00000278CAD158D0>\n",
      ">layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAD4EF98>\n",
      ">layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAD41588>\n",
      ">layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x00000278CAD8C978>\n",
      ">layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CADA8828>\n",
      ">layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CADB62B0>\n",
      ">layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x00000278CADCED68>\n",
      ">layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x00000278CAE07208>\n",
      ">layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAE07128>\n",
      ">layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CADF6CC0>\n",
      ">layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x00000278CAE35CF8>\n",
      ">layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAE859B0>\n",
      ">layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAE7DEF0>\n",
      ">layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x00000278CAE95A20>\n",
      ">layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAED90F0>\n",
      ">layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAECAE10>\n",
      ">layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x00000278CAF13A20>\n",
      ">layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x00000278CAF3FAC8>\n",
      ">layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAF3F860>\n",
      ">layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAF33CC0>\n",
      ">layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x00000278CAF4EE48>\n",
      ">layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAF91EF0>\n",
      ">layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAF9FEF0>\n",
      ">layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x00000278CAFC48D0>\n",
      ">layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAFDB080>\n",
      ">layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CB037908>\n",
      ">layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB006668>\n",
      ">layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB061CF8>\n",
      ">layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x00000278CB048828>\n",
      ">layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x00000278CB07A898>\n",
      ">layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB07AEF0>\n",
      ">layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB0BEF60>\n",
      ">layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x00000278CB0E5D68>\n",
      ">layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB119E10>\n",
      ">layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB10E400>\n",
      ">layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x00000278CB159E10>\n",
      ">layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB172CF8>\n",
      ">layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB179F98>\n",
      ">layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x00000278CB199080>\n",
      ">layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x00000278CB1E8C50>\n",
      ">layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB1C1F60>\n",
      ">layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB211978>\n",
      ">layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x00000278CB201CC0>\n",
      ">layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB2512B0>\n",
      ">layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB245DA0>\n",
      ">layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x00000278CB25DA20>\n",
      ">layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB2A5198>\n",
      ">layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB295128>\n",
      ">layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x00000278CB2E0B38>\n",
      ">layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x00000278CB309BE0>\n",
      ">layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB309978>\n",
      ">layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB322630>\n",
      ">layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x00000278CB316C88>\n",
      ">layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC32AA90>\n",
      ">layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC336C88>\n",
      ">layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x00000278CC3759E8>\n",
      ">layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC39C278>\n",
      ">layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC385780>\n",
      ">layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x00000278CC3D2F98>\n",
      ">layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x00000278CC3F9DA0>\n",
      ">layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC3ED748>\n",
      ">layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC3F9C18>\n",
      ">layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x00000278CC412F28>\n",
      ">layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC43BC18>\n",
      ">layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC461128>\n",
      ">layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x00000278CC493E48>\n",
      ">layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC4B3B38>\n",
      ">layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CC4D79B0>\n",
      ">layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC4C0F28>\n",
      ">layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC54C748>\n",
      ">layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x00000278CC5589E8>\n",
      ">layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x00000278CC57B438>\n",
      ">layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC57B240>\n",
      ">layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC5696A0>\n",
      ">layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x00000278CC590BA8>\n",
      ">layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC5E8B38>\n",
      ">layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC5DFE80>\n",
      ">layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x00000278CC5F6160>\n",
      ">layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC644EB8>\n",
      ">layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC63B390>\n",
      ">layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x00000278CC678C50>\n",
      ">layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x00000278CC6A1CF8>\n",
      ">layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC6A1C88>\n",
      ">layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC6BB780>\n",
      ">layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x00000278CC6AECC0>\n",
      ">layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC6F2D68>\n",
      ">layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC7030B8>\n",
      ">layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x00000278CC73DB38>\n",
      ">layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC7653C8>\n",
      ">layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC75B2E8>\n",
      ">layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x00000278CC79BF28>\n",
      ">layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x00000278CC7C4E80>\n",
      ">layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC7C4F60>\n",
      ">layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC7F5400>\n",
      ">layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x00000278CC805F98>\n",
      ">layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC82C240>\n",
      ">layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC816748>\n",
      ">layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x00000278CC860F98>\n",
      ">layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC87DEB8>\n",
      ">layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC88AC18>\n",
      ">layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x00000278CC8A1FD0>\n",
      ">layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x00000278CC8D8D68>\n",
      ">layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC8D8CC0>\n",
      ">layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC8C9EF0>\n",
      ">layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x00000278CC6AE128>\n",
      ">layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC90A780>\n",
      ">layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC94F9B0>\n",
      ">layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x00000278CC967978>\n",
      ">layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC9B6F28>\n",
      ">layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC99EA90>\n",
      ">layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x00000278CC9E89E8>\n",
      ">layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x00000278CCA11A90>\n",
      ">layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCA11828>\n",
      ">layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCA2AB38>\n",
      ">layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x00000278CCA209E8>\n",
      ">layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCA60F60>\n",
      ">layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCA70EB8>\n",
      ">layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x00000278CCA87B70>\n",
      ">layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCAACB38>\n",
      ">layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCAD5978>\n",
      ">layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x00000278CCB07E10>\n",
      ">layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x00000278CCB329B0>\n",
      ">layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCB265C0>\n",
      ">layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCB32EF0>\n",
      ">layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x00000278C95B87B8>\n",
      ">layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCB8F1D0>\n",
      ">layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCB73C88>\n",
      ">layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x00000278CCBCBCC0>\n",
      ">layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCBF5D68>\n",
      ">layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CCC0F6A0>\n",
      ">layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCBEA470>\n",
      ">layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCC02D68>\n",
      ">layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x00000278CCC69B70>\n",
      ">layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x00000278CCC79F98>\n",
      ">layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCC79C50>\n",
      ">layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCCBCBE0>\n",
      ">layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x00000278CCCD0D68>\n",
      ">layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCD21DD8>\n",
      ">layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCD15EF0>\n",
      ">layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x00000278CCD2DF98>\n",
      ">layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCD756A0>\n",
      ">layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCD68F60>\n",
      ">layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x00000278CCDB0AC8>\n",
      ">layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x00000278CCDD9B70>\n",
      ">layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCDD9908>\n",
      ">layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCDF35F8>\n",
      ">layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x00000278CCDE7C50>\n",
      ">layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCE37390>\n",
      ">layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCE2AB38>\n",
      ">layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x00000278CCE769B0>\n",
      ">layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCE9D240>\n",
      ">layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCE87748>\n",
      ">layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x00000278CCED2F28>\n",
      ">layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x00000278CCEFCF98>\n",
      ">layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCEEC5C0>\n",
      ">layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCF14AC8>\n",
      ">layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCF14EB8>\n",
      ">layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x00000278CCEFCEB8>\n",
      ">layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCF62860>\n",
      ">layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCF626A0>\n",
      ">layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x00000278CCF3DE10>\n",
      ">layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCFAEF98>\n",
      ">layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFAECC0>\n",
      ">layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x00000278CCF98E10>\n",
      ">layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CD02B908>\n",
      ">layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFD7C50>\n",
      ">layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFBFEF0>\n",
      ">layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CD007E10>\n",
      ">layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x00000278CD08CBE0>\n",
      ">layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x00000278CD115E80>\n",
      ">layer 190 : name : rpn_class                                 type: <keras.layers.core.Lambda object at 0x00000278CD3983C8>\n",
      ">layer 191 : name : rpn_bbox                                  type: <keras.layers.core.Lambda object at 0x00000278CD34F6A0>\n",
      ">layer 192 : name : input_gt_boxes                            type: <keras.engine.topology.InputLayer object at 0x00000278CAB0E208>\n",
      ">layer 193 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x00000278CD180B70>\n",
      ">layer 194 : name : input_gt_class_ids                        type: <keras.engine.topology.InputLayer object at 0x00000278CAB0EBA8>\n",
      ">layer 195 : name : lambda_1                                  type: <keras.layers.core.Lambda object at 0x00000278CAB31C88>\n",
      ">layer 196 : name : proposal_targets                          type: <mrcnn.detect_tgt_layer_mod.DetectionTargetLayer_mod object at 0x00000278CD172470>\n",
      ">layer 197 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x00000278CDF241D0>\n",
      ">layer 198 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE09E668>\n",
      ">layer 199 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE015FD0>\n",
      ">layer 200 : name : activation_34                             type: <keras.layers.core.Activation object at 0x00000278CE0DF208>\n",
      ">layer 201 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE0DF6D8>\n",
      ">layer 202 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE145EB8>\n",
      ">layer 203 : name : activation_35                             type: <keras.layers.core.Activation object at 0x00000278CE153CF8>\n",
      ">layer 204 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x00000278CE1530B8>\n",
      ">layer 205 : name : time_distributed_1                        type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE176E10>\n",
      ">layer 206 : name : mrcnn_class_logits                        type: <keras.layers.core.Lambda object at 0x00000278CE16B940>\n",
      ">layer 207 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE1E1FD0>\n",
      ">layer 208 : name : time_distributed_2                        type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE16BF28>\n",
      ">layer 209 : name : reshape_1                                 type: <keras.layers.core.Reshape object at 0x00000278CE1E1F60>\n",
      ">layer 210 : name : input_image_meta                          type: <keras.engine.topology.InputLayer object at 0x00000278C95C8DA0>\n",
      ">layer 211 : name : rpn_class_logits                          type: <keras.layers.core.Lambda object at 0x00000278CD180B38>\n",
      ">layer 212 : name : mrcnn_class                               type: <keras.layers.core.Lambda object at 0x00000278CE1AFD30>\n",
      ">layer 213 : name : mrcnn_bbox_regression                     type: <keras.layers.core.Lambda object at 0x00000278CE216A58>\n",
      ">layer 214 : name : input_rpn_match                           type: <keras.engine.topology.InputLayer object at 0x00000278C95C8F60>\n",
      ">layer 215 : name : input_rpn_bbox                            type: <keras.engine.topology.InputLayer object at 0x00000278CAB0ECF8>\n",
      ">layer 216 : name : lambda_4                                  type: <keras.layers.core.Lambda object at 0x00000278CD37D470>\n",
      ">layer 217 : name : rpn_class_loss                            type: <keras.layers.core.Lambda object at 0x00000278CE209668>\n",
      ">layer 218 : name : rpn_bbox_loss                             type: <keras.layers.core.Lambda object at 0x00000278CFE15C50>\n",
      ">layer 219 : name : mrcnn_class_loss                          type: <keras.layers.core.Lambda object at 0x00000278CFDEC9B0>\n",
      ">layer 220 : name : mrcnn_bbox_loss                           type: <keras.layers.core.Lambda object at 0x00000278CFF8E2E8>\n",
      ">layer 221 : name : cntxt_layer                               type: <mrcnn.chm_layer.CHMLayer object at 0x00000278CE223FD0>\n",
      "----------------\n",
      " layers to load \n",
      "----------------\n",
      ">layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x00000278C7635EF0>\n",
      ">layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x00000278CAB31518>\n",
      ">layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x00000278CAB26AC8>\n",
      ">layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAB0E0B8>\n",
      ">layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x00000278CAB4CC50>\n",
      ">layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x00000278CAB68358>\n",
      ">layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAB73048>\n",
      ">layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAB8EF98>\n",
      ">layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x00000278CABA8630>\n",
      ">layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CABD00F0>\n",
      ">layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CABB8EB8>\n",
      ">layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x00000278CAC0FDD8>\n",
      ">layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAC2EAC8>\n",
      ">layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CAC5F9B0>\n",
      ">layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAC38EB8>\n",
      ">layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAC88F60>\n",
      ">layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x00000278CACAD588>\n",
      ">layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x00000278CACBAEF0>\n",
      ">layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CACBAF28>\n",
      ">layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CACF30B8>\n",
      ">layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x00000278CAD158D0>\n",
      ">layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAD4EF98>\n",
      ">layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAD41588>\n",
      ">layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x00000278CAD8C978>\n",
      ">layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CADA8828>\n",
      ">layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CADB62B0>\n",
      ">layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x00000278CADCED68>\n",
      ">layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x00000278CAE07208>\n",
      ">layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAE07128>\n",
      ">layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CADF6CC0>\n",
      ">layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x00000278CAE35CF8>\n",
      ">layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAE859B0>\n",
      ">layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAE7DEF0>\n",
      ">layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x00000278CAE95A20>\n",
      ">layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAED90F0>\n",
      ">layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAECAE10>\n",
      ">layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x00000278CAF13A20>\n",
      ">layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x00000278CAF3FAC8>\n",
      ">layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAF3F860>\n",
      ">layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAF33CC0>\n",
      ">layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x00000278CAF4EE48>\n",
      ">layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAF91EF0>\n",
      ">layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CAF9FEF0>\n",
      ">layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x00000278CAFC48D0>\n",
      ">layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CAFDB080>\n",
      ">layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CB037908>\n",
      ">layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB006668>\n",
      ">layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB061CF8>\n",
      ">layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x00000278CB048828>\n",
      ">layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x00000278CB07A898>\n",
      ">layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB07AEF0>\n",
      ">layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB0BEF60>\n",
      ">layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x00000278CB0E5D68>\n",
      ">layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB119E10>\n",
      ">layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB10E400>\n",
      ">layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x00000278CB159E10>\n",
      ">layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB172CF8>\n",
      ">layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB179F98>\n",
      ">layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x00000278CB199080>\n",
      ">layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x00000278CB1E8C50>\n",
      ">layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB1C1F60>\n",
      ">layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB211978>\n",
      ">layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x00000278CB201CC0>\n",
      ">layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB2512B0>\n",
      ">layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB245DA0>\n",
      ">layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x00000278CB25DA20>\n",
      ">layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB2A5198>\n",
      ">layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB295128>\n",
      ">layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x00000278CB2E0B38>\n",
      ">layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x00000278CB309BE0>\n",
      ">layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CB309978>\n",
      ">layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CB322630>\n",
      ">layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x00000278CB316C88>\n",
      ">layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC32AA90>\n",
      ">layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC336C88>\n",
      ">layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x00000278CC3759E8>\n",
      ">layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC39C278>\n",
      ">layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC385780>\n",
      ">layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x00000278CC3D2F98>\n",
      ">layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x00000278CC3F9DA0>\n",
      ">layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC3ED748>\n",
      ">layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC3F9C18>\n",
      ">layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x00000278CC412F28>\n",
      ">layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC43BC18>\n",
      ">layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC461128>\n",
      ">layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x00000278CC493E48>\n",
      ">layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC4B3B38>\n",
      ">layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CC4D79B0>\n",
      ">layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC4C0F28>\n",
      ">layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC54C748>\n",
      ">layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x00000278CC5589E8>\n",
      ">layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x00000278CC57B438>\n",
      ">layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC57B240>\n",
      ">layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC5696A0>\n",
      ">layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x00000278CC590BA8>\n",
      ">layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC5E8B38>\n",
      ">layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC5DFE80>\n",
      ">layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x00000278CC5F6160>\n",
      ">layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC644EB8>\n",
      ">layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC63B390>\n",
      ">layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x00000278CC678C50>\n",
      ">layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x00000278CC6A1CF8>\n",
      ">layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC6A1C88>\n",
      ">layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC6BB780>\n",
      ">layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x00000278CC6AECC0>\n",
      ">layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC6F2D68>\n",
      ">layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC7030B8>\n",
      ">layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x00000278CC73DB38>\n",
      ">layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC7653C8>\n",
      ">layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC75B2E8>\n",
      ">layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x00000278CC79BF28>\n",
      ">layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x00000278CC7C4E80>\n",
      ">layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC7C4F60>\n",
      ">layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC7F5400>\n",
      ">layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x00000278CC805F98>\n",
      ">layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC82C240>\n",
      ">layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC816748>\n",
      ">layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x00000278CC860F98>\n",
      ">layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC87DEB8>\n",
      ">layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC88AC18>\n",
      ">layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x00000278CC8A1FD0>\n",
      ">layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x00000278CC8D8D68>\n",
      ">layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC8D8CC0>\n",
      ">layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC8C9EF0>\n",
      ">layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x00000278CC6AE128>\n",
      ">layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC90A780>\n",
      ">layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC94F9B0>\n",
      ">layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x00000278CC967978>\n",
      ">layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CC9B6F28>\n",
      ">layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CC99EA90>\n",
      ">layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x00000278CC9E89E8>\n",
      ">layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x00000278CCA11A90>\n",
      ">layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCA11828>\n",
      ">layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCA2AB38>\n",
      ">layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x00000278CCA209E8>\n",
      ">layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCA60F60>\n",
      ">layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCA70EB8>\n",
      ">layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x00000278CCA87B70>\n",
      ">layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCAACB38>\n",
      ">layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCAD5978>\n",
      ">layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x00000278CCB07E10>\n",
      ">layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x00000278CCB329B0>\n",
      ">layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCB265C0>\n",
      ">layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCB32EF0>\n",
      ">layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x00000278C95B87B8>\n",
      ">layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCB8F1D0>\n",
      ">layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCB73C88>\n",
      ">layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x00000278CCBCBCC0>\n",
      ">layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCBF5D68>\n",
      ">layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000278CCC0F6A0>\n",
      ">layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCBEA470>\n",
      ">layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCC02D68>\n",
      ">layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x00000278CCC69B70>\n",
      ">layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x00000278CCC79F98>\n",
      ">layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCC79C50>\n",
      ">layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCCBCBE0>\n",
      ">layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x00000278CCCD0D68>\n",
      ">layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCD21DD8>\n",
      ">layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCD15EF0>\n",
      ">layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x00000278CCD2DF98>\n",
      ">layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCD756A0>\n",
      ">layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCD68F60>\n",
      ">layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x00000278CCDB0AC8>\n",
      ">layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x00000278CCDD9B70>\n",
      ">layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCDD9908>\n",
      ">layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCDF35F8>\n",
      ">layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x00000278CCDE7C50>\n",
      ">layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCE37390>\n",
      ">layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCE2AB38>\n",
      ">layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x00000278CCE769B0>\n",
      ">layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000278CCE9D240>\n",
      ">layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000278CCE87748>\n",
      ">layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x00000278CCED2F28>\n",
      ">layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x00000278CCEFCF98>\n",
      ">layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCEEC5C0>\n",
      ">layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCF14AC8>\n",
      ">layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCF14EB8>\n",
      ">layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x00000278CCEFCEB8>\n",
      ">layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCF62860>\n",
      ">layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCF626A0>\n",
      ">layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x00000278CCF3DE10>\n",
      ">layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x00000278CCFAEF98>\n",
      ">layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFAECC0>\n",
      ">layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x00000278CCF98E10>\n",
      ">layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CD02B908>\n",
      ">layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFD7C50>\n",
      ">layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CCFBFEF0>\n",
      ">layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x00000278CD007E10>\n",
      ">layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x00000278CD08CBE0>\n",
      ">layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x00000278CD115E80>\n",
      ">layer 190 : name : rpn_class                                 type: <keras.layers.core.Lambda object at 0x00000278CD3983C8>\n",
      ">layer 191 : name : rpn_bbox                                  type: <keras.layers.core.Lambda object at 0x00000278CD34F6A0>\n",
      ">layer 192 : name : input_gt_boxes                            type: <keras.engine.topology.InputLayer object at 0x00000278CAB0E208>\n",
      ">layer 193 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x00000278CD180B70>\n",
      ">layer 194 : name : input_gt_class_ids                        type: <keras.engine.topology.InputLayer object at 0x00000278CAB0EBA8>\n",
      ">layer 195 : name : lambda_1                                  type: <keras.layers.core.Lambda object at 0x00000278CAB31C88>\n",
      ">layer 196 : name : proposal_targets                          type: <mrcnn.detect_tgt_layer_mod.DetectionTargetLayer_mod object at 0x00000278CD172470>\n",
      ">layer 197 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x00000278CDF241D0>\n",
      ">layer 198 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE09E668>\n",
      ">layer 199 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE015FD0>\n",
      ">layer 200 : name : activation_34                             type: <keras.layers.core.Activation object at 0x00000278CE0DF208>\n",
      ">layer 201 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE0DF6D8>\n",
      ">layer 202 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE145EB8>\n",
      ">layer 203 : name : activation_35                             type: <keras.layers.core.Activation object at 0x00000278CE153CF8>\n",
      ">layer 204 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x00000278CE1530B8>\n",
      ">layer 205 : name : time_distributed_1                        type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE176E10>\n",
      ">layer 206 : name : mrcnn_class_logits                        type: <keras.layers.core.Lambda object at 0x00000278CE16B940>\n",
      ">layer 207 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE1E1FD0>\n",
      ">layer 208 : name : time_distributed_2                        type: <keras.layers.wrappers.TimeDistributed object at 0x00000278CE16BF28>\n",
      ">layer 209 : name : reshape_1                                 type: <keras.layers.core.Reshape object at 0x00000278CE1E1F60>\n",
      ">layer 210 : name : input_image_meta                          type: <keras.engine.topology.InputLayer object at 0x00000278C95C8DA0>\n",
      ">layer 211 : name : rpn_class_logits                          type: <keras.layers.core.Lambda object at 0x00000278CD180B38>\n",
      ">layer 212 : name : mrcnn_class                               type: <keras.layers.core.Lambda object at 0x00000278CE1AFD30>\n",
      ">layer 213 : name : mrcnn_bbox_regression                     type: <keras.layers.core.Lambda object at 0x00000278CE216A58>\n",
      ">layer 214 : name : input_rpn_match                           type: <keras.engine.topology.InputLayer object at 0x00000278C95C8F60>\n",
      ">layer 215 : name : input_rpn_bbox                            type: <keras.engine.topology.InputLayer object at 0x00000278CAB0ECF8>\n",
      ">layer 216 : name : lambda_4                                  type: <keras.layers.core.Lambda object at 0x00000278CD37D470>\n",
      ">layer 217 : name : rpn_class_loss                            type: <keras.layers.core.Lambda object at 0x00000278CE209668>\n",
      ">layer 218 : name : rpn_bbox_loss                             type: <keras.layers.core.Lambda object at 0x00000278CFE15C50>\n",
      ">layer 219 : name : mrcnn_class_loss                          type: <keras.layers.core.Lambda object at 0x00000278CFDEC9B0>\n",
      ">layer 220 : name : mrcnn_bbox_loss                           type: <keras.layers.core.Lambda object at 0x00000278CFF8E2E8>\n",
      ">layer 221 : name : cntxt_layer                               type: <mrcnn.chm_layer.CHMLayer object at 0x00000278CE223FD0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    load_weights: Log directory set to : E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 566 \n",
      "    Load weights complete :  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "Load weights complete E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_FOLDER              E:\\models\\newshape_fcn\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  300\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "FCN_LAYERS                     False\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-06\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.2\n",
      "REDUCE_LR_PATIENCE             40\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAINING_IMAGES                10000\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_IMAGES              2500\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.new_shapes as new_shapes\n",
    "from mrcnn.prep_notebook import prep_newshapes_train2\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------\n",
    "config                    = new_shapes.NewShapesConfig()\n",
    "config.FCN_LAYERS         = False\n",
    "config.BATCH_SIZE         = 2                                 # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU     = config.BATCH_SIZE                 # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH    = 2\n",
    "config.LEARNING_RATE      = 0.000001\n",
    "                          \n",
    "config.EPOCHS_TO_RUN      = 300\n",
    "config.FCN_INPUT_SHAPE    = config.IMAGE_SHAPE[0:2]\n",
    "config.LAST_EPOCH_RAN     = 0\n",
    "config.WEIGHT_DECAY       = 2.0e-4\n",
    "config.VALIDATION_STEPS   = 100\n",
    "config.REDUCE_LR_FACTOR   = 0.2\n",
    "config.REDUCE_LR_COOLDOWN = 30\n",
    "config.REDUCE_LR_PATIENCE = 40\n",
    "config.MIN_LR             = 1.0e-10\n",
    "config.TRAINING_IMAGES    = 10000\n",
    "config.VALIDATION_IMAGES  = 2500\n",
    "config.CHECKPOINT_FOLDER  = 'newshape_fcn' \n",
    "\n",
    "model_file  = 'E:\\\\Models\\\\newshape_mrcnn\\\\shapes20180621T1554\\\\mask_rcnn_shapes_0565.h5'\n",
    "\n",
    "model, dataset_train, dataset_val, train_generator, val_generator, config = \\\n",
    "    prep_newshapes_train2(init_with = model_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T21:31:30.164770Z",
     "start_time": "2018-06-30T21:31:28.644807Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T22:22:40.114294Z",
     "start_time": "2018-06-30T22:22:39.873936Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T17:28:07.818008Z",
     "start_time": "2018-05-09T17:28:07.603418Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n Outputs: ') \n",
    "pp.pprint(model.keras_model.outputs)\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.get_deduped_metrics_names())\n",
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training - FCN\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "    - #### Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T22:01:57.264894Z",
     "start_time": "2018-06-30T22:01:57.035482Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.MIN_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T18:39:35.098231Z",
     "start_time": "2018-07-01T18:38:33.203731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fcn']\n",
      "['(fcn\\\\_.*)']\n",
      "layers regex : (fcn\\_.*)\n",
      " 213  fcn_block1_conv1       (Conv2D              )   TRAIN \n",
      " 214  fcn_block1_conv2       (Conv2D              )   TRAIN \n",
      " 216  fcn_block2_conv1       (Conv2D              )   TRAIN \n",
      " 217  fcn_block2_conv2       (Conv2D              )   TRAIN \n",
      " 219  fcn_block3_conv1       (Conv2D              )   TRAIN \n",
      " 220  fcn_block3_conv2       (Conv2D              )   TRAIN \n",
      " 221  fcn_block3_conv3       (Conv2D              )   TRAIN \n",
      " 223  fcn_block4_conv1       (Conv2D              )   TRAIN \n",
      " 224  fcn_block4_conv2       (Conv2D              )   TRAIN \n",
      " 225  fcn_block4_conv3       (Conv2D              )   TRAIN \n",
      " 227  fcn_block5_conv1       (Conv2D              )   TRAIN \n",
      " 228  fcn_block5_conv2       (Conv2D              )   TRAIN \n",
      " 229  fcn_block5_conv3       (Conv2D              )   TRAIN \n",
      " 231  fcn_fc1                (Conv2D              )   TRAIN \n",
      " 233  fcn_fc2                (Conv2D              )   TRAIN \n",
      " 235  fcn_classify           (Conv2D              )   TRAIN \n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['fcn_norm_loss']\n",
      "    learning rate :  1e-06\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['fcn_norm_loss']\n",
      "    keras_model.losses           : [<tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>]\n",
      "    Loss: fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add add loss for  Tensor(\"fcn_norm_loss/fcn_norm_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Keras model.losses : \n",
      "[   <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]\n",
      "    keras_model._losses:\n",
      "[<tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]\n",
      "    keras_model._per_input_losses:\n",
      "{None: [<tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]}\n",
      "    Final list of keras_model.losses \n",
      "[   <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]\n",
      " Length of Keras_Model.outputs: 27\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add metric  fcn_norm_loss  with metric tensor:  fcn_norm_loss/fcn_norm_loss:0  to list of metrics ...\n",
      " Final Keras metric_names:\n",
      "['loss', 'fcn_norm_loss']\n",
      "\n",
      "Starting at epoch  0 of 300 epochs. LR=1e-06\n",
      "\n",
      "Steps per epochs   1 \n",
      "Batch size         2 \n",
      "Checkpoint Path:   E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_{epoch:04d}.h5 \n",
      "Weight Decay:      0.0002 \n",
      "VALIDATION_STEPS   100 \n",
      "REDUCE_LR_FACTOR   0.2 \n",
      "REDUCE_LR_COOLDOWN 30 \n",
      "REDUCE_LR_PATIENCE 40 \n",
      "MIN_LR             1e-10 \n",
      "================= CALLING FIT GENERATOR ==================\n",
      "@@@@@@@@@@@@@@ Get SGD updates: \n",
      " loss :  Tensor(\"loss/add_6:0\", shape=(1, 1), dtype=float32)\n",
      " params: \n",
      "[   <tf.Variable 'fcn_block1_conv1/kernel:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv1/bias:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv2/bias:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv1/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc1/kernel:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc1/bias:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc2/kernel:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc2/bias:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_classify/kernel:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_classify/bias:0' shape=(7,) dtype=float32_ref>]\n",
      "    params:  <tf.Variable 'fcn_block1_conv1/kernel:0' shape=(3, 3, 7, 64) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond/Merge:0\", shape=(3, 3, 7, 64), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable:0' shape=(3, 3, 7, 64) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv1/bias:0' shape=(64,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_1/Merge:0\", shape=(64,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_1:0' shape=(64,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_2/Merge:0\", shape=(3, 3, 64, 64), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_2:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_3/Merge:0\", shape=(64,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_3:0' shape=(64,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_4/Merge:0\", shape=(3, 3, 64, 128), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_4:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv1/bias:0' shape=(128,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_5/Merge:0\", shape=(128,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_5:0' shape=(128,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_6/Merge:0\", shape=(3, 3, 128, 128), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_6:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv2/bias:0' shape=(128,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_7/Merge:0\", shape=(128,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_7:0' shape=(128,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_8/Merge:0\", shape=(3, 3, 128, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_8:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv1/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_9/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_9:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_10/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_10:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv2/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_11/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_11:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_12/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_12:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv3/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_13/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_13:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_14/Merge:0\", shape=(3, 3, 256, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_14:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_15/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_15:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_16/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_16:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv2/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_17/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_17:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_18/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_18:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv3/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_19/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_19:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_20/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_20:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_21/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_21:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_22/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_22:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv2/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_23/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_23:0' shape=(512,) dtype=float32_ref>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    params:  <tf.Variable 'fcn_block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_24/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_24:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv3/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_25/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_25:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc1/kernel:0' shape=(7, 7, 512, 2048) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_26/Merge:0\", shape=(7, 7, 512, 2048), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_26:0' shape=(7, 7, 512, 2048) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc1/bias:0' shape=(2048,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_27/Merge:0\", shape=(2048,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_27:0' shape=(2048,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc2/kernel:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_28/Merge:0\", shape=(1, 1, 2048, 2048), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_28:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc2/bias:0' shape=(2048,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_29/Merge:0\", shape=(2048,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_29:0' shape=(2048,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_classify/kernel:0' shape=(1, 1, 2048, 7) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_30/Merge:0\", shape=(1, 1, 2048, 7), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_30:0' shape=(1, 1, 2048, 7) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_classify/bias:0' shape=(7,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_31/Merge:0\", shape=(7,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_31:0' shape=(7,) dtype=float32_ref>\n",
      "Epoch 1/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0218]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6022]]\n",
      " generic_utils.(332) values:  loss  - [[0.6022]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0218]]\n",
      " generic_utils.(332) values:  loss  - [[0.6022]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0218]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0222]]\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6022 - fcn_norm_loss: 0.0218 - val_loss: nan - val_fcn_norm_loss: 0.0222\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:408: RuntimeWarning: invalid value encountered in greater\n",
      "  if abs(avg) > 1e-3:\n",
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\callbacks.py:438: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\callbacks.py:940: RuntimeWarning: invalid value encountered in less\n",
      "  self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)\n",
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\callbacks.py:530: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0195]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0213]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0195 - val_loss: nan - val_fcn_norm_loss: 0.0213\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.02]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.02]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.02]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0223]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0200 - val_loss: nan - val_fcn_norm_loss: 0.0223\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0199]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0199]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0199]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0212]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0199 - val_loss: nan - val_fcn_norm_loss: 0.0212\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0176]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0176]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0176]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0215]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0176 - val_loss: nan - val_fcn_norm_loss: 0.0215\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0214]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0214]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0214]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0223]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0214 - val_loss: nan - val_fcn_norm_loss: 0.0223\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0195]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0211]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0195 - val_loss: nan - val_fcn_norm_loss: 0.0211\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0223]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0223]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0223]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0213]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0223 - val_loss: nan - val_fcn_norm_loss: 0.0213\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0175]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0175]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0175]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0212]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0175 - val_loss: nan - val_fcn_norm_loss: 0.0212\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0182]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0182]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0182]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0222]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0182 - val_loss: nan - val_fcn_norm_loss: 0.0222\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0173]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0173]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0173]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0215]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0173 - val_loss: nan - val_fcn_norm_loss: 0.0215\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0191]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0191]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0191]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0213]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0191 - val_loss: nan - val_fcn_norm_loss: 0.0213\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0121]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0215]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0121 - val_loss: nan - val_fcn_norm_loss: 0.0215\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0222]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0222]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0222]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0222]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0222 - val_loss: nan - val_fcn_norm_loss: 0.0222\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0188]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0188]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0188]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0214]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0188 - val_loss: nan - val_fcn_norm_loss: 0.0214\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0148]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0215]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0148 - val_loss: nan - val_fcn_norm_loss: 0.0215\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0174]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0213]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0174 - val_loss: nan - val_fcn_norm_loss: 0.0213\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0191]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0191]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0191]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0223]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0191 - val_loss: nan - val_fcn_norm_loss: 0.0223\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0202]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0202]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0202]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0222]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0202 - val_loss: nan - val_fcn_norm_loss: 0.0222\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/300\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  fcn_norm_loss   v: [[0.0187]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[nan]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0187]]\n",
      " generic_utils.(332) values:  loss  - [[nan]]\n",
      " generic_utils.(332) values:  fcn_norm_loss  - [[0.0187]]\n",
      " generic_utils.(332) values:  val_loss  - [[nan]]\n",
      " generic_utils.(332) values:  val_fcn_norm_loss  - [[0.0222]]\n",
      "1/1 [==============================] - 2s 2s/step - loss: nan - fcn_norm_loss: 0.0187 - val_loss: nan - val_fcn_norm_loss: 0.0222\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 00020: early stopping\n",
      "Final : self.epoch 300   epochs 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_layers = ['fcn']\n",
    "loss_names   = [\"fcn_norm_loss\"]\n",
    "# config.VALIDATION_STEPS= 125\n",
    "# config.EPOCHS_TO_RUN          = 100\n",
    "config.STEPS_PER_EPOCH        = 1\n",
    "         \n",
    "model.epoch = 0\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate = config.LEARNING_RATE, \n",
    "            epochs_to_run = config.EPOCHS_TO_RUN,\n",
    "#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\n",
    "            layers = train_layers,\n",
    "            losses = loss_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training mrcnn, fpn, rpn layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:03:17.350821Z",
     "start_time": "2018-07-01T19:01:11.931271Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrcnn', 'fpn', 'rpn']\n",
      "['(mrcnn\\\\_.*)', '(fpn\\\\_.*)', '(rpn\\\\_.*)']\n",
      "layers regex : (mrcnn\\_.*)|(fpn\\_.*)|(rpn\\_.*)\n",
      " 174  fpn_c5p5               (Conv2D              )   TRAIN \n",
      " 176  fpn_c4p4               (Conv2D              )   TRAIN \n",
      " 179  fpn_c3p3               (Conv2D              )   TRAIN \n",
      " 182  fpn_c2p2               (Conv2D              )   TRAIN \n",
      " 184  fpn_p5                 (Conv2D              )   TRAIN \n",
      " 185  fpn_p2                 (Conv2D              )   TRAIN \n",
      " 186  fpn_p3                 (Conv2D              )   TRAIN \n",
      " 187  fpn_p4                 (Conv2D              )   TRAIN \n",
      "       1  rpn_conv_shared        (Conv2D              )   TRAIN \n",
      "       2  rpn_class_raw          (Conv2D              )   TRAIN \n",
      "       4  rpn_bbox_pred          (Conv2D              )   TRAIN \n",
      " 198  mrcnn_class_conv1      (TimeDistributed     )   TRAIN \n",
      " 199  mrcnn_class_bn1        (TimeDistributed     )   TRAIN \n",
      " 201  mrcnn_class_conv2      (TimeDistributed     )   TRAIN \n",
      " 202  mrcnn_class_bn2        (TimeDistributed     )   TRAIN \n",
      " 207  mrcnn_bbox_fc          (TimeDistributed     )   TRAIN \n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    learning rate :  1e-06\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    keras_model.losses           : []\n",
      "    Loss: rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_class_loss/rpn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_bbox_loss/rpn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_class_loss/mrcnn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_bbox_loss/mrcnn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Keras model.losses : \n",
      "[   <tf.Tensor 'Mean_4:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_7:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_5:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_6:0' shape=(1, 1) dtype=float32>]\n",
      "    keras_model._losses:\n",
      "[   <tf.Tensor 'Mean_4:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_5:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_6:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_7:0' shape=(1, 1) dtype=float32>]\n",
      "    keras_model._per_input_losses:\n",
      "{   None: [   <tf.Tensor 'Mean_4:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_5:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_6:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_7:0' shape=(1, 1) dtype=float32>]}\n",
      "    Final list of keras_model.losses \n",
      "[   <tf.Tensor 'Mean_4:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_7:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_5:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_6:0' shape=(1, 1) dtype=float32>]\n",
      " Length of Keras_Model.outputs: 23\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add metric  rpn_class_loss  with metric tensor:  rpn_class_loss/rpn_class_loss:0  to list of metrics ...\n",
      "    Loss name : rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add metric  rpn_bbox_loss  with metric tensor:  rpn_bbox_loss/rpn_bbox_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add metric  mrcnn_class_loss  with metric tensor:  mrcnn_class_loss/mrcnn_class_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add metric  mrcnn_bbox_loss  with metric tensor:  mrcnn_bbox_loss/mrcnn_bbox_loss:0  to list of metrics ...\n",
      " Final Keras metric_names:\n",
      "['loss', 'rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "\n",
      "Starting at epoch  566 of 866 epochs. LR=1e-06\n",
      "\n",
      "Steps per epochs   8 \n",
      "Batch size         2 \n",
      "Checkpoint Path:   E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_{epoch:04d}.h5 \n",
      "Weight Decay:      0.0002 \n",
      "VALIDATION_STEPS   100 \n",
      "REDUCE_LR_FACTOR   0.2 \n",
      "REDUCE_LR_COOLDOWN 30 \n",
      "REDUCE_LR_PATIENCE 40 \n",
      "MIN_LR             1e-10 \n",
      "================= CALLING FIT GENERATOR ==================\n",
      "@@@@@@@@@@@@@@ Get SGD updates: \n",
      " loss :  Tensor(\"loss/add_3:0\", shape=(1, 1), dtype=float32)\n",
      " params: \n",
      "[   <tf.Variable 'fpn_c5p5/kernel:0' shape=(1, 1, 2048, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c5p5/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c4p4/kernel:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c4p4/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c3p3/kernel:0' shape=(1, 1, 512, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c3p3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c2p2/kernel:0' shape=(1, 1, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_c2p2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p5/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p5/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p4/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fpn_p4/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_conv_shared/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_conv_shared/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_class_raw/kernel:0' shape=(1, 1, 512, 6) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_class_raw/bias:0' shape=(6,) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_bbox_pred/kernel:0' shape=(1, 1, 512, 12) dtype=float32_ref>,\n",
      "    <tf.Variable 'rpn_bbox_pred/bias:0' shape=(12,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_conv1/kernel:0' shape=(7, 7, 256, 1024) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_conv1/bias:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_bn1/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_bn1/beta:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_conv2/kernel:0' shape=(1, 1, 1024, 1024) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_conv2/bias:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_bn2/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_class_bn2/beta:0' shape=(1024,) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_bbox_fc/kernel:0' shape=(1024, 28) dtype=float32_ref>,\n",
      "    <tf.Variable 'mrcnn_bbox_fc/bias:0' shape=(28,) dtype=float32_ref>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    params:  <tf.Variable 'fpn_c5p5/kernel:0' shape=(1, 1, 2048, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond/Merge:0\", shape=(1, 1, 2048, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable:0' shape=(1, 1, 2048, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c5p5/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_1/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_1:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c4p4/kernel:0' shape=(1, 1, 1024, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_2/Merge:0\", shape=(1, 1, 1024, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_2:0' shape=(1, 1, 1024, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c4p4/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_3/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_3:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c3p3/kernel:0' shape=(1, 1, 512, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_4/Merge:0\", shape=(1, 1, 512, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_4:0' shape=(1, 1, 512, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c3p3/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_5/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_5:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c2p2/kernel:0' shape=(1, 1, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_6/Merge:0\", shape=(1, 1, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_6:0' shape=(1, 1, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_c2p2/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_7/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_7:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p5/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_8/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_8:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p5/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_9/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_9:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_10/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_10:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p2/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_11/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_11:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_12/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_12:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p3/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_13/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_13:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p4/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_14/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_14:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fpn_p4/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_15/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_15:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_conv_shared/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_16/Merge:0\", shape=(3, 3, 256, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_16:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_conv_shared/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_17/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_17:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_class_raw/kernel:0' shape=(1, 1, 512, 6) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_18/Merge:0\", shape=(1, 1, 512, 6), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_18:0' shape=(1, 1, 512, 6) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_class_raw/bias:0' shape=(6,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_19/Merge:0\", shape=(6,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_19:0' shape=(6,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_bbox_pred/kernel:0' shape=(1, 1, 512, 12) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_20/Merge:0\", shape=(1, 1, 512, 12), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_20:0' shape=(1, 1, 512, 12) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'rpn_bbox_pred/bias:0' shape=(12,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_21/Merge:0\", shape=(12,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_21:0' shape=(12,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_conv1/kernel:0' shape=(7, 7, 256, 1024) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_22/Merge:0\", shape=(7, 7, 256, 1024), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_22:0' shape=(7, 7, 256, 1024) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_conv1/bias:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_23/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_23:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_bn1/gamma:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_24/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_24:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_bn1/beta:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_25/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_25:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_conv2/kernel:0' shape=(1, 1, 1024, 1024) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_26/Merge:0\", shape=(1, 1, 1024, 1024), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_26:0' shape=(1, 1, 1024, 1024) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_conv2/bias:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_27/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_27:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_bn2/gamma:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_28/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_28:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_class_bn2/beta:0' shape=(1024,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_29/Merge:0\", shape=(1024,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_29:0' shape=(1024,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_bbox_fc/kernel:0' shape=(1024, 28) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_30/Merge:0\", shape=(1024, 28), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_30:0' shape=(1024, 28) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'mrcnn_bbox_fc/bias:0' shape=(28,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_31/Merge:0\", shape=(28,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_31:0' shape=(28,) dtype=float32_ref>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1457]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0401]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1307]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5611]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2447]]\n",
      " generic_utils.(332) values:  loss  - [[0.5611]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0401]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2447]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1457]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1307]]\n",
      "1/8 [==>...........................] - ETA: 28s - loss: 0.5611 - rpn_class_loss: 0.0401 - rpn_bbox_loss: 0.2447 - mrcnn_class_loss: 0.1457 - mrcnn_bbox_loss: 0.1307callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0325]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0309]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0935]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4085]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2516]]\n",
      " generic_utils.(332) values:  loss  - [[0.4085]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0309]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2516]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0325]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0935]]\n",
      "2/8 [======>.......................] - ETA: 13s - loss: 0.4848 - rpn_class_loss: 0.0355 - rpn_bbox_loss: 0.2481 - mrcnn_class_loss: 0.0891 - mrcnn_bbox_loss: 0.1121callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0945]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0275]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0711]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4533]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2603]]\n",
      " generic_utils.(332) values:  loss  - [[0.4533]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0275]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2603]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0945]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0711]]\n",
      "3/8 [==========>...................] - ETA: 8s - loss: 0.4743 - rpn_class_loss: 0.0328 - rpn_bbox_loss: 0.2522 - mrcnn_class_loss: 0.0909 - mrcnn_bbox_loss: 0.0984 callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0754]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0464]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0654]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7402]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.553]]\n",
      " generic_utils.(332) values:  loss  - [[0.7402]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0464]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.553]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0754]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0654]]\n",
      "4/8 [==============>...............] - ETA: 5s - loss: 0.5408 - rpn_class_loss: 0.0362 - rpn_bbox_loss: 0.3274 - mrcnn_class_loss: 0.0870 - mrcnn_bbox_loss: 0.0902callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0116]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0045]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.045]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1807]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1196]]\n",
      " generic_utils.(332) values:  loss  - [[0.1807]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0045]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1196]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0116]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.045]]\n",
      "5/8 [=================>............] - ETA: 3s - loss: 0.4688 - rpn_class_loss: 0.0299 - rpn_bbox_loss: 0.2858 - mrcnn_class_loss: 0.0719 - mrcnn_bbox_loss: 0.0811callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0297]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0058]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0387]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2226]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1485]]\n",
      " generic_utils.(332) values:  loss  - [[0.2226]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0058]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1485]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0297]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0387]]\n",
      "6/8 [=====================>........] - ETA: 2s - loss: 0.4277 - rpn_class_loss: 0.0259 - rpn_bbox_loss: 0.2629 - mrcnn_class_loss: 0.0649 - mrcnn_bbox_loss: 0.0741callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0228]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0169]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0274]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2832]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2161]]\n",
      " generic_utils.(332) values:  loss  - [[0.2832]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0169]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2161]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0274]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4071 - rpn_class_loss: 0.0246 - rpn_bbox_loss: 0.2562 - mrcnn_class_loss: 0.0589 - mrcnn_bbox_loss: 0.0674callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.021]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.017]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0423]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2476]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1673]]\n",
      " generic_utils.(332) values:  loss  - [[0.2476]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.017]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1673]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.021]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0423]]\n",
      " generic_utils.(332) values:  loss  - [[0.3872]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0236]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2451]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0541]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0643]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1744]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.009]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0693]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0512]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0449]]\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3872 - rpn_class_loss: 0.0236 - rpn_bbox_loss: 0.2451 - mrcnn_class_loss: 0.0541 - mrcnn_bbox_loss: 0.0643 - val_loss: 0.1744 - val_rpn_class_loss: 0.0090 - val_rpn_bbox_loss: 0.0693 - val_mrcnn_class_loss: 0.0512 - val_mrcnn_bbox_loss: 0.0449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00567: val_loss improved from inf to 0.17444825, saving model to E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_0567.h5\n",
      "Epoch 568/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1759]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0195]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.067]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5092]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2468]]\n",
      " generic_utils.(332) values:  loss  - [[0.5092]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2468]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1759]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.067]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.5092 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2468 - mrcnn_class_loss: 0.1759 - mrcnn_bbox_loss: 0.0670callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0515]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0092]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0306]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1483]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.057]]\n",
      " generic_utils.(332) values:  loss  - [[0.1483]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0092]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.057]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0515]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0306]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.3288 - rpn_class_loss: 0.0144 - rpn_bbox_loss: 0.1519 - mrcnn_class_loss: 0.1137 - mrcnn_bbox_loss: 0.0488callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0398]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0053]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0813]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2963]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1698]]\n",
      " generic_utils.(332) values:  loss  - [[0.2963]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0053]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1698]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0398]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0813]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.3179 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.1579 - mrcnn_class_loss: 0.0891 - mrcnn_bbox_loss: 0.0597callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1403]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0246]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0522]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4677]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2507]]\n",
      " generic_utils.(332) values:  loss  - [[0.4677]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0246]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2507]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1403]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0522]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3554 - rpn_class_loss: 0.0146 - rpn_bbox_loss: 0.1811 - mrcnn_class_loss: 0.1019 - mrcnn_bbox_loss: 0.0578callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0824]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0139]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0626]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3845]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2256]]\n",
      " generic_utils.(332) values:  loss  - [[0.3845]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0139]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2256]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0824]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0626]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3612 - rpn_class_loss: 0.0145 - rpn_bbox_loss: 0.1900 - mrcnn_class_loss: 0.0980 - mrcnn_bbox_loss: 0.0588callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0212]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0181]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0559]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6284]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.5332]]\n",
      " generic_utils.(332) values:  loss  - [[0.6284]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0181]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.5332]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0212]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0559]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4057 - rpn_class_loss: 0.0151 - rpn_bbox_loss: 0.2472 - mrcnn_class_loss: 0.0852 - mrcnn_bbox_loss: 0.0583callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.005]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0109]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0398]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2936]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2379]]\n",
      " generic_utils.(332) values:  loss  - [[0.2936]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0109]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2379]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.005]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0398]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3897 - rpn_class_loss: 0.0145 - rpn_bbox_loss: 0.2459 - mrcnn_class_loss: 0.0737 - mrcnn_bbox_loss: 0.0556callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0453]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0096]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1079]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.494]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3311]]\n",
      " generic_utils.(332) values:  loss  - [[0.494]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0096]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3311]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0453]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1079]]\n",
      " generic_utils.(332) values:  loss  - [[0.4028]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0139]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2565]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0702]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0622]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1451]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.009]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0248]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.042]]\n",
      "8/8 [==============================] - 3s 408ms/step - loss: 0.4028 - rpn_class_loss: 0.0139 - rpn_bbox_loss: 0.2565 - mrcnn_class_loss: 0.0702 - mrcnn_bbox_loss: 0.0622 - val_loss: 0.1451 - val_rpn_class_loss: 0.0090 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0248 - val_mrcnn_bbox_loss: 0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00568: val_loss improved from 0.17444825 to 0.14511181, saving model to E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_0568.h5\n",
      "Epoch 569/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0179]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0106]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0276]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1894]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1333]]\n",
      " generic_utils.(332) values:  loss  - [[0.1894]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0106]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1333]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0179]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0276]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.1894 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.1333 - mrcnn_class_loss: 0.0179 - mrcnn_bbox_loss: 0.0276callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0628]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0126]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0179]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1965]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1033]]\n",
      " generic_utils.(332) values:  loss  - [[0.1965]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0126]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1033]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0628]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0179]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.1929 - rpn_class_loss: 0.0116 - rpn_bbox_loss: 0.1183 - mrcnn_class_loss: 0.0403 - mrcnn_bbox_loss: 0.0228callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0136]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0138]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0569]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2775]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1932]]\n",
      " generic_utils.(332) values:  loss  - [[0.2775]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0138]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1932]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0136]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0569]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.2211 - rpn_class_loss: 0.0123 - rpn_bbox_loss: 0.1432 - mrcnn_class_loss: 0.0314 - mrcnn_bbox_loss: 0.0341callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0215]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0334]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0748]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5662]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.4364]]\n",
      " generic_utils.(332) values:  loss  - [[0.5662]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0334]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.4364]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0215]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0748]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3074 - rpn_class_loss: 0.0176 - rpn_bbox_loss: 0.2165 - mrcnn_class_loss: 0.0289 - mrcnn_bbox_loss: 0.0443callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0496]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0267]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0511]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3446]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2171]]\n",
      " generic_utils.(332) values:  loss  - [[0.3446]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0267]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2171]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0496]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0511]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3148 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.2167 - mrcnn_class_loss: 0.0331 - mrcnn_bbox_loss: 0.0457callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0995]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0289]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1009]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6644]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.435]]\n",
      " generic_utils.(332) values:  loss  - [[0.6644]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0289]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.435]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0995]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1009]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3731 - rpn_class_loss: 0.0210 - rpn_bbox_loss: 0.2531 - mrcnn_class_loss: 0.0441 - mrcnn_bbox_loss: 0.0549callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0389]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0138]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0609]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4401]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3264]]\n",
      " generic_utils.(332) values:  loss  - [[0.4401]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0138]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3264]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0389]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0609]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3827 - rpn_class_loss: 0.0200 - rpn_bbox_loss: 0.2635 - mrcnn_class_loss: 0.0434 - mrcnn_bbox_loss: 0.0557callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0547]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0269]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0659]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4046]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2571]]\n",
      " generic_utils.(332) values:  loss  - [[0.4046]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0269]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2571]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0547]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0659]]\n",
      " generic_utils.(332) values:  loss  - [[0.3854]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0208]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2627]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0448]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.057]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1274]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0224]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0267]]\n",
      "8/8 [==============================] - 4s 442ms/step - loss: 0.3854 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2627 - mrcnn_class_loss: 0.0448 - mrcnn_bbox_loss: 0.0570 - val_loss: 0.1274 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0224 - val_mrcnn_bbox_loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00569: val_loss improved from 0.14511181 to 0.12744154, saving model to E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_0569.h5\n",
      "Epoch 570/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0343]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0296]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0573]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2185]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0972]]\n",
      " generic_utils.(332) values:  loss  - [[0.2185]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0296]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0972]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0343]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0573]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2185 - rpn_class_loss: 0.0296 - rpn_bbox_loss: 0.0972 - mrcnn_class_loss: 0.0343 - mrcnn_bbox_loss: 0.0573callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1478]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.03]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.2129]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7164]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3258]]\n",
      " generic_utils.(332) values:  loss  - [[0.7164]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.03]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3258]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1478]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.2129]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4674 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.2115 - mrcnn_class_loss: 0.0910 - mrcnn_bbox_loss: 0.1351callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1026]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0227]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.079]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3969]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1926]]\n",
      " generic_utils.(332) values:  loss  - [[0.3969]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0227]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1926]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1026]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.079]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.4439 - rpn_class_loss: 0.0274 - rpn_bbox_loss: 0.2052 - mrcnn_class_loss: 0.0949 - mrcnn_bbox_loss: 0.1164callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1672]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0437]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1074]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7034]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3851]]\n",
      " generic_utils.(332) values:  loss  - [[0.7034]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0437]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3851]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1672]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1074]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5088 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.2502 - mrcnn_class_loss: 0.1130 - mrcnn_bbox_loss: 0.1141callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.147]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0205]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0945]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4145]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1525]]\n",
      " generic_utils.(332) values:  loss  - [[0.4145]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0205]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1525]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.147]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0945]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4899 - rpn_class_loss: 0.0293 - rpn_bbox_loss: 0.2306 - mrcnn_class_loss: 0.1198 - mrcnn_bbox_loss: 0.1102callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0286]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.021]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0951]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.377]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2323]]\n",
      " generic_utils.(332) values:  loss  - [[0.377]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.021]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2323]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0286]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0951]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4711 - rpn_class_loss: 0.0279 - rpn_bbox_loss: 0.2309 - mrcnn_class_loss: 0.1046 - mrcnn_bbox_loss: 0.1077callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0977]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0234]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0805]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4967]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2951]]\n",
      " generic_utils.(332) values:  loss  - [[0.4967]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0234]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2951]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0977]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0805]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4747 - rpn_class_loss: 0.0273 - rpn_bbox_loss: 0.2401 - mrcnn_class_loss: 0.1036 - mrcnn_bbox_loss: 0.1038callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1899]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0303]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0886]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5216]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2127]]\n",
      " generic_utils.(332) values:  loss  - [[0.5216]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0303]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2127]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1899]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0886]]\n",
      " generic_utils.(332) values:  loss  - [[0.4806]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0276]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2367]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1144]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1019]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1138]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0166]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0188]]\n",
      "8/8 [==============================] - 4s 441ms/step - loss: 0.4806 - rpn_class_loss: 0.0276 - rpn_bbox_loss: 0.2367 - mrcnn_class_loss: 0.1144 - mrcnn_bbox_loss: 0.1019 - val_loss: 0.1138 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0166 - val_mrcnn_bbox_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00570: val_loss improved from 0.12744154 to 0.11381402, saving model to E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_0570.h5\n",
      "Epoch 571/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0231]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0121]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0759]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3264]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2152]]\n",
      " generic_utils.(332) values:  loss  - [[0.3264]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2152]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0231]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0759]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3264 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.2152 - mrcnn_class_loss: 0.0231 - mrcnn_bbox_loss: 0.0759callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0636]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0168]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0498]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.267]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1368]]\n",
      " generic_utils.(332) values:  loss  - [[0.267]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0168]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1368]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0636]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0498]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.2967 - rpn_class_loss: 0.0145 - rpn_bbox_loss: 0.1760 - mrcnn_class_loss: 0.0434 - mrcnn_bbox_loss: 0.0628callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0669]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0383]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.032]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3509]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2136]]\n",
      " generic_utils.(332) values:  loss  - [[0.3509]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0383]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2136]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0669]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.032]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.3147 - rpn_class_loss: 0.0224 - rpn_bbox_loss: 0.1886 - mrcnn_class_loss: 0.0512 - mrcnn_bbox_loss: 0.0526callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0765]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0112]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0387]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2816]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1552]]\n",
      " generic_utils.(332) values:  loss  - [[0.2816]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0112]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1552]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0765]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0387]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3065 - rpn_class_loss: 0.0196 - rpn_bbox_loss: 0.1802 - mrcnn_class_loss: 0.0576 - mrcnn_bbox_loss: 0.0491callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0355]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0069]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0208]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3875]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3243]]\n",
      " generic_utils.(332) values:  loss  - [[0.3875]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0069]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3243]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0355]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0208]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3227 - rpn_class_loss: 0.0171 - rpn_bbox_loss: 0.2090 - mrcnn_class_loss: 0.0531 - mrcnn_bbox_loss: 0.0434callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0541]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0193]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0802]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3595]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2059]]\n",
      " generic_utils.(332) values:  loss  - [[0.3595]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0193]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2059]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0541]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0802]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3288 - rpn_class_loss: 0.0174 - rpn_bbox_loss: 0.2085 - mrcnn_class_loss: 0.0533 - mrcnn_bbox_loss: 0.0496callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0931]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0547]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0441]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.323]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1312]]\n",
      " generic_utils.(332) values:  loss  - [[0.323]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0547]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1312]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0931]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0441]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - rpn_class_loss: 0.0228 - rpn_bbox_loss: 0.1975 - mrcnn_class_loss: 0.0590 - mrcnn_bbox_loss: 0.0488callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0396]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0233]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0526]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2928]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1773]]\n",
      " generic_utils.(332) values:  loss  - [[0.2928]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0233]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1773]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0396]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0526]]\n",
      " generic_utils.(332) values:  loss  - [[0.3236]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1949]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0566]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0493]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1573]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0429]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.036]]\n",
      "8/8 [==============================] - 4s 446ms/step - loss: 0.3236 - rpn_class_loss: 0.0228 - rpn_bbox_loss: 0.1949 - mrcnn_class_loss: 0.0566 - mrcnn_bbox_loss: 0.0493 - val_loss: 0.1573 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0429 - val_mrcnn_bbox_loss: 0.0360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00571: val_loss did not improve\n",
      "Epoch 572/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0766]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.049]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1341]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6669]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.4072]]\n",
      " generic_utils.(332) values:  loss  - [[0.6669]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.049]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.4072]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0766]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1341]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.6669 - rpn_class_loss: 0.0490 - rpn_bbox_loss: 0.4072 - mrcnn_class_loss: 0.0766 - mrcnn_bbox_loss: 0.1341callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0379]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0191]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0316]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2767]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1881]]\n",
      " generic_utils.(332) values:  loss  - [[0.2767]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0191]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1881]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0379]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0316]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4718 - rpn_class_loss: 0.0340 - rpn_bbox_loss: 0.2976 - mrcnn_class_loss: 0.0572 - mrcnn_bbox_loss: 0.0829callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2034]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0141]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0937]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5768]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2656]]\n",
      " generic_utils.(332) values:  loss  - [[0.5768]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0141]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2656]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2034]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0937]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.5068 - rpn_class_loss: 0.0274 - rpn_bbox_loss: 0.2870 - mrcnn_class_loss: 0.1059 - mrcnn_bbox_loss: 0.0865callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0177]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0113]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0604]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3519]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2625]]\n",
      " generic_utils.(332) values:  loss  - [[0.3519]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0113]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2625]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0177]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0604]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.4681 - rpn_class_loss: 0.0234 - rpn_bbox_loss: 0.2808 - mrcnn_class_loss: 0.0839 - mrcnn_bbox_loss: 0.0800callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0113]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0064]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0335]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.213]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1618]]\n",
      " generic_utils.(332) values:  loss  - [[0.213]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0064]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1618]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0113]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0335]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4171 - rpn_class_loss: 0.0200 - rpn_bbox_loss: 0.2570 - mrcnn_class_loss: 0.0694 - mrcnn_bbox_loss: 0.0707callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0441]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0179]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1105]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3432]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1708]]\n",
      " generic_utils.(332) values:  loss  - [[0.3432]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0179]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1708]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0441]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1105]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4048 - rpn_class_loss: 0.0196 - rpn_bbox_loss: 0.2427 - mrcnn_class_loss: 0.0652 - mrcnn_bbox_loss: 0.0773callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0422]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0274]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.117]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4669]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2803]]\n",
      " generic_utils.(332) values:  loss  - [[0.4669]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0274]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2803]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0422]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.117]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4136 - rpn_class_loss: 0.0207 - rpn_bbox_loss: 0.2480 - mrcnn_class_loss: 0.0619 - mrcnn_bbox_loss: 0.0830callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0032]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0011]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0233]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.0682]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0406]]\n",
      " generic_utils.(332) values:  loss  - [[0.0682]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0011]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0406]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0032]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0233]]\n",
      " generic_utils.(332) values:  loss  - [[0.3705]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0183]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2221]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0545]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0755]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.3229]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.2105]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.034]]\n",
      "8/8 [==============================] - 3s 436ms/step - loss: 0.3705 - rpn_class_loss: 0.0183 - rpn_bbox_loss: 0.2221 - mrcnn_class_loss: 0.0545 - mrcnn_bbox_loss: 0.0755 - val_loss: 0.3229 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.2105 - val_mrcnn_bbox_loss: 0.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00572: val_loss did not improve\n",
      "Epoch 573/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1064]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0229]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1013]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3744]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1437]]\n",
      " generic_utils.(332) values:  loss  - [[0.3744]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0229]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1437]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1064]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1013]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.3744 - rpn_class_loss: 0.0229 - rpn_bbox_loss: 0.1437 - mrcnn_class_loss: 0.1064 - mrcnn_bbox_loss: 0.1013callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.5406]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0399]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1262]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.974]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2673]]\n",
      " generic_utils.(332) values:  loss  - [[0.974]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0399]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2673]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.5406]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1262]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.6742 - rpn_class_loss: 0.0314 - rpn_bbox_loss: 0.2055 - mrcnn_class_loss: 0.3235 - mrcnn_bbox_loss: 0.1137callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0659]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0174]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1174]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5379]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3373]]\n",
      " generic_utils.(332) values:  loss  - [[0.5379]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3373]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0659]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1174]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.6287 - rpn_class_loss: 0.0267 - rpn_bbox_loss: 0.2494 - mrcnn_class_loss: 0.2377 - mrcnn_bbox_loss: 0.1149callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0556]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0078]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0261]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2316]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1421]]\n",
      " generic_utils.(332) values:  loss  - [[0.2316]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0078]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1421]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0556]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0261]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5295 - rpn_class_loss: 0.0220 - rpn_bbox_loss: 0.2226 - mrcnn_class_loss: 0.1922 - mrcnn_bbox_loss: 0.0927callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0405]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0106]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0694]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3436]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2231]]\n",
      " generic_utils.(332) values:  loss  - [[0.3436]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0106]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2231]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0405]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0694]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4923 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.2227 - mrcnn_class_loss: 0.1618 - mrcnn_bbox_loss: 0.0881callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2175]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0302]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.101]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.672]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3232]]\n",
      " generic_utils.(332) values:  loss  - [[0.672]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0302]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3232]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2175]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.101]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.5222 - rpn_class_loss: 0.0215 - rpn_bbox_loss: 0.2394 - mrcnn_class_loss: 0.1711 - mrcnn_bbox_loss: 0.0902callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0304]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0158]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0515]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2525]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1548]]\n",
      " generic_utils.(332) values:  loss  - [[0.2525]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0158]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1548]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0304]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0515]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4837 - rpn_class_loss: 0.0207 - rpn_bbox_loss: 0.2274 - mrcnn_class_loss: 0.1510 - mrcnn_bbox_loss: 0.0847callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1528]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0217]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0963]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4708]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2]]\n",
      " generic_utils.(332) values:  loss  - [[0.4708]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0217]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1528]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0963]]\n",
      " generic_utils.(332) values:  loss  - [[0.4821]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0208]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2239]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1512]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0861]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1341]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0322]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0235]]\n",
      "8/8 [==============================] - 3s 422ms/step - loss: 0.4821 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2239 - mrcnn_class_loss: 0.1512 - mrcnn_bbox_loss: 0.0861 - val_loss: 0.1341 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0322 - val_mrcnn_bbox_loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00573: val_loss did not improve\n",
      "Epoch 574/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0492]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0298]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0603]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3787]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2394]]\n",
      " generic_utils.(332) values:  loss  - [[0.3787]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0298]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2394]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0492]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0603]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.3787 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.2394 - mrcnn_class_loss: 0.0492 - mrcnn_bbox_loss: 0.0603callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0559]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0181]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0533]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3363]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.209]]\n",
      " generic_utils.(332) values:  loss  - [[0.3363]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0181]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.209]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0559]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0533]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.3575 - rpn_class_loss: 0.0240 - rpn_bbox_loss: 0.2242 - mrcnn_class_loss: 0.0525 - mrcnn_bbox_loss: 0.0568callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0993]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0683]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.103]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[1.0118]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.7412]]\n",
      " generic_utils.(332) values:  loss  - [[1.0118]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0683]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.7412]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0993]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.103]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.5756 - rpn_class_loss: 0.0387 - rpn_bbox_loss: 0.3965 - mrcnn_class_loss: 0.0681 - mrcnn_bbox_loss: 0.0722callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1295]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0396]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0914]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4797]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2192]]\n",
      " generic_utils.(332) values:  loss  - [[0.4797]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0396]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2192]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1295]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0914]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5516 - rpn_class_loss: 0.0389 - rpn_bbox_loss: 0.3522 - mrcnn_class_loss: 0.0835 - mrcnn_bbox_loss: 0.0770callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.157]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0685]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0578]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[1.0015]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.7182]]\n",
      " generic_utils.(332) values:  loss  - [[1.0015]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0685]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.7182]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.157]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0578]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.6416 - rpn_class_loss: 0.0449 - rpn_bbox_loss: 0.4254 - mrcnn_class_loss: 0.0982 - mrcnn_bbox_loss: 0.0732callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2169]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0172]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.052]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5327]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2466]]\n",
      " generic_utils.(332) values:  loss  - [[0.5327]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0172]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2466]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2169]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.052]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.6234 - rpn_class_loss: 0.0403 - rpn_bbox_loss: 0.3956 - mrcnn_class_loss: 0.1180 - mrcnn_bbox_loss: 0.0697callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.114]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0218]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0653]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4787]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2775]]\n",
      " generic_utils.(332) values:  loss  - [[0.4787]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0218]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2775]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.114]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0653]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.6028 - rpn_class_loss: 0.0376 - rpn_bbox_loss: 0.3787 - mrcnn_class_loss: 0.1174 - mrcnn_bbox_loss: 0.0690callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0702]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0095]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0233]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2239]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.121]]\n",
      " generic_utils.(332) values:  loss  - [[0.2239]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0095]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.121]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0702]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0233]]\n",
      " generic_utils.(332) values:  loss  - [[0.5554]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0341]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3465]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1115]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0633]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1316]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0107]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0426]]\n",
      "8/8 [==============================] - 4s 442ms/step - loss: 0.5554 - rpn_class_loss: 0.0341 - rpn_bbox_loss: 0.3465 - mrcnn_class_loss: 0.1115 - mrcnn_bbox_loss: 0.0633 - val_loss: 0.1316 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0107 - val_mrcnn_bbox_loss: 0.0426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00574: val_loss did not improve\n",
      "Epoch 575/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0578]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0262]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0836]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5121]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3444]]\n",
      " generic_utils.(332) values:  loss  - [[0.5121]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0262]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3444]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0578]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0836]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.5121 - rpn_class_loss: 0.0262 - rpn_bbox_loss: 0.3444 - mrcnn_class_loss: 0.0578 - mrcnn_bbox_loss: 0.0836callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0753]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0279]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0803]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4091]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2256]]\n",
      " generic_utils.(332) values:  loss  - [[0.4091]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0279]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2256]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0753]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0803]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4606 - rpn_class_loss: 0.0270 - rpn_bbox_loss: 0.2850 - mrcnn_class_loss: 0.0666 - mrcnn_bbox_loss: 0.0820callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1215]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0219]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0675]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5534]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3425]]\n",
      " generic_utils.(332) values:  loss  - [[0.5534]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0219]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3425]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1215]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0675]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.4915 - rpn_class_loss: 0.0253 - rpn_bbox_loss: 0.3042 - mrcnn_class_loss: 0.0849 - mrcnn_bbox_loss: 0.0771callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0641]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0103]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0434]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2652]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1474]]\n",
      " generic_utils.(332) values:  loss  - [[0.2652]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0103]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1474]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0641]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0434]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.4349 - rpn_class_loss: 0.0216 - rpn_bbox_loss: 0.2650 - mrcnn_class_loss: 0.0797 - mrcnn_bbox_loss: 0.0687callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1296]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0174]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1659]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7073]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3945]]\n",
      " generic_utils.(332) values:  loss  - [[0.7073]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3945]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1296]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1659]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4894 - rpn_class_loss: 0.0207 - rpn_bbox_loss: 0.2909 - mrcnn_class_loss: 0.0897 - mrcnn_bbox_loss: 0.0881callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1295]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0155]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0806]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.383]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1573]]\n",
      " generic_utils.(332) values:  loss  - [[0.383]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0155]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1573]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1295]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0806]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4717 - rpn_class_loss: 0.0199 - rpn_bbox_loss: 0.2686 - mrcnn_class_loss: 0.0963 - mrcnn_bbox_loss: 0.0869callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.053]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0127]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0428]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1959]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0873]]\n",
      " generic_utils.(332) values:  loss  - [[0.1959]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0127]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0873]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.053]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0428]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4323 - rpn_class_loss: 0.0188 - rpn_bbox_loss: 0.2427 - mrcnn_class_loss: 0.0901 - mrcnn_bbox_loss: 0.0806callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0067]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0053]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0358]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2015]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1537]]\n",
      " generic_utils.(332) values:  loss  - [[0.2015]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0053]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1537]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0067]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0358]]\n",
      " generic_utils.(332) values:  loss  - [[0.4034]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0171]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2316]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0797]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.075]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1227]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0694]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0165]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0278]]\n",
      "8/8 [==============================] - 3s 418ms/step - loss: 0.4034 - rpn_class_loss: 0.0171 - rpn_bbox_loss: 0.2316 - mrcnn_class_loss: 0.0797 - mrcnn_bbox_loss: 0.0750 - val_loss: 0.1227 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0694 - val_mrcnn_class_loss: 0.0165 - val_mrcnn_bbox_loss: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00575: val_loss did not improve\n",
      "Epoch 576/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0683]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0199]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1361]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4949]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2706]]\n",
      " generic_utils.(332) values:  loss  - [[0.4949]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0199]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2706]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0683]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1361]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.4949 - rpn_class_loss: 0.0199 - rpn_bbox_loss: 0.2706 - mrcnn_class_loss: 0.0683 - mrcnn_bbox_loss: 0.1361callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0257]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0112]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0696]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2569]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1504]]\n",
      " generic_utils.(332) values:  loss  - [[0.2569]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0112]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1504]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0257]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0696]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.3759 - rpn_class_loss: 0.0156 - rpn_bbox_loss: 0.2105 - mrcnn_class_loss: 0.0470 - mrcnn_bbox_loss: 0.1028callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0108]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0314]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0454]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.34]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2525]]\n",
      " generic_utils.(332) values:  loss  - [[0.34]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0314]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2525]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0108]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0454]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3639 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2245 - mrcnn_class_loss: 0.0349 - mrcnn_bbox_loss: 0.0837callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0664]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0249]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.138]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3695]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1402]]\n",
      " generic_utils.(332) values:  loss  - [[0.3695]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0249]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1402]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0664]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.138]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3653 - rpn_class_loss: 0.0219 - rpn_bbox_loss: 0.2034 - mrcnn_class_loss: 0.0428 - mrcnn_bbox_loss: 0.0973callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0378]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0526]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0785]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[1.1495]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.9807]]\n",
      " generic_utils.(332) values:  loss  - [[1.1495]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0526]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.9807]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0378]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0785]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.5222 - rpn_class_loss: 0.0280 - rpn_bbox_loss: 0.3589 - mrcnn_class_loss: 0.0418 - mrcnn_bbox_loss: 0.0935callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0537]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0247]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.044]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.291]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1687]]\n",
      " generic_utils.(332) values:  loss  - [[0.291]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0247]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1687]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0537]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.044]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4836 - rpn_class_loss: 0.0274 - rpn_bbox_loss: 0.3272 - mrcnn_class_loss: 0.0438 - mrcnn_bbox_loss: 0.0853callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0725]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0356]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1132]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4764]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2551]]\n",
      " generic_utils.(332) values:  loss  - [[0.4764]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0356]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2551]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0725]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1132]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4826 - rpn_class_loss: 0.0286 - rpn_bbox_loss: 0.3169 - mrcnn_class_loss: 0.0479 - mrcnn_bbox_loss: 0.0892callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0479]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0228]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0594]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3008]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1707]]\n",
      " generic_utils.(332) values:  loss  - [[0.3008]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1707]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0479]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0594]]\n",
      " generic_utils.(332) values:  loss  - [[0.4599]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0279]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2986]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0479]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0855]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1216]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0695]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0069]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0363]]\n",
      "8/8 [==============================] - 3s 410ms/step - loss: 0.4599 - rpn_class_loss: 0.0279 - rpn_bbox_loss: 0.2986 - mrcnn_class_loss: 0.0479 - mrcnn_bbox_loss: 0.0855 - val_loss: 0.1216 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0695 - val_mrcnn_class_loss: 0.0069 - val_mrcnn_bbox_loss: 0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00576: val_loss did not improve\n",
      "Epoch 577/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0641]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0214]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.041]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2955]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.169]]\n",
      " generic_utils.(332) values:  loss  - [[0.2955]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0214]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.169]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0641]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.041]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2955 - rpn_class_loss: 0.0214 - rpn_bbox_loss: 0.1690 - mrcnn_class_loss: 0.0641 - mrcnn_bbox_loss: 0.0410callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.073]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.021]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1299]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5591]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3352]]\n",
      " generic_utils.(332) values:  loss  - [[0.5591]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.021]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3352]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.073]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1299]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4273 - rpn_class_loss: 0.0212 - rpn_bbox_loss: 0.2521 - mrcnn_class_loss: 0.0685 - mrcnn_bbox_loss: 0.0855callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0087]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0073]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0257]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1356]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0939]]\n",
      " generic_utils.(332) values:  loss  - [[0.1356]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0073]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0939]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0087]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0257]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3301 - rpn_class_loss: 0.0166 - rpn_bbox_loss: 0.1994 - mrcnn_class_loss: 0.0486 - mrcnn_bbox_loss: 0.0655callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1248]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0235]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0625]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.424]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2132]]\n",
      " generic_utils.(332) values:  loss  - [[0.424]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0235]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2132]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1248]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0625]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3536 - rpn_class_loss: 0.0183 - rpn_bbox_loss: 0.2028 - mrcnn_class_loss: 0.0676 - mrcnn_bbox_loss: 0.0648callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0366]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0187]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0255]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1767]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0959]]\n",
      " generic_utils.(332) values:  loss  - [[0.1767]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0187]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0959]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0366]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0255]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3182 - rpn_class_loss: 0.0184 - rpn_bbox_loss: 0.1814 - mrcnn_class_loss: 0.0614 - mrcnn_bbox_loss: 0.0569callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.165]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0357]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1232]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5705]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2467]]\n",
      " generic_utils.(332) values:  loss  - [[0.5705]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0357]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2467]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.165]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1232]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3603 - rpn_class_loss: 0.0213 - rpn_bbox_loss: 0.1923 - mrcnn_class_loss: 0.0787 - mrcnn_bbox_loss: 0.0680callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0778]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0112]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0328]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4437]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3219]]\n",
      " generic_utils.(332) values:  loss  - [[0.4437]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0112]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3219]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0778]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0328]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3722 - rpn_class_loss: 0.0198 - rpn_bbox_loss: 0.2108 - mrcnn_class_loss: 0.0786 - mrcnn_bbox_loss: 0.0629callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0556]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0171]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0495]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3004]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1781]]\n",
      " generic_utils.(332) values:  loss  - [[0.3004]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0171]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1781]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0556]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0495]]\n",
      " generic_utils.(332) values:  loss  - [[0.3632]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0195]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2067]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0757]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0613]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1598]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0588]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0226]]\n",
      "8/8 [==============================] - 4s 445ms/step - loss: 0.3632 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2067 - mrcnn_class_loss: 0.0757 - mrcnn_bbox_loss: 0.0613 - val_loss: 0.1598 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0588 - val_mrcnn_bbox_loss: 0.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00577: val_loss did not improve\n",
      "Epoch 578/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1011]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0149]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0517]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3218]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1542]]\n",
      " generic_utils.(332) values:  loss  - [[0.3218]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0149]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1542]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1011]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0517]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3218 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.1542 - mrcnn_class_loss: 0.1011 - mrcnn_bbox_loss: 0.0517callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1143]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0385]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0965]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7265]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.4771]]\n",
      " generic_utils.(332) values:  loss  - [[0.7265]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0385]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.4771]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1143]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0965]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.5241 - rpn_class_loss: 0.0267 - rpn_bbox_loss: 0.3156 - mrcnn_class_loss: 0.1077 - mrcnn_bbox_loss: 0.0741callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1102]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0156]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0544]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3783]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1982]]\n",
      " generic_utils.(332) values:  loss  - [[0.3783]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0156]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1982]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1102]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0544]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.4755 - rpn_class_loss: 0.0230 - rpn_bbox_loss: 0.2765 - mrcnn_class_loss: 0.1085 - mrcnn_bbox_loss: 0.0675callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1117]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0475]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0544]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.7218]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.5082]]\n",
      " generic_utils.(332) values:  loss  - [[0.7218]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0475]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.5082]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1117]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0544]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5371 - rpn_class_loss: 0.0291 - rpn_bbox_loss: 0.3344 - mrcnn_class_loss: 0.1093 - mrcnn_bbox_loss: 0.0642callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0363]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0109]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0236]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1532]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0824]]\n",
      " generic_utils.(332) values:  loss  - [[0.1532]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0109]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0824]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0363]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0236]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4603 - rpn_class_loss: 0.0255 - rpn_bbox_loss: 0.2840 - mrcnn_class_loss: 0.0947 - mrcnn_bbox_loss: 0.0561callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0371]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0228]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0489]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2934]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1846]]\n",
      " generic_utils.(332) values:  loss  - [[0.2934]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1846]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0371]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0489]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4325 - rpn_class_loss: 0.0250 - rpn_bbox_loss: 0.2675 - mrcnn_class_loss: 0.0851 - mrcnn_bbox_loss: 0.0549callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0513]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0168]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0595]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2706]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.143]]\n",
      " generic_utils.(332) values:  loss  - [[0.2706]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0168]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.143]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0513]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0595]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4094 - rpn_class_loss: 0.0239 - rpn_bbox_loss: 0.2497 - mrcnn_class_loss: 0.0803 - mrcnn_bbox_loss: 0.0556callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.078]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0157]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0745]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3504]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1821]]\n",
      " generic_utils.(332) values:  loss  - [[0.3504]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0157]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1821]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.078]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0745]]\n",
      " generic_utils.(332) values:  loss  - [[0.402]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2412]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.08]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0579]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1226]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0115]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0327]]\n",
      "8/8 [==============================] - 4s 458ms/step - loss: 0.4020 - rpn_class_loss: 0.0228 - rpn_bbox_loss: 0.2412 - mrcnn_class_loss: 0.0800 - mrcnn_bbox_loss: 0.0579 - val_loss: 0.1226 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0115 - val_mrcnn_bbox_loss: 0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00578: val_loss did not improve\n",
      "Epoch 579/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1187]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0301]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0738]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6015]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3789]]\n",
      " generic_utils.(332) values:  loss  - [[0.6015]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0301]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3789]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1187]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0738]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.6015 - rpn_class_loss: 0.0301 - rpn_bbox_loss: 0.3789 - mrcnn_class_loss: 0.1187 - mrcnn_bbox_loss: 0.0738callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0047]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0027]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0107]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.0798]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0618]]\n",
      " generic_utils.(332) values:  loss  - [[0.0798]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0027]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0618]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0047]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0107]]\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 0.3407 - rpn_class_loss: 0.0164 - rpn_bbox_loss: 0.2203 - mrcnn_class_loss: 0.0617 - mrcnn_bbox_loss: 0.0422callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.035]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0035]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0155]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2126]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1586]]\n",
      " generic_utils.(332) values:  loss  - [[0.2126]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0035]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1586]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.035]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0155]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.2980 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.1997 - mrcnn_class_loss: 0.0528 - mrcnn_bbox_loss: 0.0333callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0349]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.009]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0504]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2505]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1562]]\n",
      " generic_utils.(332) values:  loss  - [[0.2505]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.009]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1562]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0349]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0504]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.2861 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.1889 - mrcnn_class_loss: 0.0483 - mrcnn_bbox_loss: 0.0376callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.012]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0102]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0238]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2824]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2364]]\n",
      " generic_utils.(332) values:  loss  - [[0.2824]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0102]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2364]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.012]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0238]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.2854 - rpn_class_loss: 0.0111 - rpn_bbox_loss: 0.1984 - mrcnn_class_loss: 0.0410 - mrcnn_bbox_loss: 0.0348callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.06]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0186]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0511]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3797]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2499]]\n",
      " generic_utils.(332) values:  loss  - [[0.3797]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0186]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2499]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.06]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0511]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3011 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.2070 - mrcnn_class_loss: 0.0442 - mrcnn_bbox_loss: 0.0375callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0555]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0137]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0637]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3276]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1947]]\n",
      " generic_utils.(332) values:  loss  - [[0.3276]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0137]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1947]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0555]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0637]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3049 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.2052 - mrcnn_class_loss: 0.0458 - mrcnn_bbox_loss: 0.0413callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.006]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0086]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0176]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.131]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0988]]\n",
      " generic_utils.(332) values:  loss  - [[0.131]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0086]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0988]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.006]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0176]]\n",
      " generic_utils.(332) values:  loss  - [[0.2831]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1919]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0408]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0383]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1518]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0371]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0361]]\n",
      "8/8 [==============================] - 3s 382ms/step - loss: 0.2831 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.1919 - mrcnn_class_loss: 0.0408 - mrcnn_bbox_loss: 0.0383 - val_loss: 0.1518 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0371 - val_mrcnn_bbox_loss: 0.0361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00579: val_loss did not improve\n",
      "Epoch 580/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0477]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0226]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0433]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3999]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2863]]\n",
      " generic_utils.(332) values:  loss  - [[0.3999]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0226]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2863]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0477]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0433]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3999 - rpn_class_loss: 0.0226 - rpn_bbox_loss: 0.2863 - mrcnn_class_loss: 0.0477 - mrcnn_bbox_loss: 0.0433callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1414]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0309]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0584]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5346]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3039]]\n",
      " generic_utils.(332) values:  loss  - [[0.5346]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0309]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3039]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1414]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0584]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4672 - rpn_class_loss: 0.0268 - rpn_bbox_loss: 0.2951 - mrcnn_class_loss: 0.0945 - mrcnn_bbox_loss: 0.0508callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0672]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0311]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0452]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3689]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2254]]\n",
      " generic_utils.(332) values:  loss  - [[0.3689]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0311]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2254]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0672]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0452]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.4345 - rpn_class_loss: 0.0282 - rpn_bbox_loss: 0.2719 - mrcnn_class_loss: 0.0854 - mrcnn_bbox_loss: 0.0490callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.063]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0156]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1251]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4087]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.205]]\n",
      " generic_utils.(332) values:  loss  - [[0.4087]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0156]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.205]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.063]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1251]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.4280 - rpn_class_loss: 0.0251 - rpn_bbox_loss: 0.2552 - mrcnn_class_loss: 0.0798 - mrcnn_bbox_loss: 0.0680callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1043]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0357]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0397]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4141]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2344]]\n",
      " generic_utils.(332) values:  loss  - [[0.4141]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0357]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2344]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1043]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0397]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4252 - rpn_class_loss: 0.0272 - rpn_bbox_loss: 0.2510 - mrcnn_class_loss: 0.0847 - mrcnn_bbox_loss: 0.0623callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.126]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0206]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0224]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3368]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1679]]\n",
      " generic_utils.(332) values:  loss  - [[0.3368]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0206]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1679]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.126]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0224]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4105 - rpn_class_loss: 0.0261 - rpn_bbox_loss: 0.2371 - mrcnn_class_loss: 0.0916 - mrcnn_bbox_loss: 0.0557callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0777]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.018]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.085]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3814]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2008]]\n",
      " generic_utils.(332) values:  loss  - [[0.3814]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.018]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2008]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0777]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.085]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4064 - rpn_class_loss: 0.0249 - rpn_bbox_loss: 0.2320 - mrcnn_class_loss: 0.0896 - mrcnn_bbox_loss: 0.0599callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0132]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.016]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0407]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2597]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1898]]\n",
      " generic_utils.(332) values:  loss  - [[0.2597]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.016]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1898]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0132]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0407]]\n",
      " generic_utils.(332) values:  loss  - [[0.388]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0238]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2267]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0801]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0575]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1439]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0532]]\n",
      "8/8 [==============================] - 3s 430ms/step - loss: 0.3880 - rpn_class_loss: 0.0238 - rpn_bbox_loss: 0.2267 - mrcnn_class_loss: 0.0801 - mrcnn_bbox_loss: 0.0575 - val_loss: 0.1439 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0121 - val_mrcnn_bbox_loss: 0.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00580: val_loss did not improve\n",
      "Epoch 581/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0559]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0194]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0693]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3051]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1606]]\n",
      " generic_utils.(332) values:  loss  - [[0.3051]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0194]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1606]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0559]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0693]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3051 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.1606 - mrcnn_class_loss: 0.0559 - mrcnn_bbox_loss: 0.0693callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0189]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0149]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0915]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2493]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.124]]\n",
      " generic_utils.(332) values:  loss  - [[0.2493]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0149]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.124]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0189]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0915]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.2772 - rpn_class_loss: 0.0171 - rpn_bbox_loss: 0.1423 - mrcnn_class_loss: 0.0374 - mrcnn_bbox_loss: 0.0804callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0141]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0065]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0403]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1907]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1297]]\n",
      " generic_utils.(332) values:  loss  - [[0.1907]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0065]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1297]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0141]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0403]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.2484 - rpn_class_loss: 0.0136 - rpn_bbox_loss: 0.1381 - mrcnn_class_loss: 0.0296 - mrcnn_bbox_loss: 0.0671callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1142]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0254]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0954]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.457]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2219]]\n",
      " generic_utils.(332) values:  loss  - [[0.457]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0254]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2219]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1142]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0954]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3005 - rpn_class_loss: 0.0166 - rpn_bbox_loss: 0.1591 - mrcnn_class_loss: 0.0507 - mrcnn_bbox_loss: 0.0741callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1057]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0282]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1071]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5136]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2726]]\n",
      " generic_utils.(332) values:  loss  - [[0.5136]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0282]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2726]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1057]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1071]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3431 - rpn_class_loss: 0.0189 - rpn_bbox_loss: 0.1818 - mrcnn_class_loss: 0.0617 - mrcnn_bbox_loss: 0.0807callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0911]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.024]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0956]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4935]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2828]]\n",
      " generic_utils.(332) values:  loss  - [[0.4935]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.024]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2828]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0911]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0956]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3682 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.1986 - mrcnn_class_loss: 0.0666 - mrcnn_bbox_loss: 0.0832callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.062]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0319]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0401]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5556]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.4215]]\n",
      " generic_utils.(332) values:  loss  - [[0.5556]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0319]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.4215]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.062]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0401]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3950 - rpn_class_loss: 0.0215 - rpn_bbox_loss: 0.2305 - mrcnn_class_loss: 0.0660 - mrcnn_bbox_loss: 0.0771callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0802]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0123]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1212]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4132]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1995]]\n",
      " generic_utils.(332) values:  loss  - [[0.4132]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0123]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1995]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0802]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1212]]\n",
      " generic_utils.(332) values:  loss  - [[0.3972]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0203]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2266]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0678]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0826]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1034]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0083]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0165]]\n",
      "8/8 [==============================] - 3s 420ms/step - loss: 0.3972 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.2266 - mrcnn_class_loss: 0.0678 - mrcnn_bbox_loss: 0.0826 - val_loss: 0.1034 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0083 - val_mrcnn_bbox_loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00581: val_loss improved from 0.11381402 to 0.10338034, saving model to E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_0581.h5\n",
      "Epoch 582/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0732]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0102]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0553]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3384]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1997]]\n",
      " generic_utils.(332) values:  loss  - [[0.3384]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0102]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1997]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0732]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0553]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3384 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.1997 - mrcnn_class_loss: 0.0732 - mrcnn_bbox_loss: 0.0553callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0569]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0308]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0612]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4964]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3475]]\n",
      " generic_utils.(332) values:  loss  - [[0.4964]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0308]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3475]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0569]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0612]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4174 - rpn_class_loss: 0.0205 - rpn_bbox_loss: 0.2736 - mrcnn_class_loss: 0.0651 - mrcnn_bbox_loss: 0.0582callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0499]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0096]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0374]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2316]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1346]]\n",
      " generic_utils.(332) values:  loss  - [[0.2316]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0096]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1346]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0499]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0374]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.3554 - rpn_class_loss: 0.0169 - rpn_bbox_loss: 0.2273 - mrcnn_class_loss: 0.0600 - mrcnn_bbox_loss: 0.0513callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0822]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0126]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0333]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2473]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1191]]\n",
      " generic_utils.(332) values:  loss  - [[0.2473]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0126]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1191]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0822]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0333]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3284 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.2002 - mrcnn_class_loss: 0.0656 - mrcnn_bbox_loss: 0.0468callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0826]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0158]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0308]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3751]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2459]]\n",
      " generic_utils.(332) values:  loss  - [[0.3751]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0158]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2459]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0826]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0308]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3377 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.2094 - mrcnn_class_loss: 0.0690 - mrcnn_bbox_loss: 0.0436callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0364]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0128]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0239]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2211]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1481]]\n",
      " generic_utils.(332) values:  loss  - [[0.2211]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0128]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1481]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0364]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0239]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3183 - rpn_class_loss: 0.0153 - rpn_bbox_loss: 0.1991 - mrcnn_class_loss: 0.0636 - mrcnn_bbox_loss: 0.0403callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0109]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0035]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0509]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2709]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2057]]\n",
      " generic_utils.(332) values:  loss  - [[0.2709]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0035]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2057]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0109]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0509]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - rpn_class_loss: 0.0136 - rpn_bbox_loss: 0.2001 - mrcnn_class_loss: 0.0560 - mrcnn_bbox_loss: 0.0418callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1758]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0208]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0557]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4861]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2338]]\n",
      " generic_utils.(332) values:  loss  - [[0.4861]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0208]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2338]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1758]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0557]]\n",
      " generic_utils.(332) values:  loss  - [[0.3334]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0145]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2043]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.071]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0436]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1578]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0455]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0338]]\n",
      "8/8 [==============================] - 3s 416ms/step - loss: 0.3334 - rpn_class_loss: 0.0145 - rpn_bbox_loss: 0.2043 - mrcnn_class_loss: 0.0710 - mrcnn_bbox_loss: 0.0436 - val_loss: 0.1578 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0455 - val_mrcnn_bbox_loss: 0.0338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00582: val_loss did not improve\n",
      "Epoch 583/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0355]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0235]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0386]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6317]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.5341]]\n",
      " generic_utils.(332) values:  loss  - [[0.6317]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0235]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.5341]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0355]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0386]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.6317 - rpn_class_loss: 0.0235 - rpn_bbox_loss: 0.5341 - mrcnn_class_loss: 0.0355 - mrcnn_bbox_loss: 0.0386callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0138]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0014]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0855]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1869]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0862]]\n",
      " generic_utils.(332) values:  loss  - [[0.1869]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0014]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0862]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0138]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0855]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4093 - rpn_class_loss: 0.0125 - rpn_bbox_loss: 0.3102 - mrcnn_class_loss: 0.0246 - mrcnn_bbox_loss: 0.0620callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0915]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0212]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0454]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3067]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1486]]\n",
      " generic_utils.(332) values:  loss  - [[0.3067]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0212]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1486]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0915]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0454]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3751 - rpn_class_loss: 0.0154 - rpn_bbox_loss: 0.2563 - mrcnn_class_loss: 0.0469 - mrcnn_bbox_loss: 0.0565callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0517]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0122]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0435]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4036]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2962]]\n",
      " generic_utils.(332) values:  loss  - [[0.4036]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0122]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2962]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0517]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0435]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3822 - rpn_class_loss: 0.0146 - rpn_bbox_loss: 0.2663 - mrcnn_class_loss: 0.0481 - mrcnn_bbox_loss: 0.0532callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0339]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0221]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0403]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2821]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1858]]\n",
      " generic_utils.(332) values:  loss  - [[0.2821]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0221]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1858]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0339]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0403]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3622 - rpn_class_loss: 0.0161 - rpn_bbox_loss: 0.2502 - mrcnn_class_loss: 0.0452 - mrcnn_bbox_loss: 0.0507callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.056]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0086]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0254]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1414]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0513]]\n",
      " generic_utils.(332) values:  loss  - [[0.1414]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0086]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0513]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.056]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0254]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3254 - rpn_class_loss: 0.0148 - rpn_bbox_loss: 0.2171 - mrcnn_class_loss: 0.0470 - mrcnn_bbox_loss: 0.0465callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0982]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0188]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1019]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4294]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2106]]\n",
      " generic_utils.(332) values:  loss  - [[0.4294]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0188]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2106]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0982]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1019]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3403 - rpn_class_loss: 0.0154 - rpn_bbox_loss: 0.2161 - mrcnn_class_loss: 0.0544 - mrcnn_bbox_loss: 0.0544callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0024]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0102]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0185]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1583]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1271]]\n",
      " generic_utils.(332) values:  loss  - [[0.1583]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0102]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1271]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0024]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0185]]\n",
      " generic_utils.(332) values:  loss  - [[0.3175]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.205]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0479]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0499]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1205]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0255]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0164]]\n",
      "8/8 [==============================] - 3s 401ms/step - loss: 0.3175 - rpn_class_loss: 0.0148 - rpn_bbox_loss: 0.2050 - mrcnn_class_loss: 0.0479 - mrcnn_bbox_loss: 0.0499 - val_loss: 0.1205 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0255 - val_mrcnn_bbox_loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00583: val_loss did not improve\n",
      "Epoch 584/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0145]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0176]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0316]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1501]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0863]]\n",
      " generic_utils.(332) values:  loss  - [[0.1501]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0176]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0863]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0145]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0316]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.1501 - rpn_class_loss: 0.0176 - rpn_bbox_loss: 0.0863 - mrcnn_class_loss: 0.0145 - mrcnn_bbox_loss: 0.0316callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0244]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0197]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0349]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.345]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.266]]\n",
      " generic_utils.(332) values:  loss  - [[0.345]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0197]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.266]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0244]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0349]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.2476 - rpn_class_loss: 0.0187 - rpn_bbox_loss: 0.1762 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 0.0333callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1361]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0285]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1243]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5661]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2772]]\n",
      " generic_utils.(332) values:  loss  - [[0.5661]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0285]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2772]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1361]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1243]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3537 - rpn_class_loss: 0.0219 - rpn_bbox_loss: 0.2099 - mrcnn_class_loss: 0.0583 - mrcnn_bbox_loss: 0.0636callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.077]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.025]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.03]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4648]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3327]]\n",
      " generic_utils.(332) values:  loss  - [[0.4648]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.025]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3327]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.077]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.03]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3815 - rpn_class_loss: 0.0227 - rpn_bbox_loss: 0.2406 - mrcnn_class_loss: 0.0630 - mrcnn_bbox_loss: 0.0552callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0597]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0206]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.2268]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5833]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2762]]\n",
      " generic_utils.(332) values:  loss  - [[0.5833]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0206]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2762]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0597]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.2268]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4218 - rpn_class_loss: 0.0223 - rpn_bbox_loss: 0.2477 - mrcnn_class_loss: 0.0623 - mrcnn_bbox_loss: 0.0895callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0842]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0164]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1797]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.6371]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3569]]\n",
      " generic_utils.(332) values:  loss  - [[0.6371]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0164]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3569]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0842]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1797]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4577 - rpn_class_loss: 0.0213 - rpn_bbox_loss: 0.2659 - mrcnn_class_loss: 0.0660 - mrcnn_bbox_loss: 0.1045callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0613]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0121]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0428]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2062]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0901]]\n",
      " generic_utils.(332) values:  loss  - [[0.2062]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0121]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0901]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0613]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0428]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4218 - rpn_class_loss: 0.0200 - rpn_bbox_loss: 0.2408 - mrcnn_class_loss: 0.0653 - mrcnn_bbox_loss: 0.0957callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0542]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0228]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0552]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.365]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2329]]\n",
      " generic_utils.(332) values:  loss  - [[0.365]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0228]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2329]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0542]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0552]]\n",
      " generic_utils.(332) values:  loss  - [[0.4147]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0203]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2398]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0639]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0907]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.2509]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.1269]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0455]]\n",
      "8/8 [==============================] - 3s 413ms/step - loss: 0.4147 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.2398 - mrcnn_class_loss: 0.0639 - mrcnn_bbox_loss: 0.0907 - val_loss: 0.2509 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.1269 - val_mrcnn_bbox_loss: 0.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00584: val_loss did not improve\n",
      "Epoch 585/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0407]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0234]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0926]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3505]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1939]]\n",
      " generic_utils.(332) values:  loss  - [[0.3505]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0234]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1939]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0407]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0926]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.3505 - rpn_class_loss: 0.0234 - rpn_bbox_loss: 0.1939 - mrcnn_class_loss: 0.0407 - mrcnn_bbox_loss: 0.0926callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1651]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0174]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1336]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5264]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2104]]\n",
      " generic_utils.(332) values:  loss  - [[0.5264]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2104]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1651]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1336]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4385 - rpn_class_loss: 0.0204 - rpn_bbox_loss: 0.2021 - mrcnn_class_loss: 0.1029 - mrcnn_bbox_loss: 0.1131callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0155]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.008]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0365]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1554]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0953]]\n",
      " generic_utils.(332) values:  loss  - [[0.1554]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.008]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0953]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0155]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0365]]\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.3441 - rpn_class_loss: 0.0163 - rpn_bbox_loss: 0.1665 - mrcnn_class_loss: 0.0738 - mrcnn_bbox_loss: 0.0875callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0385]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0108]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.037]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3095]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2231]]\n",
      " generic_utils.(332) values:  loss  - [[0.3095]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0108]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2231]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0385]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.037]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3355 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.1807 - mrcnn_class_loss: 0.0650 - mrcnn_bbox_loss: 0.0749callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0122]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0053]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0566]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1662]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0922]]\n",
      " generic_utils.(332) values:  loss  - [[0.1662]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0053]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0922]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0122]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0566]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3016 - rpn_class_loss: 0.0130 - rpn_bbox_loss: 0.1630 - mrcnn_class_loss: 0.0544 - mrcnn_bbox_loss: 0.0712callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0122]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0096]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0335]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2696]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2142]]\n",
      " generic_utils.(332) values:  loss  - [[0.2696]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0096]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2142]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0122]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0335]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.2963 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.1715 - mrcnn_class_loss: 0.0474 - mrcnn_bbox_loss: 0.0650callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0799]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0112]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0562]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.37]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2226]]\n",
      " generic_utils.(332) values:  loss  - [[0.37]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0112]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2226]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0799]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0562]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3068 - rpn_class_loss: 0.0123 - rpn_bbox_loss: 0.1788 - mrcnn_class_loss: 0.0520 - mrcnn_bbox_loss: 0.0637callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0181]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0074]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.032]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2571]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1996]]\n",
      " generic_utils.(332) values:  loss  - [[0.2571]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0074]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1996]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0181]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.032]]\n",
      " generic_utils.(332) values:  loss  - [[0.3006]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0116]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1814]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0478]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0597]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.213]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.1059]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0285]]\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.3006 - rpn_class_loss: 0.0116 - rpn_bbox_loss: 0.1814 - mrcnn_class_loss: 0.0478 - mrcnn_bbox_loss: 0.0597 - val_loss: 0.2130 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.1059 - val_mrcnn_bbox_loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00585: val_loss did not improve\n",
      "Epoch 586/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0651]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0143]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0286]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2814]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1735]]\n",
      " generic_utils.(332) values:  loss  - [[0.2814]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0143]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1735]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0651]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0286]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2814 - rpn_class_loss: 0.0143 - rpn_bbox_loss: 0.1735 - mrcnn_class_loss: 0.0651 - mrcnn_bbox_loss: 0.0286callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0994]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0155]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0303]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2892]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.144]]\n",
      " generic_utils.(332) values:  loss  - [[0.2892]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0155]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.144]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0994]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0303]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.2853 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.1588 - mrcnn_class_loss: 0.0822 - mrcnn_bbox_loss: 0.0294callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0402]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0305]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0603]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4996]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3687]]\n",
      " generic_utils.(332) values:  loss  - [[0.4996]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0305]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3687]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0402]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0603]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3568 - rpn_class_loss: 0.0201 - rpn_bbox_loss: 0.2287 - mrcnn_class_loss: 0.0682 - mrcnn_bbox_loss: 0.0397callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0138]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0186]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0378]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1539]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0837]]\n",
      " generic_utils.(332) values:  loss  - [[0.1539]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0186]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0837]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0138]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0378]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3060 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.1925 - mrcnn_class_loss: 0.0546 - mrcnn_bbox_loss: 0.0392callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0455]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0134]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0218]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3019]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2212]]\n",
      " generic_utils.(332) values:  loss  - [[0.3019]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0134]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2212]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0455]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0218]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3052 - rpn_class_loss: 0.0185 - rpn_bbox_loss: 0.1982 - mrcnn_class_loss: 0.0528 - mrcnn_bbox_loss: 0.0358callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0438]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0166]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0576]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2995]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1815]]\n",
      " generic_utils.(332) values:  loss  - [[0.2995]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0166]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1815]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0438]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0576]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3043 - rpn_class_loss: 0.0181 - rpn_bbox_loss: 0.1954 - mrcnn_class_loss: 0.0513 - mrcnn_bbox_loss: 0.0394callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0526]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0073]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0422]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2484]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1463]]\n",
      " generic_utils.(332) values:  loss  - [[0.2484]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0073]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1463]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0526]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0422]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.2963 - rpn_class_loss: 0.0166 - rpn_bbox_loss: 0.1884 - mrcnn_class_loss: 0.0515 - mrcnn_bbox_loss: 0.0398callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0541]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0148]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0507]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3662]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2467]]\n",
      " generic_utils.(332) values:  loss  - [[0.3662]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2467]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0541]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0507]]\n",
      " generic_utils.(332) values:  loss  - [[0.305]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0164]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1957]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0518]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0412]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1277]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.016]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0332]]\n",
      "8/8 [==============================] - 4s 444ms/step - loss: 0.3050 - rpn_class_loss: 0.0164 - rpn_bbox_loss: 0.1957 - mrcnn_class_loss: 0.0518 - mrcnn_bbox_loss: 0.0412 - val_loss: 0.1277 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0160 - val_mrcnn_bbox_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00586: val_loss did not improve\n",
      "Epoch 587/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0138]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0077]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0331]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3465]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.292]]\n",
      " generic_utils.(332) values:  loss  - [[0.3465]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0077]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.292]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0138]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0331]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3465 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.2920 - mrcnn_class_loss: 0.0138 - mrcnn_bbox_loss: 0.0331callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2154]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0206]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0584]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.471]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1766]]\n",
      " generic_utils.(332) values:  loss  - [[0.471]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0206]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1766]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2154]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0584]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.4088 - rpn_class_loss: 0.0142 - rpn_bbox_loss: 0.2343 - mrcnn_class_loss: 0.1146 - mrcnn_bbox_loss: 0.0457callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0175]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0329]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0466]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3591]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2622]]\n",
      " generic_utils.(332) values:  loss  - [[0.3591]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0329]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2622]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0175]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0466]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3922 - rpn_class_loss: 0.0204 - rpn_bbox_loss: 0.2436 - mrcnn_class_loss: 0.0822 - mrcnn_bbox_loss: 0.0460callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0499]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0175]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0506]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2848]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1667]]\n",
      " generic_utils.(332) values:  loss  - [[0.2848]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0175]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1667]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0499]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0506]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3654 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.2244 - mrcnn_class_loss: 0.0741 - mrcnn_bbox_loss: 0.0472callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0023]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.005]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0264]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.0728]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0391]]\n",
      " generic_utils.(332) values:  loss  - [[0.0728]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.005]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0391]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0023]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0264]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3068 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.1873 - mrcnn_class_loss: 0.0598 - mrcnn_bbox_loss: 0.0430callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0651]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0409]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0532]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.8791]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.7198]]\n",
      " generic_utils.(332) values:  loss  - [[0.8791]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0409]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.7198]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0651]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0532]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4022 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2761 - mrcnn_class_loss: 0.0607 - mrcnn_bbox_loss: 0.0447callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0278]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0174]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0905]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.467]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3313]]\n",
      " generic_utils.(332) values:  loss  - [[0.467]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0174]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3313]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0278]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0905]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4115 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.2840 - mrcnn_class_loss: 0.0560 - mrcnn_bbox_loss: 0.0513callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2824]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.012]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0717]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4323]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0662]]\n",
      " generic_utils.(332) values:  loss  - [[0.4323]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.012]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0662]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2824]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0717]]\n",
      " generic_utils.(332) values:  loss  - [[0.4141]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0193]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2567]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0843]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0538]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1441]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0277]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0379]]\n",
      "8/8 [==============================] - 3s 392ms/step - loss: 0.4141 - rpn_class_loss: 0.0193 - rpn_bbox_loss: 0.2567 - mrcnn_class_loss: 0.0843 - mrcnn_bbox_loss: 0.0538 - val_loss: 0.1441 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0277 - val_mrcnn_bbox_loss: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00587: val_loss did not improve\n",
      "Epoch 588/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0627]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0209]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0831]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2673]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1007]]\n",
      " generic_utils.(332) values:  loss  - [[0.2673]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0209]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1007]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0627]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0831]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2673 - rpn_class_loss: 0.0209 - rpn_bbox_loss: 0.1007 - mrcnn_class_loss: 0.0627 - mrcnn_bbox_loss: 0.0831callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0609]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0085]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0257]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1936]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0984]]\n",
      " generic_utils.(332) values:  loss  - [[0.1936]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0085]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0984]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0609]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0257]]\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 0.2304 - rpn_class_loss: 0.0147 - rpn_bbox_loss: 0.0995 - mrcnn_class_loss: 0.0618 - mrcnn_bbox_loss: 0.0544callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.079]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0159]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0759]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2844]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1136]]\n",
      " generic_utils.(332) values:  loss  - [[0.2844]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0159]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1136]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.079]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0759]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.2484 - rpn_class_loss: 0.0151 - rpn_bbox_loss: 0.1042 - mrcnn_class_loss: 0.0675 - mrcnn_bbox_loss: 0.0615callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0331]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0069]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0558]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2734]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1776]]\n",
      " generic_utils.(332) values:  loss  - [[0.2734]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0069]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1776]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0331]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0558]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.2547 - rpn_class_loss: 0.0131 - rpn_bbox_loss: 0.1226 - mrcnn_class_loss: 0.0589 - mrcnn_bbox_loss: 0.0601callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0214]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0062]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0256]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.0904]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0372]]\n",
      " generic_utils.(332) values:  loss  - [[0.0904]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0062]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0372]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0214]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0256]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.2218 - rpn_class_loss: 0.0117 - rpn_bbox_loss: 0.1055 - mrcnn_class_loss: 0.0514 - mrcnn_bbox_loss: 0.0532callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0123]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0111]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0341]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2085]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1511]]\n",
      " generic_utils.(332) values:  loss  - [[0.2085]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0111]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1511]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0123]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0341]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.2196 - rpn_class_loss: 0.0116 - rpn_bbox_loss: 0.1131 - mrcnn_class_loss: 0.0449 - mrcnn_bbox_loss: 0.0500callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0923]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0185]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0872]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4486]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2506]]\n",
      " generic_utils.(332) values:  loss  - [[0.4486]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0185]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2506]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0923]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0872]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.2523 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.1327 - mrcnn_class_loss: 0.0517 - mrcnn_bbox_loss: 0.0553callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0472]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0264]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0389]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3493]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2368]]\n",
      " generic_utils.(332) values:  loss  - [[0.3493]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0264]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2368]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0472]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0389]]\n",
      " generic_utils.(332) values:  loss  - [[0.2644]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0143]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1458]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0511]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0533]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1729]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.062]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0324]]\n",
      "8/8 [==============================] - 3s 386ms/step - loss: 0.2644 - rpn_class_loss: 0.0143 - rpn_bbox_loss: 0.1458 - mrcnn_class_loss: 0.0511 - mrcnn_bbox_loss: 0.0533 - val_loss: 0.1729 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0620 - val_mrcnn_bbox_loss: 0.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00588: val_loss did not improve\n",
      "Epoch 589/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0501]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0179]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0694]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3615]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2241]]\n",
      " generic_utils.(332) values:  loss  - [[0.3615]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0179]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2241]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0501]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0694]]\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3615 - rpn_class_loss: 0.0179 - rpn_bbox_loss: 0.2241 - mrcnn_class_loss: 0.0501 - mrcnn_bbox_loss: 0.0694callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1445]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0246]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0868]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.457]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2011]]\n",
      " generic_utils.(332) values:  loss  - [[0.457]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0246]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2011]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1445]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0868]]\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 0.4092 - rpn_class_loss: 0.0212 - rpn_bbox_loss: 0.2126 - mrcnn_class_loss: 0.0973 - mrcnn_bbox_loss: 0.0781callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0568]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0215]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0363]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3321]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2175]]\n",
      " generic_utils.(332) values:  loss  - [[0.3321]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0215]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2175]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0568]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0363]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3835 - rpn_class_loss: 0.0213 - rpn_bbox_loss: 0.2142 - mrcnn_class_loss: 0.0838 - mrcnn_bbox_loss: 0.0642callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.2586]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0148]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0843]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5546]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.197]]\n",
      " generic_utils.(332) values:  loss  - [[0.5546]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.197]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.2586]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0843]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.4263 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.2099 - mrcnn_class_loss: 0.1275 - mrcnn_bbox_loss: 0.0692callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0888]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0162]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0277]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2845]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1519]]\n",
      " generic_utils.(332) values:  loss  - [[0.2845]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0162]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1519]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0888]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0277]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.3979 - rpn_class_loss: 0.0190 - rpn_bbox_loss: 0.1983 - mrcnn_class_loss: 0.1198 - mrcnn_bbox_loss: 0.0609callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0022]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0051]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0284]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1684]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1327]]\n",
      " generic_utils.(332) values:  loss  - [[0.1684]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0051]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1327]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0022]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0284]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3597 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.1874 - mrcnn_class_loss: 0.1002 - mrcnn_bbox_loss: 0.0555callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0533]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0148]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0539]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.315]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.193]]\n",
      " generic_utils.(332) values:  loss  - [[0.315]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0148]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.193]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0533]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0539]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3533 - rpn_class_loss: 0.0164 - rpn_bbox_loss: 0.1882 - mrcnn_class_loss: 0.0935 - mrcnn_bbox_loss: 0.0553callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0822]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0089]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0356]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.2406]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1139]]\n",
      " generic_utils.(332) values:  loss  - [[0.2406]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1139]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0822]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0356]]\n",
      " generic_utils.(332) values:  loss  - [[0.3392]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0155]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1789]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0921]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0528]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1659]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0415]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0459]]\n",
      "8/8 [==============================] - 3s 406ms/step - loss: 0.3392 - rpn_class_loss: 0.0155 - rpn_bbox_loss: 0.1789 - mrcnn_class_loss: 0.0921 - mrcnn_bbox_loss: 0.0528 - val_loss: 0.1659 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0415 - val_mrcnn_bbox_loss: 0.0459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00589: val_loss did not improve\n",
      "Epoch 590/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.084]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.039]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.1372]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.5661]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3059]]\n",
      " generic_utils.(332) values:  loss  - [[0.5661]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.039]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3059]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.084]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.1372]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.5661 - rpn_class_loss: 0.0390 - rpn_bbox_loss: 0.3059 - mrcnn_class_loss: 0.0840 - mrcnn_bbox_loss: 0.1372callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0867]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0269]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0641]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4509]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2732]]\n",
      " generic_utils.(332) values:  loss  - [[0.4509]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0269]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2732]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0867]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0641]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.5085 - rpn_class_loss: 0.0330 - rpn_bbox_loss: 0.2896 - mrcnn_class_loss: 0.0854 - mrcnn_bbox_loss: 0.1007callbacks (228): Baselogger: on_batch_end() callback  6\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1181]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0262]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0773]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4423]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2207]]\n",
      " generic_utils.(332) values:  loss  - [[0.4423]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0262]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2207]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1181]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0773]]\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 0.4865 - rpn_class_loss: 0.0307 - rpn_bbox_loss: 0.2666 - mrcnn_class_loss: 0.0963 - mrcnn_bbox_loss: 0.0929callbacks (228): Baselogger: on_batch_end() callback  8\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0576]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 3\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0134]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0874]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4744]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.3161]]\n",
      " generic_utils.(332) values:  loss  - [[0.4744]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0134]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.3161]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0576]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0874]]\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.4835 - rpn_class_loss: 0.0264 - rpn_bbox_loss: 0.2790 - mrcnn_class_loss: 0.0866 - mrcnn_bbox_loss: 0.0915callbacks (228): Baselogger: on_batch_end() callback  10\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0812]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 4\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0019]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.018]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1569]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0559]]\n",
      " generic_utils.(332) values:  loss  - [[0.1569]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0019]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0559]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0812]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.018]]\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.4181 - rpn_class_loss: 0.0215 - rpn_bbox_loss: 0.2344 - mrcnn_class_loss: 0.0855 - mrcnn_bbox_loss: 0.0768callbacks (228): Baselogger: on_batch_end() callback  12\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0705]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 5\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0162]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0268]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4039]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.2905]]\n",
      " generic_utils.(332) values:  loss  - [[0.4039]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0162]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2905]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0705]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0268]]\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.4158 - rpn_class_loss: 0.0206 - rpn_bbox_loss: 0.2437 - mrcnn_class_loss: 0.0830 - mrcnn_bbox_loss: 0.0685callbacks (228): Baselogger: on_batch_end() callback  14\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.048]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 6\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0084]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.095]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.3363]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.185]]\n",
      " generic_utils.(332) values:  loss  - [[0.3363]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0084]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.185]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.048]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.095]]\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4044 - rpn_class_loss: 0.0188 - rpn_bbox_loss: 0.2353 - mrcnn_class_loss: 0.0780 - mrcnn_bbox_loss: 0.0723callbacks (228): Baselogger: on_batch_end() callback  16\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.1118]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 7\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0268]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.103]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.4337]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.1921]]\n",
      " generic_utils.(332) values:  loss  - [[0.4337]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0268]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.1921]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.1118]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.103]]\n",
      " generic_utils.(332) values:  loss  - [[0.4081]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0198]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.2299]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0822]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0761]]\n",
      " generic_utils.(332) values:  val_loss  - [[0.1643]]\n",
      " generic_utils.(332) values:  val_rpn_class_loss  - [[0.0089]]\n",
      " generic_utils.(332) values:  val_rpn_bbox_loss  - [[0.0696]]\n",
      " generic_utils.(332) values:  val_mrcnn_class_loss  - [[0.0633]]\n",
      " generic_utils.(332) values:  val_mrcnn_bbox_loss  - [[0.0225]]\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.4081 - rpn_class_loss: 0.0198 - rpn_bbox_loss: 0.2299 - mrcnn_class_loss: 0.0822 - mrcnn_bbox_loss: 0.0761 - val_loss: 0.1643 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.0696 - val_mrcnn_class_loss: 0.0633 - val_mrcnn_bbox_loss: 0.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00590: val_loss did not improve\n",
      "Epoch 591/866\n",
      "callbacks (228): Baselogger: on_batch_end() callback  2\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0338]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 0\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0141]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0315]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.1585]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.0791]]\n",
      " generic_utils.(332) values:  loss  - [[0.1585]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0141]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.0791]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0338]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0315]]\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.1585 - rpn_class_loss: 0.0141 - rpn_bbox_loss: 0.0791 - mrcnn_class_loss: 0.0338 - mrcnn_bbox_loss: 0.0315callbacks (228): Baselogger: on_batch_end() callback  4\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_class_loss   v: [[0.0501]]\n",
      "    on_batch_end (229):  logs.items() k:  batch   v: 1\n",
      "    on_batch_end (229):  logs.items() k:  size   v: 2\n",
      "    on_batch_end (229):  logs.items() k:  rpn_class_loss   v: [[0.0415]]\n",
      "    on_batch_end (229):  logs.items() k:  mrcnn_bbox_loss   v: [[0.0583]]\n",
      "    on_batch_end (229):  logs.items() k:  loss   v: [[0.8488]]\n",
      "    on_batch_end (229):  logs.items() k:  rpn_bbox_loss   v: [[0.6988]]\n",
      " generic_utils.(332) values:  loss  - [[0.8488]]\n",
      " generic_utils.(332) values:  rpn_class_loss  - [[0.0415]]\n",
      " generic_utils.(332) values:  rpn_bbox_loss  - [[0.6988]]\n",
      " generic_utils.(332) values:  mrcnn_class_loss  - [[0.0501]]\n",
      " generic_utils.(332) values:  mrcnn_bbox_loss  - [[0.0583]]\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.5036 - rpn_class_loss: 0.0278 - rpn_bbox_loss: 0.3889 - mrcnn_class_loss: 0.0420 - mrcnn_bbox_loss: 0.0449"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b344c3cae5f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#             epochs_to_run =2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mloss_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             )\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, layers, losses, epochs, epochs_to_run, batch_size, steps_per_epoch, min_lr)\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# max(self.config.BATCH_SIZE // 2, 2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m         )\n\u001b[0;32m   1342\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2263\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2265\u001b[0m                     \u001b[1;31m# print(' Training.fit_generator(2265) ---------self.train_on_batch complete -----------------')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[1;31m# print(' Training.train_on_batch() (1906) outputs: ', type(outputs) , ' len: ', len(outputs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2482\u001b[0m         \u001b[1;31m# pp.pprint(self.session_kwargs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2484\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# Wed 09-05-2018\n",
    "# train_layers = ['mrcnn', 'fpn','rpn']\n",
    "# loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\", \"mrcnn_mask_loss\"]\n",
    "train_layers = ['mrcnn', 'fpn','rpn']\n",
    "loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\" ]\n",
    "config.STEPS_PER_EPOCH        = 8\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs_to_run = config.EPOCHS_TO_RUN,\n",
    "#             epochs = 2500,\n",
    "#             epochs_to_run =2, \n",
    "            layers = train_layers,\n",
    "            losses= loss_names\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Data Generators, get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:38.990259Z",
     "start_time": "2018-04-24T08:34:38.775686Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:39.932764Z",
     "start_time": "2018-04-24T08:34:39.594865Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:44.086847Z",
     "start_time": "2018-04-24T08:34:42.367242Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:35:18.936161Z",
     "start_time": "2018-04-24T08:35:09.103385Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:26:11.099812Z",
     "start_time": "2018-05-09T15:26:10.868655Z"
    }
   },
   "outputs": [],
   "source": [
    "input_gt_class_ids = train_batch_x[4]\n",
    "\n",
    "target_class_ids = layers_out[5]\n",
    "mrcnn_class_logits = layers_out[9]\n",
    "rpn_class_loss   = layers_out[13]\n",
    "rpn_bbox_loss    = layers_out[14]\n",
    "mrcnn_class_loss = layers_out[15]\n",
    "mrcnn_bbox_loss  = layers_out[16]\n",
    "mrcnn_mask_loss  = layers_out[17]\n",
    "active_class_ids = layers_out[20]\n",
    "# pred_masks = tf.identity(layers_out[18])\n",
    "# gt_masks   = tf.identity(layers_out[19])\n",
    "\n",
    "# shape = KB.int_shape(pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:34:22.819601Z",
     "start_time": "2018-05-09T15:34:22.573917Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rpn_class_loss, rpn_bbox_loss)\n",
    "print(mrcnn_class_loss, mrcnn_bbox_loss, mrcnn_mask_loss)\n",
    "print(active_class_ids)\n",
    "print()\n",
    "print(target_class_ids[1])\n",
    "print()\n",
    "print(mrcnn_class_logits[1])\n",
    "print('gt class ids')\n",
    "print(input_gt_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulate `mrcnn_class_loss` computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:33:24.601046Z",
     "start_time": "2018-05-09T15:33:24.109710Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n>>> mrcnn_class_loss_graph ' )\n",
    "print('    target_class_ids  size :', target_class_ids.shape)\n",
    "print('    pred_class_logits size :', mrcnnpred_class_logits.shape)\n",
    "print('    active_class_ids  size :', active_class_ids.shape)    \n",
    "target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "\n",
    "# Find predictions of classes that are not in the dataset.\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "\n",
    "# TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "#       images in a batch have the same active_class_ids\n",
    "pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "# Loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "# Erase losses of predictions of classes that are not in the active\n",
    "# classes of the image.\n",
    "loss = loss * pred_active\n",
    "\n",
    "# Computer loss mean. Use only predictions that contribute\n",
    "# to the loss to get a correct mean.\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "loss = KB.reshape(loss, [1, 1])\n",
    "return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:12:08.337002Z",
     "start_time": "2018-04-24T12:12:02.738105Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[21]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 2\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:09:41.413073Z",
     "start_time": "2018-04-24T12:09:35.664779Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline\n",
    "img = 2\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "Zout  = layers_out[21]     # gt_gaussiam \n",
    "Zout2 = layers_out[12]     # fcn_bilinear\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GroundTruth - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'FCN_Bilinear- image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:34:26.381655Z",
     "start_time": "2018-04-24T12:34:25.980564Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[0:2,2:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:49:29.945015Z",
     "start_time": "2018-04-24T13:49:29.457701Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 1 # <==== Class to display\n",
    "pred_tensor = layers_out[19]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:39:14.676360Z",
     "start_time": "2018-04-24T12:39:14.435714Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[0][0] * [128, 128,128,128]   #output_rois*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:03:44.110249Z",
     "start_time": "2018-04-24T15:03:38.231280Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]\n",
    "target_masks        = layers_out[27][0:3]\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print(tf.shape(less_than_one).eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean values of GT, Pred, and FCN heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:52:02.002508Z",
     "start_time": "2018-04-24T14:51:42.964543Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "pred_masks = tf.identity(layers_out[24])\n",
    "gt_masks = tf.identity(layers_out[27])\n",
    "fcn_masks = tf.identity(layers_out[12])\n",
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        gt_mean = K.mean(gt_masks[img,:,:,cls])\n",
    "        fcn_mean= K.mean(fcn_masks[img,:,:,cls])\n",
    "        pred_mean= K.mean(pred_masks[img,:,:,cls])\n",
    "        print('Img/Cls: ', img, '/', cls,'    gtmean: ', gt_mean.eval(), '\\t fcn : ' , fcn_mean.eval(), '\\t pred :', pred_mean.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:56:40.181058Z",
     "start_time": "2018-04-24T09:56:39.956461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 0\n",
    "fcn_out = layers_out[12][img]\n",
    "fcn_sum = np.sum(fcn_out, axis=(0,1))\n",
    "print(fcn_sum)\n",
    "for cls in range(4):\n",
    "    print('min :', np.min(fcn_out[:,:,cls]), 'max :', np.max(fcn_out[:,:,cls]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:55:21.917361Z",
     "start_time": "2018-04-23T20:55:21.676734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_batch_x[4][2])\n",
    "print(train_batch_x[5][2]/[128,128,128,128])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
