{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on NewShapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:42:10.695087Z",
     "start_time": "2018-07-01T19:41:25.093051Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " windows  Windows\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " Min Shapes Per Image:  1\n",
      " Max Shapes Per Image:  15\n",
      " Min Shapes Per Image:  1\n",
      " Max Shapes Per Image:  15\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\newshape_fcn\\shapes20180701T2141\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     C1 Shape: (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "     C2 Shape:  (?, 32, 32, 256) (?, 32, 32, 256)\n",
      "     C3 Shape:  (?, 16, 16, 512) (?, 16, 16, 512)\n",
      "     C4 Shape:  (?, 8, 8, 1024) (?, 8, 8, 1024)\n",
      "     C5 Shape:  (?, 4, 4, 2048) (?, 4, 4, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (2, 4092)\n",
      "     Deltas :  (2, 4092, 4)\n",
      "     Anchors:  (2, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (2, ?, ?) (2, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (2, ?, ?) (2, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (2, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (2, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (2, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 7)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 7)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 28)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 7, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 7) (None, 32, 7)\n",
      "     mrcnn_bbox.shape     : (?, 32, 7, 4) (None, 32, 7, 4)\n",
      "     output_rois.shape    : (2, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (2, ?) (None, 32)\n",
      "     gt_bboxes.shape      : (2, ?, ?) (None, 32, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 7)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 7, 4) (?, 32, 7, 4)\n",
      "    input_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (2, None, 4)\n",
      "    pred_array        (2, 32, 6)\n",
      "scatter_ind <class 'tensorflow.python.framework.ops.Tensor'> shape (2, 32, 3)\n",
      "    pred_scatter shape is  (2, 7, 32, 6)\n",
      "(2, 7, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "\n",
      "    num_rois           :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape :  (2, ?)\n",
      "    gt_bboxes.shape    :  (2, ?, 4)\n",
      "    gt_classes_exp shape  (2, ?, 1)\n",
      "    gt_scores_exp shape  (2, ?, 1)\n",
      "    gt_array shape : (2, 32, 7) (2, 32, 7)\n",
      "     gt_tensor final shape  :  (2, 7, 32, ?)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (2, 7, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (2, 7, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (2, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (2, 7, 128, 128) Keras tensor  False\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "    gauss L2 norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (2, 7, 32, 6)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (2, 7, 128, 128)\n",
      "    heatmap replicated      :  (2, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (448, 128, 128)\n",
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (448, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (2, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (2, 7, 32, ?)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (2, 7, 32)\n",
      "    dense shape  (?, ?)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (2, 7, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (2, 7, 128, 128) Keras tensor  False\n",
      "    gauss L2 norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    gauss norm   :  (2, 7, 128, 128)  Keras tensor  False\n",
      "    in_tensor                (2, 7, 32, ?)\n",
      "    in_tensorr_flattened is  (?, ?)\n",
      "    boxes shape              (?, ?)\n",
      "    Rois per image        :  32\n",
      "    heatmap original shape  :  (2, 7, 128, 128)\n",
      "    heatmap replicated      :  (2, 7, 32, 128, 128)\n",
      "    heatmap flattened       :  (448, 128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    in_tensor_flattened     :  (?, ?)\n",
      "    Scores shape            :  (448, 3)\n",
      "    boxes_scores (rehspaed) :  (?, ?, ?, ?)\n",
      "    gauss_heatmap final shape :  (2, 128, 128, 7)  Keras tensor  False\n",
      "    gauss_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "     pred_cls_cnt shape :  (2, 7) Keras tensor  True\n",
      "     gt_cls_cnt shape   :  (2, 7) Keras tensor  True\n",
      "     pred_heatmap_norm  :  (2, 128, 128, 7) Keras tensor  False\n",
      "     pred_heatmap_scores:  (?, ?, ?, ?) Keras tensor  False\n",
      "     gt_heatmap_norm    :  (2, 128, 128, 7) Keras tensor  False\n",
      "     gt_heatmap_scores  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (2, 128, 128, 7)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (2, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    Adding  FCN layers\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (2, 128, 128, 7)\n",
      "     height : 128 width : 128 classes : 7\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (2, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (2, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (2, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (2, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (2, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (2, 32, 32, 128)\n",
      "   FCN Block 31 shape is :  (2, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (2, 32, 32, 256)\n",
      "   FCN Block 33 shape is :  (2, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (2, 16, 16, 256)\n",
      "   FCN Block 41 shape is :  (2, 16, 16, 512)\n",
      "   FCN Block 42 shape is :  (2, 16, 16, 512)\n",
      "   FCN Block 43 shape is :  (2, 16, 16, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (2, 8, 8, 512)\n",
      "   FCN Block 51 shape is :  (2, 8, 8, 512)\n",
      "   FCN Block 52 shape is :  (2, 8, 8, 512)\n",
      "   FCN Block 53 shape is :  (2, 8, 8, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (2, 4, 4, 512)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (2, 4, 4, 2048)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (2, 4, 4, 2048)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (2, 4, 4, 7)  keras_tensor  True\n",
      "   h_factor :  32.0 w_factor :  32.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (32.0, 32.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (32.0, 32.0)\n",
      "     CHANNELS LAST: X:  (2, 4, 4, 7)  KB.int_shape() :  (None, 4, 4, 7)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (2, ?, ?, 7)\n",
      "     Dimensions of X after set_shape() :  (2, 128, 128, 7)\n",
      "     BilinearUpSampling2D. compute_output_shape()\n",
      "     Bilinear output shape is: None , 128 , 128 , 7\n",
      "   FCN Bilinear upsmapling layer  shape is :  (2, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "     size of reduce max is  (2, 1, 1, 7)\n",
      "     size of y is :  (2, 128, 128, 7)\n",
      "     size of reduce max is  (?, 1, 1, 7)\n",
      "     size of y is :  (?, 128, 128, 7)\n",
      "    fcn_heatmap       :  (2, 128, 128, 7)  Keras tensor  True\n",
      "    fcn_heatmap_norm  :  (2, 128, 128, 7)  Keras tensor  True\n",
      "    fcn_heatmap_L2norm:  (2, 128, 128, 7)  Keras tensor  True\n",
      "   fcn_heatmap      :  (None, 128, 128, 7)  Keras tensor  True\n",
      "   fcn_heatmap_norm :  (None, 128, 128, 7)  Keras tensor  True\n",
      "\n",
      ">>> FCN Scoring Layer \n",
      "   > FCNScoreLayer Call()  2\n",
      "     fcn_heatmap.shape    : (2, 128, 128, 7) (None, 128, 128, 7)\n",
      "      chm_scores.shape    : (?, ?, ?, ?) (None, 7, 32, 11)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  <mrcnn.new_shapes.NewShapesConfig object at 0x0000019F52202EF0>\n",
      "    orignal in_heatmap shape :  (2, 128, 128, 7)\n",
      "    num of bboxes per class is :  32\n",
      "    Rois per image  :  32\n",
      "    heatmap original shape   :  (2, 128, 128, 7)\n",
      "    heatmap transposed shape : (2, 7, 128, 128)\n",
      "    heatmap tiled            :  (2, 7, 32, 128, 128)\n",
      "    fcn_scores  final shape :  (?, ?, ?, ?)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    Output build_fcn_score \n",
      "     pred_heatmap_norm  :  (?, ?, ?, ?) Keras tensor  False\n",
      "     complete\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_scores shape : (?, ?, ?)\n",
      "    pred_scores   shape : (?, ?, ?)\n",
      "    target_scores1 shape : (?, 1) (None, 1)\n",
      "    pred_scores1  shape : (?, 1)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_scores shape : (?, 7, 100)\n",
      "    pred_scores   shape : (?, 7, 32)\n",
      "    target_scores1 shape : (?, 1) (None, 1)\n",
      "    pred_scores1  shape : (?, 1)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (2, ?)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (2, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      " Keras Tensors?? \n",
      " output_rois : True\n",
      " pr_hm       : True\n",
      " gt_heatmap  : True\n",
      " ================================================================\n",
      " self.keras_model.losses :  6\n",
      "[<tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>]\n",
      " ================================================================\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n",
      "MODEL_PATH        :  E:\\models\n",
      "COCO_MODEL_PATH   :  E:\\models\\mask_rcnn_coco.h5\n",
      "RESNET_MODEL_PATH :  E:\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "CHECKPOINT_DIR    :  E:\\models\\newshape_fcn\n",
      ">>> find_last checkpoint in :  E:\\models\\newshape_fcn\n",
      "Last Saved Model  :  ('E:\\\\models\\\\newshape_fcn\\\\shapes20180621T1554', 'E:\\\\models\\\\newshape_fcn\\\\shapes20180621T1554\\\\mask_rcnn_shapes_0581.h5')\n",
      "-----------------------------------------------\n",
      " Load model with init parm:  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      " Eclude layers: \n",
      "None\n",
      "-----------------------------------------------\n",
      "Loading weights from  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      " List of all Layers  \n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      ">layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x0000019F5B808F60>\n",
      ">layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x0000019F5ECFE550>\n",
      ">layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x0000019F5ECF3198>\n",
      ">layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ECDA828>\n",
      ">layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x0000019F5ED18DD8>\n",
      ">layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F5ED34EF0>\n",
      ">layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5ED3DFD0>\n",
      ">layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ED58198>\n",
      ">layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x0000019F5ED903C8>\n",
      ">layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EDA65F8>\n",
      ">layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ED9C8D0>\n",
      ">layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x0000019F5EDDAE48>\n",
      ">layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EDF8978>\n",
      ">layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EE36C50>\n",
      ">layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE059E8>\n",
      ">layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE53E48>\n",
      ">layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x0000019F5EE76710>\n",
      ">layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x0000019F5EE85E10>\n",
      ">layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EE85E48>\n",
      ">layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE9C3C8>\n",
      ">layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x0000019F5EEE0D30>\n",
      ">layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EF18C50>\n",
      ">layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EF23A20>\n",
      ">layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x0000019F5EF567B8>\n",
      ">layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EF82E48>\n",
      ">layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EF82E10>\n",
      ">layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x0000019F5EF97D30>\n",
      ">layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x0000019F5EFC1CC0>\n",
      ">layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EFC1D30>\n",
      ">layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EFE6390>\n",
      ">layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x0000019F5EFFEC88>\n",
      ">layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F050C50>\n",
      ">layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F046F28>\n",
      ">layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x0000019F5F05FE48>\n",
      ">layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F0A4390>\n",
      ">layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F0944E0>\n",
      ">layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x0000019F5F0DFA90>\n",
      ">layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F10A6A0>\n",
      ">layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F10AB38>\n",
      ">layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F116A90>\n",
      ">layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x0000019F5F123B38>\n",
      ">layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F169F60>\n",
      ">layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F15BF28>\n",
      ">layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x0000019F5F18CEB8>\n",
      ">layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F1A8C18>\n",
      ">layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F201EF0>\n",
      ">layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F1B8B38>\n",
      ">layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F22BA90>\n",
      ">layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x0000019F5F213588>\n",
      ">layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F244F60>\n",
      ">layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F244D68>\n",
      ">layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F289D30>\n",
      ">layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x0000019F5F2AEF28>\n",
      ">layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F2E2748>\n",
      ">layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F2ED780>\n",
      ">layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x0000019F5F323710>\n",
      ">layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F34BC50>\n",
      ">layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F34BAC8>\n",
      ">layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x0000019F5F363CF8>\n",
      ">layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F38BD30>\n",
      ">layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F38BDA0>\n",
      ">layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F3C0780>\n",
      ">layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x0000019F5F3CB6A0>\n",
      ">layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F41ABE0>\n",
      ">layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F40FE10>\n",
      ">layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x0000019F5F427390>\n",
      ">layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F44EDA0>\n",
      ">layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F46F390>\n",
      ">layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x0000019F5F4AABA8>\n",
      ">layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F4D37B8>\n",
      ">layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F4D3C50>\n",
      ">layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F4E0780>\n",
      ">layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x0000019F5F4EBD68>\n",
      ">layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F530EF0>\n",
      ">layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F525DD8>\n",
      ">layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x0000019F6053BA90>\n",
      ">layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60566240>\n",
      ">layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6055D128>\n",
      ">layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x0000019F6059C5F8>\n",
      ">layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x0000019F605C4E80>\n",
      ">layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F605B7F60>\n",
      ">layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F605F56D8>\n",
      ">layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x0000019F605DC390>\n",
      ">layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60603E48>\n",
      ">layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60614B00>\n",
      ">layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x0000019F6065DEF0>\n",
      ">layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6067DBE0>\n",
      ">layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F606A0F98>\n",
      ">layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60689A90>\n",
      ">layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F606D85F8>\n",
      ">layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x0000019F60721A58>\n",
      ">layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x0000019F6074BF60>\n",
      ">layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6074B9B0>\n",
      ">layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6075A828>\n",
      ">layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x0000019F60762828>\n",
      ">layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6079A898>\n",
      ">layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F607A9EF0>\n",
      ">layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x0000019F607BECF8>\n",
      ">layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60806668>\n",
      ">layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F607E5DA0>\n",
      ">layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x0000019F60842CC0>\n",
      ">layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x0000019F6086AE10>\n",
      ">layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6086A860>\n",
      ">layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6085EBA8>\n",
      ">layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x0000019F60885E80>\n",
      ">layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F608BE358>\n",
      ">layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F608C8748>\n",
      ">layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x0000019F60906BA8>\n",
      ">layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6092E588>\n",
      ">layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60926240>\n",
      ">layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x0000019F60965FD0>\n",
      ">layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x0000019F6098EBE0>\n",
      ">layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6098ECC0>\n",
      ">layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6097FCF8>\n",
      ">layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x0000019F609CFFD0>\n",
      ">layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F609F51D0>\n",
      ">layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F609EA0B8>\n",
      ">layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x0000019F60A28780>\n",
      ">layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60A46240>\n",
      ">layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60A53BA8>\n",
      ">layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x0000019F60A6A358>\n",
      ">layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x0000019F60AA32B0>\n",
      ">layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60AA3BE0>\n",
      ">layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60A93E48>\n",
      ">layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x0000019F60AD3EB8>\n",
      ">layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60B16E80>\n",
      ">layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60B16A20>\n",
      ">layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x0000019F60B2FF60>\n",
      ">layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60B72E48>\n",
      ">layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60B675F8>\n",
      ">layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x0000019F60BB0A58>\n",
      ">layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x0000019F60BDA668>\n",
      ">layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60BDAB00>\n",
      ">layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60BE7A20>\n",
      ">layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x0000019F60BF3BA8>\n",
      ">layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60C37AC8>\n",
      ">layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60C37D30>\n",
      ">layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x0000019F60C5DE80>\n",
      ">layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60C75EF0>\n",
      ">layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60C9E710>\n",
      ">layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x0000019F60CCFE80>\n",
      ">layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x0000019F60CFAE10>\n",
      ">layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60CEFD68>\n",
      ">layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60CFAA20>\n",
      ">layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x0000019F60D13FD0>\n",
      ">layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60D63E10>\n",
      ">layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60D3CCC0>\n",
      ">layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x0000019F60D95D30>\n",
      ">layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60DCA0B8>\n",
      ">layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F60DF1C50>\n",
      ">layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60DBE8D0>\n",
      ">layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60E10EB8>\n",
      ">layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x0000019F60E6BC18>\n",
      ">layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x0000019F60E411D0>\n",
      ">layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60E41E48>\n",
      ">layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60EA9F60>\n",
      ">layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x0000019F60E996A0>\n",
      ">layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60EEABE0>\n",
      ">layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60EDED68>\n",
      ">layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x0000019F60EF6390>\n",
      ">layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60F3D748>\n",
      ">layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60F31BE0>\n",
      ">layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x0000019F60F78B38>\n",
      ">layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x0000019F60FA0748>\n",
      ">layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60FA0BE0>\n",
      ">layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60FAFB70>\n",
      ">layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x0000019F60FBCCC0>\n",
      ">layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60FF2D68>\n",
      ">layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F61000F28>\n",
      ">layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x0000019F6103CA20>\n",
      ">layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F610651D0>\n",
      ">layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6105B0B8>\n",
      ">layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x0000019F6109BF98>\n",
      ">layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x0000019F610C5D68>\n",
      ">layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F610B5E80>\n",
      ">layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F610DC0F0>\n",
      ">layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F610DCF28>\n",
      ">layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x0000019F610C5B38>\n",
      ">layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F6112C630>\n",
      ">layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F6112C5C0>\n",
      ">layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x0000019F61105C18>\n",
      ">layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F61150940>\n",
      ">layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F61150DD8>\n",
      ">layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x0000019F61161FD0>\n",
      ">layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F611E6978>\n",
      ">layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F6119DE48>\n",
      ">layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F61184D68>\n",
      ">layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F611D0D68>\n",
      ">layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F61216400>\n",
      ">layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x0000019F612F6B00>\n",
      ">layer 190 : name : rpn_class                                 type: <keras.layers.core.Lambda object at 0x0000019F6135FE10>\n",
      ">layer 191 : name : rpn_bbox                                  type: <keras.layers.core.Lambda object at 0x0000019F6135FA58>\n",
      ">layer 192 : name : input_gt_boxes                            type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDAA90>\n",
      ">layer 193 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x0000019F613445F8>\n",
      ">layer 194 : name : input_gt_class_ids                        type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDA160>\n",
      ">layer 195 : name : lambda_1                                  type: <keras.layers.core.Lambda object at 0x0000019F5ECFEA90>\n",
      ">layer 196 : name : proposal_targets                          type: <mrcnn.detect_tgt_layer_mod.DetectionTargetLayer_mod object at 0x0000019F61604A20>\n",
      ">layer 197 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x0000019F6199EA90>\n",
      ">layer 198 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62153B38>\n",
      ">layer 199 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F6224EC50>\n",
      ">layer 200 : name : activation_34                             type: <keras.layers.core.Activation object at 0x0000019F622E6CC0>\n",
      ">layer 201 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F622B2828>\n",
      ">layer 202 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F6230FC50>\n",
      ">layer 203 : name : activation_35                             type: <keras.layers.core.Activation object at 0x0000019F6231DFD0>\n",
      ">layer 204 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x0000019F62328EF0>\n",
      ">layer 205 : name : time_distributed_1                        type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62336EB8>\n",
      ">layer 206 : name : mrcnn_class_logits                        type: <keras.layers.core.Lambda object at 0x0000019F623368D0>\n",
      ">layer 207 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62384B70>\n",
      ">layer 208 : name : time_distributed_2                        type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62336E10>\n",
      ">layer 209 : name : reshape_1                                 type: <keras.layers.core.Reshape object at 0x0000019F623BA128>\n",
      ">layer 210 : name : mrcnn_class                               type: <keras.layers.core.Lambda object at 0x0000019F62336FD0>\n",
      ">layer 211 : name : mrcnn_bbox_regression                     type: <keras.layers.core.Lambda object at 0x0000019F62384A90>\n",
      ">layer 212 : name : cntxt_layer                               type: <mrcnn.chm_layer.CHMLayer object at 0x0000019F623D2DD8>\n",
      ">layer 213 : name : fcn_block1_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F62384668>\n",
      ">layer 214 : name : fcn_block1_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640056D8>\n",
      ">layer 215 : name : fcn_block1_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F640267F0>\n",
      ">layer 216 : name : fcn_block2_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F63E174E0>\n",
      ">layer 217 : name : fcn_block2_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64041C18>\n",
      ">layer 218 : name : fcn_block2_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F6407FCF8>\n",
      ">layer 219 : name : fcn_block3_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F6405A9E8>\n",
      ">layer 220 : name : fcn_block3_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640997B8>\n",
      ">layer 221 : name : fcn_block3_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640D4978>\n",
      ">layer 222 : name : fcn_block3_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F640EF630>\n",
      ">layer 223 : name : fcn_block4_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640E3048>\n",
      ">layer 224 : name : fcn_block4_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64154898>\n",
      ">layer 225 : name : fcn_block4_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F6412FD68>\n",
      ">layer 226 : name : fcn_block4_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F6416D160>\n",
      ">layer 227 : name : fcn_block5_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64195828>\n",
      ">layer 228 : name : fcn_block5_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F641D6780>\n",
      ">layer 229 : name : fcn_block5_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F641E2F28>\n",
      ">layer 230 : name : fcn_block5_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F64216A90>\n",
      ">layer 231 : name : fcn_fc1                                   type: <keras.layers.convolutional.Conv2D object at 0x0000019F642221D0>\n",
      ">layer 232 : name : dropout_1                                 type: <keras.layers.core.Dropout object at 0x0000019F6427DE80>\n",
      ">layer 233 : name : fcn_fc2                                   type: <keras.layers.convolutional.Conv2D object at 0x0000019F6427DF28>\n",
      ">layer 234 : name : dropout_2                                 type: <keras.layers.core.Dropout object at 0x0000019F642B9B00>\n",
      ">layer 235 : name : fcn_classify                              type: <keras.layers.convolutional.Conv2D object at 0x0000019F642F7A90>\n",
      ">layer 236 : name : fcn_bilinear                              type: <mrcnn.BilinearUpSampling.BilinearUpSampling2D object at 0x0000019F6430CC88>\n",
      ">layer 237 : name : input_image_meta                          type: <keras.engine.topology.InputLayer object at 0x0000019F5D7A8E80>\n",
      ">layer 238 : name : fcn_heatmap_norm                          type: <keras.layers.core.Lambda object at 0x0000019F6432A898>\n",
      ">layer 239 : name : rpn_class_logits                          type: <keras.layers.core.Lambda object at 0x0000019F6135F780>\n",
      ">layer 240 : name : input_rpn_match                           type: <keras.engine.topology.InputLayer object at 0x0000019F58E8A630>\n",
      ">layer 241 : name : input_rpn_bbox                            type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDA048>\n",
      ">layer 242 : name : lambda_4                                  type: <keras.layers.core.Lambda object at 0x0000019F61518E48>\n",
      ">layer 243 : name : fcn_scoring                               type: <mrcnn.fcn_scoring_layer.FCNScoringLayer object at 0x0000019F643B9908>\n",
      ">layer 244 : name : rpn_class_loss                            type: <keras.layers.core.Lambda object at 0x0000019F64566BE0>\n",
      ">layer 245 : name : rpn_bbox_loss                             type: <keras.layers.core.Lambda object at 0x0000019F64629A90>\n",
      ">layer 246 : name : mrcnn_class_loss                          type: <keras.layers.core.Lambda object at 0x0000019F646DFA90>\n",
      ">layer 247 : name : mrcnn_bbox_loss                           type: <keras.layers.core.Lambda object at 0x0000019F647DAD30>\n",
      ">layer 248 : name : fcn_heatmap                               type: <keras.layers.core.Lambda object at 0x0000019F643535C0>\n",
      ">layer 249 : name : fcn_norm_loss                             type: <keras.layers.core.Lambda object at 0x0000019F642C74E0>\n",
      "----------------\n",
      " layers to load \n",
      "----------------\n",
      ">layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x0000019F5B808F60>\n",
      ">layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x0000019F5ECFE550>\n",
      ">layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x0000019F5ECF3198>\n",
      ">layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ECDA828>\n",
      ">layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x0000019F5ED18DD8>\n",
      ">layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F5ED34EF0>\n",
      ">layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5ED3DFD0>\n",
      ">layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ED58198>\n",
      ">layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x0000019F5ED903C8>\n",
      ">layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EDA65F8>\n",
      ">layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5ED9C8D0>\n",
      ">layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x0000019F5EDDAE48>\n",
      ">layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EDF8978>\n",
      ">layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EE36C50>\n",
      ">layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE059E8>\n",
      ">layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE53E48>\n",
      ">layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x0000019F5EE76710>\n",
      ">layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x0000019F5EE85E10>\n",
      ">layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EE85E48>\n",
      ">layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EE9C3C8>\n",
      ">layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x0000019F5EEE0D30>\n",
      ">layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EF18C50>\n",
      ">layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EF23A20>\n",
      ">layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x0000019F5EF567B8>\n",
      ">layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EF82E48>\n",
      ">layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EF82E10>\n",
      ">layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x0000019F5EF97D30>\n",
      ">layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x0000019F5EFC1CC0>\n",
      ">layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5EFC1D30>\n",
      ">layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5EFE6390>\n",
      ">layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x0000019F5EFFEC88>\n",
      ">layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F050C50>\n",
      ">layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F046F28>\n",
      ">layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x0000019F5F05FE48>\n",
      ">layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F0A4390>\n",
      ">layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F0944E0>\n",
      ">layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x0000019F5F0DFA90>\n",
      ">layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F10A6A0>\n",
      ">layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F10AB38>\n",
      ">layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F116A90>\n",
      ">layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x0000019F5F123B38>\n",
      ">layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F169F60>\n",
      ">layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F15BF28>\n",
      ">layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x0000019F5F18CEB8>\n",
      ">layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F1A8C18>\n",
      ">layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F201EF0>\n",
      ">layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F1B8B38>\n",
      ">layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F22BA90>\n",
      ">layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x0000019F5F213588>\n",
      ">layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F244F60>\n",
      ">layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F244D68>\n",
      ">layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F289D30>\n",
      ">layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x0000019F5F2AEF28>\n",
      ">layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F2E2748>\n",
      ">layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F2ED780>\n",
      ">layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x0000019F5F323710>\n",
      ">layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F34BC50>\n",
      ">layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F34BAC8>\n",
      ">layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x0000019F5F363CF8>\n",
      ">layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F38BD30>\n",
      ">layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F38BDA0>\n",
      ">layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F3C0780>\n",
      ">layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x0000019F5F3CB6A0>\n",
      ">layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F41ABE0>\n",
      ">layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F40FE10>\n",
      ">layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x0000019F5F427390>\n",
      ">layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F44EDA0>\n",
      ">layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F46F390>\n",
      ">layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x0000019F5F4AABA8>\n",
      ">layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x0000019F5F4D37B8>\n",
      ">layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F4D3C50>\n",
      ">layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F4E0780>\n",
      ">layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x0000019F5F4EBD68>\n",
      ">layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F5F530EF0>\n",
      ">layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F5F525DD8>\n",
      ">layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x0000019F6053BA90>\n",
      ">layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60566240>\n",
      ">layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6055D128>\n",
      ">layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x0000019F6059C5F8>\n",
      ">layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x0000019F605C4E80>\n",
      ">layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F605B7F60>\n",
      ">layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F605F56D8>\n",
      ">layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x0000019F605DC390>\n",
      ">layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60603E48>\n",
      ">layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60614B00>\n",
      ">layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x0000019F6065DEF0>\n",
      ">layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6067DBE0>\n",
      ">layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F606A0F98>\n",
      ">layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60689A90>\n",
      ">layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F606D85F8>\n",
      ">layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x0000019F60721A58>\n",
      ">layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x0000019F6074BF60>\n",
      ">layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6074B9B0>\n",
      ">layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6075A828>\n",
      ">layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x0000019F60762828>\n",
      ">layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6079A898>\n",
      ">layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F607A9EF0>\n",
      ">layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x0000019F607BECF8>\n",
      ">layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60806668>\n",
      ">layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F607E5DA0>\n",
      ">layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x0000019F60842CC0>\n",
      ">layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x0000019F6086AE10>\n",
      ">layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6086A860>\n",
      ">layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6085EBA8>\n",
      ">layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x0000019F60885E80>\n",
      ">layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F608BE358>\n",
      ">layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F608C8748>\n",
      ">layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x0000019F60906BA8>\n",
      ">layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6092E588>\n",
      ">layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60926240>\n",
      ">layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x0000019F60965FD0>\n",
      ">layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x0000019F6098EBE0>\n",
      ">layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F6098ECC0>\n",
      ">layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6097FCF8>\n",
      ">layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x0000019F609CFFD0>\n",
      ">layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F609F51D0>\n",
      ">layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F609EA0B8>\n",
      ">layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x0000019F60A28780>\n",
      ">layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60A46240>\n",
      ">layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60A53BA8>\n",
      ">layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x0000019F60A6A358>\n",
      ">layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x0000019F60AA32B0>\n",
      ">layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60AA3BE0>\n",
      ">layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60A93E48>\n",
      ">layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x0000019F60AD3EB8>\n",
      ">layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60B16E80>\n",
      ">layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60B16A20>\n",
      ">layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x0000019F60B2FF60>\n",
      ">layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60B72E48>\n",
      ">layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60B675F8>\n",
      ">layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x0000019F60BB0A58>\n",
      ">layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x0000019F60BDA668>\n",
      ">layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60BDAB00>\n",
      ">layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60BE7A20>\n",
      ">layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x0000019F60BF3BA8>\n",
      ">layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60C37AC8>\n",
      ">layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60C37D30>\n",
      ">layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x0000019F60C5DE80>\n",
      ">layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60C75EF0>\n",
      ">layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60C9E710>\n",
      ">layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x0000019F60CCFE80>\n",
      ">layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x0000019F60CFAE10>\n",
      ">layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60CEFD68>\n",
      ">layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60CFAA20>\n",
      ">layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x0000019F60D13FD0>\n",
      ">layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60D63E10>\n",
      ">layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60D3CCC0>\n",
      ">layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x0000019F60D95D30>\n",
      ">layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60DCA0B8>\n",
      ">layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000019F60DF1C50>\n",
      ">layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60DBE8D0>\n",
      ">layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60E10EB8>\n",
      ">layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x0000019F60E6BC18>\n",
      ">layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x0000019F60E411D0>\n",
      ">layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60E41E48>\n",
      ">layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60EA9F60>\n",
      ">layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x0000019F60E996A0>\n",
      ">layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60EEABE0>\n",
      ">layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60EDED68>\n",
      ">layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x0000019F60EF6390>\n",
      ">layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60F3D748>\n",
      ">layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60F31BE0>\n",
      ">layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x0000019F60F78B38>\n",
      ">layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x0000019F60FA0748>\n",
      ">layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60FA0BE0>\n",
      ">layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F60FAFB70>\n",
      ">layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x0000019F60FBCCC0>\n",
      ">layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F60FF2D68>\n",
      ">layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F61000F28>\n",
      ">layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x0000019F6103CA20>\n",
      ">layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000019F610651D0>\n",
      ">layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000019F6105B0B8>\n",
      ">layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x0000019F6109BF98>\n",
      ">layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x0000019F610C5D68>\n",
      ">layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F610B5E80>\n",
      ">layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F610DC0F0>\n",
      ">layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F610DCF28>\n",
      ">layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x0000019F610C5B38>\n",
      ">layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F6112C630>\n",
      ">layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F6112C5C0>\n",
      ">layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x0000019F61105C18>\n",
      ">layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x0000019F61150940>\n",
      ">layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x0000019F61150DD8>\n",
      ">layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x0000019F61161FD0>\n",
      ">layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F611E6978>\n",
      ">layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F6119DE48>\n",
      ">layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F61184D68>\n",
      ">layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x0000019F611D0D68>\n",
      ">layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F61216400>\n",
      ">layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x0000019F612F6B00>\n",
      ">layer 190 : name : rpn_class                                 type: <keras.layers.core.Lambda object at 0x0000019F6135FE10>\n",
      ">layer 191 : name : rpn_bbox                                  type: <keras.layers.core.Lambda object at 0x0000019F6135FA58>\n",
      ">layer 192 : name : input_gt_boxes                            type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDAA90>\n",
      ">layer 193 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x0000019F613445F8>\n",
      ">layer 194 : name : input_gt_class_ids                        type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDA160>\n",
      ">layer 195 : name : lambda_1                                  type: <keras.layers.core.Lambda object at 0x0000019F5ECFEA90>\n",
      ">layer 196 : name : proposal_targets                          type: <mrcnn.detect_tgt_layer_mod.DetectionTargetLayer_mod object at 0x0000019F61604A20>\n",
      ">layer 197 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x0000019F6199EA90>\n",
      ">layer 198 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62153B38>\n",
      ">layer 199 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F6224EC50>\n",
      ">layer 200 : name : activation_34                             type: <keras.layers.core.Activation object at 0x0000019F622E6CC0>\n",
      ">layer 201 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F622B2828>\n",
      ">layer 202 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F6230FC50>\n",
      ">layer 203 : name : activation_35                             type: <keras.layers.core.Activation object at 0x0000019F6231DFD0>\n",
      ">layer 204 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x0000019F62328EF0>\n",
      ">layer 205 : name : time_distributed_1                        type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62336EB8>\n",
      ">layer 206 : name : mrcnn_class_logits                        type: <keras.layers.core.Lambda object at 0x0000019F623368D0>\n",
      ">layer 207 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62384B70>\n",
      ">layer 208 : name : time_distributed_2                        type: <keras.layers.wrappers.TimeDistributed object at 0x0000019F62336E10>\n",
      ">layer 209 : name : reshape_1                                 type: <keras.layers.core.Reshape object at 0x0000019F623BA128>\n",
      ">layer 210 : name : mrcnn_class                               type: <keras.layers.core.Lambda object at 0x0000019F62336FD0>\n",
      ">layer 211 : name : mrcnn_bbox_regression                     type: <keras.layers.core.Lambda object at 0x0000019F62384A90>\n",
      ">layer 212 : name : cntxt_layer                               type: <mrcnn.chm_layer.CHMLayer object at 0x0000019F623D2DD8>\n",
      ">layer 213 : name : fcn_block1_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F62384668>\n",
      ">layer 214 : name : fcn_block1_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640056D8>\n",
      ">layer 215 : name : fcn_block1_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F640267F0>\n",
      ">layer 216 : name : fcn_block2_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F63E174E0>\n",
      ">layer 217 : name : fcn_block2_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64041C18>\n",
      ">layer 218 : name : fcn_block2_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F6407FCF8>\n",
      ">layer 219 : name : fcn_block3_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F6405A9E8>\n",
      ">layer 220 : name : fcn_block3_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640997B8>\n",
      ">layer 221 : name : fcn_block3_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640D4978>\n",
      ">layer 222 : name : fcn_block3_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F640EF630>\n",
      ">layer 223 : name : fcn_block4_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F640E3048>\n",
      ">layer 224 : name : fcn_block4_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64154898>\n",
      ">layer 225 : name : fcn_block4_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F6412FD68>\n",
      ">layer 226 : name : fcn_block4_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F6416D160>\n",
      ">layer 227 : name : fcn_block5_conv1                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F64195828>\n",
      ">layer 228 : name : fcn_block5_conv2                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F641D6780>\n",
      ">layer 229 : name : fcn_block5_conv3                          type: <keras.layers.convolutional.Conv2D object at 0x0000019F641E2F28>\n",
      ">layer 230 : name : fcn_block5_pool                           type: <keras.layers.pooling.MaxPooling2D object at 0x0000019F64216A90>\n",
      ">layer 231 : name : fcn_fc1                                   type: <keras.layers.convolutional.Conv2D object at 0x0000019F642221D0>\n",
      ">layer 232 : name : dropout_1                                 type: <keras.layers.core.Dropout object at 0x0000019F6427DE80>\n",
      ">layer 233 : name : fcn_fc2                                   type: <keras.layers.convolutional.Conv2D object at 0x0000019F6427DF28>\n",
      ">layer 234 : name : dropout_2                                 type: <keras.layers.core.Dropout object at 0x0000019F642B9B00>\n",
      ">layer 235 : name : fcn_classify                              type: <keras.layers.convolutional.Conv2D object at 0x0000019F642F7A90>\n",
      ">layer 236 : name : fcn_bilinear                              type: <mrcnn.BilinearUpSampling.BilinearUpSampling2D object at 0x0000019F6430CC88>\n",
      ">layer 237 : name : input_image_meta                          type: <keras.engine.topology.InputLayer object at 0x0000019F5D7A8E80>\n",
      ">layer 238 : name : fcn_heatmap_norm                          type: <keras.layers.core.Lambda object at 0x0000019F6432A898>\n",
      ">layer 239 : name : rpn_class_logits                          type: <keras.layers.core.Lambda object at 0x0000019F6135F780>\n",
      ">layer 240 : name : input_rpn_match                           type: <keras.engine.topology.InputLayer object at 0x0000019F58E8A630>\n",
      ">layer 241 : name : input_rpn_bbox                            type: <keras.engine.topology.InputLayer object at 0x0000019F5ECDA048>\n",
      ">layer 242 : name : lambda_4                                  type: <keras.layers.core.Lambda object at 0x0000019F61518E48>\n",
      ">layer 243 : name : fcn_scoring                               type: <mrcnn.fcn_scoring_layer.FCNScoringLayer object at 0x0000019F643B9908>\n",
      ">layer 244 : name : rpn_class_loss                            type: <keras.layers.core.Lambda object at 0x0000019F64566BE0>\n",
      ">layer 245 : name : rpn_bbox_loss                             type: <keras.layers.core.Lambda object at 0x0000019F64629A90>\n",
      ">layer 246 : name : mrcnn_class_loss                          type: <keras.layers.core.Lambda object at 0x0000019F646DFA90>\n",
      ">layer 247 : name : mrcnn_bbox_loss                           type: <keras.layers.core.Lambda object at 0x0000019F647DAD30>\n",
      ">layer 248 : name : fcn_heatmap                               type: <keras.layers.core.Lambda object at 0x0000019F643535C0>\n",
      ">layer 249 : name : fcn_norm_loss                             type: <keras.layers.core.Lambda object at 0x0000019F642C74E0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    load_weights: Log directory set to : E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 566 \n",
      "    Load weights complete :  E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "Load weights complete E:\\Models\\newshape_mrcnn\\shapes20180621T1554\\mask_rcnn_shapes_0565.h5\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_FOLDER              E:\\models\\newshape_fcn\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  300\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "FCN_LAYERS                     True\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-06\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.2\n",
      "REDUCE_LR_PATIENCE             40\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAINING_IMAGES                10000\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_IMAGES              2500\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.new_shapes as new_shapes\n",
    "from mrcnn.prep_notebook import prep_newshapes_train2\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration object \n",
    "##------------------------------------------------------------------------------------\n",
    "config                    = new_shapes.NewShapesConfig()\n",
    "config.FCN_LAYERS         = True\n",
    "config.BATCH_SIZE         = 2                                 # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU     = config.BATCH_SIZE                 # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH    = 2\n",
    "config.LEARNING_RATE      = 0.000001\n",
    "                          \n",
    "config.EPOCHS_TO_RUN      = 300\n",
    "config.FCN_INPUT_SHAPE    = config.IMAGE_SHAPE[0:2]\n",
    "config.LAST_EPOCH_RAN     = 0\n",
    "config.WEIGHT_DECAY       = 2.0e-4\n",
    "config.VALIDATION_STEPS   = 100\n",
    "config.REDUCE_LR_FACTOR   = 0.2\n",
    "config.REDUCE_LR_COOLDOWN = 30\n",
    "config.REDUCE_LR_PATIENCE = 40\n",
    "config.MIN_LR             = 1.0e-10\n",
    "config.TRAINING_IMAGES    = 10000\n",
    "config.VALIDATION_IMAGES  = 2500\n",
    "config.CHECKPOINT_FOLDER  = 'newshape_fcn' \n",
    "\n",
    "model_file  = 'E:\\\\Models\\\\newshape_mrcnn\\\\shapes20180621T1554\\\\mask_rcnn_shapes_0565.h5'\n",
    "\n",
    "model, dataset_train, dataset_val, train_generator, val_generator, config = \\\n",
    "    prep_newshapes_train2(init_with = model_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T21:31:30.164770Z",
     "start_time": "2018-06-30T21:31:28.644807Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T22:22:40.114294Z",
     "start_time": "2018-06-30T22:22:39.873936Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:23:30.781430Z",
     "start_time": "2018-07-01T19:23:30.522086Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n Losses (model.metrics_names): ') \n",
    "pp.pprint(model.get_deduped_metrics_names())\n",
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training - FCN\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "    - #### Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:23:37.456540Z",
     "start_time": "2018-07-01T19:23:37.205261Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.MIN_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:43:33.061792Z",
     "start_time": "2018-07-01T19:42:43.658928Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fcn']\n",
      "['(fcn\\\\_.*)']\n",
      "layers regex : (fcn\\_.*)\n",
      " 213  fcn_block1_conv1       (Conv2D              )   TRAIN \n",
      " 214  fcn_block1_conv2       (Conv2D              )   TRAIN \n",
      " 216  fcn_block2_conv1       (Conv2D              )   TRAIN \n",
      " 217  fcn_block2_conv2       (Conv2D              )   TRAIN \n",
      " 219  fcn_block3_conv1       (Conv2D              )   TRAIN \n",
      " 220  fcn_block3_conv2       (Conv2D              )   TRAIN \n",
      " 221  fcn_block3_conv3       (Conv2D              )   TRAIN \n",
      " 223  fcn_block4_conv1       (Conv2D              )   TRAIN \n",
      " 224  fcn_block4_conv2       (Conv2D              )   TRAIN \n",
      " 225  fcn_block4_conv3       (Conv2D              )   TRAIN \n",
      " 227  fcn_block5_conv1       (Conv2D              )   TRAIN \n",
      " 228  fcn_block5_conv2       (Conv2D              )   TRAIN \n",
      " 229  fcn_block5_conv3       (Conv2D              )   TRAIN \n",
      " 231  fcn_fc1                (Conv2D              )   TRAIN \n",
      " 233  fcn_fc2                (Conv2D              )   TRAIN \n",
      " 235  fcn_classify           (Conv2D              )   TRAIN \n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['fcn_norm_loss']\n",
      "    learning rate :  1e-06\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['fcn_norm_loss']\n",
      "    keras_model.losses           : [<tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>, <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>]\n",
      "    Loss: fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add add loss for  Tensor(\"fcn_norm_loss/fcn_norm_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      "Keras model.losses : \n",
      "---------------------\n",
      "[   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>]\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "[<tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "{None: [<tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>]}\n",
      "    Final list of keras_model.losses \n",
      "[   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'AddN:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block4_conv3/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv1/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv2/add:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'fcn_block5_conv3/add:0' shape=() dtype=float32>]\n",
      " Length of Keras_Model.outputs: 27\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_norm_loss  Related Layer is : fcn_norm_loss\n",
      "      >> Add metric  fcn_norm_loss  with metric tensor:  fcn_norm_loss/fcn_norm_loss:0  to list of metrics ...\n",
      " Final Keras metric_names:\n",
      "['loss', 'fcn_norm_loss']\n",
      "\n",
      "Starting at epoch  0 of 300 epochs. LR=1e-06\n",
      "\n",
      "Steps per epochs   1 \n",
      "Batch size         2 \n",
      "Checkpoint Path:   E:\\models\\newshape_fcn\\shapes20180621T1554\\mask_rcnn_shapes_{epoch:04d}.h5 \n",
      "Weight Decay:      0.0002 \n",
      "VALIDATION_STEPS   100 \n",
      "REDUCE_LR_FACTOR   0.2 \n",
      "REDUCE_LR_COOLDOWN 30 \n",
      "REDUCE_LR_PATIENCE 40 \n",
      "MIN_LR             1e-10 \n",
      "================= CALLING FIT GENERATOR ==================\n",
      "@@@@@@@@@@@@@@ Get SGD updates: \n",
      " loss :  Tensor(\"loss/add_7:0\", shape=(1, 1), dtype=float32)\n",
      " params: \n",
      "[   <tf.Variable 'fcn_block1_conv1/kernel:0' shape=(3, 3, 7, 64) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv1/bias:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block1_conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block2_conv2/bias:0' shape=(128,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv1/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block3_conv3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block4_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_block5_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc1/kernel:0' shape=(7, 7, 512, 2048) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc1/bias:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc2/kernel:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_fc2/bias:0' shape=(2048,) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_classify/kernel:0' shape=(1, 1, 2048, 7) dtype=float32_ref>,\n",
      "    <tf.Variable 'fcn_classify/bias:0' shape=(7,) dtype=float32_ref>]\n",
      "    params:  <tf.Variable 'fcn_block1_conv1/kernel:0' shape=(3, 3, 7, 64) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond/Merge:0\", shape=(3, 3, 7, 64), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable:0' shape=(3, 3, 7, 64) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv1/bias:0' shape=(64,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_1/Merge:0\", shape=(64,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_1:0' shape=(64,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_2/Merge:0\", shape=(3, 3, 64, 64), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_2:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block1_conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_3/Merge:0\", shape=(64,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_3:0' shape=(64,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_4/Merge:0\", shape=(3, 3, 64, 128), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_4:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv1/bias:0' shape=(128,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_5/Merge:0\", shape=(128,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_5:0' shape=(128,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_6/Merge:0\", shape=(3, 3, 128, 128), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_6:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block2_conv2/bias:0' shape=(128,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_7/Merge:0\", shape=(128,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_7:0' shape=(128,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_8/Merge:0\", shape=(3, 3, 128, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_8:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv1/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_9/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_9:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_10/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_10:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv2/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_11/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_11:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_12/Merge:0\", shape=(3, 3, 256, 256), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_12:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block3_conv3/bias:0' shape=(256,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_13/Merge:0\", shape=(256,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_13:0' shape=(256,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_14/Merge:0\", shape=(3, 3, 256, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_14:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_15/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_15:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_16/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_16:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    params:  <tf.Variable 'fcn_block4_conv2/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_17/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_17:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_18/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_18:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block4_conv3/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_19/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_19:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_20/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_20:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_21/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_21:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_22/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_22:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv2/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_23/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_23:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_24/Merge:0\", shape=(3, 3, 512, 512), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_24:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_block5_conv3/bias:0' shape=(512,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_25/Merge:0\", shape=(512,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_25:0' shape=(512,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc1/kernel:0' shape=(7, 7, 512, 2048) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_26/Merge:0\", shape=(7, 7, 512, 2048), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_26:0' shape=(7, 7, 512, 2048) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc1/bias:0' shape=(2048,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_27/Merge:0\", shape=(2048,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_27:0' shape=(2048,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc2/kernel:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_28/Merge:0\", shape=(1, 1, 2048, 2048), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_28:0' shape=(1, 1, 2048, 2048) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_fc2/bias:0' shape=(2048,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_29/Merge:0\", shape=(2048,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_29:0' shape=(2048,) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_classify/kernel:0' shape=(1, 1, 2048, 7) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_30/Merge:0\", shape=(1, 1, 2048, 7), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_30:0' shape=(1, 1, 2048, 7) dtype=float32_ref>\n",
      "    params:  <tf.Variable 'fcn_classify/bias:0' shape=(7,) dtype=float32_ref>\n",
      " gradients:  Tensor(\"training/SGD/cond_31/Merge:0\", shape=(7,), dtype=float32)\n",
      "  moements:  <tf.Variable 'training/SGD/Variable_31:0' shape=(7,) dtype=float32_ref>\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@fcn_fc1/convolution\"], data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fcn_block5_pool/MaxPool, training/SGD/gradients/fcn_fc1/convolution_grad/Const_1, training/SGD/gradients/fcn_fc1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e1bbc0c149a5>\", line 15, in <module>\n    losses = loss_names)\n  File \"..\\mrcnn\\model_mod.py\", line 1340, in train\n    use_multiprocessing=False\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2108, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 991, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 173, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 79, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2521, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in gradients\n    lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 377, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 523, in _Conv2DGrad\n    data_format=data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 816, in conv2d_backprop_filter\n    dilations=dilations, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'fcn_fc1/convolution', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 16 identical lines from previous traceback]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-4bacbacd4182>\", line 46, in <module>\n    model, dataset_train, dataset_val, train_generator, val_generator, config =     prep_newshapes_train2(init_with = model_file, config=config)\n  File \"..\\mrcnn\\prep_notebook.py\", line 170, in prep_newshapes_train2\n    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=config.CHECKPOINT_FOLDER, FCN_layers = config.FCN_LAYERS)\n  File \"..\\mrcnn\\model_mod.py\", line 134, in __init__\n    self.keras_model = self.build(mode=mode, config=config, FCN_layers = FCN_layers)\n  File \"..\\mrcnn\\model_mod.py\", line 382, in build\n    fcn_hm_norm, fcn_hm,  _ = fcn_graph(pr_hm_norm, config)\n  File \"..\\mrcnn\\fcn_layer.py\", line 155, in fcn_graph\n    x = KL.Conv2D(FC_SIZE, (7, 7), activation='relu', padding='same', name='fcn_fc1')(x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 781, in convolution\n    return op(input, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 876, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 521, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 205, in __call__\n    name=self.name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@fcn_fc1/convolution\"], data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fcn_block5_pool/MaxPool, training/SGD/gradients/fcn_fc1/convolution_grad/Const_1, training/SGD/gradients/fcn_fc1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@fcn_fc1/convolution\"], data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fcn_block5_pool/MaxPool, training/SGD/gradients/fcn_fc1/convolution_grad/Const_1, training/SGD/gradients/fcn_fc1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e1bbc0c149a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             losses = loss_names)\n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, layers, losses, epochs, epochs_to_run, batch_size, steps_per_epoch, min_lr)\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# max(self.config.BATCH_SIZE // 2, 2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m         )\n\u001b[0;32m   1342\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2263\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2265\u001b[0m                     \u001b[1;31m# print(' Training.fit_generator(2265) ---------self.train_on_batch complete -----------------')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[1;31m# print(' Training.train_on_batch() (1906) outputs: ', type(outputs) , ' len: ', len(outputs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2482\u001b[0m         \u001b[1;31m# pp.pprint(self.session_kwargs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2484\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@fcn_fc1/convolution\"], data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fcn_block5_pool/MaxPool, training/SGD/gradients/fcn_fc1/convolution_grad/Const_1, training/SGD/gradients/fcn_fc1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e1bbc0c149a5>\", line 15, in <module>\n    losses = loss_names)\n  File \"..\\mrcnn\\model_mod.py\", line 1340, in train\n    use_multiprocessing=False\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2108, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 991, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 173, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 79, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2521, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in gradients\n    lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 377, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 523, in _Conv2DGrad\n    data_format=data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 816, in conv2d_backprop_filter\n    dilations=dilations, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'fcn_fc1/convolution', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 16 identical lines from previous traceback]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-4bacbacd4182>\", line 46, in <module>\n    model, dataset_train, dataset_val, train_generator, val_generator, config =     prep_newshapes_train2(init_with = model_file, config=config)\n  File \"..\\mrcnn\\prep_notebook.py\", line 170, in prep_newshapes_train2\n    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=config.CHECKPOINT_FOLDER, FCN_layers = config.FCN_LAYERS)\n  File \"..\\mrcnn\\model_mod.py\", line 134, in __init__\n    self.keras_model = self.build(mode=mode, config=config, FCN_layers = FCN_layers)\n  File \"..\\mrcnn\\model_mod.py\", line 382, in build\n    fcn_hm_norm, fcn_hm,  _ = fcn_graph(pr_hm_norm, config)\n  File \"..\\mrcnn\\fcn_layer.py\", line 155, in fcn_graph\n    x = KL.Conv2D(FC_SIZE, (7, 7), activation='relu', padding='same', name='fcn_fc1')(x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 781, in convolution\n    return op(input, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 876, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 521, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 205, in __call__\n    name=self.name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/fcn_fc1/convolution_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@fcn_fc1/convolution\"], data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fcn_block5_pool/MaxPool, training/SGD/gradients/fcn_fc1/convolution_grad/Const_1, training/SGD/gradients/fcn_fc1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_layers = ['fcn']\n",
    "loss_names   = [\"fcn_norm_loss\"]\n",
    "# config.VALIDATION_STEPS= 125\n",
    "# config.EPOCHS_TO_RUN          = 100\n",
    "config.STEPS_PER_EPOCH        = 1\n",
    "         \n",
    "model.epoch = 0\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate = config.LEARNING_RATE, \n",
    "            epochs_to_run = config.EPOCHS_TO_RUN,\n",
    "#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\n",
    "            layers = train_layers,\n",
    "            losses = loss_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:07:56.033492Z",
     "start_time": "2018-07-01T19:06:04.718208Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# Wed 09-05-2018\n",
    "# train_layers = ['mrcnn', 'fpn','rpn']\n",
    "# loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\", \"mrcnn_mask_loss\"]\n",
    "train_layers = ['mrcnn', 'fpn','rpn']\n",
    "loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\" ]\n",
    "config.STEPS_PER_EPOCH        = 8\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs_to_run = config.EPOCHS_TO_RUN,\n",
    "#             epochs = 2500,\n",
    "#             epochs_to_run =2, \n",
    "            layers = train_layers,\n",
    "            losses= loss_names\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Data Generators, get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:38.990259Z",
     "start_time": "2018-04-24T08:34:38.775686Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:39.932764Z",
     "start_time": "2018-04-24T08:34:39.594865Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:34:44.086847Z",
     "start_time": "2018-04-24T08:34:42.367242Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T08:35:18.936161Z",
     "start_time": "2018-04-24T08:35:09.103385Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:26:11.099812Z",
     "start_time": "2018-05-09T15:26:10.868655Z"
    }
   },
   "outputs": [],
   "source": [
    "input_gt_class_ids = train_batch_x[4]\n",
    "\n",
    "target_class_ids = layers_out[5]\n",
    "mrcnn_class_logits = layers_out[9]\n",
    "rpn_class_loss   = layers_out[13]\n",
    "rpn_bbox_loss    = layers_out[14]\n",
    "mrcnn_class_loss = layers_out[15]\n",
    "mrcnn_bbox_loss  = layers_out[16]\n",
    "mrcnn_mask_loss  = layers_out[17]\n",
    "active_class_ids = layers_out[20]\n",
    "# pred_masks = tf.identity(layers_out[18])\n",
    "# gt_masks   = tf.identity(layers_out[19])\n",
    "\n",
    "# shape = KB.int_shape(pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:34:22.819601Z",
     "start_time": "2018-05-09T15:34:22.573917Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rpn_class_loss, rpn_bbox_loss)\n",
    "print(mrcnn_class_loss, mrcnn_bbox_loss, mrcnn_mask_loss)\n",
    "print(active_class_ids)\n",
    "print()\n",
    "print(target_class_ids[1])\n",
    "print()\n",
    "print(mrcnn_class_logits[1])\n",
    "print('gt class ids')\n",
    "print(input_gt_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulate `mrcnn_class_loss` computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:33:24.601046Z",
     "start_time": "2018-05-09T15:33:24.109710Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n>>> mrcnn_class_loss_graph ' )\n",
    "print('    target_class_ids  size :', target_class_ids.shape)\n",
    "print('    pred_class_logits size :', mrcnnpred_class_logits.shape)\n",
    "print('    active_class_ids  size :', active_class_ids.shape)    \n",
    "target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "\n",
    "# Find predictions of classes that are not in the dataset.\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "\n",
    "# TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "#       images in a batch have the same active_class_ids\n",
    "pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "# Loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "# Erase losses of predictions of classes that are not in the active\n",
    "# classes of the image.\n",
    "loss = loss * pred_active\n",
    "\n",
    "# Computer loss mean. Use only predictions that contribute\n",
    "# to the loss to get a correct mean.\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "loss = KB.reshape(loss, [1, 1])\n",
    "return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:12:08.337002Z",
     "start_time": "2018-04-24T12:12:02.738105Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[21]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 2\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:09:41.413073Z",
     "start_time": "2018-04-24T12:09:35.664779Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline\n",
    "img = 2\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "Zout  = layers_out[21]     # gt_gaussiam \n",
    "Zout2 = layers_out[12]     # fcn_bilinear\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GroundTruth - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'FCN_Bilinear- image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:34:26.381655Z",
     "start_time": "2018-04-24T12:34:25.980564Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[0:2,2:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:49:29.945015Z",
     "start_time": "2018-04-24T13:49:29.457701Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 1 # <==== Class to display\n",
    "pred_tensor = layers_out[19]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:39:14.676360Z",
     "start_time": "2018-04-24T12:39:14.435714Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[0][0] * [128, 128,128,128]   #output_rois*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:03:44.110249Z",
     "start_time": "2018-04-24T15:03:38.231280Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]\n",
    "target_masks        = layers_out[27][0:3]\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print(tf.shape(less_than_one).eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean values of GT, Pred, and FCN heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:52:02.002508Z",
     "start_time": "2018-04-24T14:51:42.964543Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "pred_masks = tf.identity(layers_out[24])\n",
    "gt_masks = tf.identity(layers_out[27])\n",
    "fcn_masks = tf.identity(layers_out[12])\n",
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        gt_mean = K.mean(gt_masks[img,:,:,cls])\n",
    "        fcn_mean= K.mean(fcn_masks[img,:,:,cls])\n",
    "        pred_mean= K.mean(pred_masks[img,:,:,cls])\n",
    "        print('Img/Cls: ', img, '/', cls,'    gtmean: ', gt_mean.eval(), '\\t fcn : ' , fcn_mean.eval(), '\\t pred :', pred_mean.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:56:40.181058Z",
     "start_time": "2018-04-24T09:56:39.956461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 0\n",
    "fcn_out = layers_out[12][img]\n",
    "fcn_sum = np.sum(fcn_out, axis=(0,1))\n",
    "print(fcn_sum)\n",
    "for cls in range(4):\n",
    "    print('min :', np.min(fcn_out[:,:,cls]), 'max :', np.max(fcn_out[:,:,cls]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:55:21.917361Z",
     "start_time": "2018-04-23T20:55:21.676734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_batch_x[4][2])\n",
    "print(train_batch_x[5][2]/[128,128,128,128])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
