{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Test on Old Shapes Dataset\n",
    "\n",
    "Run the Mask R-CNN net in inference mode, with the additional PCILayer that generates the context-based tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:40:09.160628Z",
     "start_time": "2018-06-18T16:40:05.048633Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " windows  Windows\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prep_newshapes_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-81d44990792f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel_file\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;34m'E:\\\\Models\\\\newshape_fcn\\\\\\mask_rcnn_shapes_0589.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'newshape_fcn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_newshapes_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prep_newshapes_test' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_oldshapes_test\n",
    "import matplotlib.pyplot as plt\n",
    "# model_file  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2192.h5'\n",
    "model_file  = 'E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\\\mask_rcnn_shapes_4044.h5'\n",
    "# model_file  = 'E:\\\\Models\\\\mrcnn_oldshape_test_logs\\\\mask_rcnn_shapes_3877.h5'\n",
    "# model_file   = 'E:\\Models\\mrcnn_logs\\TESTshapes20180511T1742\\mask_rcnn_shapes_0023.h5'\n",
    "\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "\n",
    " \n",
    "folder_name = 'newshape_fcn'\n",
    "model, dataset_test, test_generator, inference_config = prep_oldshapes_test(init_with = model_file, FCN_layers = True, batch_sz = 1, folder_name = folder_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T15:27:38.903494Z",
     "start_time": "2018-06-05T15:27:38.671072Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:02:55.002435Z",
     "start_time": "2018-06-05T17:02:54.760008Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:29:16.625702Z",
     "start_time": "2018-06-05T17:29:16.268658Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import pprint\n",
    "from mrcnn.utils import log\n",
    "pp = pprint.PrettyPrinter(indent=4, width=100)\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    load_image_gt(dataset_test, inference_config, image_id, use_mini_mask=False)\n",
    "    \n",
    "\n",
    "print('Image Id :', image_id)    \n",
    "shape_list = dataset_test.image_info[image_id]['shapes']\n",
    "pp.pprint(shape_list)\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "print(image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "print(\" 1: person   2: car  3: sun  4: building  5: tree  6: cloud \")\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_test.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:29:23.086423Z",
     "start_time": "2018-06-05T17:29:21.246344Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:31:00.643525Z",
     "start_time": "2018-06-05T17:31:00.182730Z"
    }
   },
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "print('  rois       : ', r['rois'])\n",
    "\n",
    "print('  class ids  : ', r['class_ids'])\n",
    "print('  class names: ', dataset_test.class_names)\n",
    "print('  scores     : ', r['scores'])\n",
    "visualize.display_instances_wo_mask(original_image, r['rois'],r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": false
   },
   "source": [
    "### Run generator to create images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:20:07.099459Z",
     "start_time": "2018-06-05T17:20:07.087492Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(test_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(inference_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    mask, class_ids = dataset_test.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T15:45:40.489432Z",
     "start_time": "2018-06-05T15:45:35.484051Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(test_generator)\n",
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "print(len(model_output))\n",
    " \n",
    "for i in model_output:\n",
    "    print( i.shape)\n",
    "# print('FCN Normalized Loss is :', fcn_normalized_loss)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:07:51.476311Z",
     "start_time": "2018-06-05T16:07:51.250905Z"
    }
   },
   "outputs": [],
   "source": [
    "detections                = model_output[0]          # layer:  0   shape: (16, 100, 6)\n",
    "rpn_proposal_rois         = model_output[1]          # layer:  1   shape: (16, 1000, 4)\n",
    "rpn_class                 = model_output[2]          # layer:  2   shape: (16, 4092, 2)\n",
    "rpn_bbox                  = model_output[3]          # layer:  3   shape: (16, 4092, 4)\n",
    "mrcnn_class               = model_output[4]          # layer:  4   shape: (16, 1000, 4)\n",
    "mrcnn_bbox                = model_output[5]          # layer:  5   shape: (16, 1000, 4, 4)\n",
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:45:37.969281Z",
     "start_time": "2018-06-05T16:45:37.735878Z"
    }
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "print(rpn_roi_proposals.shape)\n",
    "print(mrcnn_class.shape)\n",
    "print(mrcnn_bbox.shape)\n",
    "print(input_image_meta.shape)\n",
    "print(input_image.shape , input_image_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Inference Detection Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:19:58.246489Z",
     "start_time": "2018-06-05T16:19:58.017103Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import parse_image_meta, apply_box_deltas\n",
    "a1, a2, windows, a4 =  parse_image_meta(input_image_meta)\n",
    "print(windows)\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:14:58.298738Z",
     "start_time": "2018-06-05T16:14:58.073330Z"
    }
   },
   "outputs": [],
   "source": [
    "# for b in range(self.config.BATCH_SIZE):\n",
    "#     _, _, window, _ =  parse_image_meta(image_meta)\n",
    "b=0\n",
    "print(rpn_proposal_rois[b].shape, mrcnn_class[b].shape, mrcnn_bbox[b].shape)\n",
    "\n",
    "# detections = refine_detections(rois[b], mrcnn_class[b], mrcnn_bbox[b], window[b], self.config)\n",
    "\n",
    "rois = rpn_proposal_rois[b]\n",
    "probs = mrcnn_class[b]\n",
    "deltas = mrcnn_bbox[b]\n",
    "window = windows[b]\n",
    "config = inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:15:22.461101Z",
     "start_time": "2018-06-05T16:15:22.225731Z"
    }
   },
   "outputs": [],
   "source": [
    "##  1. Find Class IDs with higest scores for each per ROI\n",
    "class_ids       = np.argmax(probs, axis=1)\n",
    "print(class_ids)\n",
    "print(probs[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:11:49.448825Z",
     "start_time": "2018-06-05T16:11:49.219436Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  1. Find Class IDs with higest scores for each per ROI\n",
    "class_ids       = np.argmax(probs, axis=1)\n",
    "print(class_ids[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:17:31.207769Z",
     "start_time": "2018-06-05T16:17:30.978372Z"
    }
   },
   "outputs": [],
   "source": [
    "##  2. Get Class probability(score) and bbox delta of the top class of each ROI\n",
    "print(class_ids.shape)\n",
    "print(deltas.shape)\n",
    "class_scores    =  probs[np.arange(class_ids.shape[0]), class_ids]\n",
    "deltas_specific = deltas[np.arange(deltas.shape[0])   , class_ids]\n",
    "print(class_scores.shape)\n",
    "print(deltas_specific.shape)\n",
    "\n",
    "print(class_scores[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:32:42.682978Z",
     "start_time": "2018-06-05T16:32:42.441582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shape: [boxes, (y1, x1, y2, x2)] in normalized coordinates\n",
    "refined_rois    = apply_box_deltas(rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "\n",
    "##  4. Convert the refined roi coordiates from normalized to image domain\n",
    "# TODO: better to keep them normalized until later   \n",
    "height, width   = config.IMAGE_SHAPE[:2]\n",
    "refined_rois   *= np.array([height, width, height, width])\n",
    "\n",
    "##  5.  Clip boxes to image window\n",
    "refined_rois    = clip_to_window(window, refined_rois)\n",
    "\n",
    "##  6.  Round and cast to int since we're deadling with pixels now\n",
    "refined_rois    = np.rint(refined_rois).astype(np.int32)\n",
    "\n",
    "##  7.  TODO: Filter out boxes with zero area\n",
    "\n",
    "##  8.  Filter out background boxes\n",
    "keep = np.where(class_ids > 0)[0]\n",
    "scores = np.where(class_scores >= config.DETECTION_MIN_CONFIDENCE)[0]\n",
    "# Filter out low confidence boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:35:08.713378Z",
     "start_time": "2018-06-05T16:35:08.475003Z"
    }
   },
   "outputs": [],
   "source": [
    "print(class_ids[:40])\n",
    "print(class_scores[:40])\n",
    "print(keep[:20])\n",
    "print(scores[:20])\n",
    "print(class_ids[keep[:20]])\n",
    "print(class_scores[scores[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:33:33.623691Z",
     "start_time": "2018-06-05T16:33:33.393306Z"
    }
   },
   "outputs": [],
   "source": [
    "keep1 = np.intersect1d(keep, scores )\n",
    "print(keep1.size)\n",
    "print(keep1[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:37:50.437792Z",
     "start_time": "2018-06-05T16:37:50.216301Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_nms_class_ids = class_ids[keep1]\n",
    "pre_nms_scores    = class_scores[keep1]\n",
    "pre_nms_rois      = refined_rois[keep1]\n",
    "nms_keep          = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:42:57.526373Z",
     "start_time": "2018-06-05T16:42:57.290005Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pre_nms_class_ids[:20])\n",
    "print(pre_nms_scores[:20])\n",
    "print(np.unique(pre_nms_class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with zeros if detections < DETECTION_MAX_INSTANCES\n",
    "gap = self.config.DETECTION_MAX_INSTANCES - detections.shape[0]\n",
    "assert gap >= 0\n",
    "if gap > 0:\n",
    "    detections = np.pad(detections, [(0, gap), (0, 0)], 'constant', constant_values=0)\n",
    "detections_batch.append(detections)\n",
    "\n",
    "# Stack detections and cast to float32\n",
    "# TODO: track where float64 is introduced\n",
    "detections_batch = np.array(detections_batch).astype(np.float32)\n",
    "# Reshape output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:05:54.706908Z",
     "start_time": "2018-06-05T16:05:54.467566Z"
    }
   },
   "outputs": [],
   "source": [
    "def refine_detections(rois, probs, deltas, window, config):\n",
    "    '''\n",
    "    Refine classified proposals and filter overlaps and return final detections.\n",
    "\n",
    "    Inputs:\n",
    "    ------\n",
    "        \n",
    "    rois:           rpn_rois    - [N, (y1, x1, y2, x2)] in normalized coordinates\n",
    "    probs:          mrcnn_class - [N, num_classes]. Class probabilities.\n",
    "    deltas:         mrcnn_bbox  - [N, num_classes, (dy, dx, log(dh), log(dw))]. \n",
    "                                  Class-specific bounding box deltas.\n",
    "                                  \n",
    "    window:         (y1, x1, y2, x2) in image coordinates. The part of the image\n",
    "                    that contains the image excluding the padding.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    detections      [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    '''\n",
    "\n",
    "    \n",
    "    ##  1. Find Class IDs with higest scores for each per ROI\n",
    "    class_ids       = np.argmax(probs, axis=1)\n",
    "    print(class_ids)\n",
    "    ##  2. Get Class probability(score) and bbox delta of the top class of each ROI\n",
    "    class_scores    =  probs[np.arange(class_ids.shape[0]), class_ids]\n",
    "    deltas_specific = deltas[np.arange(deltas.shape[0])   , class_ids]\n",
    "    \n",
    "    ##  3. Apply bounding box delta to the corrsponding rpn_proposal\n",
    "    # Shape: [boxes, (y1, x1, y2, x2)] in normalized coordinates\n",
    "    refined_rois    = apply_box_deltas(rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "    \n",
    "    ##  4. Convert the refined roi coordiates from normalized to image domain\n",
    "    # TODO: better to keep them normalized until later   \n",
    "    height, width   = config.IMAGE_SHAPE[:2]\n",
    "    refined_rois   *= np.array([height, width, height, width])\n",
    "    \n",
    "    ##  5.  Clip boxes to image window\n",
    "    refined_rois    = clip_to_window(window, refined_rois)\n",
    "    \n",
    "    ##  6.  Round and cast to int since we're deadling with pixels now\n",
    "    refined_rois    = np.rint(refined_rois).astype(np.int32)\n",
    "\n",
    "    ##  7.  TODO: Filter out boxes with zero area\n",
    "\n",
    "    ##  8.  Filter out background boxes\n",
    "    keep = np.where(class_ids > 0)[0]\n",
    "    # Filter out low confidence boxes\n",
    "    if config.DETECTION_MIN_CONFIDENCE:\n",
    "        keep = np.intersect1d(keep, np.where(class_scores >= config.DETECTION_MIN_CONFIDENCE)[0])\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ##  9.  Apply per-class NMS\n",
    "    ##----------------------------------------------------------------------------\n",
    "    pre_nms_class_ids = class_ids[keep]\n",
    "    pre_nms_scores    = class_scores[keep]\n",
    "    pre_nms_rois      = refined_rois[keep]\n",
    "    nms_keep          = []\n",
    "    # print(' apply per class nms')    \n",
    "    for class_id in np.unique(pre_nms_class_ids):\n",
    "        # Pick detections of this class\n",
    "        ixs = np.where(pre_nms_class_ids == class_id)[0]\n",
    "\n",
    "        # print('class_id : ', class_id)\n",
    "        # print('pre_nms_rois.shape:', pre_nms_rois[ixs].shape)\n",
    "        # pp.pprint(pre_nms_rois[ixs])\n",
    "        # print('pre_nms_scores.shape :', pre_nms_scores[ixs].shape)\n",
    "        # pp.pprint(pre_nms_scores[ixs])    \n",
    "        # Apply NMS\n",
    "        class_keep = non_max_suppression(pre_nms_rois[ixs], \n",
    "                                         pre_nms_scores[ixs],\n",
    "                                         config.DETECTION_NMS_THRESHOLD)\n",
    "        # Map indicies\n",
    "        class_keep = keep[ixs[class_keep]]\n",
    "        nms_keep   = np.union1d(nms_keep, class_keep)\n",
    "    \n",
    "    keep = np.intersect1d(keep, nms_keep).astype(np.int32)\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ## 10.  Keep top detections\n",
    "    ##----------------------------------------------------------------------------\n",
    "    roi_count = config.DETECTION_MAX_INSTANCES\n",
    "    top_ids   = np.argsort(class_scores[keep])[::-1][:roi_count]\n",
    "    keep      = keep[top_ids]\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ## 11.  Arrange output as [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    ##      Coordinates are in image domain.\n",
    "    ##----------------------------------------------------------------------------\n",
    "    result = np.hstack((refined_rois[keep],\n",
    "                        class_ids   [keep][..., np.newaxis],\n",
    "                        class_scores[keep][..., np.newaxis]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:05:54.706908Z",
     "start_time": "2018-06-05T16:05:54.467566Z"
    }
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Detection Layer\n",
    "############################################################\n",
    "\n",
    "def clip_to_window(window, boxes):\n",
    "    '''\n",
    "    window: (y1, x1, y2, x2). The window in the image we want to clip to.\n",
    "    boxes: [N, (y1, x1, y2, x2)]\n",
    "    '''\n",
    "    \n",
    "    boxes[:, 0] = np.maximum(np.minimum(boxes[:, 0], window[2]), window[0])\n",
    "    boxes[:, 1] = np.maximum(np.minimum(boxes[:, 1], window[3]), window[1])\n",
    "    boxes[:, 2] = np.maximum(np.minimum(boxes[:, 2], window[2]), window[0])\n",
    "    boxes[:, 3] = np.maximum(np.minimum(boxes[:, 3], window[3]), window[1])\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:47:59.541625Z",
     "start_time": "2018-06-05T16:47:59.296263Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_image = train_batch_x\n",
    "results = model.detect(original_image, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T11:56:20.774651Z",
     "start_time": "2018-05-10T11:56:20.439754Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "print('  rois       : ', r['rois'])\n",
    "print('  masks      : ', r['masks'].shape)\n",
    "print('  class ids  : ', r['class_ids'])\n",
    "print('  class names: ', dataset_test.class_names)\n",
    "print('  scores     : ', r['scores'])\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T11:57:47.846606Z",
     "start_time": "2018-05-10T11:57:22.672337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "import  mrcnn.utils as utils \n",
    "\n",
    "image_ids = np.random.choice(dataset_test.image_ids, 100)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        load_image_gt(dataset_test, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(utils.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulation of `detect()` routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:56:16.446332Z",
     "start_time": "2018-06-05T16:56:14.479593Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('>>> model detect()')\n",
    "print(model.config.BATCH_SIZE)\n",
    "images = train_batch_x[0]\n",
    "print(len(input_images))\n",
    "verbose = 1\n",
    "# images  = [original_image]\n",
    "assert model.mode   == \"inference\", \"Create model in inference mode.\"\n",
    "assert len(images) == model.config.BATCH_SIZE, \"len(images) must be equal to BATCH_SIZE\"\n",
    "\n",
    "if verbose:\n",
    "    log(\"Processing {} images\".format(len(images)))\n",
    "    for image in images:\n",
    "        log(\"image\", image)\n",
    "\n",
    "# Mold inputs to format expected by the neural network\n",
    "molded_images, image_metas, windows = model.mold_inputs(images)\n",
    "if verbose:\n",
    "    log(\"molded_images\", molded_images)\n",
    "    log(\"image_metas\"  , image_metas)\n",
    "\n",
    "## Run object detection pipeline\n",
    "# print('    call predict()')\n",
    "detections, rpn_rois, rpn_class, rpn_bbox,\\\n",
    "            mrcnn_class, mrcnn_bbox \\\n",
    "                      =  model.keras_model.predict([molded_images, image_metas], verbose=0)\n",
    "\n",
    "print('    return from  predict()')\n",
    "print('    Length of detections : ', len(detections))\n",
    "print('    Length of rpn_rois   : ', len(rpn_rois   ))\n",
    "print('    Length of rpn_class  : ', len(rpn_class  ))\n",
    "print('    Length of rpn_bbox   : ', len(rpn_bbox   ))\n",
    "print('    Length of mrcnn_class: ', len(mrcnn_class))\n",
    "print('    Length of mrcnn_bbox : ', len(mrcnn_bbox ))\n",
    "# print('    Length of mrcnn_mask : ', len(mrcnn_mask ))\n",
    "\n",
    "####  detection array layout is `[ y1, x1, y2, x2, class, score]`\n",
    "\n",
    "detections[0].shape\n",
    "print(detections[0])\n",
    "\n",
    "## Process detections\n",
    "results = []\n",
    "for i, image in enumerate(images):\n",
    "    final_rois, final_class_ids, final_scores  =\\\n",
    "        model.unmold_detections(detections[i], \n",
    "                               image.shape  ,\n",
    "                               windows[i])\n",
    "    results.append({\n",
    "        \"rois\"     : final_rois,\n",
    "        \"class_ids\": final_class_ids,\n",
    "        \"scores\"   : final_scores,\n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:12:25.863446Z",
     "start_time": "2018-06-05T17:12:25.631052Z"
    }
   },
   "outputs": [],
   "source": [
    "original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:16:46.871340Z",
     "start_time": "2018-06-05T17:16:44.311189Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(config.BATCH_SIZE)   :\n",
    "    r = results[i]\n",
    "    print('  rois       : ', r['rois'])\n",
    "    print('  class ids  : ', r['class_ids'])\n",
    "    print('  class names: ', dataset_test.class_names)\n",
    "    print('  scores     : ', r['scores'])\n",
    "    visualize.display_instances_wo_mask(input_image[i], r['rois'], r['class_ids'], dataset_test.class_names, r['scores'], figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
