{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "## `build_heatmap()`\n",
    "\n",
    "#### Prepare values to pass to build_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:05:33.772086Z",
     "start_time": "2018-05-17T19:05:25.027624Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    temp = output_norm\n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3]).eval()\n",
    "    temp_min = tf.reduce_min(temp, [2,3]).eval()\n",
    "    temp_max = tf.reduce_max(temp, [2,3]).eval()\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:08:24.047270Z",
     "start_time": "2018-05-17T19:08:15.738081Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    temp = tf.nn.l2_normalize(gauss_sum, axis = [1]) \n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3]).eval()\n",
    "    temp_min = tf.reduce_min(temp, [2,3]).eval()\n",
    "    temp_max = tf.reduce_max(temp, [2,3]).eval()\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T17:39:22.671030Z",
     "start_time": "2018-05-17T17:39:21.953645Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "with sess.as_default():\n",
    "    print('  Temp shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [3,4]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)dd\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            for k in range(32):\n",
    "                print('img ',i,' class ', j, 'copy ',k, ' sum:',temp_sum[i,j,k])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Old method - generating `gauss_heatmap_scores` using `gauss_scatter`\n",
    "\n",
    "This will NOT work for generating scores in FCN, since we do not have the heatmaps per individual bounding box. \n",
    "We need to apply the boundingbox masks on the GAUSS_SUM\n",
    "\n",
    "#### If we use this to generate scores, the scores will only reflect the heatmap produced for one object's bounding box. The overlapping of bounding boxes will not affect the generated scores. Therefore, the scores are invariant of possible overlapping. \n",
    "#### We could possibly use this if we want to generate independent scores for bounding boxes with no overlaps. However it's important to consider the ramifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T10:52:16.836988Z",
     "start_time": "2018-05-17T10:52:16.578780Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bouding box masks \n",
    "    ## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "    ##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    in_tensor_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "    bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    print('    in_tensor               ', in_tensor.shape)\n",
    "    print('    in_tensorr_flattened is ', in_tensor_flattened.shape)\n",
    "    print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "    # DONT NEED THIS - was put there to try to avoid computing sum/area for zero bboxes.\n",
    "    # kept as reference for future generations .....\n",
    "    # bbox_sum = tf.reduce_max(in_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "    # print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "    gauss_scatt_shape   = KB.int_shape(gauss_scatt)\n",
    "    gauss_scatt_reshape = KB.reshape(gauss_scatt, (-1, gauss_scatt_shape[-2], gauss_scatt_shape[-1]))\n",
    "    print('    gaussian scatter shape : ', gauss_scatt_shape)\n",
    "    print('    gaussian scatter reshaped : ', gauss_scatt_reshape.shape)\n",
    "    print('    gaussian sum shape          ', KB.int_shape(gauss_sum))\n",
    "\n",
    "    # ones_map = tf.ones([384,128,128])   \n",
    "    scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)\n",
    "\n",
    "    new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]        \n",
    "    gaussian_bbox_scores = tf.concat([in_tensor_flattened, scores], axis = -1)\n",
    "    print('    in_tensor_flattened shape : ', scatter_flattened.shape)\n",
    "    print('    Scores shape              : ', scores.shape)\n",
    "    print('    gaussian_boxes_scores     : ', gaussian_bbox_scores.shape)    \n",
    "    gaussian_bbox_scores = tf.reshape(gaussian_bbox_scores, new_shape, name = names[0]+'_scores')\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## Normalize computed score above, and add it to the heatmap_score tensor as last column\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "#     scr = gaussian_bbox_scores[...,-2]/gaussian_bbox_scores[...,-1]\n",
    "#     scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "#     scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "#     scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "#     gaussian_bbox_scores = tf.concat([gaussian_bbox_scores, scr_norm], axis = -1)\n",
    "\n",
    "#     print('    gaussian_bbox_scores final shape   : ', gaussian_bbox_scores.shape)\n",
    "#     print('    complete')\n",
    "\n",
    "# return  gauss_norm, gaussian_bbox_scores    # [gauss_sum, gauss_scatt, means, covar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### NEW method - generating `gauss_heatmap_scores` using `gauss_sum`\n",
    "\n",
    "Since FCN provides a heatmap per class , and not per individual object, we use the similar method here to generate heat maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:43:11.833374Z",
     "start_time": "2018-05-17T12:43:07.138502Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bouding box masks \n",
    "    ## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "    ##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    in_tensor_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "    bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    print('    in_tensor               ', in_tensor.shape)\n",
    "    print('    in_tensorr_flattened is ', in_tensor_flattened.shape)\n",
    "    print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "    print(rois_per_image)\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # duplicate gauss_sum <num_roi> times to pass along with bboxes to map_fn function\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    temp = tf.expand_dims(gauss_sum, axis =2)\n",
    "    print('  Gauss_Sum expanced shape :',  temp.get_shape())\n",
    "    temp = tf.tile(temp, [1,1, rois_per_image ,1,1])\n",
    "    print('  Gauss_Sum expanded/tiled shape :',  temp.get_shape())\n",
    "    temp_shape   = KB.int_shape(temp)\n",
    "    temp_reshape = KB.reshape(temp, (-1, temp_shape[-2], temp_shape[-1]))\n",
    "    print('    gauss_sum original shape  : ', gauss_sum.shape)\n",
    "    print('    gauss_sum replicated      : ', temp_shape)\n",
    "    print('    gaussian scatter reshaped : ', temp_reshape.shape)\n",
    "\n",
    "    scores = tf.map_fn(build_mask_routine, [temp_reshape, bboxes], dtype=tf.float32)\n",
    "    # consider the two new columns for reshaping the gaussian_bbox_scores\n",
    "    new_shape = tf.shape(in_tensor)+ [0,0,0, tf.shape(scores)[-1]]        \n",
    "    gaussian_bbox_scores = tf.concat([scatter_flattened, scores], axis = -1)\n",
    "    print('    Scatter Flattened shape : ', scatter_flattened.shape)\n",
    "    print('    Scores shape :            ', scores.shape)\n",
    "    print('    gaussian_boxes_scores initial shape: ', gaussian_bbox_scores.shape)    \n",
    "    gaussian_bbox_scores = tf.reshape(gaussian_bbox_scores, new_shape, name = names[0]+'_scores')\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## Normalize computed score above, and add it to the heatmap_score tensor as last column\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    scr = gaussian_bbox_scores[...,-2]/gaussian_bbox_scores[...,-1]\n",
    "    scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "    scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "    scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "    gaussian_bbox_scores = tf.concat([gaussian_bbox_scores, scr_norm], axis = -1)\n",
    "    gauss_norm = tf.transpose(gauss_norm,[0,2,3,1], name = names[0])  \n",
    "    \n",
    "    \n",
    "    print('    gauss_norm           final shape   : ', gauss_norm.shape)\n",
    "    print('    gaussian_bbox_scores final shape   : ', tf.shape(gaussian_bbox_scores).eval())\n",
    "    print('    complete')\n",
    "\n",
    "# return  gauss_norm, gaussian_bbox_scores    # [gauss_sum, gauss_scatt, means, covar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:43:54.164205Z",
     "start_time": "2018-05-17T12:43:53.577870Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(pred_heatmap_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Compare results from old and new method of generating `gauss_sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T10:40:06.501659Z",
     "start_time": "2018-05-17T10:39:03.275888Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     sess.close()\n",
    "#     print('session was deleted ')\n",
    "# except:\n",
    "#     print('Session was not defined ')\n",
    "#     pass\n",
    "# sess = tf.InteractiveSession()\n",
    "with sess.as_default():\n",
    "    np.set_printoptions(linewidth=130, threshold=20000)\n",
    "    gt   = gauss_norm_tp2 # gt_gaussian \n",
    "    gt2  = gauss_norm_tp # gt_gaussian_2\n",
    "    # gt   = np.where(gt > 1e-6,gt,0)\n",
    "    # gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "    print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "    for img in range(3):\n",
    "        print('Image', img)\n",
    "\n",
    "        for cls in range(4):\n",
    "\n",
    "            all_equal = np.all(np.equal(gt2[img, :,:,cls], gt[img, :,:,cls]))\n",
    "        #         for roi in range(32):\n",
    "    #             print('roi:', roi)\n",
    "    #             equal = tf.equal(gt2[img, cls, roi, line], gt[img, cls,roi, line])\n",
    "    #             all_equal = tf.reduce_all(equal).eval()     \n",
    "            if all_equal:\n",
    "                max_diff = np.max(gt2[img, :,:, cls]- gt[img, :,:,cls]).eval()\n",
    "                print('Img: ', img, ' Cls',cls, 'All equal', all_equal, '    Largest diffeence in cls', cls,':', max_diff)            \n",
    "            else:\n",
    "                for line in range(128):\n",
    "                    all_equal = np.all(np.equal(gt2[img, line,:,cls], gt[img, line,:,cls]))\n",
    "                    if all_equal:\n",
    "                        print('Img: ', img, 'Calss',cls, 'LINE', line, 'All equal', all_equal)   \n",
    "                    else:\n",
    "                        max_diff = np.max(gt2[img, line,:, cls]- gt[img, line,:,cls])\n",
    "                        print('Img: ', img, 'Calss',cls, 'LINE', line, 'All equal', all_equal,' Max difference :', max_diff.eval() )\n",
    "    #                 print(' -- pred_hm\\n',  gt[img, line, :,cls])\n",
    "    #                 print(' -- prd_hm2\\n', gt2[img, line, :, cls])                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:04.730267Z",
     "start_time": "2018-05-10T15:10:00.524802Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {in_tensor: pred_tensor}\n",
    "fetches = [stacked_tensor, rnd_tensor, gauss_sum]\n",
    "sess = tf.Session()\n",
    "print(' tfsession() is ', sess)\n",
    "tt = sess.run(fetches, feed_dict = feed_dict )\n",
    "print(type(tt), len(tt))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:04.974515Z",
     "start_time": "2018-05-10T15:10:04.731741Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "img = 1\n",
    "print(' Stacked Tensor Shape: ', tt[0].shape)\n",
    "print(' Stacked Tensor :   \\n ', tt[0][img])\n",
    "\n",
    "print(' rnd_tensor shape ', tt[1].shape)\n",
    "print(' rnd_tensor :  \\n ', tt[1][img])\n",
    "\n",
    "print(' Gauss_Sum shape :\\n', tt[2].shape)\n",
    "# print(' FP gt boxes        :\\n', tt[3])\n",
    "# print(' FP gt class assign :\\n', tt[4])\n",
    "# print(' gt class ids assign :\\n', tt[5])\n",
    "# print()\n",
    "# print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "# print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "# print()\n",
    "# print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "# print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "# print()\n",
    "# print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "# print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# # return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T13:43:36.617141Z",
     "start_time": "2018-05-10T13:43:35.151625Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    gauss_sum = development_build_gaussian_tf(KB.constant(pred_tensor), model.config, names = ['Dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "    rnd_tensor = tf.floor(stacked_tensor)    \n",
    "    sum_tensor = tf.reduce_sum(tf.abs(rnd_tensor[:,:,:4]), axis=-1)\n",
    "    non_zero   = tf.cast(sum_tensor, tf.bool)\n",
    "    non_zero_exp = tf.expand_dims(non_zero, axis =-1)\n",
    "    \n",
    "    print(' rnd_tensor :', tf.shape(rnd_tensor).eval())\n",
    "    print(' sum_tensor :', tf.shape(sum_tensor).eval())\n",
    "    print(' non_zero   :', tf.shape(non_zero).eval())\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    non_zero_exp = KB.repeat_elements(non_zero_exp, 6, axis=-1)\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    nz_tensor  = tf.boolean_mask(rnd_tensor, non_zero_exp, axis = -1)\n",
    "    print(' nz_tensor  :', tf.shape(nz_tensor).eval())\n",
    "\n",
    "#     print(stacked_tensor[0].eval())\n",
    "    print(rnd_tensor[0].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[1].eval())\n",
    "    print(rnd_tensor[1].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[2].eval())\n",
    "    print(rnd_tensor[2].eval())\n",
    "    \n",
    "    print(sum_tensor[1].eval())    \n",
    "    print(non_zero[1].eval())    \n",
    "#     non_zeros = tf.cast(tf.reduce_sum(tf.abs(rnd_tensor), axis=1), tf.bool)\n",
    "    print(non_zero_exp[1].eval())    \n",
    "\n",
    "    print(nz_tensor[1].eval())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "INPUT1 = pred_hm\n",
    "INPUT2 = pred_hm_norm\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('INPUT1 shape : ', INPUT1.shape, ' INPUT2 shape: ', INPUT2.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'INPUT1 -  image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', INPUT1[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(INPUT1[img,:,:,cls], title = ttl)  \n",
    "    \n",
    "    ttl = 'INPUT2 -  image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', INPUT2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(INPUT2[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:12:47.630505Z",
     "start_time": "2018-05-11T13:12:47.372814Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(pred_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = pred_tensor[:,:,:,3] - pred_tensor[:,:,:,1]      # x2 - x1\n",
    "height = pred_tensor[:,:,:,2] - pred_tensor[:,:,:,0]\n",
    "cx     = pred_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = pred_tensor[:,:,:,0] + ( height / 2.0)\n",
    "means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(means.shape)\n",
    "print(means[0,2,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:20:27.357106Z",
     "start_time": "2018-05-11T13:20:27.100938Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gt_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = gt_tensor[:,:,:,3] - gt_tensor[:,:,:,1]      # x2 - x1\n",
    "height = gt_tensor[:,:,:,2] - gt_tensor[:,:,:,0]\n",
    "cx     = gt_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = gt_tensor[:,:,:,0] + ( height / 2.0)\n",
    "gt_means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(gt_means.shape)\n",
    "print(gt_means[0,2,:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Find maximum of gaussian distributions for the pred_heatmap\n",
    "Potentially use this as our heatmap scores \n",
    "Found out that using MAX values from the class heatmap (currently generated from the pred_tensor that itself is generated form output_rois and mrcnn_class) is not a viable option, because mutlple max values tend to congreagate around the peak of the gaussian distribution. \n",
    "This is also the case for gt_heatmaps.\n",
    "This will probably also be the case for the FCN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### pred_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:23:37.739059Z",
     "start_time": "2018-05-11T13:23:37.484900Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "\n",
    "print(pred_hm.shape)\n",
    "cls_hm = pred_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print(pred_hm_norm.shape)\n",
    "cls_hm_norm = pred_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:09:06.929477Z",
     "start_time": "2018-05-11T13:09:06.655253Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### gt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:12.185707Z",
     "start_time": "2018-05-11T13:24:11.932533Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print(pred_hm.shape)\n",
    "cls_hm = gt_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print('---- norm -----')\n",
    "print(gt_hm_norm.shape)\n",
    "cls_hm_norm = gt_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:14.243495Z",
     "start_time": "2018-05-11T13:24:13.965220Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:48:39.739236Z",
     "start_time": "2018-05-11T11:48:39.479040Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "max_a = np.max(cls_pred_heatmap)\n",
    "print(max_a.shape)\n",
    "\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Compute mean and max of `gauss_grid()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.778443Z",
     "start_time": "2018-05-02T10:04:08.500Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Compute mean and max of `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.776944Z",
     "start_time": "2018-05-02T10:03:27.542792Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid2[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Compute `gauss_grid()` and   `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:39.307514Z",
     "start_time": "2018-05-02T11:10:38.603585Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "gauss_max  = KB.max(gauss_grid, axis = [2,3]).eval()\n",
    "gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max[img, bbx],gauss_max2[img,bbx],(gauss_max[img,bbx]== gauss_max2[img,bbx])))\n",
    "del gauss_max, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Compute `gauss_sum()` and  `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:52.883112Z",
     "start_time": "2018-05-02T11:10:52.154331Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape, gauss_sum2.shape)\n",
    "# print(gauss_grid2.shape)\n",
    "tst1 = tf.transpose(gauss_sum, [0,3,1,2])\n",
    "tst2 = tf.transpose(gauss_sum2, [0,3,1,2])\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "gauss_max1 = KB.max(tst1, axis = [2,3]).eval()\n",
    "gauss_max2 = KB.max(tst2, axis = [2,3]).eval()\n",
    "print(gauss_max1.shape, gauss_max2.shape)\n",
    "\n",
    "# gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max1[img, bbx],gauss_max2[img,bbx],(gauss_max1[img,bbx]== gauss_max2[img,bbx])))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:58:45.332214Z",
     "start_time": "2018-05-02T10:58:44.117193Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}    Equal : {}'.format(img, bbx, (tst1[img,bbx]==  tst2[img,bbx])))\n",
    "del gauss_max1, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "###  Compute mean and max OF `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:55:59.702691Z",
     "start_time": "2018-05-02T09:55:42.231847Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum2[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(gauss_sum2[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(gauss_sum2[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Compute min and max of `gauss_sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:57:11.807587Z",
     "start_time": "2018-05-02T09:56:55.286325Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum[img,:,:,cls]).eval()\n",
    "        gauss_min  =  KB.min(gauss_sum[img, :,:,cls]).eval()\n",
    "        gauss_max  =  KB.max(gauss_sum[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:44:41.071788Z",
     "start_time": "2018-05-02T08:44:33.434419Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "pred_gauss = tf.constant(layers_out[19])\n",
    "print(pred_gauss.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(pred_gauss[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(pred_gauss[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(pred_gauss[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:14:01.486755Z",
     "start_time": "2018-05-02T11:13:59.680438Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = gauss_sum.eval()    # gt_gaussiam \n",
    "gt_heatmap  = layers_out[18]     # gt_gaussiam \n",
    "\n",
    "pred_heatmap= gauss_sum2.eval()  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "### Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Softmax Sparse Cross Entropy Ignoring Last Label -- Used in Keras FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T07:53:31.114036Z",
     "start_time": "2018-04-27T07:53:30.853311Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "\n",
    "y_pred = tf.placeholder(dtype=tf.float32, shape=(16,320,320,20))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(16,320,320,1))\n",
    "print(K.int_shape(y_pred), K.int_shape(y_true))\n",
    "y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "print(K.int_shape(y_pred))\n",
    "log_softmax = tf.nn.log_softmax(y_pred)\n",
    "print(K.int_shape(log_softmax))\n",
    "\n",
    "y_true = K.flatten(y_true)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "y_true = K.one_hot(tf.to_int32(y_true), K.int_shape(y_pred)[-1]+1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "unpacked = tf.unstack(y_true, axis=-1)\n",
    "print(len(unpacked), unpacked[0].shape)\n",
    "\n",
    "y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "\n",
    "cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "print(K.int_shape(cross_entropy))\n",
    "\n",
    "cross_entropy_mean = K.mean(cross_entropy)\n",
    "print(K.int_shape(cross_entropy_mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import keras.backend as K\n",
    "# print(K.int_shape(bef_pos)[-1])\n",
    "# unpacked  = K.flatten(test)\n",
    "# unpacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:19:54.102900Z",
     "start_time": "2018-04-16T23:19:53.889289Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Experimental code to Create mask for class bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Comparing Scipy / Tensorflow Multivar normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:10:11.958301Z",
     "start_time": "2018-04-16T10:10:10.121532Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "tfd        = tf.contrib.distributions\n",
    "grid       = pos_grid_1[:,:,0,0,:]\n",
    "covar      = np.array([27.7818, 26.6678],dtype = np.float32)\n",
    "covar_sqrt = np.sqrt(covar)\n",
    "covar_sqrd = covar ** 2\n",
    "full_covar = np.array([[27.7818, 0],[0, 26.6678]],dtype = np.float32)\n",
    "mean       = np.array([48.8926, 36.101 ],dtype = np.float32)\n",
    "\n",
    "print('   grid :', grid.dtype, grid.shape)\n",
    "print('   Covar sqrt :', covar_sqrt)\n",
    "print('   Covar sqrd :', covar_sqrd)\n",
    "\n",
    "mvn1  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar_sqrt)\n",
    "prob1 = mvn1.prob(grid2)\n",
    "print()\n",
    "print('   mvn1 mean             ', mvn1.mean().eval())\n",
    "print('   mvn1 std deviation    ', mvn1.stddev().eval())\n",
    "print('   mvn1 covariance:      ', '\\n', mvn1.covariance().eval())\n",
    "print('   mvn1 location         ', mvn1.loc.eval())\n",
    "print('   Linear OP shape       ', mvn1.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn1.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn1.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn1.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn1.scale.diag_part().eval()) \n",
    "\n",
    "mvn2  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar)\n",
    "prob2 = mvn2.prob(grid2)\n",
    "print()\n",
    "print('   mvn2 mean             ', mvn2.mean().eval())\n",
    "print('   mvn2 std deviation    ', mvn2.stddev().eval())\n",
    "print('   mvn2 covariance:      ', '\\n', mvn2.covariance().eval())\n",
    "print('   mvn2 location         ', mvn2.loc.eval())\n",
    "print('   Linear OP shape       ', mvn2.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn2.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn2.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn2.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn2.scale.diag_part().eval()) \n",
    "\n",
    "\n",
    "mvn3  = tfd.MultivariateNormalFullCovariance( loc = mean, covariance_matrix = full_covar)\n",
    "prob3 = mvn3.prob(grid2)\n",
    "print()\n",
    "print('   mvn3 mean             ', mvn3.mean().eval())\n",
    "print('   mvn3 std deviation    ', mvn3.stddev().eval())\n",
    "print('   mvn3 covariance:      ', '\\n', mvn3.covariance().eval())\n",
    "print('   mvn3 location         ', mvn3.loc.eval())\n",
    "print('   Linear OP shape       ', mvn3.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn3.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn3.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn3.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn3.scale.diag_part().eval()) \n",
    "\n",
    "print('   << output probabilities shape:' )\n",
    "print(' prob1 ', prob1.get_shape())\n",
    "print(prob1.eval())\n",
    "print(' prob2 ', prob2.get_shape())\n",
    "print(prob2.eval())\n",
    "print(' prob3 ', prob3.get_shape())\n",
    "print(prob3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:30.850107Z",
     "start_time": "2018-04-16T09:59:30.182014Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "# print(XX)\n",
    "# print(YY)\n",
    "# print(pos[0,:,:])\n",
    "# print(pos[0])\n",
    "# print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna    = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "prob_b = mvnb.pdf(pos)\n",
    "\n",
    "print(prob_a[35:50, 45:54])\n",
    "max_a = np.max(prob_a)\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Original `build heatmap()` prior to modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T14:45:58.207448Z",
     "start_time": "2018-05-15T14:45:55.245020Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "##def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "# in_tensor = KB.constant(pred_tensor)\n",
    "# graph1 = tf.Graph()\n",
    "# with graph1.as_default():\n",
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "in_tensor = tf.identity(pred_tensor)\n",
    "# in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "config = model.config\n",
    "names = ['Dev']\n",
    "\n",
    "\n",
    "\n",
    "num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "batch_size      = config.BATCH_SIZE\n",
    "num_classes     = config.NUM_CLASSES  \n",
    "print('\\n ')\n",
    "print('  > build_heatmap() for ', names )\n",
    "\n",
    "# rois per image is determined by size of input tensor \n",
    "#   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "#   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "# in_tensor = in_tensor[:,:,:,2:7]\n",
    "print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "\n",
    "rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "# strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "print('    num of bboxes per class is : ', rois_per_image.eval(session=sess))\n",
    "#-----------------------------------------------------------------------------\n",
    "## Build mesh-grid to hold pixel coordinates  \n",
    "#-----------------------------------------------------------------------------\n",
    "X = tf.range(img_w, dtype=tf.int32)\n",
    "Y = tf.range(img_h, dtype=tf.int32)\n",
    "X, Y = tf.meshgrid(X, Y)\n",
    "print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "# print('    X : \\n',X.eval())\n",
    "# print('    Y : \\n',Y.eval())\n",
    "\n",
    "# duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "rep_X = ones * X\n",
    "rep_Y = ones * Y \n",
    "print('    Ones: ',ones.shape)                \n",
    "print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "# # stack the X and Y grids \n",
    "bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "print('    before transpse ', bef_pos.get_shape())\n",
    "pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "#-----------------------------------------------------------------------------    \n",
    "## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "# pt2_ind shape is [?, 3]. \n",
    "#   pt2_ind[0] corresponds to image_index \n",
    "#   pt2_ind[1] corresponds to class_index \n",
    "#   pt2_ind[2] corresponds to roi row_index \n",
    "# pt2_dense shape is [?, 6]\n",
    "#    pt2_dense[0] is image index\n",
    "#    pt2_dense[1:4]  roi cooridnaytes \n",
    "#    pt2_dense[5]    is class id \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "print('    pt2_sum shape ',pt2_sum.shape)\n",
    "# print(pt2_sum[0].eval())\n",
    "pt2_ind = tf.where(pt2_sum > 0)\n",
    "\n",
    "## replaced the two operations with the one above\n",
    "# pt2_mask = tf.greater(pt2_sum , 0)\n",
    "# pt2_ind  = tf.where(pt2_mask)\n",
    "\n",
    "# print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "# print(pt2_mask.eval())\n",
    "print('    pt2_ind shape ', tf.shape(pt2_ind).eval() )\n",
    "print(pt2_ind.eval())\n",
    "# pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "# append image index to front of rows - REMOVED 1-5-2018\n",
    "# pt2_ind[:,0] is the same informaiton and is used in dynamic_partition\n",
    "\n",
    "#  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "print('    dense shape ',tf.shape(pt2_dense).eval())\n",
    "print(pt2_dense.eval())\n",
    " \n",
    "\n",
    "## we want to slice pt2._dense by Batch size.\n",
    "## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "##  Build Stacked output from dynamically partitioned lists \n",
    "#-----------------------------------------------------------------------------\n",
    "print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "stacked_output=[]\n",
    "for img, item  in enumerate(stacked_list) : \n",
    "    rois_in_image  = tf.shape(item)[0]\n",
    "    pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "    stacked_output.append(pad_item)\n",
    "stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "# print()    \n",
    "# print('   -- Stacked output contents --------------')    \n",
    "# print('    stacked_output shape : ', len(stacked_output))\n",
    "# for img, item  in enumerate(stacked_output) :\n",
    "    # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "print(stacked_tensor.eval())\n",
    "\n",
    "##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "#-----------------------------------------------------------------------------\n",
    "width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "means  = tf.stack((cx,cy),axis = -1)\n",
    "covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "covar  = tf.sqrt(covar)\n",
    "\n",
    "\n",
    "print('    means shape :', tf.shape(means).eval(),' covar shape ', tf.shape(covar).eval())\n",
    "\n",
    "tfd = tf.contrib.distributions\n",
    "mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "prob_grid = mvn.prob(pos_grid)\n",
    "print(prob_grid.shape)\n",
    "prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "print(prob_grid.shape)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "# which cause singular sigma cov matrices\n",
    "#--------------------------------------------------------------------------------\n",
    "gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "\n",
    "## scatter out the probability distributions based on class --------------------------\n",
    "print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                    indexing = 'ij' )\n",
    "scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "print('    class shape        : ', class_inds.get_shape())\n",
    "print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "print(scatter_classes.eval())\n",
    "\n",
    "## heatmap: sum gauss_scattered based on class ---------------------------------------\n",
    "print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap')\n",
    "print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )  \n",
    "gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "### development of `build_mask_routine()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:31:10.879155Z",
     "start_time": "2018-05-15T17:31:10.540145Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(' Heatmap tensor shape is :', gauss_scatt2_reshape.shape)\n",
    "\n",
    "def build_mask_routine(input_list):\n",
    "    heatmap_tensor, input_row = input_list\n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        #         tensor_output = tf.zeros_like(config.IMAGE_SHAPE[:2], dtype = tf.int32)\n",
    "        #         input_row = tf.cast(input_row, tf.int32)\n",
    "        y_extent  = tf.range(input_row[0], input_row[2])\n",
    "        x_extent  = tf.range(input_row[1], input_row[3])\n",
    "\n",
    "        Y,X       = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        mask_indices = tf.to_int32(mask_indices)\n",
    "        #     print('===> Box input is : ', row)   \n",
    "        #     print('    y_extent (Row) ', y_extent, y_extent.shape)\n",
    "        #     print('    x_extent (Cols)', x_extent, x_extent.shape)   \n",
    "        #     print(Y.shape, X.shape)\n",
    "        #     print(X.eval())\n",
    "        #     print('    bbox_mask shape: ',bbox_mask.shape)\n",
    "        #     print(bbox_mask.eval())\n",
    "        #     rows = mask_indices.shape[0]\n",
    "        #     class_id,_ = tf.meshgrid(row[4], mask_indices[:,1] )\n",
    "        #     class_id = row[4]\n",
    "        #     print('    Size of mask_indices: ', mask_indices.shape)\n",
    "        #     print('    Number of rows : ',rows )     \n",
    "        #     mask_indices = tf.concat([class_id,  mask_indices ], axis= 1)\n",
    "        #     print('    Size of mask_indices for this bbox: ', mask_indices.shape)\n",
    "        #     print(mask_indices.eval())         \n",
    "        #     mask_size = mask_indices.get_shape()\n",
    "        #     print(mask_size)\n",
    "        #     mask_updates = tf.ones_like(tf.shape(mask_size), dtype = tf.int32)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        #     print('    Size of mask_updates for this bbox: ', mask_updates.shape)    \n",
    "        #     print('  size of bbox_mask: ', mask_size)\n",
    "        #     print(' Before scatter_nd_add ')\n",
    "        #     print(tensor_var.eval())\n",
    "        mask = tf.scatter_nd(mask_indices, mask_updates, config.IMAGE_SHAPE[:2])\n",
    "        #         mask_applied = tf.multiply(heatmap_tensor[index[0], index[1]], mask, name = 'mask_applied')\n",
    "        mask_applied  = tf.multiply(heatmap_tensor, mask, name = 'mask_applied')\n",
    "#         bbox_pred_sum = tf.expand_dims( tf.reduce_sum(mask_applied),-1)\n",
    "#         area      = tf.expand_dims((input_row[2]-input_row[0]) * (input_row[3]-input_row[1]), axis = -1)\n",
    "        area      = (input_row[2]-input_row[0]) * (input_row[3]-input_row[1])    \n",
    "        bbox_pred_sum =  tf.reduce_sum(mask_applied)\n",
    "    return tf.stack([bbox_pred_sum, area], axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "## generate score based on gaussian using bouding box masks ----------------------------------\n",
    "## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "##--------------------------------------------------------------------------------------------\n",
    "# flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "scatter_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "bboxes = tf.to_int32(tf.round(scatter_flattened[...,0:4]))\n",
    "print('    scatter_flattened is ', scatter_flattened.shape)\n",
    "print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "# DONT NEED THIS - was put there to try to avoid computing sum/area for zero bboxes.\n",
    "# kept as reference for future generations .....\n",
    "# bbox_sum = tf.reduce_max(in_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "# print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "gauss_scatt_shape   = KB.int_shape(gauss_scatt)\n",
    "gauss_scatt_reshape = KB.reshape(gauss_scatt, (-1, gauss_scatt_shape[-2], gauss_scatt_shape[-1]))\n",
    "print('    gaussian scatter shape : ', gauss_scatt_shape)\n",
    "print('    gaussian scatter reshaped : ', gauss_scatt_reshape.shape)\n",
    "# ones_map = tf.ones([384,128,128])   \n",
    "scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)\n",
    "\n",
    "new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]        \n",
    "gaussian_bbox_scores = tf.concat([scatter_flattened, scores], axis = -1)\n",
    "print('    Scatter Flattened shape : ', scatter_flattened.shape))\n",
    "print('    Scores shape :            ', scores.shape)\n",
    "print('    gaussian_boxes_scores initial shape: ', gaussian_bbox_scores.shape)    \n",
    "gaussian_bbox_scores = tf.reshape(concat, new_shape)\n",
    "print('    gaussian_bbox_scores final shape   : ', gaussian_bbox_scores.shape)\n",
    "print('    complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:59:33.486569Z",
     "start_time": "2018-05-15T17:59:32.859747Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:12:00.528378Z",
     "start_time": "2018-05-15T18:11:57.234725Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]\n",
    "print(tf.shape(in_tensor).eval())\n",
    "print(new_shape.eval())      \n",
    "print(tf.shape(reshape_tensor).eval())\n",
    "print(tf.shape(scores).eval())\n",
    "\n",
    "concat = tf.concat([reshape_tensor, scores], axis = -1)\n",
    "gaussian_boxes_scores = tf.reshape(concat, new_shape)\n",
    "print(tf.shape(gaussian_boxes_scores).eval())\n",
    "print(gaussian_boxes_scores[0,0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:12:17.044573Z",
     "start_time": "2018-05-15T18:12:16.786856Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(pred_tensor[0,0])\n",
    "# print(type(int_scores), len(int_scores), int_scores[0].shape, int_scores[1].shape)\n",
    "# print(type(int_scores), int_scores.shape)\n",
    "# results = tf.concat(int_scores, axis = -1)\n",
    "# print(tf.shape(results).eval())\n",
    "# print(results[:32].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:30:13.657068Z",
     "start_time": "2018-05-15T17:30:12.045620Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# print(pred_tensor[0,0])\n",
    "# bboxes = tf.concat([bboxes, tf.expand_dims(int_scores, axis = -1)],axis = -1 )\n",
    "print(reshape_tensor[10].eval())\n",
    "tst = gauss_scatt_reshape[10]\n",
    "print(tst.eval())\n",
    "tst1 = tf.where(tf.is_nan(tst),  tf.zeros_like(tst), tst)\n",
    "print(tst1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T19:55:35.838068Z",
     "start_time": "2018-05-15T19:55:35.570335Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(output_rois[1]*[128,128,128,128])\n",
    "print(pred_tensor[1,2])\n",
    "print(pred_hm_scores[1,2])\n",
    "print(pred_hm_scores[1,2,:,-2]/pred_hm_scores[1,2,:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Successful attempt to nbuild masks based on boudiung boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:09:26.303677Z",
     "start_time": "2018-05-14T23:09:26.051088Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "try: \n",
    "    del input_tensor\n",
    "    print('input_tensor was deleted')\n",
    "except:\n",
    "    print('input tensor was not defined ')\n",
    "    pass\n",
    "# \n",
    "# tf.reset_default_graph()  \n",
    "try: \n",
    "    del canvas\n",
    "    print('Canvas was deleted')\n",
    "except:\n",
    "    print('Canvas was not defined ')\n",
    "# sess = KB.get_session()\n",
    "# print(sess)\n",
    "# pred_tensor_tf = tf.identity(pred_tensor)\n",
    "# gauss_sum2 =  build_heatmap(pred_tensor_tf, model.config, names = 'Kevin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:48:27.547714Z",
     "start_time": "2018-05-14T23:48:27.177650Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess= tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "input_tensor = tf.identity(pred_tensor)\n",
    "# heatmap_tensor = tf.identity(tf.transpose(pred_hm_norm, perm=[0,3,1,2]))\n",
    "heatmap_tensor = tf.ones([3,4,128,128])\n",
    "heatmap_tensor  += heatmap_tensor\n",
    "print(' Heatmap tensor shae is :', heatmap_tensor.shape)\n",
    "\n",
    "def f1(): return  tf.zeros_like(config.IMAGE_SHAPE[:2])\n",
    "\n",
    "def build_mask_routine(heatmap_tensor, input_row, index):\n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        #         tensor_output = tf.zeros_like(config.IMAGE_SHAPE[:2], dtype = tf.int32)\n",
    "        #         input_row = tf.cast(input_row, tf.int32)\n",
    "        y_extent  = tf.range(input_row[0], input_row[2])\n",
    "        x_extent  = tf.range(input_row[1], input_row[3])\n",
    "        Y,X       = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        #     print('===> Box input is : ', row)   \n",
    "        #     print('    y_extent (Row) ', y_extent, y_extent.shape)\n",
    "        #     print('    x_extent (Cols)', x_extent, x_extent.shape)   \n",
    "        #     print(Y.shape, X.shape)\n",
    "        #     print(X.eval())\n",
    "        #     print('    bbox_mask shape: ',bbox_mask.shape)\n",
    "        #     print(bbox_mask.eval())\n",
    "        #     rows = mask_indices.shape[0]\n",
    "        #     class_id,_ = tf.meshgrid(row[4], mask_indices[:,1] )\n",
    "        #     class_id = row[4]\n",
    "        #     print('    Size of mask_indices: ', mask_indices.shape)\n",
    "        #     print('    Number of rows : ',rows )     \n",
    "        #     mask_indices = tf.concat([class_id,  mask_indices ], axis= 1)\n",
    "        #     print('    Size of mask_indices for this bbox: ', mask_indices.shape)\n",
    "        #     print(mask_indices.eval())         \n",
    "        #     mask_size = mask_indices.get_shape()\n",
    "        #     print(mask_size)\n",
    "        #     mask_updates = tf.ones_like(tf.shape(mask_size), dtype = tf.int32)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        #     print('    Size of mask_updates for this bbox: ', mask_updates.shape)    \n",
    "        #     print('  size of bbox_mask: ', mask_size)\n",
    "        #     print(' Before scatter_nd_add ')\n",
    "        #     print(tensor_var.eval())\n",
    "        mask = tf.scatter_nd(mask_indices, mask_updates, config.IMAGE_SHAPE[:2])\n",
    "        mask_applied = tf.multiply(heatmap_tensor[index[0], index[1]], mask, name = 'mask_applied')\n",
    "        bbox_pred_sum = tf.reduce_sum(mask_applied)\n",
    "    return bbox_pred_sum\n",
    "\n",
    "\n",
    "#     tensor_output = tf.scatter_nd_add(tensor_input, mask_indices, mask_updates)\n",
    "#     print('    Tensor_output shape:  ', tensor_output.shape)\n",
    "#     print(tensor_output[2].eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:48:31.132863Z",
     "start_time": "2018-05-14T23:48:30.817404Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "input is a row of the pred_tensor array (x1,y1, x2,y2)\n",
    "'''\n",
    "# input_tensor = tf.placeholder(tf.float32,shape=[config.BATCH_SIZE, config.NUM_CLASSES, config.TRAIN_ROIS_PER_IMAGE,6])\n",
    "# heatmap_tensor = tf.placeholder(tf.float32,shape=[config.BATCH_SIZE, config.FCN_INPUT_SHAPE[0], config.FCN_INPUT_SHAPE[1], config.NUM_CLASSES])\n",
    "\n",
    "reshape_tensor  = tf.reshape(input_tensor, [-1,6])\n",
    "# num_imgs, num_classes, num_rois, cols = KB.int_shape(input_tensor)\n",
    "print('input_shape is ', input_tensor.shape) \n",
    "# print(' Or: ', num_imgs, num_classes, num_rois, cols)\n",
    "num_boxes, num_cols = KB.int_shape(reshape_tensor)\n",
    "print('reshape_tensor is ', reshape_tensor.shape)\n",
    "\n",
    "bbox_sum = tf.reduce_max(input_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "bboxes = tf.concat([tf.to_int32(tf.round(reshape_tensor[...,0:4])), reshape_tensor[...,4:]], axis = -1, name='nz_boxes')\n",
    "print('boxes shape', bboxes.shape)\n",
    "# print(bboxes.eval())\n",
    "\n",
    "#     print(bbox_sum.eval(session = sess))\n",
    "# nz_inds  = tf.where(bbox_sum > 0 , name ='nz_inds')\n",
    "# print(' shape of indexes to non zeros bouding boxes : ',nz_inds.shape)\n",
    "#     print(nz_inds.eval(session = sess))\n",
    "\n",
    "# nz_inds = nz_inds[0:6]\n",
    "# num_nz_inds = tf.shape(nz_inds)[0]\n",
    "# print('number of non-zeros indices:', num_nz_inds.eval())\n",
    "\n",
    "# tmp = tf.gather_nd(input_tensor, nz_inds, name = 'tmp')\n",
    "# print(nz_boxes.get_shape())\n",
    "#     print(nz_boxes.eval(session = sess))\n",
    "\n",
    "\n",
    "# print('non zeros boxes shape:', tf.shape(nz_boxes).eval(session = sess)) \n",
    "# print(nz_boxes[:11].eval(session = sess))\n",
    "\n",
    "# print('non zeros boxes shape:', tf.shape(tst_boxes)) \n",
    "# print(tst_boxes.eval(session = sess))\n",
    "\n",
    "# nz_boxes = tf.Print(nz_boxes, [tf.shape(nz_inds)],message='Non zero bounding boxes')\n",
    "# print(nz_boxes.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T00:08:57.949522Z",
     "start_time": "2018-05-14T23:53:50.353147Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bboxes.shape)\n",
    "num_bboxes = bboxes.shape[0]\n",
    "score_list = []\n",
    "\n",
    "print('num_bboxes: ', num_bboxes)\n",
    "for i in range(num_bboxes):\n",
    "    index = tf.unravel_index(i, input_tensor.shape[0:3])\n",
    "    heatmap_tensor = tf.Print(heatmap_tensor, [index], message= 'Index is ')\n",
    "    print('Call ', i, 'Unraveled: (' ,index.eval(), ') for ', bboxes[i].eval())\n",
    "    \n",
    "#     new_mask = tf.assign(mask, zero)    \n",
    "    summ = tf.reduce_max(bboxes[i,0:4],name = \"max_element\")\n",
    "#     output=tf.cond(tf.equal(summ, 0),\n",
    "#                 f1,\n",
    "#                 lambda: build_mask_routine(mask , bboxes[i])   )\n",
    "#         return tensor_output    \n",
    "    score = build_mask_routine(heatmap_tensor, bboxes[i], index)\n",
    "    print('       Score', score.eval())\n",
    "#     print(' Mask shape: ',mask.get_shape() )\n",
    "    score_list.append(score)\n",
    "final_scores = tf.stack(score_list,axis=-1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:52:22.284988Z",
     "start_time": "2018-05-14T23:52:21.321147Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(final_scores.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Run TF session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T22:50:07.054593Z",
     "start_time": "2018-05-14T22:50:05.476250Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {input_tensor: pred_tensor}\n",
    "# fetches = [nz_boxes, int_masks]\n",
    "fetches = [bboxes, output, reshape_tensor, final_output]\n",
    "sess = tf.Session()\n",
    "print(' tfsession() is ', sess)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tt = sess.run(fetches, feed_dict = feed_dict )\n",
    "print(type(tt), len(tt))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T21:24:56.753927Z",
     "start_time": "2018-05-14T21:24:56.499752Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(len(Output_list))\n",
    "for i in range(len(Output_list)):\n",
    "    print(Output_list[i].shape, type(Output_list[i]))\n",
    "    print(mask_string(Output_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T22:07:10.133092Z",
     "start_time": "2018-05-14T22:07:09.861953Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import mask_string\n",
    "# img = 1\n",
    "np.set_printoptions(linewidth=150, precision=6, threshold=20000)\n",
    "print(' bboxes Shape: ', tt[0].shape)\n",
    "print(' bboxes Tensor :   \\n ', tt[0][32:48])\n",
    "\n",
    "print('\\n')\n",
    "print(' pred_tensor shape : ', pred_tensor.shape)\n",
    "print(' pred_tensor      \\n ', pred_tensor[0,0,32:48])\n",
    "\n",
    "# print(' tst_boxes shape ', tt[1].shape)\n",
    "# print(' tst_boxes :   \\n ', tt[1])\n",
    "\n",
    "# print(' masks shape :   ', tt[1].shape, type(tt[1]))\n",
    "# print(' masks :      \\n ', mask_string(tt[1]))\n",
    "print('\\n')\n",
    "print(' reshape_tensor shape :   ', tt[2].shape, type(tt[2]))\n",
    "print(' reshape_tensor :      \\n ', tt[2][32:48])\n",
    "print('\\n')\n",
    "print(' reshape_tensor shape :   ', tt[3].shape, type(tt[3]))\n",
    "# print(' reshape_tensor :      \\n ', tt[3][0:10])\n",
    "  \n",
    "\n",
    "\n",
    "print(mask_string(tt[3][:,:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat tesnor at given axis n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T11:59:13.056822Z",
     "start_time": "2018-05-17T11:59:11.096615Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.layers as KL\n",
    "np.set_printoptions(linewidth=130,precision=4,threshold=7000, suppress = True)\n",
    "\n",
    "sess  = KB.get_session()\n",
    "print(sess)\n",
    "test1 = KB.identity(output_rois)\n",
    "print(pred_heatmap_norm.shape)\n",
    "pred_hm_norm = KB.identity(pred_heatmap_norm)\n",
    "test1 = tf.transpose(pred_heatmap_norm, (0,3,1,2))\n",
    "test1_shape = KB.int_shape(test1)\n",
    "\n",
    "with sess.as_default():\n",
    "    print(test1_shape)\n",
    "    test1_sum = tf.reduce_sum(test1, [2,3]).eval()\n",
    "    print('test1_sum is ', test1_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            print('img ',i,' class ', j, ' sum: ', test1_sum[i,j])\n",
    "            \n",
    "    test2 = tf.expand_dims(test1, axis =2)\n",
    "    print('  Test2 shapes :',  test2.get_shape())\n",
    "    test2 = tf.tile(test2, [1,2,32,1,1])\n",
    "    print('  Test2 shapes :',  test2.get_shape())\n",
    "    test2_sum = tf.reduce_sum(test2, [3,4]).eval()\n",
    "    print('test2_sum is ', test2_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            for k in range(32):\n",
    "                print('img ',i,' class ', j, 'copy ',k, ' sum:',test2_sum[i,j,k])\n",
    "\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "#     ones = tf.ones([7 ,1, 1, 1], dtype = tf.float32)    \n",
    "#     test2 = test1 * ones\n",
    "#     print(KB.int_shape(test2))\n",
    "\n",
    "#     test2 = tf.tile(test2, [1,3,1,1])\n",
    "#     for i in range(5):\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "\n",
    "# with sess.as_default():\n",
    "#     print(KB.int_shape(pred_hm_norm))\n",
    "#     test1_shape = KB.int_shape(test1)\n",
    "#     print(test1_shape)\n",
    "#     print(test1[0,:6].eval())\n",
    "#     print(test1[1,:6].eval())\n",
    "#     print(test1[2,:6].eval())\n",
    "#     print(test1[3,:6].eval())    \n",
    "#     print(test1[4,:6].eval())    \n",
    "#     test2 = tf.expand_dims(test1, axis =1)\n",
    "# #     print('  Test1 shapes :',  test1.get_shape())\n",
    "# #     ones = tf.ones([7 ,1, 1, 1], dtype = tf.float32)    \n",
    "# #     test2 = test1 * ones\n",
    "#     print(KB.int_shape(test2))\n",
    "\n",
    "#     test2 = tf.tile(test2, [1,3,1,1])\n",
    "#     for i in range(5):\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "# #     test3 = KB.reshape(test2, (-1,test1_shape[0], test1_shape[1]))    \n",
    "# #     print(KB.int_shape(test3))\n",
    "# #     print(test3.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate L2 norm on heatmap score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T08:39:30.643505Z",
     "start_time": "2018-05-17T08:39:29.898717Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# del scr\n",
    "# del scr_norm\n",
    "with sess.as_default():\n",
    "#     print(tf.shape(scr).eval())\n",
    "    print(pred_heatmap_scores[img,0])\n",
    "    scr = pred_heatmap_scores[...,6]/pred_heatmap_scores[...,7]\n",
    "    scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "    scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "#     print('l2 normalzied - 2')\n",
    "#     print(tf.shape(scr_norm).eval())    \n",
    "#     print(scr_norm.eval())\n",
    "    scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "#     print(tf.shape(scr_norm).eval())\n",
    "    print('tst')\n",
    "    tst = tf.concat([pred_heatmap_scores, scr_norm], axis = -1)\n",
    "    print(tst.shape)\n",
    "    print(tst[0].eval())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
