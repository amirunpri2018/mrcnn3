{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Development of a score based on the gaussian heatmaps \n",
    "This can be used to generate the 'ground truth' score of the heatmaps produced from the Contextual layer , which will be compared with the score produced from the FCN heatmaps layer. \n",
    "\n",
    "- First we generate the heatmaps, and also visually cehck them. \n",
    "- the we pass the heatmaps to the routine that prodcues the scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:49.763387Z",
     "start_time": "2018-05-17T19:52:29.040841Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_oldshapes_dev\n",
    "\n",
    "model, dataset_train, train_generator, config = prep_oldshapes_dev(init_with = 'last', FCN_layers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:50.026616Z",
     "start_time": "2018-05-17T19:52:49.766425Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:51.804107Z",
     "start_time": "2018-05-17T19:52:50.028621Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:52.058312Z",
     "start_time": "2018-05-17T19:52:51.807114Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.layer_info()\n",
    "# model.keras_model.outputs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:52.294944Z",
     "start_time": "2018-05-17T19:52:52.060287Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "print(sess)\n",
    "print(sess.list_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:55.141219Z",
     "start_time": "2018-05-17T19:52:52.296948Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "model_output = get_layer_output_1(model.keras_model, train_batch_x, [1,2,3,4, 15,17,19], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:52:55.379854Z",
     "start_time": "2018-05-17T19:52:55.143224Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "\n",
    "rpn_class                 = model_output[0]          # layer:  1   shape: (5, 4092, 2)\n",
    "rpn_bbox                  = model_output[1]          # layer:  2   shape: (5, 4092, 4)\n",
    "rpn_proposal_rois         = model_output[2]          # layer:  3   shape: (5, 2000, 4)\n",
    "output_rois               = model_output[3]          # layer:  4   shape: (5, 32, 4)\n",
    "pred_heatmap_norm         = model_output[4]          # layer: 15   shape: (5, 128, 128, 4)\n",
    "pred_heatmap_scores       = model_output[5]          # layer: 17   shape: (5, 4, 32, 8)\n",
    "pred_tensor               = model_output[6]          # layer: 19   shape: (5, 4, 32, 6)\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T17:14:53.861366Z",
     "start_time": "2018-05-17T17:14:43.641Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "input_gt_masks     = train_batch_x[6]\n",
    "print(' Input image shape is :', input_image.shape)\n",
    "h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  display Pred_Tensor, Pred_heatmap, mrcnn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T17:14:53.862356Z",
     "start_time": "2018-05-17T17:14:45.809Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=120, suppress=True)\n",
    "img = 0\n",
    "\n",
    "print(KB.int_shape(output_rois))\n",
    "print(output_rois[img,:15]*[128, 128,128,128])\n",
    "print(input_gt_class_ids[0])\n",
    "\n",
    "print(' Pred_tensor')\n",
    "print(pred_tensor.dtype)\n",
    "print(pred_tensor[img,:,:10])\n",
    "\n",
    "print(' Pred Heatmap Scores')\n",
    "print(pred_heatmap_scores.dtype)\n",
    "print(pred_heatmap_scores[img,:,:10])\n",
    "\n",
    "# img = 2\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "## `build_heatmap()`\n",
    "\n",
    "#### Prepare values to pass to build_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:33:12.884723Z",
     "start_time": "2018-05-17T19:33:12.640572Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in range(5):\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:34:28.313470Z",
     "start_time": "2018-05-17T19:34:28.064404Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor shape is ', pred_tensor.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_tensor[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T12:24:42.473397Z",
     "start_time": "2018-05-14T12:24:42.202707Z"
    },
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "print('gt_tensor shape is ', gt_tensor.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_tensor[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_heatmap_norm` is the final result from  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:37:21.686231Z",
     "start_time": "2018-05-17T19:37:21.448599Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "            print('img ',i,' class ', j, ' sum:',temp_sum[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_heatmap_scores` is the final result which is passed from  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T20:23:41.258810Z",
     "start_time": "2018-05-17T20:23:40.997610Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Copy of `build_heatmap` - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:28:04.381220Z",
     "start_time": "2018-05-17T19:28:03.802681Z"
    }
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "##  INPUTS :\n",
    "##    FCN_HEATMAP    [ numn_images x height x width x num classes ] \n",
    "##    PRED_HEATMAP_SCORES \n",
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "    \n",
    "# def build_heatmap(in_tensor, config, names = None):\n",
    "\n",
    "##def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "# in_tensor = KB.constant(pred_tensor)\n",
    "# graph1 = tf.Graph()\n",
    "# with graph1.as_default():\n",
    "# try:\n",
    "#     print(' Session to close ', sess)\n",
    "#     sess.close()\n",
    "#     print('session was deleted ')\n",
    "# except:\n",
    "#     print(' Session was not defined ', sess)\n",
    "#     pass\n",
    "sess = KB.get_session()\n",
    "print(' New session obtained from Kras', sess)\n",
    "\n",
    "with sess.as_default():\n",
    "##--------------------------------------------------------------------------\n",
    "## setup input values\n",
    "    in_tensor = tf.identity(pred_tensor)\n",
    "    # in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "\n",
    "    config = model.config\n",
    "    names = ['Dev']\n",
    "##--------------------------------------------------------------------------\n",
    "    \n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    print('\\n ')\n",
    "    print('  > NEW build_heatmap() for ', names )\n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)       \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    rois_per_image  = (in_tensor.shape)[2] \n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image )\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    # print(pt2_sum[0].eval())\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "\n",
    "    ## replaced the two operations below with the one above - 15-05-2018\n",
    "    # pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    # pt2_ind  = tf.where(pt2_mask)\n",
    "    # print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "    # print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "    # print(pt2_ind.eval())\n",
    "\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "    print('    dense shape ',pt2_dense.get_shape())\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([tf.shape(pt2_dense)[0] , 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[1,2,0,3])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = pt2_dense[:,3] - pt2_dense[:,1]      # x2 - x1\n",
    "    height = pt2_dense[:,2] - pt2_dense[:,0]\n",
    "    cx     = pt2_dense[:,1] + ( width  / 2.0)\n",
    "    cy     = pt2_dense[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('     Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('     Prob_grid shape after tanspose: ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## IMPORTANT: kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    ## which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    prob_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "\n",
    "    # scatter out the probability distributions based on class --------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------') \n",
    "    gauss_scatt   = tf.scatter_nd(pt2_ind, prob_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "    print('    pt2_ind shape   : ', pt2_ind.shape)  \n",
    "    print('    prob_grid shape : ', prob_grid.shape)  \n",
    "    print('    gauss_scatt     : ', gauss_scatt.shape)   # batch_sz , num_classes, num_rois, image_h, image_w\n",
    "    \n",
    "    # heatmap: sum gauss_scattered based on class ---------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap2')\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-12, gauss_sum, tf.zeros_like(gauss_sum))\n",
    "    \n",
    "    print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )      \n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## heatmap L2 normalization\n",
    "    ## Normalization using the  `gauss_sum` (batchsize , num_classes, height, width) \n",
    "    ## 17-05-2018 (New method, replace dthe previous method that usedthe transposed gauss sum\n",
    "    ## 17-05-2018 Replaced with normalization across the CLASS axis \n",
    "    ##---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:28:27.447957Z",
     "start_time": "2018-05-17T19:28:27.193968Z"
    }
   },
   "outputs": [],
   "source": [
    "    print('\\n    L2 normalization ------------------------------------------------------')   \n",
    "    gauss_norm   = KB.l2_normalize(gauss_sum, axis = +1)   # normalize along the CLASS axis \n",
    "    print('    gauss_norm   : ', gauss_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    \n",
    "    # heatmap_shape=KB.shape(gauss_sum)\n",
    "    # print('    gauss-sum.shape:', gauss_sum.shape, 'tf.shape :', tf.shape(gauss_sum))\n",
    "    # gauss_flatten = KB.reshape(gauss_sum, (heatmap_shape[0], heatmap_shape[1], -1 ) )  # reshape to image, class\n",
    "    # gauss_norm   = KB.l2_normalize(gauss_flatten, axis = -1)    \n",
    "    # print('    gauss_norm   : ', gauss_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    # gauss_norm   = KB.reshape(gauss_norm,  heatmap_shape )\n",
    "    # print('    gauss_norm (reshped) : ', gauss_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    # print('    gauss_flatten    : ', gauss_flatten.shape ,' Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:04:48.436902Z",
     "start_time": "2018-05-17T19:04:39.947781Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    temp = gauss_sum\n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3]).eval()\n",
    "    temp_min = tf.reduce_min(temp, [2,3]).eval()\n",
    "    temp_max = tf.reduce_max(temp, [2,3]).eval()\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:05:33.772086Z",
     "start_time": "2018-05-17T19:05:25.027624Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    temp = output_norm\n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3]).eval()\n",
    "    temp_min = tf.reduce_min(temp, [2,3]).eval()\n",
    "    temp_max = tf.reduce_max(temp, [2,3]).eval()\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:08:24.047270Z",
     "start_time": "2018-05-17T19:08:15.738081Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    temp = tf.nn.l2_normalize(gauss_sum, axis = [1]) \n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3]).eval()\n",
    "    temp_min = tf.reduce_min(temp, [2,3]).eval()\n",
    "    temp_max = tf.reduce_max(temp, [2,3]).eval()\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:28:50.117938Z",
     "start_time": "2018-05-17T19:28:49.849210Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():    \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bounding box masks \n",
    "    ## NOTE: Score is generated on NORMALIZED gaussian distributions (GAUSS_NORM)\n",
    "    ##       If want to do this on NON-NORMALIZED, we need to apply it on GAUSS_SUM\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    in_shape = tf.shape(in_tensor)\n",
    "    in_tensor_flattened  = tf.reshape(in_tensor, [-1, in_shape[-1]])\n",
    "    bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    print('    in_tensor               ', in_tensor.shape)\n",
    "    print('    in_tensorr_flattened is ', in_tensor_flattened.shape)\n",
    "    print('    boxes shape             ', bboxes.shape)\n",
    "    print('    Rois per image        : ', rois_per_image)\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    # duplicate GAUSS_NORM <num_roi> times to pass along with bboxes to map_fn function\n",
    "    #   Here we have a choice to calculate scores using the GAUSS_SUM (unnormalized) or GAUSS_NORM (normalized)\n",
    "    #   after looking at the scores and ratios for each option, I decided to go with the normalized \n",
    "    #   as the numbers are larger\n",
    "    #\n",
    "    # Examples>\n",
    "    #   Using GAUSS_SUM\n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.          0.999997    4.998889 2450.          0.00204     0.444867]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.          0.999991    4.981591 1892.          0.002633    0.574077]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.          0.999971    4.957398 2303.          0.002153    0.469335]\n",
    "    # [   0.          0.         66.42349    56.123024    1.          0.999908    4.999996 3696.          0.001353    0.294958]\n",
    "    # [   0.          0.         40.78952    60.404335    1.          0.999833    4.586552 2460.          0.001864    0.406513]    \n",
    "    #\n",
    "    #   Using GAUSS_NORM:\n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.          0.999997 1832.9218   2450.          0.748131    0.479411]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.          0.999991 1659.3965   1892.          0.877059    0.56203 ]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.          0.999971 1540.4974   2303.          0.668909    0.428645]\n",
    "    # [   0.          0.         66.42349    56.123024    1.          0.999908 1925.3267   3696.          0.520922    0.333813]\n",
    "    # [   0.          0.         40.78952    60.404335    1.          0.999833 1531.321    2460.          0.622488    0.398898]\n",
    "    # \n",
    "    #  to change the source, change the following line gauss_norm <--> gauss_sum\n",
    "    #---------------------------------------------------------------------------------------------------------------------------\n",
    "    temp = tf.expand_dims(gauss_norm, axis =2)\n",
    "    print('    heatmap expanded shape :',  temp.get_shape())\n",
    "    temp = tf.tile(temp, [1,1, rois_per_image ,1,1])\n",
    "    temp_shape   = KB.int_shape(temp)\n",
    "    temp_reshape = KB.reshape(temp, (-1, temp_shape[-2], temp_shape[-1]))\n",
    "    print('    heatmap original shape  : ', gauss_norm.shape)\n",
    "    print('    heatmap replicated      : ', temp_shape)\n",
    "    print('    heatmap flattened       : ', temp_reshape.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:28:54.309401Z",
     "start_time": "2018-05-17T19:28:53.904846Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default(): \n",
    "    scores = tf.map_fn(build_mask_routine, [temp_reshape, bboxes], dtype=tf.float32)\n",
    "\n",
    "    print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:11:11.830143Z",
     "start_time": "2018-05-17T19:11:07.858459Z"
    },
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(scores[320:].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T17:39:22.671030Z",
     "start_time": "2018-05-17T17:39:21.953645Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "with sess.as_default():\n",
    "    print('  Temp shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [3,4]).eval()\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            for k in range(32):\n",
    "                print('img ',i,' class ', j, 'copy ',k, ' sum:',temp_sum[i,j,k])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:29:13.211740Z",
     "start_time": "2018-05-17T19:29:12.240618Z"
    }
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "\n",
    "    # consider the two new columns for reshaping the gaussian_bbox_scores\n",
    "    new_shape   = tf.shape(in_tensor)+ [0,0,0, tf.shape(scores)[-1]]        \n",
    "    bbox_scores = tf.concat([in_tensor_flattened, scores], axis = -1)\n",
    "    bbox_scores = tf.reshape(bbox_scores, new_shape)\n",
    "    # print('    new shape is            : ', new_shape.eval())\n",
    "    print('    in_tensor_flattened     : ', in_tensor_flattened.shape)\n",
    "    print('    Scores shape            : ', scores.shape)   # [(num_batches x num_class x num_rois ), 3]\n",
    "    print('    boxes_scores (rehspaed) : ', bbox_scores.shape)    \n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## Normalize computed score above, and add it to the heatmap_score tensor as last column\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    scr_norm     = tf.nn.l2_normalize(bbox_scores[...,-1], axis = -1)   # shape (num_imgs, num_class, num_rois)\n",
    "    scr_norm     = tf.expand_dims(scr_norm, axis = -1)\n",
    "    bbox_scores  = tf.concat([bbox_scores, scr_norm], axis = -1)\n",
    "    \n",
    "    gauss_heatmap= KB.identity(tf.transpose(gauss_norm,[0,2,3,1]), name = names[0]+'_norm')\n",
    "    gauss_scores = KB.identity(bbox_scores, name = names[0]+'_scores') \n",
    "    \n",
    "    print('    gauss_heatmap final shape : ', gauss_heatmap.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )  \n",
    "    print('    gauss_scores  final shape : ', gauss_scores.shape ,' Keras tensor ', KB.is_keras_tensor(gauss_scores) )  \n",
    "    print('    complete')\n",
    "\n",
    "#     return  gauss_norm, gauss_scores    # [gauss_sum, gauss_scatt, means, covar]    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `gauss_scores`  the final result from    `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:29:37.264107Z",
     "start_time": "2018-05-17T19:29:33.144352Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "with sess.as_default():\n",
    "    test = gauss_scores.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:29:37.507844Z",
     "start_time": "2018-05-17T19:29:37.265609Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    img = 0\n",
    "    for k in range(4):\n",
    "        print('Gauss_Scores Image ', img , '/ Class ',k,' ------------')\n",
    "        print(test[img,k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following results were produced using GAUSS_SUM for score generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:12:18.121947Z",
     "start_time": "2018-05-17T19:12:14.114729Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "with sess.as_default():\n",
    "    test = gauss_scores.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T19:12:19.870544Z",
     "start_time": "2018-05-17T19:12:19.617364Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    img = 0\n",
    "    for k in range(4):\n",
    "        print('Gauss_Scores Image ', img , '/ Class ',k,' ------------')\n",
    "        print(test[img,k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  `build_mask` routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T18:29:55.893198Z",
     "start_time": "2018-05-17T18:29:55.644446Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "def build_mask_routine(input_list):\n",
    "    '''\n",
    "    Inputs:\n",
    "    -----------\n",
    "        heatmap_tensor :    [ image height, image width ]\n",
    "        input_row      :    [y1, x1, y2, x2] in absolute (non-normalized) scale\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "        gaussian_sum :      sum of gaussian heatmap vlaues over the area covered by the bounding box\n",
    "        bbox_area    :      bounding box area (in pixels)\n",
    "    '''\n",
    "    heatmap_tensor, input_row = input_list\n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        y_extent     = tf.range(input_row[0], input_row[2])\n",
    "        x_extent     = tf.range(input_row[1], input_row[3])\n",
    "        Y,X          = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask    = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        mask_indices = tf.to_int32(mask_indices)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        mask         = tf.scatter_nd(mask_indices, mask_updates, tf.shape(heatmap_tensor))\n",
    "        mask_sum    =  tf.reduce_sum(mask)\n",
    "        mask_applied = tf.multiply(heatmap_tensor, mask, name = 'mask_applied')\n",
    "        bbox_area    = tf.to_float((input_row[2]-input_row[0]) * (input_row[3]-input_row[1]))\n",
    "        gaussian_sum = tf.reduce_sum(mask_applied)\n",
    "        ratio        = gaussian_sum / bbox_area \n",
    "        ratio        = tf.where(tf.is_nan(ratio),  0.0, ratio)  \n",
    "    return tf.stack([gaussian_sum, bbox_area, ratio], axis = -1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "## `development_build_heatmap` - Using Alternative , more efficient method to generate `gauss_sum`\n",
    "    Develped a more efficient way of gneerating the heatmap without dynamic_parittioning and avoiding redundant tensor manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:41:37.050069Z",
     "start_time": "2018-05-17T12:41:30.490797Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "##def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "# in_tensor = KB.constant(pred_tensor)\n",
    "# graph1 = tf.Graph()\n",
    "# with graph1.as_default():\n",
    "# try:\n",
    "#     print(' Session to close ', sess)\n",
    "#     sess.close()\n",
    "#     print('session was deleted ')\n",
    "# except:\n",
    "#     print(' Session was not defined ', sess)\n",
    "#     pass\n",
    "sess = KB.get_session()\n",
    "print(' New session obtained from Kras', sess)\n",
    "\n",
    "with sess.as_default():\n",
    "##--------------------------------------------------------------------------\n",
    "## setup input values\n",
    "    in_tensor = tf.identity(pred_tensor)\n",
    "    # in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "\n",
    "    config = model.config\n",
    "    names = ['Dev']\n",
    "##--------------------------------------------------------------------------\n",
    "    \n",
    "    # def build_heatmap(in_tensor, config, names = None):\n",
    "\n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    print('\\n ')\n",
    "    print('  > NEW build_heatmap() for ', names )\n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)       \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    rois_per_image  = (in_tensor.shape)[2] \n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image )\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    # print(pt2_sum[0].eval())\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "\n",
    "    ## replaced the two operations below with the one above - 15-05-2018\n",
    "    # pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    # pt2_ind  = tf.where(pt2_mask)\n",
    "    # print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "    # print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "    # print(pt2_ind.eval())\n",
    "\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "    print('    dense shape ',pt2_dense.get_shape())\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([tf.shape(pt2_dense)[0] , 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[1,2,0,3])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = pt2_dense[:,3] - pt2_dense[:,1]      # x2 - x1\n",
    "    height = pt2_dense[:,2] - pt2_dense[:,0]\n",
    "    cx     = pt2_dense[:,1] + ( width  / 2.0)\n",
    "    cy     = pt2_dense[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('     Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('     Prob_grid shape after tanspose: ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## IMPORTANT: kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    ## which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    prob_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "\n",
    "    ## scatter out the probability distributions based on class --------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------') \n",
    "    gauss_scatt   = tf.scatter_nd(pt2_ind, prob_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "    print('    pt2_ind shape   : ', pt2_ind.shape)  \n",
    "    print('    prob_grid shape : ', prob_grid.shape)  \n",
    "    print('    gauss_scatt     : ', gauss_scatt.shape)   # batch_sz , num_classes, num_rois, image_h, image_w\n",
    "    \n",
    "    ## heatmap: sum gauss_scattered based on class ---------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap2')\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-12, gauss_sum, tf.zeros_like(gauss_sum))\n",
    "    print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )      \n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## heatmap L2 normalization\n",
    "    ## Normalization using the  `gauss_sum` (batchsize , num_classes, height, width) \n",
    "    ## 17-05-2018 (New method, replace dthe previous method that usedthe transposed gauss sum\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    L2 normalization ------------------------------------------------------')   \n",
    "    heatmap_shape=KB.shape(gauss_sum)\n",
    "    print('    gauss-sum.shape:', gauss_sum.shape, 'tf.shape :', tf.shape(gauss_sum))\n",
    "\n",
    "    gauss_flatten = KB.reshape(gauss_sum, (heatmap_shape[0], heatmap_shape[1], -1 ) )  # reshape to image, class\n",
    "    output_norm   = KB.l2_normalize(gauss_flatten, axis = -1)    \n",
    "    gauss_norm    = KB.identity(KB.reshape(output_norm,  heatmap_shape ) , name = names[0]+'_norm')   \n",
    "\n",
    "    print('    gauss_flatten    : ', tf.shape(gauss_flatten).eval(session=sess) , gauss_flatten.shape,' Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "    print('    output of norm   : ', tf.shape(output_norm).eval(session=sess)   , output_norm.shape  ,' Keras tensor ', KB.is_keras_tensor(output_norm) )\n",
    "    print('    gauss_norm final : ', tf.shape(gauss_norm).eval(session=sess)    , gauss_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using the  `gauss_sum` (batchsize , num_classes, height, width) (New method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:33:00.523586Z",
     "start_time": "2018-05-17T12:32:54.739124Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "#     ## heatmap: L2 normalization  -----------------------------------------------------------------\n",
    "#     print('\\n    L2 normalization ------------------------------------------------------')   \n",
    "#     heatmap_shape=KB.shape(gauss_sum)\n",
    "#     print('    gauss-sum.shape:', gauss_sum.shape, 'tf.shape :', tf.shape(gauss_sum))\n",
    "\n",
    "#     gauss_flatten = KB.reshape(gauss_sum, (heatmap_shape[0], heatmap_shape[1], -1 ) )  # reshape to image, class\n",
    "#     output_norm   = KB.l2_normalize(gauss_flatten, axis = -1)    \n",
    "#     gauss_norm    = KB.identity(KB.reshape(output_norm,  heatmap_shape ) , name = names[0]+'_norm')   \n",
    "\n",
    "#     print('    gauss_flatten    : ', tf.shape(gauss_flatten).eval(session=sess) , gauss_flatten.shape,' Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "#     print('    output of norm   : ', tf.shape(output_norm).eval(session=sess)   , output_norm.shape  ,' Keras tensor ', KB.is_keras_tensor(output_norm) )\n",
    "#     print('    gauss_norm final : ', tf.shape(gauss_norm).eval(session=sess)    , gauss_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using the TRANSPOSED `gauss_sum` (batchsize, height, width , num_classes)   (OLD method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T10:33:39.255864Z",
     "start_time": "2018-05-17T10:33:33.780634Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "### (old method) Normalization using the TRANSPOSED gauss_sum\n",
    "\n",
    "# with sess.as_default():\n",
    "#     ## heatmap: L2 normalization  -----------------------------------------------------------------\n",
    "#     print('\\n    L2 normalization ------------------------------------------------------')   \n",
    "#     heatmap_shape=KB.shape(gauss_sum_tp)\n",
    "#     print('    gauss-sum.shape:', gauss_sum_tp.shape, 'tf.shape :', tf.shape(gauss_sum_tp))\n",
    "\n",
    "#     gauss_flatten_tp = KB.reshape(gauss_sum, (heatmap_shape[0], -1, heatmap_shape[-1]) )  # reshape to image, class\n",
    "#     output_norm_tp   = KB.l2_normalize(gauss_flatten_tp, axis = 1)    \n",
    "#     gauss_norm_tp    = KB.identity(KB.reshape(output_norm_tp,  heatmap_shape ) , name = names[0]+'_norm')   \n",
    "\n",
    "#     print('    gauss_flatten    : ', tf.shape(gauss_flatten_tp).eval() , gauss_flatten_tp.shape,' Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "#     print('    output of norm   : ', tf.shape(output_norm_tp).eval()   , output_norm_tp.shape  ,' Keras tensor ', KB.is_keras_tensor(output_norm) )\n",
    "#     print('    gauss_norm final : ', tf.shape(gauss_norm_tp).eval()    , gauss_norm_tp.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_norm) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "### Old method - generating `gauss_heatmap_scores` using `gauss_scatter`\n",
    "\n",
    "This will NOT work for generating scores in FCN, since we do not have the heatmaps per individual bounding box. \n",
    "We need to apply the boundingbox masks on the GAUSS_SUM\n",
    "\n",
    "#### If we use this to generate scores, the scores will only reflect the heatmap produced for one object's bounding box. The overlapping of bounding boxes will not affect the generated scores. Therefore, the scores are invariant of possible overlapping. \n",
    "#### We could possibly use this if we want to generate independent scores for bounding boxes with no overlaps. However it's important to consider the ramifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T10:52:16.836988Z",
     "start_time": "2018-05-17T10:52:16.578780Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bouding box masks \n",
    "    ## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "    ##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    in_tensor_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "    bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    print('    in_tensor               ', in_tensor.shape)\n",
    "    print('    in_tensorr_flattened is ', in_tensor_flattened.shape)\n",
    "    print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "    # DONT NEED THIS - was put there to try to avoid computing sum/area for zero bboxes.\n",
    "    # kept as reference for future generations .....\n",
    "    # bbox_sum = tf.reduce_max(in_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "    # print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "    gauss_scatt_shape   = KB.int_shape(gauss_scatt)\n",
    "    gauss_scatt_reshape = KB.reshape(gauss_scatt, (-1, gauss_scatt_shape[-2], gauss_scatt_shape[-1]))\n",
    "    print('    gaussian scatter shape : ', gauss_scatt_shape)\n",
    "    print('    gaussian scatter reshaped : ', gauss_scatt_reshape.shape)\n",
    "    print('    gaussian sum shape          ', KB.int_shape(gauss_sum))\n",
    "\n",
    "    # ones_map = tf.ones([384,128,128])   \n",
    "    scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)\n",
    "\n",
    "    new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]        \n",
    "    gaussian_bbox_scores = tf.concat([in_tensor_flattened, scores], axis = -1)\n",
    "    print('    in_tensor_flattened shape : ', scatter_flattened.shape)\n",
    "    print('    Scores shape              : ', scores.shape)\n",
    "    print('    gaussian_boxes_scores     : ', gaussian_bbox_scores.shape)    \n",
    "    gaussian_bbox_scores = tf.reshape(gaussian_bbox_scores, new_shape, name = names[0]+'_scores')\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## Normalize computed score above, and add it to the heatmap_score tensor as last column\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "#     scr = gaussian_bbox_scores[...,-2]/gaussian_bbox_scores[...,-1]\n",
    "#     scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "#     scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "#     scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "#     gaussian_bbox_scores = tf.concat([gaussian_bbox_scores, scr_norm], axis = -1)\n",
    "\n",
    "#     print('    gaussian_bbox_scores final shape   : ', gaussian_bbox_scores.shape)\n",
    "#     print('    complete')\n",
    "\n",
    "# return  gauss_norm, gaussian_bbox_scores    # [gauss_sum, gauss_scatt, means, covar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "### NEW method - generating `gauss_heatmap_scores` using `gauss_sum`\n",
    "\n",
    "Since FCN provides a heatmap per class , and not per individual object, we use the similar method here to generate heat maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:43:11.833374Z",
     "start_time": "2018-05-17T12:43:07.138502Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bouding box masks \n",
    "    ## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "    ##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    in_tensor_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "    bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    print('    in_tensor               ', in_tensor.shape)\n",
    "    print('    in_tensorr_flattened is ', in_tensor_flattened.shape)\n",
    "    print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "    print(rois_per_image)\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    # duplicate gauss_sum <num_roi> times to pass along with bboxes to map_fn function\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    temp = tf.expand_dims(gauss_sum, axis =2)\n",
    "    print('  Gauss_Sum expanced shape :',  temp.get_shape())\n",
    "    temp = tf.tile(temp, [1,1, rois_per_image ,1,1])\n",
    "    print('  Gauss_Sum expanded/tiled shape :',  temp.get_shape())\n",
    "    temp_shape   = KB.int_shape(temp)\n",
    "    temp_reshape = KB.reshape(temp, (-1, temp_shape[-2], temp_shape[-1]))\n",
    "    print('    gauss_sum original shape  : ', gauss_sum.shape)\n",
    "    print('    gauss_sum replicated      : ', temp_shape)\n",
    "    print('    gaussian scatter reshaped : ', temp_reshape.shape)\n",
    "\n",
    "    scores = tf.map_fn(build_mask_routine, [temp_reshape, bboxes], dtype=tf.float32)\n",
    "    # consider the two new columns for reshaping the gaussian_bbox_scores\n",
    "    new_shape = tf.shape(in_tensor)+ [0,0,0, tf.shape(scores)[-1]]        \n",
    "    gaussian_bbox_scores = tf.concat([scatter_flattened, scores], axis = -1)\n",
    "    print('    Scatter Flattened shape : ', scatter_flattened.shape)\n",
    "    print('    Scores shape :            ', scores.shape)\n",
    "    print('    gaussian_boxes_scores initial shape: ', gaussian_bbox_scores.shape)    \n",
    "    gaussian_bbox_scores = tf.reshape(gaussian_bbox_scores, new_shape, name = names[0]+'_scores')\n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## Normalize computed score above, and add it to the heatmap_score tensor as last column\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    scr = gaussian_bbox_scores[...,-2]/gaussian_bbox_scores[...,-1]\n",
    "    scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "    scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "    scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "    gaussian_bbox_scores = tf.concat([gaussian_bbox_scores, scr_norm], axis = -1)\n",
    "    gauss_norm = tf.transpose(gauss_norm,[0,2,3,1], name = names[0])  \n",
    "    \n",
    "    \n",
    "    print('    gauss_norm           final shape   : ', gauss_norm.shape)\n",
    "    print('    gaussian_bbox_scores final shape   : ', tf.shape(gaussian_bbox_scores).eval())\n",
    "    print('    complete')\n",
    "\n",
    "# return  gauss_norm, gaussian_bbox_scores    # [gauss_sum, gauss_scatt, means, covar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T12:43:54.164205Z",
     "start_time": "2018-05-17T12:43:53.577870Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(pred_heatmap_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Compare results from old and new method of generating `gauss_sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T10:40:06.501659Z",
     "start_time": "2018-05-17T10:39:03.275888Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     sess.close()\n",
    "#     print('session was deleted ')\n",
    "# except:\n",
    "#     print('Session was not defined ')\n",
    "#     pass\n",
    "# sess = tf.InteractiveSession()\n",
    "with sess.as_default():\n",
    "    np.set_printoptions(linewidth=130, threshold=20000)\n",
    "    gt   = gauss_norm_tp2 # gt_gaussian \n",
    "    gt2  = gauss_norm_tp # gt_gaussian_2\n",
    "    # gt   = np.where(gt > 1e-6,gt,0)\n",
    "    # gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "    print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "    for img in range(3):\n",
    "        print('Image', img)\n",
    "\n",
    "        for cls in range(4):\n",
    "\n",
    "            all_equal = np.all(np.equal(gt2[img, :,:,cls], gt[img, :,:,cls]))\n",
    "        #         for roi in range(32):\n",
    "    #             print('roi:', roi)\n",
    "    #             equal = tf.equal(gt2[img, cls, roi, line], gt[img, cls,roi, line])\n",
    "    #             all_equal = tf.reduce_all(equal).eval()     \n",
    "            if all_equal:\n",
    "                max_diff = np.max(gt2[img, :,:, cls]- gt[img, :,:,cls]).eval()\n",
    "                print('Img: ', img, ' Cls',cls, 'All equal', all_equal, '    Largest diffeence in cls', cls,':', max_diff)            \n",
    "            else:\n",
    "                for line in range(128):\n",
    "                    all_equal = np.all(np.equal(gt2[img, line,:,cls], gt[img, line,:,cls]))\n",
    "                    if all_equal:\n",
    "                        print('Img: ', img, 'Calss',cls, 'LINE', line, 'All equal', all_equal)   \n",
    "                    else:\n",
    "                        max_diff = np.max(gt2[img, line,:, cls]- gt[img, line,:,cls])\n",
    "                        print('Img: ', img, 'Calss',cls, 'LINE', line, 'All equal', all_equal,' Max difference :', max_diff.eval() )\n",
    "    #                 print(' -- pred_hm\\n',  gt[img, line, :,cls])\n",
    "    #                 print(' -- prd_hm2\\n', gt2[img, line, :, cls])                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:04.730267Z",
     "start_time": "2018-05-10T15:10:00.524802Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {in_tensor: pred_tensor}\n",
    "fetches = [stacked_tensor, rnd_tensor, gauss_sum]\n",
    "sess = tf.Session()\n",
    "print(' tfsession() is ', sess)\n",
    "tt = sess.run(fetches, feed_dict = feed_dict )\n",
    "print(type(tt), len(tt))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:04.974515Z",
     "start_time": "2018-05-10T15:10:04.731741Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "img = 1\n",
    "print(' Stacked Tensor Shape: ', tt[0].shape)\n",
    "print(' Stacked Tensor :   \\n ', tt[0][img])\n",
    "\n",
    "print(' rnd_tensor shape ', tt[1].shape)\n",
    "print(' rnd_tensor :  \\n ', tt[1][img])\n",
    "\n",
    "print(' Gauss_Sum shape :\\n', tt[2].shape)\n",
    "# print(' FP gt boxes        :\\n', tt[3])\n",
    "# print(' FP gt class assign :\\n', tt[4])\n",
    "# print(' gt class ids assign :\\n', tt[5])\n",
    "# print()\n",
    "# print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "# print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "# print()\n",
    "# print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "# print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "# print()\n",
    "# print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "# print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# # return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T13:43:36.617141Z",
     "start_time": "2018-05-10T13:43:35.151625Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    gauss_sum = development_build_gaussian_tf(KB.constant(pred_tensor), model.config, names = ['Dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "    rnd_tensor = tf.floor(stacked_tensor)    \n",
    "    sum_tensor = tf.reduce_sum(tf.abs(rnd_tensor[:,:,:4]), axis=-1)\n",
    "    non_zero   = tf.cast(sum_tensor, tf.bool)\n",
    "    non_zero_exp = tf.expand_dims(non_zero, axis =-1)\n",
    "    \n",
    "    print(' rnd_tensor :', tf.shape(rnd_tensor).eval())\n",
    "    print(' sum_tensor :', tf.shape(sum_tensor).eval())\n",
    "    print(' non_zero   :', tf.shape(non_zero).eval())\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    non_zero_exp = KB.repeat_elements(non_zero_exp, 6, axis=-1)\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    nz_tensor  = tf.boolean_mask(rnd_tensor, non_zero_exp, axis = -1)\n",
    "    print(' nz_tensor  :', tf.shape(nz_tensor).eval())\n",
    "\n",
    "#     print(stacked_tensor[0].eval())\n",
    "    print(rnd_tensor[0].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[1].eval())\n",
    "    print(rnd_tensor[1].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[2].eval())\n",
    "    print(rnd_tensor[2].eval())\n",
    "    \n",
    "    print(sum_tensor[1].eval())    \n",
    "    print(non_zero[1].eval())    \n",
    "#     non_zeros = tf.cast(tf.reduce_sum(tf.abs(rnd_tensor), axis=1), tf.bool)\n",
    "    print(non_zero_exp[1].eval())    \n",
    "\n",
    "    print(nz_tensor[1].eval())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "INPUT1 = pred_hm\n",
    "INPUT2 = pred_hm_norm\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('INPUT1 shape : ', INPUT1.shape, ' INPUT2 shape: ', INPUT2.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'INPUT1 -  image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', INPUT1[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(INPUT1[img,:,:,cls], title = ttl)  \n",
    "    \n",
    "    ttl = 'INPUT2 -  image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', INPUT2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(INPUT2[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:12:47.630505Z",
     "start_time": "2018-05-11T13:12:47.372814Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(pred_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = pred_tensor[:,:,:,3] - pred_tensor[:,:,:,1]      # x2 - x1\n",
    "height = pred_tensor[:,:,:,2] - pred_tensor[:,:,:,0]\n",
    "cx     = pred_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = pred_tensor[:,:,:,0] + ( height / 2.0)\n",
    "means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(means.shape)\n",
    "print(means[0,2,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:20:27.357106Z",
     "start_time": "2018-05-11T13:20:27.100938Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gt_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = gt_tensor[:,:,:,3] - gt_tensor[:,:,:,1]      # x2 - x1\n",
    "height = gt_tensor[:,:,:,2] - gt_tensor[:,:,:,0]\n",
    "cx     = gt_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = gt_tensor[:,:,:,0] + ( height / 2.0)\n",
    "gt_means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(gt_means.shape)\n",
    "print(gt_means[0,2,:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Find maximum of gaussian distributions for the pred_heatmap\n",
    "Potentially use this as our heatmap scores \n",
    "Found out that using MAX values from the class heatmap (currently generated from the pred_tensor that itself is generated form output_rois and mrcnn_class) is not a viable option, because mutlple max values tend to congreagate around the peak of the gaussian distribution. \n",
    "This is also the case for gt_heatmaps.\n",
    "This will probably also be the case for the FCN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "#### pred_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:23:37.739059Z",
     "start_time": "2018-05-11T13:23:37.484900Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "\n",
    "print(pred_hm.shape)\n",
    "cls_hm = pred_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print(pred_hm_norm.shape)\n",
    "cls_hm_norm = pred_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:09:06.929477Z",
     "start_time": "2018-05-11T13:09:06.655253Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "#### gt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:12.185707Z",
     "start_time": "2018-05-11T13:24:11.932533Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print(pred_hm.shape)\n",
    "cls_hm = gt_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print('---- norm -----')\n",
    "print(gt_hm_norm.shape)\n",
    "cls_hm_norm = gt_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:14.243495Z",
     "start_time": "2018-05-11T13:24:13.965220Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:48:39.739236Z",
     "start_time": "2018-05-11T11:48:39.479040Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "max_a = np.max(cls_pred_heatmap)\n",
    "print(max_a.shape)\n",
    "\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Compute mean and max of `gauss_grid()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.778443Z",
     "start_time": "2018-05-02T10:04:08.500Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Compute mean and max of `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.776944Z",
     "start_time": "2018-05-02T10:03:27.542792Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid2[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Compute `gauss_grid()` and   `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:39.307514Z",
     "start_time": "2018-05-02T11:10:38.603585Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "gauss_max  = KB.max(gauss_grid, axis = [2,3]).eval()\n",
    "gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max[img, bbx],gauss_max2[img,bbx],(gauss_max[img,bbx]== gauss_max2[img,bbx])))\n",
    "del gauss_max, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Compute `gauss_sum()` and  `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:52.883112Z",
     "start_time": "2018-05-02T11:10:52.154331Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape, gauss_sum2.shape)\n",
    "# print(gauss_grid2.shape)\n",
    "tst1 = tf.transpose(gauss_sum, [0,3,1,2])\n",
    "tst2 = tf.transpose(gauss_sum2, [0,3,1,2])\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "gauss_max1 = KB.max(tst1, axis = [2,3]).eval()\n",
    "gauss_max2 = KB.max(tst2, axis = [2,3]).eval()\n",
    "print(gauss_max1.shape, gauss_max2.shape)\n",
    "\n",
    "# gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max1[img, bbx],gauss_max2[img,bbx],(gauss_max1[img,bbx]== gauss_max2[img,bbx])))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:58:45.332214Z",
     "start_time": "2018-05-02T10:58:44.117193Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}    Equal : {}'.format(img, bbx, (tst1[img,bbx]==  tst2[img,bbx])))\n",
    "del gauss_max1, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "###  Compute mean and max OF `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:55:59.702691Z",
     "start_time": "2018-05-02T09:55:42.231847Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum2[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(gauss_sum2[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(gauss_sum2[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Compute min and max of `gauss_sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:57:11.807587Z",
     "start_time": "2018-05-02T09:56:55.286325Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum[img,:,:,cls]).eval()\n",
    "        gauss_min  =  KB.min(gauss_sum[img, :,:,cls]).eval()\n",
    "        gauss_max  =  KB.max(gauss_sum[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:44:41.071788Z",
     "start_time": "2018-05-02T08:44:33.434419Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "pred_gauss = tf.constant(layers_out[19])\n",
    "print(pred_gauss.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(pred_gauss[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(pred_gauss[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(pred_gauss[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:14:01.486755Z",
     "start_time": "2018-05-02T11:13:59.680438Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = gauss_sum.eval()    # gt_gaussiam \n",
    "gt_heatmap  = layers_out[18]     # gt_gaussiam \n",
    "\n",
    "pred_heatmap= gauss_sum2.eval()  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "### Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Softmax Sparse Cross Entropy Ignoring Last Label -- Used in Keras FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T07:53:31.114036Z",
     "start_time": "2018-04-27T07:53:30.853311Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "\n",
    "y_pred = tf.placeholder(dtype=tf.float32, shape=(16,320,320,20))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(16,320,320,1))\n",
    "print(K.int_shape(y_pred), K.int_shape(y_true))\n",
    "y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "print(K.int_shape(y_pred))\n",
    "log_softmax = tf.nn.log_softmax(y_pred)\n",
    "print(K.int_shape(log_softmax))\n",
    "\n",
    "y_true = K.flatten(y_true)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "y_true = K.one_hot(tf.to_int32(y_true), K.int_shape(y_pred)[-1]+1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "unpacked = tf.unstack(y_true, axis=-1)\n",
    "print(len(unpacked), unpacked[0].shape)\n",
    "\n",
    "y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "\n",
    "cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "print(K.int_shape(cross_entropy))\n",
    "\n",
    "cross_entropy_mean = K.mean(cross_entropy)\n",
    "print(K.int_shape(cross_entropy_mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import keras.backend as K\n",
    "# print(K.int_shape(bef_pos)[-1])\n",
    "# unpacked  = K.flatten(test)\n",
    "# unpacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:19:54.102900Z",
     "start_time": "2018-04-16T23:19:53.889289Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Experimental code to Create mask for class bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "###  Comparing Scipy / Tensorflow Multivar normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:10:11.958301Z",
     "start_time": "2018-04-16T10:10:10.121532Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "tfd        = tf.contrib.distributions\n",
    "grid       = pos_grid_1[:,:,0,0,:]\n",
    "covar      = np.array([27.7818, 26.6678],dtype = np.float32)\n",
    "covar_sqrt = np.sqrt(covar)\n",
    "covar_sqrd = covar ** 2\n",
    "full_covar = np.array([[27.7818, 0],[0, 26.6678]],dtype = np.float32)\n",
    "mean       = np.array([48.8926, 36.101 ],dtype = np.float32)\n",
    "\n",
    "print('   grid :', grid.dtype, grid.shape)\n",
    "print('   Covar sqrt :', covar_sqrt)\n",
    "print('   Covar sqrd :', covar_sqrd)\n",
    "\n",
    "mvn1  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar_sqrt)\n",
    "prob1 = mvn1.prob(grid2)\n",
    "print()\n",
    "print('   mvn1 mean             ', mvn1.mean().eval())\n",
    "print('   mvn1 std deviation    ', mvn1.stddev().eval())\n",
    "print('   mvn1 covariance:      ', '\\n', mvn1.covariance().eval())\n",
    "print('   mvn1 location         ', mvn1.loc.eval())\n",
    "print('   Linear OP shape       ', mvn1.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn1.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn1.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn1.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn1.scale.diag_part().eval()) \n",
    "\n",
    "mvn2  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar)\n",
    "prob2 = mvn2.prob(grid2)\n",
    "print()\n",
    "print('   mvn2 mean             ', mvn2.mean().eval())\n",
    "print('   mvn2 std deviation    ', mvn2.stddev().eval())\n",
    "print('   mvn2 covariance:      ', '\\n', mvn2.covariance().eval())\n",
    "print('   mvn2 location         ', mvn2.loc.eval())\n",
    "print('   Linear OP shape       ', mvn2.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn2.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn2.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn2.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn2.scale.diag_part().eval()) \n",
    "\n",
    "\n",
    "mvn3  = tfd.MultivariateNormalFullCovariance( loc = mean, covariance_matrix = full_covar)\n",
    "prob3 = mvn3.prob(grid2)\n",
    "print()\n",
    "print('   mvn3 mean             ', mvn3.mean().eval())\n",
    "print('   mvn3 std deviation    ', mvn3.stddev().eval())\n",
    "print('   mvn3 covariance:      ', '\\n', mvn3.covariance().eval())\n",
    "print('   mvn3 location         ', mvn3.loc.eval())\n",
    "print('   Linear OP shape       ', mvn3.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn3.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn3.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn3.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn3.scale.diag_part().eval()) \n",
    "\n",
    "print('   << output probabilities shape:' )\n",
    "print(' prob1 ', prob1.get_shape())\n",
    "print(prob1.eval())\n",
    "print(' prob2 ', prob2.get_shape())\n",
    "print(prob2.eval())\n",
    "print(' prob3 ', prob3.get_shape())\n",
    "print(prob3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:30.850107Z",
     "start_time": "2018-04-16T09:59:30.182014Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "# print(XX)\n",
    "# print(YY)\n",
    "# print(pos[0,:,:])\n",
    "# print(pos[0])\n",
    "# print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna    = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "prob_b = mvnb.pdf(pos)\n",
    "\n",
    "print(prob_a[35:50, 45:54])\n",
    "max_a = np.max(prob_a)\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Original `build heatmap()` prior to modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T14:45:58.207448Z",
     "start_time": "2018-05-15T14:45:55.245020Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "##def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "# in_tensor = KB.constant(pred_tensor)\n",
    "# graph1 = tf.Graph()\n",
    "# with graph1.as_default():\n",
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "in_tensor = tf.identity(pred_tensor)\n",
    "# in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "config = model.config\n",
    "names = ['Dev']\n",
    "\n",
    "\n",
    "\n",
    "num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "batch_size      = config.BATCH_SIZE\n",
    "num_classes     = config.NUM_CLASSES  \n",
    "print('\\n ')\n",
    "print('  > build_heatmap() for ', names )\n",
    "\n",
    "# rois per image is determined by size of input tensor \n",
    "#   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "#   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "# in_tensor = in_tensor[:,:,:,2:7]\n",
    "print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "\n",
    "rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "# strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "print('    num of bboxes per class is : ', rois_per_image.eval(session=sess))\n",
    "#-----------------------------------------------------------------------------\n",
    "## Build mesh-grid to hold pixel coordinates  \n",
    "#-----------------------------------------------------------------------------\n",
    "X = tf.range(img_w, dtype=tf.int32)\n",
    "Y = tf.range(img_h, dtype=tf.int32)\n",
    "X, Y = tf.meshgrid(X, Y)\n",
    "print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "# print('    X : \\n',X.eval())\n",
    "# print('    Y : \\n',Y.eval())\n",
    "\n",
    "# duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "rep_X = ones * X\n",
    "rep_Y = ones * Y \n",
    "print('    Ones: ',ones.shape)                \n",
    "print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "# # stack the X and Y grids \n",
    "bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "print('    before transpse ', bef_pos.get_shape())\n",
    "pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "#-----------------------------------------------------------------------------    \n",
    "## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "# pt2_ind shape is [?, 3]. \n",
    "#   pt2_ind[0] corresponds to image_index \n",
    "#   pt2_ind[1] corresponds to class_index \n",
    "#   pt2_ind[2] corresponds to roi row_index \n",
    "# pt2_dense shape is [?, 6]\n",
    "#    pt2_dense[0] is image index\n",
    "#    pt2_dense[1:4]  roi cooridnaytes \n",
    "#    pt2_dense[5]    is class id \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "print('    pt2_sum shape ',pt2_sum.shape)\n",
    "# print(pt2_sum[0].eval())\n",
    "pt2_ind = tf.where(pt2_sum > 0)\n",
    "\n",
    "## replaced the two operations with the one above\n",
    "# pt2_mask = tf.greater(pt2_sum , 0)\n",
    "# pt2_ind  = tf.where(pt2_mask)\n",
    "\n",
    "# print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "# print(pt2_mask.eval())\n",
    "print('    pt2_ind shape ', tf.shape(pt2_ind).eval() )\n",
    "print(pt2_ind.eval())\n",
    "# pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "# append image index to front of rows - REMOVED 1-5-2018\n",
    "# pt2_ind[:,0] is the same informaiton and is used in dynamic_partition\n",
    "\n",
    "#  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "print('    dense shape ',tf.shape(pt2_dense).eval())\n",
    "print(pt2_dense.eval())\n",
    " \n",
    "\n",
    "## we want to slice pt2._dense by Batch size.\n",
    "## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "##  Build Stacked output from dynamically partitioned lists \n",
    "#-----------------------------------------------------------------------------\n",
    "print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "stacked_output=[]\n",
    "for img, item  in enumerate(stacked_list) : \n",
    "    rois_in_image  = tf.shape(item)[0]\n",
    "    pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "    stacked_output.append(pad_item)\n",
    "stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "# print()    \n",
    "# print('   -- Stacked output contents --------------')    \n",
    "# print('    stacked_output shape : ', len(stacked_output))\n",
    "# for img, item  in enumerate(stacked_output) :\n",
    "    # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "print(stacked_tensor.eval())\n",
    "\n",
    "##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "#-----------------------------------------------------------------------------\n",
    "width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "means  = tf.stack((cx,cy),axis = -1)\n",
    "covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "covar  = tf.sqrt(covar)\n",
    "\n",
    "\n",
    "print('    means shape :', tf.shape(means).eval(),' covar shape ', tf.shape(covar).eval())\n",
    "\n",
    "tfd = tf.contrib.distributions\n",
    "mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "prob_grid = mvn.prob(pos_grid)\n",
    "print(prob_grid.shape)\n",
    "prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "print(prob_grid.shape)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "# which cause singular sigma cov matrices\n",
    "#--------------------------------------------------------------------------------\n",
    "gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "\n",
    "## scatter out the probability distributions based on class --------------------------\n",
    "print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                    indexing = 'ij' )\n",
    "scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "print('    class shape        : ', class_inds.get_shape())\n",
    "print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "print(scatter_classes.eval())\n",
    "\n",
    "## heatmap: sum gauss_scattered based on class ---------------------------------------\n",
    "print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap')\n",
    "print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )  \n",
    "gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "### development of `build_mask_routine()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:31:10.879155Z",
     "start_time": "2018-05-15T17:31:10.540145Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(' Heatmap tensor shape is :', gauss_scatt2_reshape.shape)\n",
    "\n",
    "def build_mask_routine(input_list):\n",
    "    heatmap_tensor, input_row = input_list\n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        #         tensor_output = tf.zeros_like(config.IMAGE_SHAPE[:2], dtype = tf.int32)\n",
    "        #         input_row = tf.cast(input_row, tf.int32)\n",
    "        y_extent  = tf.range(input_row[0], input_row[2])\n",
    "        x_extent  = tf.range(input_row[1], input_row[3])\n",
    "\n",
    "        Y,X       = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        mask_indices = tf.to_int32(mask_indices)\n",
    "        #     print('===> Box input is : ', row)   \n",
    "        #     print('    y_extent (Row) ', y_extent, y_extent.shape)\n",
    "        #     print('    x_extent (Cols)', x_extent, x_extent.shape)   \n",
    "        #     print(Y.shape, X.shape)\n",
    "        #     print(X.eval())\n",
    "        #     print('    bbox_mask shape: ',bbox_mask.shape)\n",
    "        #     print(bbox_mask.eval())\n",
    "        #     rows = mask_indices.shape[0]\n",
    "        #     class_id,_ = tf.meshgrid(row[4], mask_indices[:,1] )\n",
    "        #     class_id = row[4]\n",
    "        #     print('    Size of mask_indices: ', mask_indices.shape)\n",
    "        #     print('    Number of rows : ',rows )     \n",
    "        #     mask_indices = tf.concat([class_id,  mask_indices ], axis= 1)\n",
    "        #     print('    Size of mask_indices for this bbox: ', mask_indices.shape)\n",
    "        #     print(mask_indices.eval())         \n",
    "        #     mask_size = mask_indices.get_shape()\n",
    "        #     print(mask_size)\n",
    "        #     mask_updates = tf.ones_like(tf.shape(mask_size), dtype = tf.int32)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        #     print('    Size of mask_updates for this bbox: ', mask_updates.shape)    \n",
    "        #     print('  size of bbox_mask: ', mask_size)\n",
    "        #     print(' Before scatter_nd_add ')\n",
    "        #     print(tensor_var.eval())\n",
    "        mask = tf.scatter_nd(mask_indices, mask_updates, config.IMAGE_SHAPE[:2])\n",
    "        #         mask_applied = tf.multiply(heatmap_tensor[index[0], index[1]], mask, name = 'mask_applied')\n",
    "        mask_applied  = tf.multiply(heatmap_tensor, mask, name = 'mask_applied')\n",
    "#         bbox_pred_sum = tf.expand_dims( tf.reduce_sum(mask_applied),-1)\n",
    "#         area      = tf.expand_dims((input_row[2]-input_row[0]) * (input_row[3]-input_row[1]), axis = -1)\n",
    "        area      = (input_row[2]-input_row[0]) * (input_row[3]-input_row[1])    \n",
    "        bbox_pred_sum =  tf.reduce_sum(mask_applied)\n",
    "    return tf.stack([bbox_pred_sum, area], axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "## generate score based on gaussian using bouding box masks ----------------------------------\n",
    "## NOTE: Score is generated on NON-NORMALIZED gaussian distributions\n",
    "##       If want to do this on normalized, we need to apply normalization to gauss_scatt first\n",
    "##--------------------------------------------------------------------------------------------\n",
    "# flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "scatter_flattened  = tf.reshape(in_tensor, [-1,6])\n",
    "bboxes = tf.to_int32(tf.round(scatter_flattened[...,0:4]))\n",
    "print('    scatter_flattened is ', scatter_flattened.shape)\n",
    "print('    boxes shape          ', bboxes.shape)\n",
    "\n",
    "# DONT NEED THIS - was put there to try to avoid computing sum/area for zero bboxes.\n",
    "# kept as reference for future generations .....\n",
    "# bbox_sum = tf.reduce_max(in_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "# print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "gauss_scatt_shape   = KB.int_shape(gauss_scatt)\n",
    "gauss_scatt_reshape = KB.reshape(gauss_scatt, (-1, gauss_scatt_shape[-2], gauss_scatt_shape[-1]))\n",
    "print('    gaussian scatter shape : ', gauss_scatt_shape)\n",
    "print('    gaussian scatter reshaped : ', gauss_scatt_reshape.shape)\n",
    "# ones_map = tf.ones([384,128,128])   \n",
    "scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)\n",
    "\n",
    "new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]        \n",
    "gaussian_bbox_scores = tf.concat([scatter_flattened, scores], axis = -1)\n",
    "print('    Scatter Flattened shape : ', scatter_flattened.shape))\n",
    "print('    Scores shape :            ', scores.shape)\n",
    "print('    gaussian_boxes_scores initial shape: ', gaussian_bbox_scores.shape)    \n",
    "gaussian_bbox_scores = tf.reshape(concat, new_shape)\n",
    "print('    gaussian_bbox_scores final shape   : ', gaussian_bbox_scores.shape)\n",
    "print('    complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:59:33.486569Z",
     "start_time": "2018-05-15T17:59:32.859747Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "scores = tf.map_fn(build_mask_routine, [gauss_scatt_reshape, bboxes], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:12:00.528378Z",
     "start_time": "2018-05-15T18:11:57.234725Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "new_shape = tf.shape(in_tensor)+ [0,0,0,tf.shape(scores)[-1]]\n",
    "print(tf.shape(in_tensor).eval())\n",
    "print(new_shape.eval())      \n",
    "print(tf.shape(reshape_tensor).eval())\n",
    "print(tf.shape(scores).eval())\n",
    "\n",
    "concat = tf.concat([reshape_tensor, scores], axis = -1)\n",
    "gaussian_boxes_scores = tf.reshape(concat, new_shape)\n",
    "print(tf.shape(gaussian_boxes_scores).eval())\n",
    "print(gaussian_boxes_scores[0,0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:12:17.044573Z",
     "start_time": "2018-05-15T18:12:16.786856Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(pred_tensor[0,0])\n",
    "# print(type(int_scores), len(int_scores), int_scores[0].shape, int_scores[1].shape)\n",
    "# print(type(int_scores), int_scores.shape)\n",
    "# results = tf.concat(int_scores, axis = -1)\n",
    "# print(tf.shape(results).eval())\n",
    "# print(results[:32].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:30:13.657068Z",
     "start_time": "2018-05-15T17:30:12.045620Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# print(pred_tensor[0,0])\n",
    "# bboxes = tf.concat([bboxes, tf.expand_dims(int_scores, axis = -1)],axis = -1 )\n",
    "print(reshape_tensor[10].eval())\n",
    "tst = gauss_scatt_reshape[10]\n",
    "print(tst.eval())\n",
    "tst1 = tf.where(tf.is_nan(tst),  tf.zeros_like(tst), tst)\n",
    "print(tst1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T19:55:35.838068Z",
     "start_time": "2018-05-15T19:55:35.570335Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(output_rois[1]*[128,128,128,128])\n",
    "print(pred_tensor[1,2])\n",
    "print(pred_hm_scores[1,2])\n",
    "print(pred_hm_scores[1,2,:,-2]/pred_hm_scores[1,2,:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Successful attempt to nbuild masks based on boudiung boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:09:26.303677Z",
     "start_time": "2018-05-14T23:09:26.051088Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "try: \n",
    "    del input_tensor\n",
    "    print('input_tensor was deleted')\n",
    "except:\n",
    "    print('input tensor was not defined ')\n",
    "    pass\n",
    "# \n",
    "# tf.reset_default_graph()  \n",
    "try: \n",
    "    del canvas\n",
    "    print('Canvas was deleted')\n",
    "except:\n",
    "    print('Canvas was not defined ')\n",
    "# sess = KB.get_session()\n",
    "# print(sess)\n",
    "# pred_tensor_tf = tf.identity(pred_tensor)\n",
    "# gauss_sum2 =  build_heatmap(pred_tensor_tf, model.config, names = 'Kevin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:48:27.547714Z",
     "start_time": "2018-05-14T23:48:27.177650Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "    print('session was deleted ')\n",
    "except:\n",
    "    print('Session was not defined ')\n",
    "    pass\n",
    "sess= tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "input_tensor = tf.identity(pred_tensor)\n",
    "# heatmap_tensor = tf.identity(tf.transpose(pred_hm_norm, perm=[0,3,1,2]))\n",
    "heatmap_tensor = tf.ones([3,4,128,128])\n",
    "heatmap_tensor  += heatmap_tensor\n",
    "print(' Heatmap tensor shae is :', heatmap_tensor.shape)\n",
    "\n",
    "def f1(): return  tf.zeros_like(config.IMAGE_SHAPE[:2])\n",
    "\n",
    "def build_mask_routine(heatmap_tensor, input_row, index):\n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        #         tensor_output = tf.zeros_like(config.IMAGE_SHAPE[:2], dtype = tf.int32)\n",
    "        #         input_row = tf.cast(input_row, tf.int32)\n",
    "        y_extent  = tf.range(input_row[0], input_row[2])\n",
    "        x_extent  = tf.range(input_row[1], input_row[3])\n",
    "        Y,X       = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        #     print('===> Box input is : ', row)   \n",
    "        #     print('    y_extent (Row) ', y_extent, y_extent.shape)\n",
    "        #     print('    x_extent (Cols)', x_extent, x_extent.shape)   \n",
    "        #     print(Y.shape, X.shape)\n",
    "        #     print(X.eval())\n",
    "        #     print('    bbox_mask shape: ',bbox_mask.shape)\n",
    "        #     print(bbox_mask.eval())\n",
    "        #     rows = mask_indices.shape[0]\n",
    "        #     class_id,_ = tf.meshgrid(row[4], mask_indices[:,1] )\n",
    "        #     class_id = row[4]\n",
    "        #     print('    Size of mask_indices: ', mask_indices.shape)\n",
    "        #     print('    Number of rows : ',rows )     \n",
    "        #     mask_indices = tf.concat([class_id,  mask_indices ], axis= 1)\n",
    "        #     print('    Size of mask_indices for this bbox: ', mask_indices.shape)\n",
    "        #     print(mask_indices.eval())         \n",
    "        #     mask_size = mask_indices.get_shape()\n",
    "        #     print(mask_size)\n",
    "        #     mask_updates = tf.ones_like(tf.shape(mask_size), dtype = tf.int32)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        #     print('    Size of mask_updates for this bbox: ', mask_updates.shape)    \n",
    "        #     print('  size of bbox_mask: ', mask_size)\n",
    "        #     print(' Before scatter_nd_add ')\n",
    "        #     print(tensor_var.eval())\n",
    "        mask = tf.scatter_nd(mask_indices, mask_updates, config.IMAGE_SHAPE[:2])\n",
    "        mask_applied = tf.multiply(heatmap_tensor[index[0], index[1]], mask, name = 'mask_applied')\n",
    "        bbox_pred_sum = tf.reduce_sum(mask_applied)\n",
    "    return bbox_pred_sum\n",
    "\n",
    "\n",
    "#     tensor_output = tf.scatter_nd_add(tensor_input, mask_indices, mask_updates)\n",
    "#     print('    Tensor_output shape:  ', tensor_output.shape)\n",
    "#     print(tensor_output[2].eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:48:31.132863Z",
     "start_time": "2018-05-14T23:48:30.817404Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "input is a row of the pred_tensor array (x1,y1, x2,y2)\n",
    "'''\n",
    "# input_tensor = tf.placeholder(tf.float32,shape=[config.BATCH_SIZE, config.NUM_CLASSES, config.TRAIN_ROIS_PER_IMAGE,6])\n",
    "# heatmap_tensor = tf.placeholder(tf.float32,shape=[config.BATCH_SIZE, config.FCN_INPUT_SHAPE[0], config.FCN_INPUT_SHAPE[1], config.NUM_CLASSES])\n",
    "\n",
    "reshape_tensor  = tf.reshape(input_tensor, [-1,6])\n",
    "# num_imgs, num_classes, num_rois, cols = KB.int_shape(input_tensor)\n",
    "print('input_shape is ', input_tensor.shape) \n",
    "# print(' Or: ', num_imgs, num_classes, num_rois, cols)\n",
    "num_boxes, num_cols = KB.int_shape(reshape_tensor)\n",
    "print('reshape_tensor is ', reshape_tensor.shape)\n",
    "\n",
    "bbox_sum = tf.reduce_max(input_tensor[...,0:3], axis = -1, name  = 'bbox_sum')\n",
    "print(' bbox sum shape: ', bbox_sum.shape)\n",
    "\n",
    "bboxes = tf.concat([tf.to_int32(tf.round(reshape_tensor[...,0:4])), reshape_tensor[...,4:]], axis = -1, name='nz_boxes')\n",
    "print('boxes shape', bboxes.shape)\n",
    "# print(bboxes.eval())\n",
    "\n",
    "#     print(bbox_sum.eval(session = sess))\n",
    "# nz_inds  = tf.where(bbox_sum > 0 , name ='nz_inds')\n",
    "# print(' shape of indexes to non zeros bouding boxes : ',nz_inds.shape)\n",
    "#     print(nz_inds.eval(session = sess))\n",
    "\n",
    "# nz_inds = nz_inds[0:6]\n",
    "# num_nz_inds = tf.shape(nz_inds)[0]\n",
    "# print('number of non-zeros indices:', num_nz_inds.eval())\n",
    "\n",
    "# tmp = tf.gather_nd(input_tensor, nz_inds, name = 'tmp')\n",
    "# print(nz_boxes.get_shape())\n",
    "#     print(nz_boxes.eval(session = sess))\n",
    "\n",
    "\n",
    "# print('non zeros boxes shape:', tf.shape(nz_boxes).eval(session = sess)) \n",
    "# print(nz_boxes[:11].eval(session = sess))\n",
    "\n",
    "# print('non zeros boxes shape:', tf.shape(tst_boxes)) \n",
    "# print(tst_boxes.eval(session = sess))\n",
    "\n",
    "# nz_boxes = tf.Print(nz_boxes, [tf.shape(nz_inds)],message='Non zero bounding boxes')\n",
    "# print(nz_boxes.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T00:08:57.949522Z",
     "start_time": "2018-05-14T23:53:50.353147Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bboxes.shape)\n",
    "num_bboxes = bboxes.shape[0]\n",
    "score_list = []\n",
    "\n",
    "print('num_bboxes: ', num_bboxes)\n",
    "for i in range(num_bboxes):\n",
    "    index = tf.unravel_index(i, input_tensor.shape[0:3])\n",
    "    heatmap_tensor = tf.Print(heatmap_tensor, [index], message= 'Index is ')\n",
    "    print('Call ', i, 'Unraveled: (' ,index.eval(), ') for ', bboxes[i].eval())\n",
    "    \n",
    "#     new_mask = tf.assign(mask, zero)    \n",
    "    summ = tf.reduce_max(bboxes[i,0:4],name = \"max_element\")\n",
    "#     output=tf.cond(tf.equal(summ, 0),\n",
    "#                 f1,\n",
    "#                 lambda: build_mask_routine(mask , bboxes[i])   )\n",
    "#         return tensor_output    \n",
    "    score = build_mask_routine(heatmap_tensor, bboxes[i], index)\n",
    "    print('       Score', score.eval())\n",
    "#     print(' Mask shape: ',mask.get_shape() )\n",
    "    score_list.append(score)\n",
    "final_scores = tf.stack(score_list,axis=-1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T23:52:22.284988Z",
     "start_time": "2018-05-14T23:52:21.321147Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(final_scores.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "###  Run TF session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T22:50:07.054593Z",
     "start_time": "2018-05-14T22:50:05.476250Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {input_tensor: pred_tensor}\n",
    "# fetches = [nz_boxes, int_masks]\n",
    "fetches = [bboxes, output, reshape_tensor, final_output]\n",
    "sess = tf.Session()\n",
    "print(' tfsession() is ', sess)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tt = sess.run(fetches, feed_dict = feed_dict )\n",
    "print(type(tt), len(tt))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T21:24:56.753927Z",
     "start_time": "2018-05-14T21:24:56.499752Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "print(len(Output_list))\n",
    "for i in range(len(Output_list)):\n",
    "    print(Output_list[i].shape, type(Output_list[i]))\n",
    "    print(mask_string(Output_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T22:07:10.133092Z",
     "start_time": "2018-05-14T22:07:09.861953Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import mask_string\n",
    "# img = 1\n",
    "np.set_printoptions(linewidth=150, precision=6, threshold=20000)\n",
    "print(' bboxes Shape: ', tt[0].shape)\n",
    "print(' bboxes Tensor :   \\n ', tt[0][32:48])\n",
    "\n",
    "print('\\n')\n",
    "print(' pred_tensor shape : ', pred_tensor.shape)\n",
    "print(' pred_tensor      \\n ', pred_tensor[0,0,32:48])\n",
    "\n",
    "# print(' tst_boxes shape ', tt[1].shape)\n",
    "# print(' tst_boxes :   \\n ', tt[1])\n",
    "\n",
    "# print(' masks shape :   ', tt[1].shape, type(tt[1]))\n",
    "# print(' masks :      \\n ', mask_string(tt[1]))\n",
    "print('\\n')\n",
    "print(' reshape_tensor shape :   ', tt[2].shape, type(tt[2]))\n",
    "print(' reshape_tensor :      \\n ', tt[2][32:48])\n",
    "print('\\n')\n",
    "print(' reshape_tensor shape :   ', tt[3].shape, type(tt[3]))\n",
    "# print(' reshape_tensor :      \\n ', tt[3][0:10])\n",
    "  \n",
    "\n",
    "\n",
    "print(mask_string(tt[3][:,:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat tesnor at given axis n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T11:59:13.056822Z",
     "start_time": "2018-05-17T11:59:11.096615Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.layers as KL\n",
    "np.set_printoptions(linewidth=130,precision=4,threshold=7000, suppress = True)\n",
    "\n",
    "sess  = KB.get_session()\n",
    "print(sess)\n",
    "test1 = KB.identity(output_rois)\n",
    "print(pred_heatmap_norm.shape)\n",
    "pred_hm_norm = KB.identity(pred_heatmap_norm)\n",
    "test1 = tf.transpose(pred_heatmap_norm, (0,3,1,2))\n",
    "test1_shape = KB.int_shape(test1)\n",
    "\n",
    "with sess.as_default():\n",
    "    print(test1_shape)\n",
    "    test1_sum = tf.reduce_sum(test1, [2,3]).eval()\n",
    "    print('test1_sum is ', test1_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            print('img ',i,' class ', j, ' sum: ', test1_sum[i,j])\n",
    "            \n",
    "    test2 = tf.expand_dims(test1, axis =2)\n",
    "    print('  Test2 shapes :',  test2.get_shape())\n",
    "    test2 = tf.tile(test2, [1,2,32,1,1])\n",
    "    print('  Test2 shapes :',  test2.get_shape())\n",
    "    test2_sum = tf.reduce_sum(test2, [3,4]).eval()\n",
    "    print('test2_sum is ', test2_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            for k in range(32):\n",
    "                print('img ',i,' class ', j, 'copy ',k, ' sum:',test2_sum[i,j,k])\n",
    "\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "#     ones = tf.ones([7 ,1, 1, 1], dtype = tf.float32)    \n",
    "#     test2 = test1 * ones\n",
    "#     print(KB.int_shape(test2))\n",
    "\n",
    "#     test2 = tf.tile(test2, [1,3,1,1])\n",
    "#     for i in range(5):\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "\n",
    "# with sess.as_default():\n",
    "#     print(KB.int_shape(pred_hm_norm))\n",
    "#     test1_shape = KB.int_shape(test1)\n",
    "#     print(test1_shape)\n",
    "#     print(test1[0,:6].eval())\n",
    "#     print(test1[1,:6].eval())\n",
    "#     print(test1[2,:6].eval())\n",
    "#     print(test1[3,:6].eval())    \n",
    "#     print(test1[4,:6].eval())    \n",
    "#     test2 = tf.expand_dims(test1, axis =1)\n",
    "# #     print('  Test1 shapes :',  test1.get_shape())\n",
    "# #     ones = tf.ones([7 ,1, 1, 1], dtype = tf.float32)    \n",
    "# #     test2 = test1 * ones\n",
    "#     print(KB.int_shape(test2))\n",
    "\n",
    "#     test2 = tf.tile(test2, [1,3,1,1])\n",
    "#     for i in range(5):\n",
    "#         print(KB.int_shape(test2))\n",
    "#         print(' Test2 - ',i)\n",
    "#         print(test2[i,0,:6].eval())\n",
    "#         print(test2[i,1,:6].eval())\n",
    "#         print(test2[i,2,:6].eval())\n",
    "\n",
    "# #     test3 = KB.reshape(test2, (-1,test1_shape[0], test1_shape[1]))    \n",
    "# #     print(KB.int_shape(test3))\n",
    "# #     print(test3.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate L2 norm on heatmap score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T08:39:30.643505Z",
     "start_time": "2018-05-17T08:39:29.898717Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# del scr\n",
    "# del scr_norm\n",
    "with sess.as_default():\n",
    "#     print(tf.shape(scr).eval())\n",
    "    print(pred_heatmap_scores[img,0])\n",
    "    scr = pred_heatmap_scores[...,6]/pred_heatmap_scores[...,7]\n",
    "    scr = tf.where(tf.is_nan(scr),  tf.zeros_like(scr), scr)       \n",
    "    scr_norm = tf.nn.l2_normalize(scr, axis = -1)\n",
    "#     print('l2 normalzied - 2')\n",
    "#     print(tf.shape(scr_norm).eval())    \n",
    "#     print(scr_norm.eval())\n",
    "    scr_norm = tf.expand_dims(scr_norm, axis = -1)\n",
    "#     print(tf.shape(scr_norm).eval())\n",
    "    print('tst')\n",
    "    tst = tf.concat([pred_heatmap_scores, scr_norm], axis = -1)\n",
    "    print(tst.shape)\n",
    "    print(tst[0].eval())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
