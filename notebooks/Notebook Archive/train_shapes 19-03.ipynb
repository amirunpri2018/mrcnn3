{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.4.0   Keras Version : 2.1.3 \n",
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                7\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mrcnn.shapes as shapes\n",
    "from mrcnn.dataset import Dataset \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pprint\n",
    "import keras.backend as KB\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 2                    #Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 2\n",
    "config.STEPS_PER_EPOCH = 7\n",
    "# config.IMAGES_PER_GPU  = 1\n",
    "\n",
    "config.display() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as KB\n",
    "# if 'tensorflow' == KB.backend():\n",
    "#     import tensorflow as tf\n",
    "#     from keras.backend.tensorflow_backend import set_session\n",
    "#     # tfconfig = tf.ConfigProto(\n",
    "#         # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5),\n",
    "#         # device_count = {'GPU': 1}\n",
    "#     # )    \n",
    "#     tfconfig = tf.ConfigProto()\n",
    "#     tfconfig.gpu_options.allow_growth=True\n",
    "#     tfconfig.gpu_options.visible_device_list = \"0\"\n",
    "#     tfconfig.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "#     tf_sess = tf.Session(config=tfconfig)\n",
    "#     set_session(tf_sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180319T0843\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      " IMAGE SHAPE is : 128    128\n",
      "<class 'list'>\n",
      "Tensor(\"rpn_class_logits/concat:0\", shape=(?, ?, 2), dtype=float32) rpn_class_logits/concat:0\n",
      "Tensor(\"rpn_class/concat:0\", shape=(?, ?, 2), dtype=float32) rpn_class/concat:0\n",
      "Tensor(\"rpn_bbox/concat:0\", shape=(?, ?, 4), dtype=float32) rpn_bbox/concat:0\n",
      "Proposal Layer init complete. Size of anchors:  (4092, 4)\n",
      "Tensor(\"proposal_targets/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_4:0\", shape=(2,), dtype=int32)\n",
      "Shape of overlaps Tensor(\"proposal_targets/Shape_7:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_9:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_11:0\", shape=(2,), dtype=int32)\n",
      "Shape of overlaps Tensor(\"proposal_targets/Shape_14:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_21:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_23:0\", shape=(2,), dtype=int32)\n",
      "Shape of overlaps Tensor(\"proposal_targets/Shape_26:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_28:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"proposal_targets/Shape_30:0\", shape=(2,), dtype=int32)\n",
      "Shape of overlaps Tensor(\"proposal_targets/Shape_33:0\", shape=(2,), dtype=int32)\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(model)\n",
    "# Create model in training mode\n",
    "# MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "import  gc\n",
    "# del history\n",
    "try :\n",
    "    del model\n",
    "except: \n",
    "    pass\n",
    " \n",
    "gc.collect()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n",
      "find_last info:   dir_name: E:\\Models\\mrcnn_logs\\shapes20180313T1856\n",
      "find_last info: checkpoint: E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0215.h5\n",
      "('E:\\\\Models\\\\mrcnn_logs\\\\shapes20180313T1856', 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180313T1856\\\\mask_rcnn_shapes_0215.h5')\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n",
    "print(model.find_last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_last info:   dir_name: E:\\Models\\mrcnn_logs\\shapes20180313T1856\n",
      "find_last info: checkpoint: E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0215.h5\n",
      "load_weights:      from: E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0215.h5\n",
      "set_log_dir:  model_path (input) is : E:/Models/mrcnn_logs/shapes20180313T1856/mask_rcnn_shapes_0215.h5  \n",
      "self.epoch set to 216  (Next epoch to run)\n",
      "set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Load weights complete\n"
     ]
    }
   ],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(model.keras_model.layers)):\n",
    "#     print(i, ' Name of layer: ', model.keras_model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# model.keras_model.layers[229].output.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                7\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7eee005b96f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             layers='heads')\n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\Mask_RCNN_2\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, batch_size, steps_per_epoch)\u001b[0m\n\u001b[0;32m    904\u001b[0m         callbacks = [\n\u001b[0;32m    905\u001b[0m             keras.callbacks.TensorBoard(log_dir=self.log_dir,\n\u001b[1;32m--> 906\u001b[1;33m                                         histogram_freq=0, write_graph=True, write_images=False),\n\u001b[0m\u001b[0;32m    907\u001b[0m             keras.callbacks.ModelCheckpoint(self.checkpoint_path,\n\u001b[0;32m    908\u001b[0m                                             monitor='loss', verbose=1, save_best_only = True, save_weights_only=True)\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, histogram_freq, batch_size, write_graph, write_grads, write_images, embeddings_freq, embeddings_layer_names, embeddings_metadata)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_editor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgrid_rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\contrib\\gan\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Collapse TFGAN into a tiered namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meval\u001b[0m  \u001b[1;31m# pylint:disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\contrib\\gan\\python\\estimator\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Collapse `estimator` into a single namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgan_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\contrib\\gan\\python\\estimator\\python\\gan_estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgan_estimator_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan_estimator_impl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=69, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training heads using train_on_batch()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last epoch completed : 216 \n",
      "Starting from epoch 216 for 5 epochs. LR=0.001\n",
      "Steps per epoch:   7 \n",
      "Checkpoint Folder: E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Checkpoint folder already exists\n",
      "\n",
      "Selecting layers to train\n",
      "Layer    Layer Name               Layer Type\n",
      "174  fpn_c5p5               (Conv2D)\n",
      "176  fpn_c4p4               (Conv2D)\n",
      "179  fpn_c3p3               (Conv2D)\n",
      "182  fpn_c2p2               (Conv2D)\n",
      "184  fpn_p5                 (Conv2D)\n",
      "185  fpn_p2                 (Conv2D)\n",
      "186  fpn_p3                 (Conv2D)\n",
      "187  fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "      1  rpn_conv_shared        (Conv2D)\n",
      "      2  rpn_class_raw          (Conv2D)\n",
      "      4  rpn_bbox_pred          (Conv2D)\n",
      "199  mrcnn_mask_conv1       (TimeDistributed)\n",
      "200  mrcnn_mask_bn1         (TimeDistributed)\n",
      "202  mrcnn_mask_conv2       (TimeDistributed)\n",
      "204  mrcnn_mask_bn2         (TimeDistributed)\n",
      "205  mrcnn_class_conv1      (TimeDistributed)\n",
      "207  mrcnn_class_bn1        (TimeDistributed)\n",
      "208  mrcnn_mask_conv3       (TimeDistributed)\n",
      "210  mrcnn_mask_bn3         (TimeDistributed)\n",
      "211  mrcnn_class_conv2      (TimeDistributed)\n",
      "213  mrcnn_class_bn2        (TimeDistributed)\n",
      "214  mrcnn_mask_conv4       (TimeDistributed)\n",
      "216  mrcnn_mask_bn4         (TimeDistributed)\n",
      "219  mrcnn_bbox_fc          (TimeDistributed)\n",
      "220  mrcnn_mask_deconv      (TimeDistributed)\n",
      "223  mrcnn_class_logits     (TimeDistributed)\n",
      "225  mrcnn_mask             (TimeDistributed)\n",
      "Epoch 217/221\n",
      " Loading shapes obj mask infofor image_id :  191\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  471\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 1:52 - loss: 0.3904 - rpn_class_loss: 0.0085 - rpn_bbox_loss: 0.2740 - mrcnn_class_loss: 0.0062 - mrcnn_bbox_loss: 0.0494 - mrcnn_mask_loss: 0.0523 Loading shapes obj mask infofor image_id :  388\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  288\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "2/7 [=======>......................] - ETA: 47s - loss: 0.5607 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.3488 - mrcnn_class_loss: 0.0705 - mrcnn_bbox_loss: 0.0588 - mrcnn_mask_loss: 0.0726  Loading shapes obj mask infofor image_id :  449\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  409\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "3/7 [===========>..................] - ETA: 25s - loss: 0.7640 - rpn_class_loss: 0.0109 - rpn_bbox_loss: 0.2966 - mrcnn_class_loss: 0.0849 - mrcnn_bbox_loss: 0.0888 - mrcnn_mask_loss: 0.2829 Loading shapes obj mask infofor image_id :  439\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  173\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "4/7 [================>.............] - ETA: 14s - loss: 0.7579 - rpn_class_loss: 0.0108 - rpn_bbox_loss: 0.2926 - mrcnn_class_loss: 0.0831 - mrcnn_bbox_loss: 0.0798 - mrcnn_mask_loss: 0.2917 Loading shapes obj mask infofor image_id :  498\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  207\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "5/7 [====================>.........] - ETA: 7s - loss: 0.7648 - rpn_class_loss: 0.0116 - rpn_bbox_loss: 0.3022 - mrcnn_class_loss: 0.1062 - mrcnn_bbox_loss: 0.0845 - mrcnn_mask_loss: 0.2603  Loading shapes obj mask infofor image_id :  198\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  24\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 0.8615 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.3336 - mrcnn_class_loss: 0.1301 - mrcnn_bbox_loss: 0.0998 - mrcnn_mask_loss: 0.2866 Loading shapes obj mask infofor image_id :  358\n",
      " Shapes obj mask shape is : (128, 128, 4)\n",
      "shape of mask is : (128, 128, 4)\n",
      "after resize_mask shape is : (128, 128, 4)\n",
      "after use_mini_mask  shape is : (56, 56, 4)\n",
      " Loading shapes obj mask infofor image_id :  479\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.8622 - rpn_class_loss: 0.0123 - rpn_bbox_loss: 0.3442 - mrcnn_class_loss: 0.1363 - mrcnn_bbox_loss: 0.1013 - mrcnn_mask_loss: 0.2681\n",
      "\n",
      "Epoch 00217: loss improved from inf to 0.86686, saving model to E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0217.h5\n",
      "Epoch 218/221\n",
      " Loading shapes obj mask infofor image_id :  406\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  373\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "1/7 [===>..........................] - ETA: 1s - loss: 1.0976 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.3629 - mrcnn_class_loss: 0.3086 - mrcnn_bbox_loss: 0.1646 - mrcnn_mask_loss: 0.2577 Loading shapes obj mask infofor image_id :  62\n",
      " Shapes obj mask shape is : (128, 128, 4)\n",
      "shape of mask is : (128, 128, 4)\n",
      "after resize_mask shape is : (128, 128, 4)\n",
      "after use_mini_mask  shape is : (56, 56, 4)\n",
      " Loading shapes obj mask infofor image_id :  312\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "2/7 [=======>......................] - ETA: 1s - loss: 0.9839 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.4239 - mrcnn_class_loss: 0.2282 - mrcnn_bbox_loss: 0.1125 - mrcnn_mask_loss: 0.2123 Loading shapes obj mask infofor image_id :  318\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  204\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.8112 - rpn_class_loss: 0.0078 - rpn_bbox_loss: 0.3445 - mrcnn_class_loss: 0.1773 - mrcnn_bbox_loss: 0.0897 - mrcnn_mask_loss: 0.1919 Loading shapes obj mask infofor image_id :  50\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  466\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.7548 - rpn_class_loss: 0.0079 - rpn_bbox_loss: 0.3395 - mrcnn_class_loss: 0.1523 - mrcnn_bbox_loss: 0.0747 - mrcnn_mask_loss: 0.1804 Loading shapes obj mask infofor image_id :  132\n",
      " Shapes obj mask shape is : (128, 128, 4)\n",
      "shape of mask is : (128, 128, 4)\n",
      "after resize_mask shape is : (128, 128, 4)\n",
      "after use_mini_mask  shape is : (56, 56, 4)\n",
      " Loading shapes obj mask infofor image_id :  135\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.8222 - rpn_class_loss: 0.0108 - rpn_bbox_loss: 0.3624 - mrcnn_class_loss: 0.1842 - mrcnn_bbox_loss: 0.0837 - mrcnn_mask_loss: 0.1810 Loading shapes obj mask infofor image_id :  246\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  57\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.9969 - rpn_class_loss: 0.0128 - rpn_bbox_loss: 0.5686 - mrcnn_class_loss: 0.1674 - mrcnn_bbox_loss: 0.0770 - mrcnn_mask_loss: 0.1710 Loading shapes obj mask infofor image_id :  123\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  405\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.9354 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.5424 - mrcnn_class_loss: 0.1510 - mrcnn_bbox_loss: 0.0741 - mrcnn_mask_loss: 0.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00218: loss improved from 0.86686 to 0.56648, saving model to E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0218.h5\n",
      "Epoch 219/221\n",
      " Loading shapes obj mask infofor image_id :  92\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  411\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "1/7 [===>..........................] - ETA: 2s - loss: 0.5448 - rpn_class_loss: 0.0168 - rpn_bbox_loss: 0.2376 - mrcnn_class_loss: 0.0644 - mrcnn_bbox_loss: 0.0635 - mrcnn_mask_loss: 0.1626 Loading shapes obj mask infofor image_id :  395\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  213\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "2/7 [=======>......................] - ETA: 1s - loss: 0.4578 - rpn_class_loss: 0.0140 - rpn_bbox_loss: 0.2512 - mrcnn_class_loss: 0.0419 - mrcnn_bbox_loss: 0.0431 - mrcnn_mask_loss: 0.1076 Loading shapes obj mask infofor image_id :  28\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  276\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.4201 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.2279 - mrcnn_class_loss: 0.0382 - mrcnn_bbox_loss: 0.0426 - mrcnn_mask_loss: 0.1001 Loading shapes obj mask infofor image_id :  419\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  73\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "4/7 [================>.............] - ETA: 1s - loss: 0.4594 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.1971 - mrcnn_class_loss: 0.0458 - mrcnn_bbox_loss: 0.0507 - mrcnn_mask_loss: 0.1551 Loading shapes obj mask infofor image_id :  263\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  381\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5118 - rpn_class_loss: 0.0111 - rpn_bbox_loss: 0.2135 - mrcnn_class_loss: 0.0494 - mrcnn_bbox_loss: 0.0472 - mrcnn_mask_loss: 0.1906 Loading shapes obj mask infofor image_id :  87\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  46\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.5464 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2542 - mrcnn_class_loss: 0.0586 - mrcnn_bbox_loss: 0.0509 - mrcnn_mask_loss: 0.1722 Loading shapes obj mask infofor image_id :  350\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  301\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "7/7 [==============================] - 2s 352ms/step - loss: 0.6767 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2550 - mrcnn_class_loss: 0.0885 - mrcnn_bbox_loss: 0.0673 - mrcnn_mask_loss: 0.2555\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "Epoch 220/221\n",
      " Loading shapes obj mask infofor image_id :  360\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  169\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "1/7 [===>..........................] - ETA: 2s - loss: 0.6140 - rpn_class_loss: 0.0079 - rpn_bbox_loss: 0.4247 - mrcnn_class_loss: 0.0865 - mrcnn_bbox_loss: 0.0303 - mrcnn_mask_loss: 0.0646 Loading shapes obj mask infofor image_id :  423\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  196\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "2/7 [=======>......................] - ETA: 1s - loss: 0.5081 - rpn_class_loss: 0.0117 - rpn_bbox_loss: 0.3238 - mrcnn_class_loss: 0.0648 - mrcnn_bbox_loss: 0.0294 - mrcnn_mask_loss: 0.0784 Loading shapes obj mask infofor image_id :  154\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  322\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.6007 - rpn_class_loss: 0.0125 - rpn_bbox_loss: 0.4074 - mrcnn_class_loss: 0.0667 - mrcnn_bbox_loss: 0.0334 - mrcnn_mask_loss: 0.0807 Loading shapes obj mask infofor image_id :  252\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  98\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "4/7 [================>.............] - ETA: 1s - loss: 0.5737 - rpn_class_loss: 0.0112 - rpn_bbox_loss: 0.3770 - mrcnn_class_loss: 0.0692 - mrcnn_bbox_loss: 0.0391 - mrcnn_mask_loss: 0.0773 Loading shapes obj mask infofor image_id :  269\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  366\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6562 - rpn_class_loss: 0.0122 - rpn_bbox_loss: 0.3660 - mrcnn_class_loss: 0.0748 - mrcnn_bbox_loss: 0.0420 - mrcnn_mask_loss: 0.1612 Loading shapes obj mask infofor image_id :  247\n",
      " Shapes obj mask shape is : (128, 128, 4)\n",
      "shape of mask is : (128, 128, 4)\n",
      "after resize_mask shape is : (128, 128, 4)\n",
      "after use_mini_mask  shape is : (56, 56, 4)\n",
      " Loading shapes obj mask infofor image_id :  97\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.7148 - rpn_class_loss: 0.0132 - rpn_bbox_loss: 0.3464 - mrcnn_class_loss: 0.0976 - mrcnn_bbox_loss: 0.0637 - mrcnn_mask_loss: 0.1939 Loading shapes obj mask infofor image_id :  216\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  8\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 353ms/step - loss: 0.7064 - rpn_class_loss: 0.0139 - rpn_bbox_loss: 0.3483 - mrcnn_class_loss: 0.0913 - mrcnn_bbox_loss: 0.0657 - mrcnn_mask_loss: 0.1872\n",
      "\n",
      "Epoch 00220: loss did not improve\n",
      "Epoch 221/221\n",
      " Loading shapes obj mask infofor image_id :  82\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  255\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "1/7 [===>..........................] - ETA: 2s - loss: 1.3223 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.2238 - mrcnn_class_loss: 0.2510 - mrcnn_bbox_loss: 0.1874 - mrcnn_mask_loss: 0.6526 Loading shapes obj mask infofor image_id :  491\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  424\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "2/7 [=======>......................] - ETA: 1s - loss: 0.8806 - rpn_class_loss: 0.0086 - rpn_bbox_loss: 0.2566 - mrcnn_class_loss: 0.1498 - mrcnn_bbox_loss: 0.1087 - mrcnn_mask_loss: 0.3568 Loading shapes obj mask infofor image_id :  88\n",
      " Shapes obj mask shape is : (128, 128, 4)\n",
      "shape of mask is : (128, 128, 4)\n",
      "after resize_mask shape is : (128, 128, 4)\n",
      "after use_mini_mask  shape is : (56, 56, 4)\n",
      " Loading shapes obj mask infofor image_id :  378\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.9189 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.2726 - mrcnn_class_loss: 0.1727 - mrcnn_bbox_loss: 0.0979 - mrcnn_mask_loss: 0.3655 Loading shapes obj mask infofor image_id :  404\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  167\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "4/7 [================>.............] - ETA: 1s - loss: 0.9280 - rpn_class_loss: 0.0110 - rpn_bbox_loss: 0.3032 - mrcnn_class_loss: 0.1551 - mrcnn_bbox_loss: 0.0951 - mrcnn_mask_loss: 0.3636 Loading shapes obj mask infofor image_id :  473\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  309\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.9523 - rpn_class_loss: 0.0112 - rpn_bbox_loss: 0.3440 - mrcnn_class_loss: 0.1567 - mrcnn_bbox_loss: 0.0951 - mrcnn_mask_loss: 0.3452 Loading shapes obj mask infofor image_id :  95\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  248\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.9435 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.3481 - mrcnn_class_loss: 0.1777 - mrcnn_bbox_loss: 0.0920 - mrcnn_mask_loss: 0.3145 Loading shapes obj mask infofor image_id :  141\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      " Loading shapes obj mask infofor image_id :  421\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n",
      "7/7 [==============================] - 2s 354ms/step - loss: 0.8876 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.3529 - mrcnn_class_loss: 0.1616 - mrcnn_bbox_loss: 0.0843 - mrcnn_mask_loss: 0.2782\n",
      "\n",
      "Epoch 00221: loss improved from 0.56648 to 0.55222, saving model to E:\\Models\\mrcnn_logs\\shapes20180313T1856\\mask_rcnn_shapes_0221.h5\n",
      "Final : self.epoch 221   epochs 221\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs_to_run = 5,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some network information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning phase value is:  1\n",
      "\n",
      " Metrics: \n",
      "[ 'loss',\n",
      "  'rpn_class_loss',\n",
      "  'rpn_bbox_loss',\n",
      "  'mrcnn_class_loss',\n",
      "  'mrcnn_bbox_loss',\n",
      "  'mrcnn_mask_loss']\n",
      "\n",
      " Outputs: \n",
      "[ <tf.Tensor 'output_rois/mul:0' shape=(2, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class_logits/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "  <tf.Tensor 'proposal_rois/packed_2:0' shape=(2, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_bbox/concat:0' shape=(?, ?, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class_logits/Reshape_1:0' shape=(?, 32, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class/Reshape_1:0' shape=(?, 32, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_bbox/Reshape:0' shape=(?, 32, 4, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_mask/Reshape_1:0' shape=(?, 32, 28, 28, 4) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class_loss/cond/Merge:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'rpn_bbox_loss/cond/Merge:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class_loss/truediv:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_bbox_loss/Reshape_3:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_mask_loss/Reshape_3:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      " Losses: \n",
      "[ 'loss',\n",
      "  'rpn_class_loss',\n",
      "  'rpn_bbox_loss',\n",
      "  'mrcnn_class_loss',\n",
      "  'mrcnn_bbox_loss',\n",
      "  'mrcnn_mask_loss']\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.draft import show_modelstuff\n",
    "model.compile(model.config.LEARNING_RATE, model.config.LEARNING_MOMENTUM)\n",
    "show_modelstuff(model.keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_layer_output(model, model_input,output_layer, training_flag = True):\n",
    "#     _my_input = model_input \n",
    "#     for name,inp in zip(model.input_names, model_input):\n",
    "#         print(' Input Name:  ({:24}) \\t  Input shape: {}'.format(name, inp.shape))\n",
    "\n",
    "\n",
    "#     _mrcnn_class = KB.function(model.input , model.output)\n",
    "# #                               [model.keras_model.layers[output_layer].output])\n",
    "#     output = _mrcnn_class(_my_input)                  \n",
    "    \n",
    "#     for name,out in zip (model.output_names,output):\n",
    "#         print(' Output Name: ({:24}) \\t Output shape: {}'.format(name, out.shape))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import  multivariate_normal\n",
    "import numpy as np\n",
    "def bbox_gaussian( bbox, Zin ):\n",
    "    \"\"\"\n",
    "    receive a bounding box, and generate a gaussian distribution centered on the bounding box and with a \n",
    "    covariance matrix based on the width and height of the bounding box/. \n",
    "    Inputs : \n",
    "    --------\n",
    "    bbox :  (index, class_id, class_prob, y1, x1, y2, x2)\n",
    "    bbox :  (index, class_id, class_prob, cx, cy, width, height)\n",
    "    Returns:\n",
    "    --------\n",
    "    bbox_g  grid mesh [image_height, image width] covering the distribution\n",
    "\n",
    "    \"\"\"\n",
    "    print(bbox.shape)\n",
    "    width  = bbox[6] - bbox[4]\n",
    "    height = bbox[5] - bbox[3]\n",
    "    cx     = bbox[4] + ( width  / 2.0)\n",
    "    cy     = bbox[3] + ( height / 2.0)\n",
    "#     cx, cy, width, height = bbox[3:]\n",
    "    print('center is ({},{}) width: {}  height: {} '.format(cx, cy, width,  height))\n",
    "#     srtd_cpb_2 = np.column_stack((srtd_cpb[:, 0:2], cx,cy, width, height ))\n",
    "    X = np.arange(0, 128, 1)\n",
    "    Y = np.arange(0, 128, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    pos = np.empty(X.shape+(2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "    pos[:,:,0] = X;\n",
    "    pos[:,:,1] = Y;\n",
    "\n",
    "    rv = multivariate_normal([cx,cy],[[12,0.0] , [0.0,19]])\n",
    "    Zout  = rv.pdf(pos)\n",
    "    Zout += Zin\n",
    "    return Zout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "def plot_gaussian( Z ):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    \n",
    "    X = np.arange(0, 128, 1)\n",
    "    Y = np.arange(0, 128, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    \n",
    "    pos = np.empty(X.shape+(2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "    pos[:,:,0] = X;\n",
    "    pos[:,:,1] = Y;\n",
    "    surf = ax.plot_surface(X, Y, Z,cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    \n",
    "    # # Customize the z axis.\n",
    "    ax.set_zlim(0.0 , 0.05)\n",
    "    ax.set_ylim(0,130)\n",
    "    ax.set_xlim(0,130)\n",
    "    ax.set_xlabel(' X axis')\n",
    "    ax.set_ylabel(' Y axis')\n",
    "    ax.invert_yaxis()\n",
    "    ax.view_init(elev=140, azim=-88)\n",
    "    # ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    # ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_tensor(model):\n",
    "    pred_cpb_all = np.empty((0,8))\n",
    "    for i in range(1,model.config.NUM_CLASSES):\n",
    "    if pred_cls_cnt[i] > 0:\n",
    "        pred_cpb_all = np.vstack((pred_cpb_all, pred_cpb[i,0:pred_cls_cnt[i]] ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.datagen import data_generator, load_image_gt\n",
    "np.set_printoptions(linewidth=100)\n",
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)\n",
    "\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "mm = model.keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display shape loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading shapes obj mask infofor image_id :  282\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " Loading shapes obj mask infofor image_id :  244\n",
      " Shapes obj mask shape is : (128, 128, 1)\n",
      "shape of mask is : (128, 128, 1)\n",
      "after resize_mask shape is : (128, 128, 1)\n",
      "after use_mini_mask  shape is : (56, 56, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading shapes obj mask infofor image_id :  245\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "shape of mask is : (128, 128, 2)\n",
      "after resize_mask shape is : (128, 128, 2)\n",
      "after use_mini_mask  shape is : (56, 56, 2)\n",
      " Loading shapes obj mask infofor image_id :  479\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "shape of mask is : (128, 128, 3)\n",
      "after resize_mask shape is : (128, 128, 3)\n",
      "after use_mini_mask  shape is : (56, 56, 3)\n",
      " image id is : [245 479]\n",
      " Loading shapes obj mask infofor image_id :  245\n",
      " Shapes obj mask shape is : (128, 128, 2)\n",
      "(128, 128, 2) (2,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fea7c8fcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " image id is : [128 128]\n",
      " Loading shapes obj mask infofor image_id :  479\n",
      " Shapes obj mask shape is : (128, 128, 3)\n",
      "(128, 128, 3) (3,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fea7c6ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_x, sample_y = next(train_generator)\n",
    "\n",
    "imgmeta_idx= mm.input_names.index('input_image_meta')\n",
    "img_meta   =  sample_x[imgmeta_idx]\n",
    "image_id   = img_meta[0,0]\n",
    "print(' image id is :',img_meta[:,0])\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "print(mask.shape, class_ids.shape)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "print(' image id is :',img_meta[:,1])\n",
    "image_id = img_meta[1,0]\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "print(mask.shape, class_ids.shape)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_0 = mask[:,:,:]\n",
    "# print(mask_0.shape)\n",
    "# print(mask[:,:,0])\n",
    "# print('\\n\\n\\n')\n",
    "# print(mask[:,:,1])\n",
    "# print('\\n\\n\\n')\n",
    "# print(mask[:,:,2])\n",
    "# print('\\n\\n\\n')\n",
    "\n",
    "from mrcnn.utils  import minimize_mask, extract_bboxes,resize_mask\n",
    "import scipy    \n",
    "\n",
    "# img = 1\n",
    "# image_1 = sample_x[0][img]\n",
    "# class_ids_1 = sample_x[4][img,0:objs].astype(int)\n",
    "# bbox_1  = sample_x[5][img,0:objs]\n",
    "# mask_1  = sample_x[6][img,:,:,0:objs]\n",
    "# objs = np.count_nonzero(sample_x[4][img]) \n",
    "# print(class_ids_1, objs)\n",
    "\n",
    "# print(objs)\n",
    "# # mask_1  = minimize_mask(sampl,sample_x[6][0,:,:,0:objs],model.config.MINI_MASK_SHAPE)\n",
    "# print(mask_1.shape, bbox_1.shape)\n",
    "\n",
    "# print(mask_1[:,:,0])\n",
    "# print('\\n\\n\\n')\n",
    "# print(mask_1[:,:,1])\n",
    "# print('\\n\\n\\n')\n",
    "# print(mask_1[:,:,2])\n",
    "# i  = 0\n",
    "\n",
    "# mask is 128 x 128 x num_masks\n",
    "# m = mask[:,:,1]\n",
    "# m_str = np.array2string(m.astype('int'))\n",
    "# print(m.shape, m.size)\n",
    "# print(m_str)\n",
    "\n",
    "# y1, x1, y2, x2 = bbox_1[0][:4]\n",
    "# print(y1,':', y2, x1,':', x2, y2-y1, x2-x1 )\n",
    "# mm = m[y1:y2, x1:x2]\n",
    "\n",
    "# mask_1 is 56x56\n",
    "# m1 = mask_1[:,:,0]\n",
    "# m1_str = np.array2string(m1.astype('int'))\n",
    "# print(m1.shape, m1.size)\n",
    "# print(m1_str)\n",
    "\n",
    "\n",
    "\n",
    "# m_str = np.array2string(m[0:50,:].astype(int))\n",
    "# print(m.shape)\n",
    "# print(m_str)\n",
    "# print('\\n\\n\\n')\n",
    "\n",
    "# m2 = scipy.misc.imresize(m.astype(float), (56,56), interp='bilinear')\n",
    "# m2_mask = np.where(m2 >= 128, 1, 0)\n",
    "# m2_str = np.array2string(m2.astype('int'))\n",
    "# print(m2.size)\n",
    "# print(m2_str)\n",
    "\n",
    "# mini_mask = np.zeros((56,56, objs), dtype=bool)\n",
    "# mini_mask[:, :, i] = np.where(m2 >= 128, 1, 0)\n",
    "# print(np.array2string(np.where(m >= 128, 1, 0)[:,:,0]))\n",
    "# m[25:60,30:60]\n",
    "# class_ids_1 = sample_x[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [TF_gpu]",
   "language": "python",
   "name": "Python [TF_gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
