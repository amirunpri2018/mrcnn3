{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:21:47.211797Z",
     "start_time": "2018-04-21T10:21:17.402458Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pprint\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 4                   #Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 4\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "# config.IMAGES_PER_GPU  = 1\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Process outside of training \n",
    "\n",
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:24:30.877889Z",
     "start_time": "2018-04-21T10:24:22.071454Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "#model.keras_model.summary(line_length = 120) \n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "if init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "\n",
    "model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "KB.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# mm = model.keras_model\n",
    "# print('\\n Learning phase values is L ' ,KB.learning_phase())\n",
    "# print('\\n Metrics (_get_deduped_metrics_names():) ') \n",
    "# pp.pprint(mm._get_deduped_metrics_names())\n",
    "# print('\\n Outputs: ') \n",
    "# pp.pprint(mm.outputs)\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(mm.metrics_names)\n",
    "\n",
    "# model.keras_model.summary(line_length = 120) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:12:39.724564Z",
     "start_time": "2018-04-20T17:12:39.485931Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:12:58.684135Z",
     "start_time": "2018-04-20T17:12:58.430462Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:13:01.548758Z",
     "start_time": "2018-04-20T17:13:00.207190Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print(class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:13:08.189801Z",
     "start_time": "2018-04-20T17:13:02.926423Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control pred_tensor / pred_tensor2 on 100 training shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:06:35.226178Z",
     "start_time": "2018-04-20T17:00:25.526424Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "    layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1, verbose = False)\n",
    "\n",
    "    pt   = layers_out[5]   # pred_tensor\n",
    "    pt2  = layers_out[11]  # pred_tensor_2\n",
    "    \n",
    "#     pcc  = layers_out[9]   # pred_cls_cnt\n",
    "#     pcc2 = layers_out[15]  # pred_cls_cnt_2\n",
    "\n",
    "#     print( pt2.shape, pcc2.shape)\n",
    "#     print( pt.shape, pt2.shape)\n",
    "#     print(pc2)\n",
    "\n",
    "    for img in range(config.BATCH_SIZE):\n",
    "        for cls in range(4):\n",
    "#             print(pt2[img][cls])\n",
    "#             print(pt[img][cls])\n",
    "            pt_equal = np.all(pt2[img,cls,:,1:-1]== pt[img,cls,:,1:-1], axis = -1)\n",
    "            print('* Iteration', i , 'Image ',img,' Class ',cls, ' pred_tesnor == pred_tensor2 : ',pt_equal.all())\n",
    "            \n",
    "            if (~pt_equal.all()):\n",
    "#                 print(' Iteration', i , 'Image ',img,' Class ',cls, ' ALL pt_equal: ',pt_equal.all())\n",
    "                print(pt_equal)\n",
    "                print('\\n -- using numpy \\n',pt[img][cls,~pt_equal,:-1])\n",
    "                print('\\n -- using tensorflow \\n',pt2[img][cls,~pt_equal])\n",
    "                print()\n",
    "    #             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "    #             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control pred_tesnor / pred_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:43:43.392596Z",
     "start_time": "2018-04-17T10:43:43.123879Z"
    },
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt   = layers_out[4]   # pred_tensor\n",
    "pt2  = layers_out[12] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "        print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "        if (~equal.all()):\n",
    "#             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "            print(equal)\n",
    "            print('\\n -- using numpy (pt) \\n',pt[img][cls,~equal,:-1])\n",
    "            print('\\n -- using tensorflow (pt2) \\n',pt2[img][cls,~equal])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Display pred_tensor from Numpy and Tensorflow PCN_Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:44:42.193764Z",
     "start_time": "2018-04-20T14:44:41.915023Z"
    },
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=99999, linewidth=2000)\n",
    "# print(np.array2string(mask[...,0],max_line_width=2000,separator=''))\n",
    "pt   = layers_out[4]   # pred_tensor\n",
    "pt2  = layers_out[12] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "img = 0\n",
    "\n",
    "for cls in range(4):\n",
    "#     equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "    print('Image ',img,' Class ',cls)\n",
    "    print(' Output from PCN_Layer (Numpy)')\n",
    "    print( pt[img,cls])\n",
    "    print(' Output from PCN_Layer (Tensorflow)')\n",
    "    print(pt2[img,cls])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "source": [
    "### gt_tensor / gt_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T21:37:15.933436Z",
     "start_time": "2018-04-16T21:37:15.683773Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pt   = layers_out[10]   # pred_tensor\n",
    "pt2  = layers_out[18] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "        print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "        \n",
    "        if (~equal.all()):\n",
    "#             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "            print(equal)\n",
    "            print('\\n -- using numpy (pt) \\n',pt[img][cls,~equal,:-1])\n",
    "            print('\\n -- using tensorflow (pt2) \\n',pt2[img][cls,~equal])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Means / Covar comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:37:25.132852Z",
     "start_time": "2018-04-17T10:37:24.835030Z"
    },
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mns  = layers_out[6]   # pred_tensor\n",
    "# cov  = np.sqrt(layers_out[7])   # pred_cls_cnt\n",
    "# mns2 = layers_out[12]  # pred_TNESOR_2\n",
    "# cov2 = layers_out[13] # pred_cls_cnt_2\n",
    "\n",
    "# mns  = np.sort(layers_out[8] ,axis=0 )           # gt_tensor\n",
    "# cov  = np.sort(np.sqrt(layers_out[9]),axis=0 )   # gt_cls_cnt\n",
    "# mns2 = np.sort(layers_out[16] ,axis=0 )          # gt_tensor2\n",
    "# cov2 = np.sort(layers_out[17] ,axis=0 )          # gt_cls_cnt_2\n",
    "\n",
    "mns  = layers_out[8]            # gt_tensor\n",
    "cov  = np.sqrt(layers_out[9])   # gt_cls_cnt\n",
    "mns2 = layers_out[16]           # gt_tensor2\n",
    "cov2 = layers_out[17]          # gt_cls_cnt_2\n",
    "\n",
    "\n",
    "print( mns.shape, mns2.shape)\n",
    "# print( pt.shape, pcc.shape)\n",
    "# print(pc2)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal1 = np.all(mns[img,cls] == mns2[img,cls], axis = -1)\n",
    "        equal2 = np.all(cov[img,cls] == cov2[img,cls])\n",
    "        print('Image ',img,' Class ',cls, ' means equal: ',equal1.all(), '  covar equal: ',equal2.all())\n",
    "\n",
    "#         print('mns  :')\n",
    "#         print(mns[img])\n",
    "#         print('mns2 :')\n",
    "#         print(mns2[img])\n",
    "#         print( cov[img])\n",
    "#         print(cov2[img])\n",
    "\n",
    "        if (~equal1.all()):\n",
    "            print('Image ',img,' Class ',cls, 'equal 1: ', equal1,  ' MEANS EQUAL: ',equal1.all())\n",
    "            print('\\n -- numpy      \\n',  mns[img,~equal1])\n",
    "            print('\\n -- tensorflow \\n', mns2[img,~equal1])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "\n",
    "        if (~equal2.all()):\n",
    "            print('Image ',img,' Class ',cls, 'equal 2: ', equal2, ' COVAR EQUAL: ',equal2.all())\n",
    "            print('\\n -- numpy      \\n',  cov[img, ~equal2])\n",
    "            print('\\n -- tensorflow \\n', cov2[img, ~equal2])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T20:29:23.571977Z",
     "start_time": "2018-04-16T20:29:23.326323Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mmm_np =  mns[:,:5]\n",
    "mmm_tf = mns2[:,:5]\n",
    "print(mmm.shape)\n",
    "print(mmm_np)\n",
    "print()\n",
    "print(mmm_tf)\n",
    "# mmm1 = np.sort(mmm,axis = 2) \n",
    "# print()\n",
    "# print(mmm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T21:38:17.419043Z",
     "start_time": "2018-04-16T21:38:17.186442Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "img = 1\n",
    "print( mns[img,:5])\n",
    "print(mns2[img,:5])\n",
    "# print(np.sort(mns2[2,:4],axis=0 ))\n",
    "print(pt.shape)\n",
    "print(pt[img,:,:3])\n",
    "print()\n",
    "print(pt2[img,:,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control pred_cls_cnt / pred_cls_cnt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T18:55:34.172700Z",
     "start_time": "2018-04-16T18:55:33.632299Z"
    },
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# pt  = layers_out[9]   # pred_cls_cnt\n",
    "# pt2 = layers_out[15]  # pred_cls_cnt_2\n",
    "pt  = layers_out[11]   # gt_cls_cnt\n",
    "pt2 = layers_out[19]  # gt_cls_cnt_2\n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    print('  pt2  ', pt2[img])\n",
    "    print('  pt   ', pt[img])\n",
    "    equal = np.all(pt2[img]== pt[img], axis = -1)\n",
    "\n",
    "    if (~equal.all()):\n",
    "        print('Image ',img, ' ALL EQUAL: ',equal.all())\n",
    "        print(equal)\n",
    "        print('\\n -- using numpy \\n',pt[img][~equal])\n",
    "        print('\\n -- using tensorflow \\n',pt2[img][~equal])\n",
    "        print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  pred_gaussian / pred_gaussian2  & gt_gaussian / gt_gaussian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T17:16:55.122333Z",
     "start_time": "2018-04-20T17:16:54.624011Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pt   = layers_out[4]   # pred_gaussian \n",
    "# pt2  = layers_out[10]  # pred_gaussian_2\n",
    "np.set_printoptions(linewidth=130, threshold=20000)\n",
    "gt   = layers_out[7]   # gt_gaussian \n",
    "gt2  = layers_out[13]  # gt_gaussian_2\n",
    "# gt   = np.where(gt > 1e-6,gt,0)\n",
    "# gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "#     print(' from np ')\n",
    "#     print(pt[img])\n",
    "#     print(' from tensorflow')\n",
    "#     print(pt2[img])\n",
    "    for cls in range(4):\n",
    "        equal = np.all(gt2[img, cls] == gt[img, cls], axis=-1)      \n",
    "        print( 'Image ',img,' Class ',cls, '  all equal: ',equal.all())        \n",
    "        \n",
    "        if (~equal.all()):\n",
    "            print(~equal)\n",
    "            print( 'Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#             print('\\n -- using numpy      \\n',  gt[img, cls, ~equal])\n",
    "#             print('\\n -- using tensorflow \\n', gt2[img, cls, ~equal])\n",
    "# if not equal display the different between the mismatching rows\n",
    "            for i in range(equal.shape[0]):\n",
    "                if ~equal[i]:\n",
    "                    diff = np.abs(gt2[img, cls, i] - gt[img, cls, i])\n",
    "                    big_error = np.any(diff > 3.0e-9, axis = -1)\n",
    "                    print('   row = ', i, ' rows equal = ',equal[i], '   Big Error (larger than 7.0e-8): ' ,big_error)\n",
    "                    if big_error:\n",
    "                        print(' difference  :', diff )\n",
    "#                     print(' -- using numpy      \\n',gt[img,cls,i])            \n",
    "#                     print(' -- using tensorflow \\n',gt2[img,cls,i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Pred_Scatter / Gt_Scatter comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:27:27.842035Z",
     "start_time": "2018-04-17T10:27:27.109087Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pt   = layers_out[4]   # pred_gaussian \n",
    "# pt2  = layers_out[10]  # pred_gaussian_2\n",
    "\n",
    "gt   = layers_out[6]   # gt_scatter \n",
    "gt2  = layers_out[14]  # gt_scatter\n",
    "\n",
    "print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "#     print(' from np ')\n",
    "#     print(pt[img])\n",
    "#     print(' from tensorflow')\n",
    "#     print(pt2[img])\n",
    "    for cls in range(4):\n",
    "        for roi in range(32):\n",
    "            equal = np.all(gt2[img, cls, roi] == gt[img, cls,roi], axis = -1)      \n",
    "            print( 'Image ',img,' Class ',cls, ' ROI: ', roi, '  all equal: ',equal.all())        \n",
    "        \n",
    "#             if (~equal.all()):\n",
    "#                 print( 'Image ',img,' Class ',cls, ' ROI: ', roi, ' equal : ', equal, ' ALL EQUAL: ',equal.all())\n",
    "#                 print('\\n -- using numpy      \\n',  gt[img, cls, roi])\n",
    "#                 print('\\n -- using tensorflow \\n', gt2[img, cls, roi])\n",
    "                \n",
    "#                 print()\n",
    "#                 print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#                 print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display first two images from training batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:41:52.059523Z",
     "start_time": "2018-04-20T14:41:51.267415Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "image_id = img_meta[0,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "image_id = img_meta[1,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Plot Predicition Probability Heatmaps `pred_gaussian`\n",
    "\n",
    "`pred_gaussian` and `pred_gaussian2` from Numpy and Tensorflow layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:09:56.542911Z",
     "start_time": "2018-04-21T10:09:54.573673Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mrcnn.visualize import plot_gaussian\n",
    "Zout  = layers_out[4]\n",
    "Zout2 = layers_out[10]\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'NUMPY - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,cls], title = ttl)\n",
    "    ttl = 'TENSORFLOW - image :  {} class: {} '.format(img,cls)    \n",
    "    print(' *** Zout2 ', Zout2[img,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,cls], title = ttl)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Plot Ground Truth Probability Heatmaps `gt_gaussian`\n",
    "`gt_gaussian` and `gt_gaussian2` from Numpy and Tensorflow PCN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:12:04.046721Z",
     "start_time": "2018-04-21T10:12:02.418392Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "Zout  = layers_out[7]     # gt_gaussiam \n",
    "Zout2 = layers_out[13]    # gt_gaussian2\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'NUMPY - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'TENSORFLOW - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display predicted bounding boxes - calculate center and width/height of bboxes displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T13:39:18.410894Z",
     "start_time": "2018-04-16T13:39:18.124129Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import trim_zeros\n",
    "np.set_printoptions( edgeitems=32, suppress=True)\n",
    "pred_bb = layers_out[14]\n",
    "print(pred_bb.shape)\n",
    "x0 = [ trim_zeros((pred_bb[0,i,:,:])) for i in range(4)]\n",
    "ps0 = np.concatenate( x0, axis=0 )\n",
    "# print(ps0)\n",
    "print(ps0.shape)\n",
    "width  = ps0[:,5] - ps0[:,3]\n",
    "height = ps0[:,4] - ps0[:,2]\n",
    "cx     = ps0[:,3] + ( width  / 2.0)\n",
    "cy     = ps0[:,2] + ( height / 2.0)\n",
    "means0  = np.stack((cx,cy,width, height),axis = -1)\n",
    "print(means0)\n",
    "## compute boounding box coordiantes for all classes \n",
    "\n",
    "x1 = [ trim_zeros((pred_bb[1,i,:,:])) for i in range(4)]\n",
    "ps1 = np.concatenate( x1, axis=0 )\n",
    "# print(np.concatenate( x1, axis=0 ))\n",
    "# print(ps1)\n",
    "print(ps1.shape)\n",
    "width  = ps1[:,5] - ps1[:,3]\n",
    "height = ps1[:,4] - ps1[:,2]\n",
    "cx     = ps1[:,3] + ( width  / 2.0)\n",
    "cy     = ps1[:,2] + ( height / 2.0)\n",
    "means1  = np.stack((cx,cy,width, height),axis = -1)\n",
    "print(means1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:57:15.798087Z",
     "start_time": "2018-04-20T14:57:15.214563Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "image_id = img_meta[0,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox)\n",
    "\n",
    "image_id = img_meta[1,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `pred_bboxes`\n",
    "\n",
    "layers_out[10]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:52:38.876895Z",
     "start_time": "2018-04-20T15:52:38.098830Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "    \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[12][img])\n",
    "print(gt_bboxes_stacked)\n",
    "# gt_bboxes_stacked = stack_tensors_3d(layers_out[18][img])\n",
    "# print(gt_bboxes_stacked)\n",
    "\n",
    "# gt_bb = np.vstack((gt_bboxes[0,1,0:1,2:6],gt_bboxes[0,2,0:2,2:6],gt_bboxes[0,3,0:2,2:6]))\n",
    "# gt_bb.shape\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,2:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_bboxes` from PCN_layer \n",
    "\n",
    "layers_out[10]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:54:29.103672Z",
     "start_time": "2018-04-20T15:54:28.682560Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "    \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[18][img])\n",
    "print(gt_bboxes_stacked)\n",
    "\n",
    "# gt_bb = np.vstack((gt_bboxes[0,1,0:1,2:6],gt_bboxes[0,2,0:2,2:6],gt_bboxes[0,3,0:2,2:6]))\n",
    "# gt_bb.shape\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,2:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:57:11.173145Z",
     "start_time": "2018-04-20T15:57:10.930483Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=120, precision=5)\n",
    "print(' gt_cls_cnt from Numpy - shape: ', layers_out[5].shape)\n",
    "print(layers_out[5])\n",
    "\n",
    "\n",
    "print(' gt_cls_cnt from TF - shape: ', layers_out[13].shape)\n",
    "print(layers_out[13])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:03:57.839704Z",
     "start_time": "2018-04-20T16:03:57.442649Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3 # <==== Class to display\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "\n",
    "pred_tensor = layers_out[4]\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for all classes in image\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:08:04.719657Z",
     "start_time": "2018-04-20T16:08:04.051881Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "# cls = 1  # <==== Class to dispaly\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "\n",
    "pred_tensor = layers_out[4][img]\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "pred_bboxes_stacked = stack_tensors_3d(pred_tensor)\n",
    "# lst2   = [np.squeeze(item) for item in np.split(pred_tensor, pred_tensor.shape[0], axis = 0 )]\n",
    "# results = np.concatenate( [ i[~np.all(i[:,2:6] == 0, axis=1)] for i in lst2] , axis = 0)\n",
    "caps = [str(int(x[6]))+'-'+str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_bboxes_stacked.tolist() ]\n",
    "print(caps)\n",
    "\n",
    "# print(pc_tensor.pred_tensor[1,3,:])\n",
    "# print(pc_tensor.pred_tensor[1,3,:,2:6])\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[:,2:6], captions = caps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "# caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "# print(caps)\n",
    "\n",
    "# visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "For each class:\n",
    "- determine the center of each bounding box.\n",
    "- center a 2d gaussian distribution with the mean = center of bounding box and sigma = height/width\n",
    "- place dist on mesh grid\n",
    "- normalize\n",
    "- draw heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T22:48:21.160813Z",
     "start_time": "2018-04-14T22:48:04.860Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# del history\n",
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "#model.keras_model.summary(line_length = 120)\n",
    "# print(model.find_last())\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "if init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs_to_run =2, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs_to_run = 2,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.datagen import data_generator, load_image_gt\n",
    "np.set_printoptions(linewidth=100)\n",
    "learning_rate=model.config.LEARNING_RATE\n",
    "epochs_to_run = 2\n",
    "layers='heads'\n",
    "batch_size = 0\n",
    "steps_per_epoch = 0\n",
    "# assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "# Pre-defined layer regular expressions\n",
    "layer_regex = {\n",
    "    # all layers but the backbone\n",
    "    \"heads\": r\"(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    # From a specific Resnet stage and up\n",
    "    \"3+\": r\"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"4+\": r\"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    # All layers\n",
    "    \"all\": \".*\",\n",
    "}\n",
    "\n",
    "if layers in layer_regex.keys():\n",
    "    layers = layer_regex[layers]\n",
    "if batch_size == 0 :\n",
    "    batch_size = model.config.BATCH_SIZE            \n",
    "if steps_per_epoch == 0:\n",
    "    steps_per_epoch = model.config.STEPS_PER_EPOCH\n",
    "\n",
    "# Data generators\n",
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "val_generator   = data_generator(dataset_val, model.config, shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 augment=False)\n",
    "\n",
    "# Train\n",
    "log(\"Last epoch completed : {} \".format(model.epoch))\n",
    "log(\"Starting from epoch {} for {} epochs. LR={}\".format(model.epoch, epochs_to_run, learning_rate))\n",
    "log(\"Steps per epoch:    {} \".format(steps_per_epoch))\n",
    "log(\"Batchsize      :    {} \".format(batch_size))\n",
    "log(\"Checkpoint Folder:  {} \".format(model.checkpoint_path))\n",
    "epochs = model.epoch + epochs_to_run\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "if not gfile.IsDirectory(model.log_dir):\n",
    "    log('Creating checkpoint folder')\n",
    "    gfile.MakeDirs(model.log_dir)\n",
    "else:\n",
    "    log('Checkpoint folder already exists')\n",
    "\n",
    "model.set_trainable(layers)            \n",
    "model.compile(learning_rate, model.config.LEARNING_MOMENTUM)        \n",
    "\n",
    "out_labels = model.keras_model._get_deduped_metrics_names()\n",
    "callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "\n",
    "progbar = keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "progbar.set_model(model.keras_model)\n",
    "progbar.set_params({\n",
    "    'epochs': epochs,\n",
    "    'steps': steps_per_epoch,\n",
    "    'verbose': 1,\n",
    "    'do_validation': False,\n",
    "    'metrics': callback_metrics,\n",
    "})\n",
    "\n",
    "progbar.set_model(model.keras_model) \n",
    "\n",
    "chkpoint = keras.callbacks.ModelCheckpoint(model.checkpoint_path, \n",
    "                                           monitor='loss', verbose=1, save_best_only = True, save_weights_only=True)\n",
    "chkpoint.set_model(model.keras_model)\n",
    "\n",
    "progbar.on_train_begin()\n",
    "epoch_idx = model.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T14:03:38.566464Z",
     "start_time": "2018-04-13T14:03:38.322749Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if epoch_idx >= epochs:\n",
    "    print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "\n",
    "# while epoch_idx < epochs :\n",
    "progbar.on_epoch_begin(epoch_idx)\n",
    "steps_index = 0\n",
    "# for steps_index in range(steps_per_epoch):\n",
    "\n",
    "batch_logs = {}\n",
    "print(' self.epoch {}   epochs {}  step {} '.format(model.epoch, epochs, steps_index))\n",
    "batch_logs['batch'] = steps_index\n",
    "batch_logs['size']  = batch_size\n",
    "progbar.on_batch_begin(steps_index, batch_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "imgmeta_idx= model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta  =  train_batch_x[imgmeta_idx]\n",
    "\n",
    "image_id = img_meta[0,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "image_id = img_meta[1,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "outs = model.keras_model.train_on_batch(train_batch_x, train_batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Stacking routine -- break down by images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T15:52:06.157379Z",
     "start_time": "2018-04-16T15:52:05.913730Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## stack an [Batch x Class x Row x Col] tensor into Row x Cols\n",
    "##------------------------------------------------------------------\n",
    "pred_tensor = layers_out[8]\n",
    "lst2 = [ np.squeeze(item) for item in np.split(pred_tensor, pred_tensor.shape[0], axis = 0 )]\n",
    "lst2 = [ np.squeeze(np.concatenate(np\n",
    "                                   .split(item, item.shape[0], axis = 0 ), axis = 1)) for item in lst2]\n",
    "result = [ item[~np.all(item[:,2:6] == 0, axis=1)] for item in lst2]\n",
    "print(len(result))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Stack tensor routine for one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T15:52:11.571785Z",
     "start_time": "2018-04-16T15:52:11.337160Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## stack an  [Class x Row x Col] tensor into Row x Cols\n",
    "##------------------------------------------------------------------\n",
    "pred_tensor = layers_out[8][0]\n",
    "lst2   = [np.squeeze(item) for item in np.split(pred_tensor, pred_tensor.shape[0], axis = 0 )]\n",
    "result = np.concatenate( [ i[~np.all(i[:,2:6] == 0, axis=1)] for i in lst2] , axis = 0)\n",
    "print(result.shape)\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [TF_gpu]",
   "language": "python",
   "name": "Python [TF_gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
